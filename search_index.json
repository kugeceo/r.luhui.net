[["index.html", "R语言教程 前言", " R语言教程 李东风 2020-12-28 前言 这是李东风的《R语言教程》的草稿， 还在更新中。 错漏之处难免，欢迎指出错误或提出改进意见。 相关下载： Rbook-data.zip：一些配套数据的打包文件 bookdown-template-v0-5.zip：R Markdown和bookdown的模板 书中的数学公式使用MathJax库显示， 下面是数学公式测试。 如果数学公式显示的中文不正常， 在浏览器中用鼠标右键单击中文公式， 在弹出的菜单中选择Math Settings--Math Renderer选HTML-CSS或SVG即可。 公式测试： \\[ f(x) = \\sum_{k=0}^\\infty \\frac{x^k}{k!} \\] 中文公式测试： \\[ \\text{相对误差} = \\frac{a - A}{A} \\] 使用本教程必须安装的软件包： tidyverse bookdown xtable microbenchmark 本教程中用到的软件包列表（更新R软件后可以在一个基本R中运行如下命令）： pkgs &lt;- c( &quot;assertthat&quot;, &quot;backports&quot;, &quot;base64enc&quot;, &quot;BH&quot;, &quot;bindr&quot;, &quot;bindrcpp&quot;, &quot;bookdown&quot;, &quot;broom&quot;, &quot;callr&quot;, &quot;car&quot;, &quot;cellranger&quot;, &quot;cli&quot;, &quot;clipr&quot;, &quot;clorspace&quot;, &quot;cowplot&quot;, &quot;crayon&quot;, &quot;curl&quot;, &quot;DBI&quot;, &quot;dbplyr&quot;, &quot;dichromat&quot;, &quot;digest&quot;, &quot;dplyr&quot;, &quot;evaluate&quot;, &quot;forcats&quot;, &quot;ggplot2&quot;, &quot;ggrepel&quot;, &quot;glue&quot;, &quot;gtable&quot;, &quot;haven&quot;, &quot;highr&quot;, &quot;hms&quot;, &quot;htmltools&quot;, &quot;httr&quot;, &quot;jsonlite&quot;, &quot;knitr&quot;, &quot;labeling&quot;, &quot;lazyeval&quot;, &quot;lubridate&quot;, &quot;magrittr&quot;, &quot;markdown&quot;, &quot;microbenchmark&quot;, &quot;mime&quot;, &quot;mnormt&quot;, &quot;modelr&quot;, &quot;munsell&quot;, &quot;NHANES&quot;, &quot;openssl&quot;, &quot;pillar&quot;, &quot;pkgconfig&quot;, &quot;plogr&quot;, &quot;plyr&quot;, &quot;psych&quot;, &quot;purr&quot;, &quot;R6&quot;, &quot;RColorBrewer&quot;, &quot;Rcpp&quot;, &quot;readr&quot;, &quot;readxl&quot;, &quot;rematch&quot;, &quot;reprex&quot;, &quot;reshape2&quot;, &quot;rlang&quot;, &quot;rmarkdown&quot;, &quot;rprojroot&quot;, &quot;rstudioapi&quot;, &quot;rvest&quot;, &quot;scales&quot;, &quot;selectr&quot;, &quot;socviz&quot;, &quot;stringi&quot;, &quot;stringr&quot;, &quot;tibble&quot;, &quot;tidyr&quot;, &quot;tidyselect&quot;, &quot;tidyverse&quot;, &quot;utf8&quot;, &quot;viridisLite&quot;, &quot;whisker&quot;, &quot;xml2&quot;, &quot;xtable&quot;, &quot;yaml&quot; ) install.packages(unique(pkgs)) 编译本教程所用的R软件环境： devtools::session_info() ## - Session info --------------------------------------------------------------- ## setting value ## version R version 4.0.2 (2020-06-22) ## os Windows 10 x64 ## system x86_64, mingw32 ## ui RTerm ## language (EN) ## collate Chinese (Simplified)_China.936 ## ctype Chinese (Simplified)_China.936 ## tz Asia/Taipei ## date 2020-12-28 ## ## - Packages ------------------------------------------------------------------- ## package * version date lib source ## assertthat 0.2.1 2019-03-21 [1] CRAN (R 4.0.2) ## bookdown 0.21 2020-10-13 [1] CRAN (R 4.0.3) ## callr 3.5.1 2020-10-13 [1] CRAN (R 4.0.3) ## cli 2.2.0 2020-11-20 [1] CRAN (R 4.0.3) ## crayon 1.3.4 2017-09-16 [1] CRAN (R 4.0.2) ## desc 1.2.0 2018-05-01 [1] CRAN (R 4.0.2) ## devtools 2.3.2 2020-09-18 [1] CRAN (R 4.0.3) ## digest 0.6.27 2020-10-24 [1] CRAN (R 4.0.3) ## ellipsis 0.3.1 2020-05-15 [1] CRAN (R 4.0.2) ## evaluate 0.14 2019-05-28 [1] CRAN (R 4.0.2) ## fansi 0.4.1 2020-01-08 [1] CRAN (R 4.0.2) ## fs 1.5.0 2020-07-31 [1] CRAN (R 4.0.2) ## glue 1.4.2 2020-08-27 [1] CRAN (R 4.0.3) ## htmltools 0.5.0 2020-06-16 [1] CRAN (R 4.0.2) ## knitr 1.30 2020-09-22 [1] CRAN (R 4.0.2) ## lifecycle 0.2.0 2020-03-06 [1] CRAN (R 4.0.2) ## magrittr 2.0.1 2020-11-17 [1] CRAN (R 4.0.3) ## memoise 1.1.0 2017-04-21 [1] CRAN (R 4.0.2) ## pkgbuild 1.2.0 2020-12-15 [1] CRAN (R 4.0.3) ## pkgload 1.1.0 2020-05-29 [1] CRAN (R 4.0.2) ## prettyunits 1.1.1 2020-01-24 [1] CRAN (R 4.0.2) ## processx 3.4.5 2020-11-30 [1] CRAN (R 4.0.3) ## ps 1.5.0 2020-12-05 [1] CRAN (R 4.0.3) ## purrr 0.3.4 2020-04-17 [1] CRAN (R 4.0.2) ## R6 2.5.0 2020-10-28 [1] CRAN (R 4.0.3) ## remotes 2.2.0 2020-07-21 [1] CRAN (R 4.0.2) ## rlang 0.4.9 2020-11-26 [1] CRAN (R 4.0.3) ## rmarkdown 2.6 2020-12-14 [1] CRAN (R 4.0.3) ## rprojroot 2.0.2 2020-11-15 [1] CRAN (R 4.0.3) ## sessioninfo 1.1.1 2018-11-05 [1] CRAN (R 4.0.2) ## stringi 1.5.3 2020-09-09 [1] CRAN (R 4.0.2) ## stringr 1.4.0 2019-02-10 [1] CRAN (R 4.0.2) ## testthat 3.0.1 2020-12-17 [1] CRAN (R 4.0.3) ## usethis 2.0.0 2020-12-10 [1] CRAN (R 4.0.3) ## withr 2.3.0 2020-09-22 [1] CRAN (R 4.0.3) ## xfun 0.19 2020-10-30 [1] CRAN (R 4.0.3) ## yaml 2.2.1 2020-02-01 [1] CRAN (R 4.0.2) ## ## [1] D:/R/R-4.0.2/library "],["intro.html", "1 R语言介绍 1.1 R的历史和特点 1.2 R的下载与安装 1.3 R扩展软件包的安装与管理 1.4 基本R软件的用法 1.5 RStudio软件 1.6 练习", " 1 R语言介绍 1.1 R的历史和特点 1.1.1 R的历史 R语言来自S语言，是S语言的一个变种。S语言由Rick Becker, John Chambers等人在贝尔实验室开发， 著名的C语言、Unix系统也是贝尔实验室开发的。 S语言第一个版本开发于1976-1980，基于Fortran； 于1980年移植到Unix, 并对外发布源代码。 1984年出版的“棕皮书” (Becker and Chambers 1984) 总结了1984年为止的版本, 并开始发布授权的源代码。 这个版本叫做旧S。与我们现在用的S语言有较大差别。 1989–1988对S进行了较大更新， 变成了我们现在使用的S语言，称为第二版。 1988年出版的“蓝皮书” (Becker, Chambers, and Wilks 1988) 做了总结。 1992年出版的“白皮书” (Chambers and Hastie 1992) 描述了在S语言中实现的统计建模功能， 增强了面向对象的特性。软件称为第三版，这是我们现在用的多数版本。 1998年出版的“绿皮书” (Chambers 2008) 描述了第四版S语言，主要是编程功能的深层次改进。 现行的S系统并没有都采用第四版，S-PLUS的第5版才采用了S语言第四版。 S语言商业版本为S-PLUS, 1988年发布，现在为Tibco Software拥有。 命运多舛，多次易主。 R是一个自由软件，GPL授权， 最初由新西兰Auckland 大学的Ross Ihaka 和 Robert Gentleman于1997年发布， R实现了与S语言基本相同的功能和统计功能。 现在由R核心团队开发，但全世界的用户都可以贡献软件包。 R的网站: http://www.r-project.org/ 1.1.2 R的特点 1.1.2.1 R语言一般特点 自由软件，免费、开放源代码，支持各个主要计算机系统； 完整的程序设计语言，基于函数和对象，可以自定义函数，调入C、C++、Fortran编译的代码； 具有完善的数据类型，如向量、矩阵、因子、数据集、一般对象等，支持缺失值，代码像伪代码一样简洁、可读; 强调交互式数据分析，支持复杂算法描述，图形功能强; 实现了经典的、现代的统计方法，如参数和非参数假设检验、线性回归、广义线性回归、非线性回归、可加模型、树回归、混合模型、方差分析、判别、聚类、时间序列分析等。 统计科研工作者广泛使用R进行计算和发表算法。R有上万软件包(截止2019年7月有一万四千多个)。 1.1.2.2 R语言和R软件的技术特点 函数编程（functional programming）。R语言虽然不是严格的functional programming语言，但可以遵照其原则编程，得到可验证的可靠程序。 支持对象类和类方法。基于对象的程序设计。 是动态类型语言，解释执行，运行速度较慢。 数据框是基本的观测数据类型，类似于数据库的表。 开源软件（Open source software）。可深入探查，开发者和用户交互。 可以用作C和C++、FORTRAN语言编写的算法库的接口。 主要数值算法采用已广泛测试和采纳的算法实现，如排序、随机数生成、线性代数（LAPACK软件包）。 1.1.2.3 推荐参考书 Hadley Wickham and Garrett Grolemund(2017) “R for Data Science”，https://r4ds.had.co.nz/, O’Reilly, 讲基本的数据整理、汇总。 Hadley Wickham(2019) “Advanced R”, 2nd ed., https://adv-r.hadley.nz/, Chapman &amp; Hall/CRC The R Series，高级R编程，属于对R高级编程技术的讲解。 Hadley Wickham(2016) ggplot2 Elegant Graphics for Data Analysis, 2nd ed., https://ggplot2-book.org/, Springer，优雅易用的R作图功能。 Susan Holmes, Wolfgang Huber(2020) Modern Statistics for Modern Biology, https://www.huber.embl.de/msmb/index.html, R的统计功能在生物学中的应用 1.1.2.4 其它参考书 R网站上的初学者手册“An Introduction to R”和其它技术手册。 John M. Chambers(2008), “Software for Data Analysis-Programming with R”, Springer. Venables, W. N. &amp; Ripley, B. D.(2002) “Modern Applied Statistics with S”, Springer R.L. Kabacoff(2012)《R语言实战》，人民邮电出版社。 薛毅、陈立萍（2007）《统计建模与R软件》，清华大学出版社。 汤银才（2008），《R语言与统计分析》，高等教育出版社。 李东风（2006）《统计软件教程》，人民邮电出版社。 1.2 R的下载与安装 1.2.1 R的下载 以MS Windows操作系统为例。R的主网站在https://www.r-project.org/。 从CRAN的镜像网站下载软件，其中一个镜像如http://mirror.bjtu.edu.cn/cran/。 选“Download R for Windows-base-Download R 3.4.1 for windows” (3.4.1是版本号，应下载网站上给出的最新版本）链接进行下载。 在“Download R for Windows”链接的页面， 除了base为R的安装程序， 还有contrib为R附加的扩展软件包下载链接（一般不需要从这里下载）， 以及Rtools链接， 是在R中调用C、C++和Fortran程序代码时需要用的编译工具。 RStudio（https://www.rstudio.com/）是功能更强的一个R图形界面， 在安装好R的官方版本后安装RStudio可以更方便地使用R。 1.2.2 R软件安装 下载官方的R软件后按提示安装。 安装后获得一个桌面快捷方式，如“R i386 3.4.1”(这是32位版本)。 如果是64位操作系统，可以同时安装32位版本和64位版本， 对初学者这两种版本区别不大， 尽量选用64位版本，这是将来的趋势。 安装官方的R软件后， 可以安装RStudio。 平时使用可以使用RStudio， 其界面更方便， 对R Markdown格式(.Rmd)文件支持更好。 如果使用RStudio， 每个分析项目需要单独建立一个“项目”（project）， 每个项目也有一个工作文件夹。 1.2.3 辅助软件 R可以把一段程序写在一个以.r或.R为扩展名的文本文件中， 如“date.r”, 称为一个_源程序_文件， 然后在R命令行用 source(&quot;date.r&quot;) 运行源程序。 这样的文件可以用记事本生成和编辑。 在MS Windows操作系统中建议使用notepad++软件， 这是MS Windows下记事本程序的增强型软件。 安装后，在MS Windows资源管理器中右键弹出菜单会有“edit with notepadpp”选项。 notepad++可以方便地在不同的中文编码之间转换。 RStudio则是一个集成环境， 可以在RStudio内进行源程序文件编辑和运行。 1.3 R扩展软件包的安装与管理 1.3.1 安装 R有一万多个扩展软件包，提供了各种各样的功能。 以安装sos包为例。sos包用来搜索某些函数的帮助文档。 在RStudio中用“Tools”菜单的“Install Packages”安装， 输入sos就可以安装该扩展包。 如果不用RStudio， 在R图形界面选菜单“程序包-安装程序包”， 在弹出的“CRAN mirror”选择窗口中选择一个中国的镜像如“China (Beijing 2)”， 然后在弹出的“Packages”选择窗口中选择要安装的扩展软件包名称， 即可完成下载和安装。 还可以用如下程序制定镜像网站(例子中是位于清华大学的镜像网站)并安装指定的扩展包： options(repos=c(CRAN=&quot;http://mirror.tuna.tsinghua.edu.cn/CRAN/&quot;)) install.packages(&quot;sos&quot;) 还可以选择扩展包的安装路径， 如果权限允许， 可以选择安装在R软件的主目录内或者用户自己的私有目录位置。 由于用户的对子目录的读写权限问题， 有时不允许一般用户安装扩展包到R的主目录中。 用.libPaths()查看允许的扩展包安装位置， 在install.packages()中用lib=指定安装位置： print(.libPaths()) ## [1] &quot;D:/R/R-3.3.1/library&quot; install.packages(&quot;sos&quot;, lib=.libPaths()[1]) 1.3.2 Github和BioConductor的扩展包 还有一些扩展包没有在CRAN系统提供， 而是放在了Github网站。 对于这样的包， 安装方法举例如下： if(!require(devtools)) install.packages(&#39;devtools&#39;) devtools::install_github(&quot;kjhealy/socviz&quot;) 其中kjhealy是Github网站的某个作者的名称， socviz是该作者名下的一个R扩展包。 还有一些包需要从Bioconductor网站安装。 示例如下： if (!requireNamespace(&quot;BiocManager&quot;, quietly = TRUE)) install.packages(&quot;BiocManager&quot;) BiocManager::install(c(&quot;Biostrings&quot;)) 1.3.3 更新扩展包 在RStudio中用“Tools–Check for Package Updates”菜单， 可以显示有新版本的扩展包， 并选择进行更新。 或者在命令行用如下命令更新本地安装的所有有新版本的CRAN扩展包： options(repos=c(CRAN=&quot;http://mirror.tuna.tsinghua.edu.cn/CRAN/&quot;)) update.packages(checkBuilt=TRUE, ask=FALSE) RStudio在运行时会载入某些包， 如rlang， 这使得RStudio无法更新这些包， 需要在R的命令行程序中更新。 1.3.4 迁移扩展包 在每一次R软件更新后， 需要重新安装原来的软件包， 这个过程很麻烦。 如果仅仅是小的版本更新， 比如从3.5.1变成3.5.2， 或者从3.4.2变成3.5.0， 可以在安装新版本后， 临时将新版本的library子目录更名为library0， 将老版本的library子目录剪切为新版本的library子目录， 然后将library0中所有内容复制并覆盖进入library子目录， 删除library0即可。 然后在基本R中（不要用RStudio）运行如下命令以更新有新版本的包： options(repos=c(CRAN=&quot;http://mirror.tuna.tsinghua.edu.cn/CRAN/&quot;)) update.packages(checkBuilt=TRUE, ask=FALSE) 如果版本改变比较大， 可以用如下方法批量地重新安装原有的软件包。 首先，在更新R软件前，在原来的R中运行： packages &lt;- .packages(TRUE) dump(&quot;packages&quot;, file=&quot;packages-20180704.R&quot;) 这样可以获得要安装的软件包的列表。 在更新R软件后， 运行如下程序： options(repos=c(CRAN=&quot;http://mirror.tuna.tsinghua.edu.cn/CRAN/&quot;)) source(&quot;packages-20180704.R&quot;) install.packages(packages) 安装时如果提问是否安装需要编译的源代码包， 最好选择否， 因为安装源代码包速度很慢还有可能失败。 1.3.5 项目私有扩展包目录 在使用了R一段较长时间以后， 会安装了许多扩展包， 这些扩展包在某个时期是有用的， 但是一旦某个任务完成了就不再有用。 但是， 用户自己无法判断哪些包已经不需要。 R的renv扩展包支持每个项目保存私有的扩展包目录， 这样， 不同的项目使用不同的扩展包集合， 不至于引发版本冲突， 也不必总是为公用的R扩展包目录增加许多仅是短暂使用的扩展包。 那些不需要安装许多扩展包的项目仍可以不启用renv， 使用公用的R扩展包目录。 在生成新的RStudio项目时， 可以点击选中“Use renv with this project”复选框； 对已有的RStdio项目， 如果要启用renv， 可以选菜单“Tools – Project Options – Environment”， 选中“Use renv with this project”复选框。 启用了renv的项目， 在安装新的扩展包时， 将安装在项目目录中， 而不再修改R的公用的扩展包目录。 这也有助于将项目迁移到其它计算机上。 1.4 基本R软件的用法 1.4.1 基本运行 在MS Windows操作系统中的R软件有一个R GUI软件， 即图形窗口模式的R软件，如图1.1。 图1.1: RGUI截图 R GUI中有一个命令行窗口(R Console)， 以大于号为提示符， 在提示符后面键入命令， 命令的文字型结果马上显示在命令下方， 命令的图形结果单独显示在一个图形窗口中。 在命令行可以通过左右光标键移动光标到适当位置进行修改。 可以用上下光标在已经运行过的历史命令中切换， 调回已经运行过的命令， 修改后重新执行。 如果某个文件如myprog.R在当前工作目录中， 保存的都是R程序， 称这样的文件为源程序文件。 可以在命令行用如下命令运行其中的程序： source(&quot;myprog.R&quot;) 但是， 在MS Windows操作系统中， 默认的中文编码是GB18030编码。 R源程序文件的中文编码可能是GB18030也可能是UTF-8。 UTF-8是在世界范围更通用的编码。 如果发现用如下命令运行时出现中文乱码， 可能是因为源程序用了UTF-8编码， 这时source()命令要加上编码选项如下： source(&quot;myprog.R&quot;, encoding=&quot;UTF-8&quot;) 1.4.2 项目目录 用R进行数据分析， 不同的分析问题需要放在不同的文件夹中。 以MS Windows操作系统为例， 设某个分析问题的数据与程序放在了c:\\work 文件夹中。 把R的快捷方式从桌面复制入此文件夹， 在Windows资源管理器中， 右键单击此快捷方式，在弹出菜单中选“属性”， 把“快捷方式”页面的“起始位置”的内容清除为空白，点击确定按钮。 启动在work文件夹中的R快捷方式，出现命令行界面。 这时，C:\\work称为当前工作目录。 在命令行运行如下命令可以显示当前工作目录位置： getwd() ## &quot;C:/work&quot; 显示结果中的目录、子目录、文件之间的分隔符用了/符号， 在Windows操作系统中一般应该使用\\\\符号， 但是， 在R的字符串中一个\\需要写成两个， 所以等价的写法是\"C:\\\\work\"。 不同的分析项目需要存放在不同的文件夹中， 每个文件夹都放置一个“起始位置”为空的R快捷方式图标， 分析哪一个项目， 就从对应的快捷图标启动，而不是从桌面上的R图标启动。 这样做的好处时， 用到源文件和数据文件时， 只要文件在该项目的文件夹中， 就不需要写完全路径而只需要用文件名即可。 1.5 RStudio软件 1.5.1 介绍 RStudio软件是R软件的应用界面与增强系统， 可以在其中编辑、运行R的程序文件， 可以跟踪运行， 还可以构造文字、R结果图表融合在一起的研究报告、论文、图书、网站等。 一个运行中的RStudio界面见图1.2。 图1.2: RStudio截图 界面一般分为四个窗格， 其中编辑窗口与控制台（Console）是最重要的两个窗格。 编辑窗格用来查看和编辑程序、文本型的数据文件、程序与文字融合在一起的Rmd文件等。 控制台与基本R软件的命令行窗口基本相同， 功能有所增强。 在编辑窗口中可以用操作系统中常用的编辑方法对源文件进行编辑， 如复制、粘贴、查找、替换， 还支持基于正则表达式的查找替换（关于正则表达式见36）。 其它的一些重要窗格包括： Files: 列出当前项目的目录（文件夹）内容。 其中以.R或者.r为扩展名的是R源程序文件， 单击某一源程序文件就可以在编辑窗格中打开该文件。 Plots: 如果程序中有绘图结果， 将会显示在这个窗格。 因为绘图需要足够的空间， 所以当屏幕分辨率过低或者Plots窗格太小的时候， 可以点击“Zoom”图标将图形显示在一个单独的窗口中， 或者将图形窗口作为唯一窗格显示。 如何放大窗格见下面的使用技巧。 Help: R软件的文档与RStudio的文档都在这里。 Environment: 已经有定义的变量、函数都显示在这里。 History: 以前运行过的命令都显示在这里。 不限于本次RStdudio运行期间， 也包括以前使用RStudio时运行过的命令。 Packages: 显示已安装的R扩展包及其文档。 Viewer, Connection, Build, Git等窗格。 1.5.2 项目 用R和RStudio进行研究和数据分析， 每个研究问题应该单独建立一个文件夹（目录）。 该问题的所有数据、程序都放在对应的文件夹中。 在RStudio中， 用“File – New Project – Existing Directory”选中该问题的目录， 建立一个新的“项目”（project）。 再次进入RStudio后， 用菜单“File – Recent Projects”找到已有的项目打开， 然后就可以针对该项目进行分析了。 这样分项目进行研究的好处是， 不同项目的可以使用同名的文件而不会有冲突， 程序中用到某个文件时， 只需要写文件名而不需要写文件所在的目录。 一个项目还可以有项目本身的一些特殊设置， 用“Tools – Project Options”菜单打开设置。 1.5.3 帮助 在RStudio中有一个单独的Help窗格， 如果需要，可以用菜单“View–Panes–Zoom help”将其放大到占据整个窗口空间。 但是，这一功能目前不支持放大显示字体的功能， 不如在浏览器中方便。 RStudio的帮助窗格中包含R软件的官方文档， 以及RStudio软件的的文档。 “Search engine and keywords”项下面有分类的帮助。 有软件包列表。 在基本R软件而不是RStudio的命令行中运行命令help.start()或者用RGUI的帮助菜单中“html帮助”可以打开系统默认的互联网浏览器， 在其中查看帮助文档。 在命令行，用问号后面跟随函数名查询某函数的帮助。 用example(函数名)的格式可以运行此函数的样例，如: example(mean) ## ## mean&gt; x &lt;- c(0:10, 50) ## ## mean&gt; xm &lt;- mean(x) ## ## mean&gt; c(xm, mean(x, trim = 0.10)) ## [1] 8.75 5.50 有时仅知道一些方法的名字而不知道具体的扩展包和函数名称， 可以安装sos扩展包（package）， 用findFn(\"函数名\")查询某个函数， 结果显示在互联网浏览器软件中。 1.5.4 使用技巧 RStudio使用方法概要PDF下载： rstudio-ide.pdf。 1.5.4.1 使用历史 在控制台（命令行窗格）中， 除了可以用左右光标键移动光标位置， 用上下光标键调回以前运行过的命令， 还有一个重要的增强（以MS Windows操作系统为例）： 键入要运行的命令的前几个字母，如book， 按“Ctrl+向上光标键”， 就可以显示历史命令中以book开头的所有命令， 单击哪一个， 哪一个就自动复制到命令行。 这一技巧十分重要， 我们需要反复允许同一命令时， 这一方法让我们很容易从许多命令历史中找到所需的命令。 1.5.4.2 放大显示某一窗格 当屏幕分辨率较低时， 将整个RStudio界面分为四个窗格会使得每个窗格都没有足够的显示精度。 为此， 可以将某个窗格放大到整个窗口区域， 需要使用其它窗格时再恢复到四个窗格的状态或者直接放大其它窗格到整个窗口区域。 使用菜单“View – Panes – Zoom Source”可以将编辑窗格放到最大， 在MS Windows下也可以使用快捷键“Ctrl+Alt+1”。 其它操作系统也有类似的快捷键可用。 使用菜单“View – Panes – Show All Panes”可以显示所有四个窗格。 放大其它窗格也可以用“Ctrl + Alt + 数字”，数字与窗格的对应关系为： 1: 编辑窗格； 2: 控制台（Console）； 3: 帮助； 4: 历史； 5: 文件； 6: 图形； 7: 扩展包； 8: 已定义变量和函数； 9: 研究报告或网站结果显示。 1.5.4.3 运行程序 可以在命令行直接输入命令运行， 文字结果会显示在命令行窗口， 图形结果显示在“Plots”窗格中。 在命令行窗口（Console）中可以用左右光标键移动光标， 用上下光标键查找历史命令， 输入命令的前几个字母后用“Ctrl+向上光标键”可以匹配地查找历史命令。 一般情况下， 还是应该将R源程序保存在一个源程序文件中运行。 RStudio中“File – New File – R Script”可以打开一个新的无名的R源程序文件窗口供输入R源程序用。 输入一些程序后，保存文件， 然后点击“Source”快捷图标就可以运行整个文件中的所有源程序， 并会自动加上关于编码的选项。 编写R程序的正常做法是一边写一遍试验运行， 运行一般不是整体的运行而是写完一部分就运行一部分， 运行没有错误才继续编写下一部分。 在R源程序窗口中， 当光标在某一程序上的时候， 点击窗口的“Run”快捷图标或者用快捷键“Ctrl+Enter键”可以运行该行； 选中若干程序行后， 点击窗口的“Run”快捷图标或者用快捷键“Ctrl+Enter键”可以运行这些行。 1.5.4.4 中文编码问题 对于中文内容的R源程序、R Markdown源文件（.Rmd文件）、文本型数据文件(.txt，.csv)， 其中的中文内容可能有不同的编码选择， 在中国国内主要使用GB18030(基本兼容于GB, GBK)和UTF-8， UTF-8是国际上更普遍使用的统一文字编码， 涉及到计算机编程时应尽可能使用此编码系统。 在RStudio中新生成的R源程序、Rmd源文件一般自动用UTF-8编码。 点击RStudio的文件窗格中显示的源文件， 可以打开该源文件， 但是因为已有源文件的编码不一定与RStudio的默认编码一致， 可以会显示成乱码。 为此， RStdio提供了“File – Reopen with Encoding”命令， 我们主要试验其中GB18030和UTF-8两种选择一般就可以解决问题。 如果选择GB18030显示就没有乱码了， 最好再用菜单“File – Save with Encoding”并选择UTF-8将其保存为UTF-8编码。 其它的文本格式的文件也可以类似地处理， 后面将会陆续提及。 1.5.5 Rmd文件 在科学研究中， R软件可以用来分析数据， 生成数据分析报表和图形。 R Markdown(简称Rmd)是一种特殊的文件格式， 在这种文件中， 即有R程序， 又有说明文字， 通过R和RStudio软件， 可以运行其中的程序， 并将说明文字、程序、程序的文字结果、图形结果统一地转换为一个研究报告， 支持Word、PDF、网页、网站、幻灯片等许多种输出格式。 在打开的Rmd源文件中， 也可以选择其中的某一段R程序单独运行。 所以， Rmd文件也可以作为一种特殊的R源程序文件。 用RStudio的“File – New File – R Markdown”菜单就可以生成一个新的Rmd文件并显示在编辑窗格中， 其中已经有了一些样例内容， 可以修改这些样例内容为自己的文字和程序。 Rmd文件中用```{r}开头，用```结尾的段落是R程序段， 在显示的程序段的右侧有一个向右箭头形状的小图标（类似于媒体播放图标）， 点击该图标就可以运行该程序段。 打开Rmd文件后， 用编辑窗口的Knit命令可以选择将文件整个地转换为HTML(网页)或者MS Word格式， 如果操作系统中安装有LaTeX软件， 还可以以LaTeX为中间格式转换为PDF文件。 为了将网页转换为PDF文件， 建议使用Chrome浏览器打开HTML文件， 然后选择菜单“打印”， 选打印机为“另存为PDF”， 然后选“更多设置”， 将其中的“缩放”改为自定义， 比例改为“90%”。 详见20、21、22。 1.6 练习 下载R安装程序，安装R，建立work文件夹并在其中建立R的快捷方式。 Windows用户还需要下载RTools软件并安装。 下载RStudio软件并安装。 在work文件夹中建立一个新的项目。 下载安装notepad++软件(仅MS Windows用户)。 在RStudio中下载安装sos扩展软件包。 References "],["intro-example.html", "2 R语言入门运行样例 2.1 命令行界面 2.2 四则运算 2.3 数学函数 2.4 输出 2.5 向量计算与变量赋值 2.6 工作空间介绍 2.7 绘图示例 2.8 汇总统计示例 2.9 运行源程序文件 2.10 附录：数据", " 2 R语言入门运行样例 2.1 命令行界面 启动R软件后进入命令行界面，每输入一行命令，就在后面显示计算结果。 可以用向上和向下箭头访问历史命令； 可以从已经运行过的命令中用鼠标拖选加亮后， 用Ctrl+C复制后用Ctrl+V粘贴， 或用Ctrl+X一步完成复制粘贴， 粘贴的目标都是当前命令行。 如果使用RStudio软件， 有一个“Console窗格”相当于命令行界面。 在RStudio中， 可以用New File–Script file功能建立一个源程序文件（脚本文件）， 在脚本文件中写程序， 然后用Run图标或者Ctrl+Enter键运行当前行或者选定的部分。 2.2 四则运算 四则运算如: 5 + (2.3 - 1.125)*3.2/1.1 + 1.23E3 ## [1] 1238.418 结果为1238.418, 前面显示的结果在行首加了井号， 这在R语言中表示注释。 本教程的输出前面一般都加了井号以区分于程序语句。 输出前面的方括号和序号1是在输出有多个值时提供的提示性序号， 只有单个值时为了统一起见也显示出来了。 这里1.23E3是科学记数法， 表示\\(1.23\\times 10^3\\)。 用星号*表示乘法，用正斜杠/表示除法。 用^表示乘方运算，如 2^10 ## [1] 1024 重要提示：关闭中文输入法，否则输入一些中文标点将导致程序错误。 2.2.1 计算例子 从52张扑克牌中任取3张， 有多少种不同的组合可能？ 解答：有 \\[ C_{52}^3 = \\frac{52!}{3! (52-3)!} = \\frac{52 \\times 51 \\times 50}{3\\times 2 \\times 1} \\] 种， 在R中计算如: 52*51*50/(3*2) ## [1] 22100 2.2.2 练习 某人存入10000元1年期定期存款，年利率3%, 约定到期自动转存（包括利息）。问： 10年后本息共多少元？ 需要存多少年这10000元才能增值到20000元？ 成语说：“智者千虑，必有一失；愚者千虑，必有一得”。 设智者作判断的准确率为\\(p_1 = 0.99\\), 愚者作判断的准确率为\\(p_2=0.01\\)， 计算智者做1000次独立的判断至少犯一次错误的概率， 与愚者做1000次独立判断至少对一次的概率。 2.3 数学函数 2.3.1 数学函数——平方根、指数、对数 例: sqrt(6.25) ## [1] 2.5 exp(1) ## [1] 2.718282 log10(10000) ## [1] 4 sqrt(6.25)表示\\(\\sqrt{6.25}\\)，结果为2.5。 exp(1)表示\\(e^1\\)，结果为\\(e=2.718282\\)。 log10(10000)表示\\(\\lg 10000\\)，结果为\\(4\\)。 log为自然对数。 2.3.2 数学函数——取整 例: round(1.1234, 2) ## [1] 1.12 round(-1.9876, 2) ## [1] -1.99 floor(1.1234) ## [1] 1 floor(-1.1234) ## [1] -2 ceiling(1.1234) ## [1] 2 ceiling(-1.1234) ## [1] -1 round(1.1234, 2)表示把1.1234四舍五入到两位小数。 floor(1.1234)表示把1.1234向下取整，结果为1。 ceiling(1.1234)表示把1.1234向上取整，结果为2。 2.3.3 数学函数——三角函数 例: pi ## [1] 3.141593 sin(pi/6) ## [1] 0.5 cos(pi/6) ## [1] 0.8660254 sqrt(3)/2 ## [1] 0.8660254 tan(pi/6) ## [1] 0.5773503 pi表示圆周率\\(\\pi\\)。sin正弦, cos余弦, tan正切, 自变量以弧度为单位。 pi/6是\\(30^\\circ\\)。 2.3.4 数学函数——反三角函数 例: pi/6 ## [1] 0.5235988 asin(0.5) ## [1] 0.5235988 acos(sqrt(3)/2) ## [1] 0.5235988 atan(sqrt(3)/3) ## [1] 0.5235988 asin反正弦, acos反余弦, atan反正切， 结果以弧度为单位。 2.3.5 分布函数和分位数函数 例: dnorm(1.98) ## [1] 0.05618314 pnorm(1.98) ## [1] 0.9761482 qnorm(0.975) ## [1] 1.959964 dnorm(x)表示标准正态分布密度 \\(\\phi(x) = \\frac{1}{\\sqrt{2\\pi}} e^{-\\frac12 x^2}\\). pnorm(x)表示标准正态分布函数\\(\\Phi(x) = \\int_{-\\infty}^x \\phi(t) \\,dt\\)。 qnorm(y)表示标准正态分布分位数函数 \\(\\Phi^{-1}(x)\\)。 还有其它许多分布的密度函数、分布函数和分位数函数。 例如， qt(1 - 0.05/2, 10) ## [1] 2.228139 求自由度为10的t检验的双侧临界值。 其中qt(y,df)表示自由度为df的t分布的分位数函数。 2.4 输出 2.4.1 简单输出 命令行的计算结果直接显示在命令的后面。 在用source()运行程序文件时， 需要用print()函数显示一个表达式的结果，如： print(sin(pi/2)) ## [1] 1 用cat()函数显示多项内容， 包括数值和文本， 文本包在两个单撇号或两个双撇号中，如: cat(&quot;sin(pi/2)=&quot;, sin(pi/2), &quot;\\n&quot;) ## sin(pi/2)= 1 cat()函数最后一项一般是\"\\n\", 表示换行。 忽略此项将不换行。 再次提示：要避免打开中文输入法导致误使用中文标点。 2.4.2 用sink()函数作运行记录 R使用经常是在命令行逐行输入命令（程序）， 结果紧接着显示在命令后面。 如何保存这些命令和显示结果？ 在R命令行中运行过的命令会被保存在运行的工作文件夹中的一个名为.Rhistory的文件中。 用sink()函数打开一个文本文件开始记录文本型输出结果。 结束记录时用空的sink()即可关闭文件不再记录。 如 sink(&quot;tmpres01.txt&quot;, split=TRUE) print(sin(pi/6)) print(cos(pi/6)) cat(&quot;t(10)的双侧0.05分位数（临界值）=&quot;, qt(1 - 0.05/2, 10), &quot;\\n&quot;) sink() sink()用作输出记录主要是在测试运行中使用， 正常的输出应该使用cat()函数、write.table()、write.csv()等函数。 2.4.3 练习 用cat()函数显示 log10(2)=*** log10(5)=*** 其中***应该代以实际函数值。 用sink()函数开始把运行过程记录到文件“log001.txt”中，在命令行试验几个命令，然后关闭运行记录，查看生成的“log001.txt”的内容。 2.5 向量计算与变量赋值 R语言以向量为最小单位。用&lt;-赋值。如 x1 &lt;- 1:10 x1 ## [1] 1 2 3 4 5 6 7 8 9 10 一般的向量可以用c()生成， 如 marks &lt;- c(3, 5, 10, 5, 6) 在程序语言中，变量用来保存输入的值或计算的结果。 变量可以存放各种不同类型的值， 如单个数值、多个数值（称为向量）、单个字符串、多个字符串（称为字符型向量），等等。 单个数值称为标量。 技术秘诀：用程序设计语言的术语描述， R语言是动态类型的， 其变量的类型不需要预先声明， 运行过程中允许变量类型改变， 实际上变量赋值是一种“绑定”（binding）， 将一个变量的名称（变量名）与实际的一个存储位置联系在一起。 在命令行定义的变量称为全局变量。 用print()函数显示向量或在命令行中显示向量时， 每行显示的行首会有方括号和数字序号， 代表该行显示的第一个向量元素的下标。如 12345678901:12345678920 ## [1] 12345678901 12345678902 12345678903 12345678904 12345678905 ## [6] 12345678906 12345678907 12345678908 12345678909 12345678910 ## [11] 12345678911 12345678912 12345678913 12345678914 12345678915 ## [16] 12345678916 12345678917 12345678918 12345678919 12345678920 向量可以和一个标量作四则运算， 结果是每个元素都和这个标量作四则运算，如： x1 + 200 ## [1] 201 202 203 204 205 206 207 208 209 210 2*x1 ## [1] 2 4 6 8 10 12 14 16 18 20 2520/x1 ## [1] 2520 1260 840 630 504 420 360 315 280 252 两个等长的向量可以进行四则运算， 相当于对应元素进行四则运算，如 x2 &lt;- x1 * 3 x2 ## [1] 3 6 9 12 15 18 21 24 27 30 x2 - x1 ## [1] 2 4 6 8 10 12 14 16 18 20 R的许多函数都可以用向量作为自变量， 结果是自变量的每个元素各自的函数值。 如 sqrt(x1) ## [1] 1.000000 1.414214 1.732051 2.000000 2.236068 2.449490 2.645751 ## [8] 2.828427 3.000000 3.162278 结果是1到10的整数各自的平方根。 2.6 工作空间介绍 在命令行中定义的变量， 在退出R时，会提问是否保存工作空间， 初学时可选择保存， 真正用R进行数据分析时往往不保存工作空间。 再次启动R后， 能够看到以前定义的各个变量的值。 在使用R的官方版本时， 如果在Windows中使用， 一般把不同的数据分析项目放在不同的文件夹中。 将R的程序快捷图标复制到每一个项目的文件夹中， 并用右键菜单讲快捷图标的“属性”中“起始位置”改为空白。 要分析哪一个项目的数据， 就从那个项目文件夹中的R快捷图标启动， 这样可以保证不同的项目有不同的工作空间。 如果使用RStudio软件， 也需要把不同项目放在不同文件夹， 并且每个项目在RStudio中单独建立一个“项目”（project）。 要分析那个项目的数据， 就打开那个项目。 不同项目使用不同的工作空间。 RStudio中的“Environment”窗格会显示当前已定义的R变量与函数。 2.6.1 练习 某人存入10000元1年期定期存款，年利率3%, 约定到期自动转存（包括利息）。列出1、2、……、10年后的本息金额。 显示2的1,2,……, 20次方。 定义x1为1到10的向量，定义x2为x1的3倍，然后退出R，再次启动R，查看x1和x2的值。 2.7 绘图示例 2.7.1 函数曲线示例 如下程序用curve()函数制作\\(y=x^2\\)函数的曲线图， curve()函数第二、第三自变量是绘图区间： curve(x^2, -2, 2) 类似地，\\(\\sin(x)\\)函数曲线图用如下程序可制作, 用abline()函数添加参考线: curve(sin(x), 0, 2*pi) abline(h=0) 2.7.2 条形图示例 假设有10个男生，7个女生，如下程序绘制男生、女生人数的条形图： barplot(c(&quot;男生&quot;=10, &quot;女生&quot;=7), main=&quot;男女生人数&quot;) 利用适当选项可以人为定制颜色、控制条形宽窄。 实际问题中，个数（频数）一般是从数据中统计得到的。 2.7.3 散点图示例 下面的例子用plot()函数做了散点图, plot()函数第一个自变量是各个点的横坐标值， 第二个自变量是对应的纵坐标值。 plot(1:10, sqrt(1:10)) 2.7.4 R软件自带的图形示例 R软件中自带了一些演示图形。通过如下程序可以调用： demo(&quot;graphics&quot;) demo(&quot;image&quot;) 2.7.5 练习 画\\(\\exp(x)\\)在\\((-2,2)\\)区间的函数图形。 画\\(\\ln(x)\\)在\\((0.01, 10)\\)区间的函数图形。 2.8 汇总统计示例 2.8.1 表格数据 统计用的输入数据典型样式是Excel表那样的表格数据。 表格数据特点：每一列应该是相同的类型（或者都是数值， 或者都是文字，或者都是日期）， 每一列应该有一个名字。 这样的表格数据，一般可以保存为.csv格式： 数据项之间用逗号分开，文件本身是文本型的， 可以用普通记事本程序查看和编辑。 Excel表可以用“另存为”命令保存为.csv格式。 常用的数据库管理系统一般也可以把表保存为.csv格式。 2.8.2 读入表格数据 例如，taxsamp.csv是这样一个csv格式表格数据文件， 可以用Excel打开，也可以用记事本程序或notepad++打开。 内容见本页面后面的附录。 用如下程序可以把.csv文件读入到R中： tax.tab &lt;- read.csv(&quot;taxsamp.csv&quot;, header=TRUE, as.is=TRUE) print(head(tax.tab)) 程序中的选项header=TRUE指明第一行作为变量名行， 选项as.is=TRUE说明字符型列要原样读入而不是转换为因子(factor)。 读入的变量tax.tab称为一个数据框(data.frame)。 head()函数返回数据框或向量的前几项。 比较大的表最好不要显示整个表， 会使得前面的运行过程难以查看。 技巧：read.csv()的一个改进版本是readr扩展包的read_csv()函数， 此函数读入较大表格速度要快得多， 而且读入的转换设置更倾向于不做不必要的转换。 但是， 这两种输入方法的默认中文编码可能不一样。 2.8.3 练习 用Excel软件查看“taxsamp.csv”的内容(双击即可)。 用记事本程序或notepad++软件查看“taxsamp.csv”的内容。 读入“taxsamp.csv”到R数据框tax.tab中，查看tax.tab内容。 2.8.4 分类变量频数统计 在tax.tab中， “征收方式”是一个分类变量。 用table()函数计算每个不同值的个数，称为频数(frequency): table(tax.tab[[&quot;征收方式&quot;]]) ## ## 查帐征收 定期定额征收 定期定率征收 ## 31 16 2 类似地可以统计 “申报渠道”的取值频数: table(tax.tab[[&quot;申报渠道&quot;]]) ## ## 大厅申报 网上申报 ## 18 31 也可以用table()函数统计“征收方式”和“申报渠道”交叉分类频数，如： table(tax.tab[[&quot;征收方式&quot;]], tax.tab[[&quot;申报渠道&quot;]]) ## ## 大厅申报 网上申报 ## 查帐征收 9 22 ## 定期定额征收 9 7 ## 定期定率征收 0 2 上述结果制表如下: knitr::kable(table(tax.tab[[&quot;征收方式&quot;]], tax.tab[[&quot;申报渠道&quot;]]) ) 大厅申报 网上申报 查帐征收 9 22 定期定额征收 9 7 定期定率征收 0 2 2.8.5 数值型变量的统计 数值型变量可以计算各种不同的统计量, 如平均值、标准差和各个分位数。 summary()可以给出最小值、最大值、中位数、四分之一分位数、四分之三分位数和平均值。如 summary(tax.tab[[&quot;营业额&quot;]]) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0 650 2130 247327 9421 6048000 中位数是从小到大排序后排在中间的值。 四分之一和四分之三分位数类似。 统计函数以一个数值型向量为自变量， 包括sum(求和), mean(平均值), var(样本方差), sd(样本标准差), min(最小值), max(最大值), range(最小值和最大值)等。如 mean(tax.tab[[&quot;营业额&quot;]]) ## [1] 247327.4 sd(tax.tab[[&quot;营业额&quot;]]) ## [1] 1036453 如果数据中有缺失值， 可以删去缺失值后计算统计量， 这时在mean, sd等函数中加入na.rm=TRUE选项。 2.8.6 练习 用如下程序定义一个变量x, 然后求x的平均值和最小值、最大值。 x &lt;- c(3, 5, 10, 5, 6) 2.9 运行源程序文件 用source()函数可以运行保存在一个文本文件中的源程序。 比如，如下内容保存在文件ssq.r中： sum.of.squares &lt;- function(x){ sum(x^2) } 用如下source()命令运行： source(&quot;ssq.r&quot;) 运行后就可以调用自定义函数sum.of.squares()了。 2.9.1 源文件编码 源程序文件存在编码问题。 对于源程序编码与系统默认编码不同的情况， 在source()函数中可以添加encoding=选项。 例如， 保存为UTF-8编码的源程序在简体中文MS Windows系统的R中运行， 可以在source()函数中可以添加encoding=\"UTF-8\"选项。 保存为GBK编码的源程序文件在MAC系统的R中运行， 可以在source()函数中可以添加encoding=\"GBK\"选项。 在RStudio中， 可以打开一个源程序文件查看与编辑。 用快捷键“Ctrl+Enter”或快捷图标“Run”可以运行当前行或者加亮选中行， 快捷图标“Source”可以运行整个文件。 如果发现中文乱码， 可以用菜单“Reopen with encoding”选择合适的编码打开， 用菜单“Save with encoding”选择需要的编码保存。 2.9.2 当前工作目录 在用source()调用源程序文件或者用read.csv()读入数据文件时， 如果不写文件名的全路径， 就认为文件位置是在所谓“当前工作目录”。 用getwd()函数可以查询当前工作目录， 用setwd()函数可以设置当前工作目录。 在RStudio中用菜单“Session–Set working directory”设置当前工作目录。 在MS Windows操作系统中使用R软件时， 一种好的做法是把某个研究项目所有数据和程序放在某个文件夹如 c:\\work中， 把R的程序快捷图标复制到该目录中， 在资源管理器中对该图标调用鼠标右键菜单“属性”， 从弹出对话框中，把“起始位置”一栏清除。 这样，每次从这个快捷图标启动R， 就可以自动以所在子目录为当前工作目录， 工作空间和命令历史记录也默认存放在这里。 在MS Windows操作系统的R中使用文件路径时， 要用正斜杠作为连接符， 使用反斜杠则需要成对使用， 如setwd(\"d:/work\")或setwd(\"d:\\\\work\")。 如果使用RStudio软件， 将某个研究项目所有数据和程序放在某个文件夹中， 然后建立一个新项目（project）指向该文件夹。 2.9.3 练习 编辑生成ssq.r源程序文件并用source()函数运行， 然后计算： sum.of.squares(1:5) 2.10 附录：数据 2.10.1 公司纳税数据样例 本数据是某地区2013年12月所属税款申报信息的一个子集， 仅含20个公司的数据。 数据文件显示 "],["prog-type-intro.html", "3 常量与变量 3.1 常量 3.2 变量 3.3 R数据类型", " 3 常量与变量 3.1 常量 R语言基本的数据类型有数值型， 逻辑型（TRUE, FALSE），文本（字符串）。 支持缺失值，有专门的复数类型。 常量是指直接写在程序中的值。 数值型常量包括整型、单精度、双精度等，一般不需要区分。写法如123, 123.45, -123.45, -0.012, 1.23E2, -1.2E-2等。 为了表示123是整型，可以写成123L。 字符型常量用两个双撇号或两个单撇号包围，如\"Li Ming\"或'Li Ming'。 字符型支持中文，如\"李明\"或'李明'。 国内的中文编码主要有GBK编码和UTF-8编码， 有时会遇到编码错误造成乱码的问题，MS Windows下R程序一般用GBK编码，但是RStudio软件采用UTF-8编码。 在R软件内字符串一般用UTF-8编码保存。 逻辑型常量只有TRUE和FALSE。 缺失值用NA表示。统计计算中经常会遇到缺失值，表示记录丢失、因为错误而不能用、节假日没有数据等。 除了数值型，逻辑型和字符型也可以有缺失值， 而且字符型的空白值不会自动辨识为缺失值，需要自己规定。 R支持特殊的Inf值，这是实数型值，表示正无穷大，不算缺失值。 复数常量写法如2.2 + 3.5i, 1i等。 3.2 变量 程序语言中的变量用来保存输入的值或者计算得到的值。 在R中，变量可以保存所有的数据类型， 比如标量、向量、矩阵、数据框、函数等。 变量都有变量名，R变量名必须以字母、数字、下划线和句点组成， 变量名的第一个字符不能取为数字。 在中文环境下，汉字也可以作为变量名的合法字符使用。 变量名是区分大小写的， y和Y是两个不同的变量名。 变量名举例: x, x1, X, cancer.tab, clean_data, diseaseData。 用&lt;-赋值的方法定义变量。&lt;-也可以写成=，但是&lt;-更直观。 如 x5 &lt;- 6.25 x6 = sqrt(x5) R的变量没有固定的类型， 给已有变量赋值为新的类型， 该变量就变成新的类型， 但一般应避免这样的行为。 R是“动态类型”语言， 赋值实际上是“绑定”（binding）， 即将一个变量名与一个存储地址联系在一起， 同一个存储地址可以有多个变量名与其联系。 3.3 R数据类型 R语言基本的数据类型有数值， 逻辑型（TRUE, FALSE），文本（字符串）。 支持缺失值，有专门的复数类型。 R语言数据结构包括向量，矩阵和数据框，多维数组， 列表，对象等。数据中元素、行、列还可以用名字访问。 最基本的是向量类型。 向量类型数据的访问方式也是其他数据类型访问方式的基础。 "],["prog-type-num.html", "4 数值型向量及其运算 4.1 数值型向量 4.2 向量运算 4.3 向量函数 4.4 复数向量 4.5 练习", " 4 数值型向量及其运算 4.1 数值型向量 向量是将若干个基础类型相同的值存储在一起， 各个元素可以按序号访问。 如果将若干个数值存储在一起可以用序号访问， 就叫做一个数值型向量。 用c()函数把多个元素或向量组合成一个向量。如 marks &lt;- c(10, 6, 4, 7, 8) x &lt;- c(1:3, 10:13) x1 &lt;- c(1, 2) x2 &lt;- c(3, 4) x &lt;- c(x1, x2) x ## [1] 1 2 3 4 10:13这样的写法表示从10到13的整数组成的向量。 用print()函数显示向量或在命令行中显示向量时， 每行显示的行首会有方括号和数字序号， 代表该行显示的第一个向量元素的下标。如 12345678901:12345678920 ## [1] 12345678901 12345678902 12345678903 12345678904 12345678905 12345678906 ## [7] 12345678907 12345678908 12345678909 12345678910 12345678911 12345678912 ## [13] 12345678913 12345678914 12345678915 12345678916 12345678917 12345678918 ## [19] 12345678919 12345678920 length(x)可以求x的长度。 长度为零的向量表示为numeric(0)。 numeric()函数可以用来初始化一个指定元素个数而元素都等于零的数值型向量， 如numeric(10)会生成元素为10个零的向量。 4.2 向量运算 4.2.1 标量和标量运算 单个数值称为标量， R没有单独的标量类型， 标量实际是长度为1的向量。 R中四则运算用+ - * / ^表示(加、减、乘、除、乘方)，如 1.5 + 2.3 - 0.6 + 2.1*1.2 - 1.5/0.5 + 2^3 ## [1] 10.72 R中四则运算仍遵从通常的优先级规则， 可以用圆括号()改变运算的先后次序。 如 1.5 + 2.3 - (0.6 + 2.1)*1.2 - 1.5/0.5 + 2^3 ## [1] 5.56 除了加、减、乘、除、乘方， R还支持整除运算和求余运算。 用%/%表示整除，用%%表示求余。如 5 %/% 3 ## [1] 1 5 %% 3 ## [1] 2 5.1 %/% 2.5 ## [1] 2 5.1 %% 2.5 ## [1] 0.1 4.2.2 向量与标量运算 向量与标量的运算为每个元素与标量的运算, 如 x &lt;- c(1, 10) x + 2 ## [1] 3 12 x - 2 ## [1] -1 8 x * 2 ## [1] 2 20 x / 2 ## [1] 0.5 5.0 x ^ 2 ## [1] 1 100 2 / x ## [1] 2.0 0.2 2 ^ x ## [1] 2 1024 一个向量乘以一个标量， 就是线性代数中的数乘运算。 四则运算时如果有缺失值，缺失元素参加的运算相应结果元素仍缺失。 如 c(1, NA, 3) + 10 ## [1] 11 NA 13 4.2.3 等长向量运算 等长向量的运算为对应元素两两运算。 如 x1 &lt;- c(1, 10) x2 &lt;- c(4, 2) x1 + x2 ## [1] 5 12 x1 - x2 ## [1] -3 8 x1 * x2 ## [1] 4 20 x1 / x2 ## [1] 0.25 5.00 两个等长向量的加、减运算就是线性代数中两个向量的加、减运算。 4.2.4 不等长向量的运算 两个不等长向量的四则运算， 如果其长度为倍数关系，规则是每次从头重复利用短的一个。 如 x1 &lt;- c(10, 20) x2 &lt;- c(1, 3, 5, 7) x1 + x2 ## [1] 11 23 15 27 x1 * x2 ## [1] 10 60 50 140 不仅是四则运算，R中有两个或多个向量按照元素一一对应参与某种运算或函数调用时， 如果向量长度不同，一般都采用这样的规则。 如果两个向量的长度不是倍数关系，会给出警告信息。如 c(1,2) + c(1,2,3) ## Warning in c(1, 2) + c(1, 2, 3): 长的对象长度不是短的对象长度的整倍数 ## [1] 2 4 4 4.3 向量函数 4.3.1 向量化的函数 R中的函数一般都是向量化的: 在R中， 如果普通的一元函数以向量为自变量，一般会对每个元素计算。 这样的函数包括sqrt, log10, log, exp, sin, cos, tan等许多。 如 sqrt(c(1, 4, 6.25)) ## [1] 1.0 2.0 2.5 为了查看这些基础的数学函数的列表，运行命令help.start()， 点击链接“Search Engine and Keywords”， 找到“Mathematics”栏目， 浏览其中的“arith”和“math”链接中的说明。 常用的数学函数有： 舍入：ceiling, floor, round, signif, trunc, zapsmall 符号函数 sign 绝对值 abs 平方根 sqrt 对数与指数函数 log, exp, log10, log2 三角函数 sin, cos, tan 反三角函数 asin, acos, atan, atan2 双曲函数 sinh, cosh, tanh 反双曲函数 asinh, acosh, atanh 有一些不太常用的数学函数： 贝塔函数 beta, lbeta 伽玛函数 gamma, lgamma, digamma, trigamma, tetragamma, pentagamma 组合数 choose, lchoose 富利叶变换和卷积 fft, mvfft, convolve 正交多项式 poly 求根 polyroot, uniroot 最优化 optimize, optim Bessel函数 besselI, besselK, besselJ, besselY 样条插值 spline, splinefun 简单的微分 deriv 如果自己编写的函数没有考虑向量化问题， 可以用Vectorize()函数将其转换成向量化版本。 4.3.2 排序函数 sort(x)返回排序结果。 rev(x)返回把各元素排列次序反转后的结果。 order(x)返回排序用的下标。如 x &lt;- c(33, 55, 11) sort(x) ## [1] 11 33 55 rev(sort(x)) ## [1] 55 33 11 order(x) ## [1] 3 1 2 x[order(x)] ## [1] 11 33 55 例子中， order(x)结果中3是x的最小元素11所在的位置下标， 1是x的第二小元素33所在的位置下标， 2是x的最大元素55所在的位置下标。 4.3.3 统计函数 sum(求和), mean(求平均值), var(求样本方差), sd(求样本标准差), min(求最小值), max(求最大值), range(求最小值和最大值)等函数称为统计函数， 把输入向量看作样本，计算样本统计量。 prod求所有元素的乘积。 cumsum和cumprod计算累加和累乘积。如 cumsum(1:5) ## [1] 1 3 6 10 15 cumprod(1:5) ## [1] 1 2 6 24 120 其它一些类似函数有pmax, pmin, cummax, cummin等。 4.3.4 生成规则序列的函数 seq函数是冒号运算符的推广。 比如，seq(5)等同于1:5。 seq(2,5)等同于2:5。 seq(11, 15, by=2)产生11,13,15。 seq(0, 2*pi, length.out=100)产生从0到\\(2\\pi\\)的等间隔序列， 序列长度指定为100。 从这些例子可以看出，S函数可以带自变量名调用。 每个函数的变量名和用法可以查询其帮助信息， 在命令行界面用“?函数名”的方法查询。 在使用变量名时次序可以颠倒， 比如seq(to=5, from=2)}仍等同于2:5。 rep()函数用来产生重复数值。 为了产生一个初值为零的长度为n的向量， 用x &lt;- rep(0, n)。 rep(c(1,3), 2)把第一个自变量重复两次， 结果相当于c(1,3,1,3)。 rep(c(1,3), c(2,4))则需要利用R的一般向量化规则， 把第一自变量的第一个元素1按照第二自变量中第一个元素2的次数重复， 把第一自变量中第二个元素3按照第二自变量中第二个元素4的次数重复， 结果相当于c(1,1,3,3,3,3)。 如果希望重复完一个元素后再重复另一元素，用each=选项， 比如rep(c(1,3), each=2)结果相当于c(1,1,3,3)。 有一点技术性的小问题： 1:5和seq(5)的结果是整型（integer）的， c(1,3,5)和seq(1, 5, by=2)的结果是浮点型（double）的。 4.4 复数向量 复数常数表示如3.5+2.4i, 1i。 用函数complex()生成复数向量， 指定实部和虚部。 如complex(real = c(1,0,-1,0), imaginary = c(0,1,0,-1))相当于c(1+0i, 1i, -1+0i, -1i)。 在complex()中可以用mod和arg指定模和辐角，如 complex(mod=1, arg=(0:3)/2*pi)结果同上。 用Re(z)求z的实部， 用Im(z)求z的虚部， 用Mod(z)或abs(z)求z的模， 用Arg(z)求z的辐角， 用Conj(z)求z的共轭。 sqrt, log, exp, sin等函数对复数也有定义， 但是函数定义域在自变量为实数时可能有限制而复数无限制， 这时需要区分自变量类型。如 sqrt(-1) ## [1] NaN ## Warning message: ## In sqrt(-1) : NaNs produced sqrt(-1 + 0i) ## [1] 0+1i 4.5 练习 显示1到100的整数的平方根和立方根（提示：立方根就是三分之一次方）。 设有10个人的小测验成绩为: \\[ 77\\ 60\\ 91\\ 73\\ 85\\ 82\\ 35\\ 100\\ 66\\ 75 \\] 把这10个成绩存入变量x; 从小到大排序； 计算order(x)，解释order(x)结果中第3项代表的意义。 计算这些成绩的平均值、标准差、最小值、最大值、中位数。 生成\\([0,1]\\)区间上等间隔的100个格子点存入变量x中。 "],["prog-type-logi.html", "5 逻辑型向量及其运算 5.1 逻辑型向量与比较运算 5.2 逻辑运算 5.3 逻辑运算函数", " 5 逻辑型向量及其运算 5.1 逻辑型向量与比较运算 逻辑型是R的基本数据类型之一，只有两个值TRUE和FALSE, 缺失时为NA。逻辑值一般产生自比较，如 sele &lt;- (log10(15) &lt; 2); print(sele) ## [1] TRUE 向量比较结果为逻辑型向量。如 c(1, 3, 5) &gt; 2 ## [1] FALSE TRUE TRUE (1:4) &gt;= (4:1) ## [1] FALSE FALSE TRUE TRUE 从例子可以看出，向量比较也遵从R的向量间运算的一般规则： 向量与标量的运算是向量每个元素与标量都分别运算一次， 等长向量的运算时对应元素的运算， 不等长但长度为倍数关系的向量运算是把短的从头重复利用。 与NA比较产生NA，如 c(1, NA, 3) &gt; 2 ## [1] FALSE NA TRUE NA == NA ## [1] NA 为了判断向量每个元素是否NA， 用is.na()函数，如 is.na(c(1, NA, 3) &gt; 2) ## [1] FALSE TRUE FALSE 用is.finite()判断向量每个元素是否Inf值。 比较运算符包括 &lt; &lt;= &gt; &gt;= == != %in% 分别表示小于、小于等于、大于、大于等于、等于、不等于、属于。 要注意等于比较用了两个等号。 %in%是比较特殊的比较， x %in% y的运算把向量y看成集合， 运算结果是一个逻辑型向量， 第\\(i\\)个元素的值为x的第\\(i\\)元素是否属于y的逻辑型值。 如 c(1,3) %in% c(2,3,4) ## [1] FALSE TRUE c(NA,3) %in% c(2,3,4) ## [1] FALSE TRUE c(1,3) %in% c(NA, 3, 4) ## [1] FALSE TRUE c(NA,3) %in% c(NA, 3, 4) ## [1] TRUE TRUE 函数match(x, y)起到和x %in% y运算类似的作用， 但是其返回结果不是找到与否， 而是对x的每个元素， 找到其在y中首次出现的下标，找不到时取缺失值，如 match(c(1, 3), c(2,3,4,3)) ## [1] NA 2 5.2 逻辑运算 为了表达如“\\(x&gt;0\\)而且\\(x&lt;1\\)”, “\\(x \\leq 0\\)或者\\(x \\geq 1\\)”之类的复合比较， 需要使用逻辑运算把两个比较连接起来。 逻辑运算符为&amp;, |和!, 分别表示“同时成立”、“两者至少其一成立”、“条件的反面”。 比如，设age&lt;=3表示婴儿，sex=='女'表示女性，则 age&lt;=3 &amp; sex=='女'表示女婴, age&lt;=3 | sex=='女'表示婴儿或妇女, !(age&lt;=3 | sex=='女')表示既非婴儿也非妇女。 为了确定运算的先后次序可以用圆括号()指定。 用xor(x, y)表示x与y的异或运算， 即值不相等时为真值，相等时为假值， 有缺失值参加运算时为缺失值。 逻辑向量与逻辑标量之间的逻辑运算， 两个逻辑向量之间的逻辑运算规则遵从一般R向量间运算规则。 在右运算符是缺失值时， 如果左运算符能够确定结果真假， 可以得到非缺失的结果。 例如，TRUE | NA为TRUE, FALSE &amp; NA为FALSE。 不能确定结果时返回NA， 比如， TRUE &amp; NA为NA, FALSE | NA为NA。 &amp;&amp;和||分别为短路的标量逻辑与和短路的标量逻辑或， 仅对两个标量进行运算，如果有向量也仅使用第一个元素。 一般用在if语句、while语句中， 且只要第一个比较已经决定最终结果就不计算第二个比较。 例如 if(TRUE || sqrt(-1)&gt;0) next 其中的sqrt(-1)部分不会执行。 这里结果为TRUE, 第二部分没有参加计算， 否则第二部分的计算会发生函数自变量范围错误。 5.3 逻辑运算函数 因为R中比较与逻辑运算都支持向量之间、向量与标量之间的运算， 所以在需要一个标量结果时要特别注意， 后面讲到的if结构、while结构都需要逻辑标量而且不能是缺失值。 这时，应该对缺失值结果单独考虑。 若cond是逻辑向量， 用all(cond)测试cond的所有元素为真； 用any(cond)测试cond至少一个元素为真。 cond中允许有缺失值，结果可能为缺失值。 如 c(1, NA, 3) &gt; 2 ## [1] FALSE NA TRUE all(c(1, NA, 3) &gt; 2) ## [1] FALSE any(c(1, NA, 3) &gt; 2) ## [1] TRUE all(NA) ## [1] NA any(NA) ## [1] NA 函数which()返回真值对应的所有下标，如 which(c(FALSE, TRUE, TRUE, FALSE, NA)) ## [1] 2 3 which((11:15) &gt; 12) ## [1] 3 4 5 函数identical(x,y)比较两个R对象x与y的内容是否完全相同， 结果只会取标量TRUE与FALSE两种。 如 identical(c(1,2,3), c(1,2,NA)) ## [1] FALSE identical(c(1L,2L,3L), c(1,2,3)) ## [1] FALSE 其中第二个结果假值是因为前一向量是整数型， 后一向量是实数型。 函数all.equal()与identical()类似， 但是在比较数值型时不区分整数型与实数型， 而且相同时返回标量TRUE， 但是不同时会返回一个说明有何不同的字符串。如 all.equal(c(1,2,3), c(1,2,NA)) ## [1] &quot;&#39;is.NA&#39; value mismatch: 1 in current 0 in target&quot; all.equal(c(1L,2L,3L), c(1,2,3)) ## [1] TRUE 函数duplicated()返回每个元素是否为重复值的结果，如： duplicated(c(1,2,1,3,NA,4,NA)) ## [1] FALSE FALSE TRUE FALSE FALSE FALSE TRUE 用函数unique()可以返回去掉重复值的结果。 "],["prog-type-char.html", "6 字符型数据及其处理 6.1 字符型向量 6.2 paste()函数 6.3 转换大小写 6.4 字符串长度 6.5 取子串 6.6 类型转换 6.7 字符串拆分 6.8 字符串替换功能 6.9 正则表达式", " 6 字符型数据及其处理 6.1 字符型向量 字符型向量是元素为字符串的向量。 如 s1 &lt;- c(&#39;abc&#39;, &#39;&#39;, &#39;a cat&#39;, NA, &#39;李明&#39;) 注意空字符串并不能自动认为是缺失值， 字符型的缺失值仍用NA表示。 6.2 paste()函数 针对字符型数据最常用的R函数是paste()函数。 paste()用来连接两个字符型向量， 元素一一对应连接， 默认用空格连接。 如paste(c(\"ab\", \"cd\"), c(\"ef\", \"gh\")) 结果相当于c(\"ab ef\", \"cd gh\")。 paste()在连接两个字符型向量时采用R的一般向量间运算规则， 而且可以自动把数值型向量转换为字符型向量。 可以作一对多连接， 如paste(\"x\", 1:3)结果相当于c(\"x 1\", \"x 2\", \"x 3\")。 用sep=指定分隔符， 如paste(\"x\", 1:3, sep=\"\")结果相当于c(\"x1\", \"x2\", \"x3\")。 使用collapse=参数可以把字符型向量的各个元素连接成一个单一的字符串, 如paste(c(\"a\", \"b\", \"c\"), collapse=\"\")结果相当于\"abc\"。 6.3 转换大小写 toupper()函数把字符型向量内容转为大写， tolower()函数转为小写。 比如，toupper('aB cd')结果为\"AB CD\"， tolower(c('aB', 'cd'))结果相当于c(\"ab\" \"cd\")。 这两个函数可以用于不区分大小写的比较， 比如，不论x的值是'JAN', 'Jan'还是'jan'， toupper(x)=='JAN'的结果都为TRUE。 6.4 字符串长度 用nchar(x, type='bytes')计算字符型向量x中每个字符串的以字节为单位的长度，这一点对中英文是有差别的， 中文通常一个汉字占两个字节，英文字母、数字、标点占一个字节。 用nchar(x, type='chars')计算字符型向量x中每个字符串的以字符个数为单位的长度，这时一个汉字算一个单位。 在画图时可以用strwidth()函数计算某个字符串或表达式占用的空间大小。 6.5 取子串 substr(x, start, stop)从字符串x中取出从第start个到第stop个的子串， 如 substr(&#39;JAN07&#39;, 1, 3) ## [1] &quot;JAN&quot; 如果x是一个字符型向量，substr将对每个元素取子串。如 substr(c(&#39;JAN07&#39;, &#39;MAR66&#39;), 1, 3) ## [1] &quot;JAN&quot; &quot;MAR&quot; 用substring(x, start)可以从字符串x中取出从第start个到末尾的子串。如 substring(c(&#39;JAN07&#39;, &#39;MAR66&#39;), 4) ## [1] &quot;07&quot; &quot;66&quot; 6.6 类型转换 用as.numeric()把内容是数字的字符型值转换为数值，如 substr(&#39;JAN07&#39;, 4, 5) ## [1] &quot;07&quot; substr(&#39;JAN07&#39;, 4, 5) + 2000 ## Error in substr(&quot;JAN07&quot;, 4, 5) + 2000 : ## non-numeric argument to binary operator as.numeric(substr(&#39;JAN07&#39;, 4, 5)) + 2000 ## [1] 2007 as.numeric(substr(c(&#39;JAN07&#39;, &#39;MAR66&#39;), 4, 5)) ## [1] 7 66 as.numeric()是向量化的， 可以转换一个向量的每个元素为数值型。 用as.character()函数把数值型转换为字符型，如 as.character((1:5)*5) ## [1] &quot;5&quot; &quot;10&quot; &quot;15&quot; &quot;20&quot; &quot;25&quot; 如果自变量本来已经是字符型则结果不变。 为了用指定的格式数值型转换成字符型， 可以使用sprintf()函数， 其用法与C语言的sprintf()函数相似， 只不过是向量化的。例如 sprintf(&#39;file%03d.txt&#39;, c(1, 99, 100)) ## [1] &quot;file001.txt&quot; &quot;file099.txt&quot; &quot;file100.txt&quot; 6.7 字符串拆分 用strsplit()函数可以把一个字符串按照某种分隔符拆分开，例如 x &lt;- &#39;10,8,7&#39; strsplit(x, &#39;,&#39;, fixed=TRUE)[[1]] ## [1] &quot;10&quot; &quot;8&quot; &quot;7&quot; sum(as.numeric(strsplit(x, &#39;,&#39;, fixed=TRUE)[[1]])) ## [1] 25 因为strsplit()的结果是一个列表， 这个函数延后再详细讲。 6.8 字符串替换功能 用gsub()可以替换字符串中的子串， 这样的功能经常用在数据清理中。 比如，把数据中的中文标点改为英文标点， 去掉空格，等等。 如 x &lt;- &#39;1, 3; 5&#39; gsub(&#39;;&#39;, &#39;,&#39;, x, fixed=TRUE) ## [1] &quot;1, 3, 5&quot; strsplit(gsub(&#39;;&#39;, &#39;,&#39;, x, fixed=TRUE), &#39;,&#39;)[[1]] ## [1] &quot;1&quot; &quot; 3&quot; &quot; 5&quot; 字符串x中分隔符既有逗号又有分号， 上面的程序用gsub()把分号都换成逗号。 更多的文本数据（字符型数据）功能参见36。 6.9 正则表达式 正则表达式(regular expression)是一种匹配某种字符串模式的方法。 用这样的方法，可以从字符串中查找某种模式的出现位置， 替换某种模式，等等。 这样的技术可以用于文本数据的预处理， 比如用网络爬虫下载的大量网页文本数据。 R中支持perl语言格式的正则表达式， grep()和grepl()函数从字符串中查询某个模式， sub()和gsub()替换某模式。 比如， 下面的程序把多于一个空格替换成一个空格 gsub(&#39;[[:space:]]+&#39;, &#39; &#39;, &#39;a cat in a box&#39;, perl=TRUE) ## [1] &quot;a cat in a box&quot; 正则表达式功能强大但也不容易掌握。 详见36。 "],["prog-type-index.html", "7 R向量下标和子集 7.1 正整数下标 7.2 负整数下标 7.3 空下标与零下标 7.4 下标超界 7.5 逻辑下标 7.6 which()、which.min()、which.max()函数 7.7 元素名 7.8 用R向量下标作映射 7.9 集合运算 7.10 练习", " 7 R向量下标和子集 在R中下标与子集是极为强大的功能， 需要一些练习才能熟练掌握， 许多其它语言中需要多个语句才能完成的工作在R中都可以简单地通过下标和子集来完成。 7.1 正整数下标 对向量x, 在后面加方括号和下标可以访问向量的元素和子集。 设x &lt;- c(1, 4, 6.25)。 x[2]取出第二个元素； x[2] &lt;- 99修改第二个元素。 x[c(1,3)]取出第1、3号元素； x[c(1,3)] &lt;- c(11, 13)修改第1、3号元素。 下标可重复。 例如 x &lt;- c(1, 4, 6.25) x[2] ## [1] 4 x[2] &lt;- 99; x ## [1] 1.00 99.00 6.25 x[c(1,3)] ## [1] 1.00 6.25 x[c(1,3)] &lt;- c(11, 13); x ## [1] 11 99 13 x[c(1,3,1)] ## [1] 11 13 11 7.2 负整数下标 负下标表示扣除相应的元素后的子集，如 x &lt;- c(1,4,6.25) x[-2] ## [1] 1.00 6.25 x[-c(1,3)] ## [1] 4 负整数下标不能与正整数下标同时用来从某一向量中取子集， 比如，x[c(1,-2)]没有意义。 7.3 空下标与零下标 x[]表示取x的全部元素作为子集。 这与x本身不同，比如 x &lt;- c(1,4,6.25) x[] &lt;- 999 x ## [1] 999 999 999 x &lt;- c(1,4,6.25) x &lt;- 999 x ## [1] 999 x[0]是一种少见的做法， 结果返回类型相同、长度为零的向量， 如numeric(0)。 相当于空集。 当0与正整数下标一起使用时会被忽略。 当0与负整数下标一起使用时也会被忽略。 7.4 下标超界 设向量x长度为\\(n\\), 则使用正整数下标时下标应在\\(\\{1, 2, \\ldots, n \\}\\)中取值。 如果使用大于\\(n\\)的下标， 读取时返回缺失值，并不出错。 给超出\\(n\\)的下标元素赋值， 则向量自动变长， 中间没有赋值的元素为缺失值。 例如 x &lt;- c(1,4,6.25) x[5] ## [1] NA x ## [1] 1.00 4.00 6.25 x[5] &lt;- 9 x ## [1] 1.00 4.00 6.25 NA 9.00 虽然R的语法对下标超界不视作错误， 但是这样的做法往往来自不良的程序思路， 而且对程序效率有影响， 所以实际编程中应避免下标超界。 7.5 逻辑下标 下标可以是与向量等长的逻辑表达式， 一般是关于本向量或者与本向量等长的其它向量的比较结果，如 x &lt;- c(1,4,6.25) x[x &gt; 3] ## [1] 4.00 6.25 取出x的大于3的元素组成的子集。 逻辑下标除了用来对向量取子集， 还经常用来对数据框取取子集， 也用在向量化的运算中。 例如，对如下示性函数 \\[ f(x) = \\begin{cases} 1, &amp; x \\ge 0 \\\\ 0, &amp; x &lt; 0 \\end{cases} \\] 输入向量x，结果y需要也是一个向量，程序可以写成 f &lt;- function(x){ y &lt;- numeric(length(x)) y[x &gt;= 0] &lt;- 1 y[x &lt; 0] &lt;- 0 # 此语句多余 y } 事实上，向量化的逻辑选择有一个ifelse()函数， 比如，对上面的示性函数， 如果x是一个向量， 输出y向量可以写成y &lt;- ifelse(x&gt;=0, 1, 0)。 要注意的是，如果逻辑下标中有缺失值， 对应结果也是缺失值。 所以，在用逻辑下标作子集选择时， 一定要考虑到缺失值问题。正确的做法是加上!is.na前提， 如 x &lt;- c(1, 4, 6.25, NA) x[x &gt; 2] ## [1] 4.00 6.25 NA x[!is.na(x) &amp; x &gt; 2] ## [1] 4.00 6.25 7.6 which()、which.min()、which.max()函数 函数which()可以用来找到满足条件的下标， 如 x &lt;- c(3, 4, 3, 5, 7, 5, 9) which(x &gt; 5) ## [1] 5 7 seq(along=x)[x &gt; 5] ## [1] 5 7 这里seq(along=x)会生成由x的下标组成的向量。 用which.min()、which.max求最小值的下标和最大值的下标， 不唯一时只取第一个。如 which.min(x) ## [1] 1 which.max(x) ## [1] 7 7.7 元素名 向量可以为每个元素命名。如 ages &lt;- c(&quot;李明&quot;=30, &quot;张聪&quot;=25, &quot;刘颖&quot;=28) 或 ages &lt;- c(30, 25, 28) names(ages) &lt;- c(&quot;李明&quot;, &quot;张聪&quot;, &quot;刘颖&quot;) 或 ages &lt;- setNames(c(30, 25, 28), c(&quot;李明&quot;, &quot;张聪&quot;, &quot;刘颖&quot;)) 这时可以用元素名或元素名向量作为向量的下标，如 ages[&quot;张聪&quot;] ## 张聪 ## 25 ages[c(&quot;李明&quot;, &quot;刘颖&quot;)] ## 李明 刘颖 ## 30 28 ages[&quot;张聪&quot;] &lt;- 26 这实际上建立了字符串到数值的映射表。 用字符串作为下标时， 如果该字符串不在向量的元素名中， 读取时返回缺失值结果， 赋值时该向量会增加一个元素并以该字符串为元素名。 带有元素名的向量也可以是字符型或其它基本类型，如 sex &lt;- c(&quot;李明&quot;=&quot;男&quot;, &quot;张聪&quot;=&quot;男&quot;, &quot;刘颖&quot;=&quot;女&quot;) 除了给向量元素命名外， 在矩阵和数据框中还可以给行、列命名， 这会使得程序的扩展更为容易和安全。 R允许仅给部分元素命名， 这时其它元素名字为空字符串。 不同元素的元素名一般应该是不同的， 否则在使用元素作为下标时会发生误读， 但是R语法允许存在重名。 用unname(x)返回去掉了元素名的x的副本， 用names(x) &lt;- NULL可以去掉x的元素名。 7.8 用R向量下标作映射 R在使用整数作为向量下标时，允许使用重复下标， 这样可以把数组x看成一个\\(1:n\\)的整数到 x[1], x[2], \\(\\ldots\\), x[n]的一个映射表, 其中\\(n\\)是x的长度。 比如，某商店有三种礼品，编号为1,2,3， 价格分别为68, 88和168。令 price.map &lt;- c(68, 88, 168) 设某个收银员在一天内分别售出礼品编号为3,2,1,1,2,2,3， 可以用如下的映射方式获得售出的这些礼品对应的价格： items &lt;- c(3,2,1,1,2,2,3) y &lt;- price.map[items]; print(y) ## [1] 168 88 68 68 88 88 168 R向量可以用字符型向量作下标， 字符型下标也允许重复， 所以可以把带有元素名的R向量看成是元素名到元素值的映射表。 比如，设sex为10个学生的性别（男、女） sex &lt;- c(&quot;男&quot;, &quot;男&quot;, &quot;女&quot;, &quot;女&quot;, &quot;男&quot;, &quot;女&quot;, &quot;女&quot;, &quot;女&quot;, &quot;女&quot;, &quot;男&quot;) 希望把每个学生按照性别分别对应到蓝色和红色。 首先建立一个R向量当作映射 sex.color &lt;- c(&quot;男&quot;=&quot;blue&quot;, &quot;女&quot;=&quot;red&quot;) 用R向量sex.color当作映射，可以获得每个学生对应的颜色 cols &lt;- sex.color[sex]; print(cols) ## 男 男 女 女 男 女 女 女 女 男 ## &quot;blue&quot; &quot;blue&quot; &quot;red&quot; &quot;red&quot; &quot;blue&quot; &quot;red&quot; &quot;red&quot; &quot;red&quot; &quot;red&quot; &quot;blue&quot; 这样的映射结果中带有不必要的元素名， 用unname()函数可以去掉元素名，如 unname(cols) ## [1] &quot;blue&quot; &quot;blue&quot; &quot;red&quot; &quot;red&quot; &quot;blue&quot; &quot;red&quot; &quot;red&quot; &quot;red&quot; &quot;red&quot; &quot;blue&quot; 7.9 集合运算 可以把向量x看成一个集合，但是其中的元素允许有重复。 用unique(x)可以获得x的所有不同值。如 unique(c(1, 5, 2, 5)) ## [1] 1 5 2 用a %in% x判断a的每个元素是否属于向量x，如 5 %in% c(1,5,2) ## [1] TRUE c(5,6) %in% c(1,5,2) ## [1] TRUE FALSE 与%in运算符类似， 函数match(x, table)对向量x的每个元素， 从向量table中查找其首次出现位置并返回这些位置。 没有匹配到的元素位置返回NA_integer_(整数型缺失值)。 如 match(5, c(1,5,2)) ## [1] 2 match(5, c(1,5,2,5)) ## [1] 2 match(c(2,5), c(1,5,2,5)) ## [1] 3 2 match(c(2,5,0), c(1,5,2,5)) ## [1] 3 2 NA 用intersect(x,y)求交集，结果中不含重复元素，如 intersect(c(5, 7), c(1, 5, 2, 5)) ## [1] 5 用union(x,y)求并集，结果中不含重复元素，如 union(c(5, 7), c(1, 5, 2, 5)) ## [1] 5 7 1 2 用setdiff(x,y)求差集，即x的元素中不属于y的元素组成的集合， 结果中不含重复元素，如 setdiff(c(5, 7), c(1, 5, 2, 5)) ## [1] 7 用setequal(x,y)判断两个集合是否相等， 不受次序与重复元素的影响，如 setequal(c(1,5,2), c(2,5,1)) ## [1] TRUE setequal(c(1,5,2), c(2,5,1,5)) ## [1] TRUE 7.10 练习 设文件class.csv内容如下: name,sex,age,height,weight Alice,F,13,56.5,84 Becka,F,13,65.3,98 Gail,F,14,64.3,90 Karen,F,12,56.3,77 Kathy,F,12,59.8,84.5 Mary,F,15,66.5,112 Sandy,F,11,51.3,50.5 Sharon,F,15,62.5,112.5 Tammy,F,14,62.8,102.5 Alfred,M,14,69,112.5 Duke,M,14,63.5,102.5 Guido,M,15,67,133 James,M,12,57.3,83 Jeffrey,M,13,62.5,84 John,M,12,59,99.5 Philip,M,16,72,150 Robert,M,12,64.8,128 Thomas,M,11,57.5,85 William,M,15,66.5,112 用如下程序可以把上述文件读入为R数据框d.class, 并取出其中的name和age列到变量name和age中： d.class &lt;- read.csv(&quot;class.csv&quot;, header=TRUE, stringsAsFactors=FALSE) name &lt;- d.class[,&quot;name&quot;] age &lt;- d.class[,&quot;age&quot;] 求出age中第3, 5, 7号的值； 用变量age, 求出达到15岁及以上的那些值； 用变量name和age, 求出Mary与James的年龄。 求age中除Mary与James这两人之外的那些人的年龄值，保存到变量age1中。 假设向量x长度为n, 其元素是\\(\\{1,2,\\dots,n \\}\\)的一个重排。 可以把x看成一个i到x[i]的映射(i在\\(\\{1,2,\\dots,n \\}\\)中取值)。 求向量y, 保存了上述映射的逆映射，即： 如果x[i]=j, 则y[j]=i。 "],["prog-type-attr.html", "8 R数据类型的性质 8.1 存储模式与基本类型 8.2 类型转换与类型升档 8.3 属性 8.4 类属 8.5 str()函数", " 8 R数据类型的性质 8.1 存储模式与基本类型 R的变量可以存储多种不同的数据类型， 可以用typeof()函数来返回一个变量或表达式的类型。比如 typeof(1:3) ## [1] &quot;integer&quot; typeof(c(1,2,3)) ## [1] &quot;double&quot; typeof(c(1, 2.1, 3)) ## [1] &quot;double&quot; typeof(c(TRUE, NA, FALSE)) ## [1] &quot;logical&quot; typeof(&#39;Abc&#39;) ## [1] &quot;character&quot; typeof(factor(c(&#39;F&#39;, &#39;M&#39;, &#39;M&#39;, &#39;F&#39;))) ## [1] &quot;integer&quot; 注意因子的结果是integer而不是因子。 R还有两个函数mode()和storage.mode()起到与typeof()类似的作用， 这是为了提供与S语言兼容所遗留的， 应停止使用。 R中数据的最基本的类型包括logical, integer, double, character, complex, raw, 其它数据类型都是由基本类型组合或转变得到的。 character类型就是字符串类型， raw类型是直接使用其二进制内容的类型。 为了判断某个向量x保存的基本类型， 可以用is.xxx()类函数， 如is.integer(x), is.double(x), is.numeric(x), is.logical(x), is.character(x), is.complex(x), is.raw(x)。 其中is.numeric(x)对integer和double内容都返回真值。 在R语言中数值一般看作double, 如果需要明确表明某些数值是整数， 可以在数值后面附加字母L，如 is.integer(c(1, -3)) ## [1] FALSE is.integer(c(1L, -3L)) ## [1] TRUE 整数型的缺失值是NA， 而double型的特殊值除了NA外， 还包括Inf, -Inf和NaN， 其中NaN也算是缺失值, Inf和-Inf不算是缺失值。 如: c(-1, 0, 1)/0 ## [1] -Inf NaN Inf is.na(c(-1, 0, 1)/0) ## [1] FALSE TRUE FALSE 对double类型，可以用is.finite()判断是否有限值， NA、Inf, -Inf和NaN都不是有限值； 用is.infinite()判断是否Inf或-Inf； is.na()判断是否NA或NaN； is.nan()判断是否NaN。 严格说来， NA表示逻辑型缺失值， 但是当作其它类型缺失值时一般能自动识别。 NA_integer_是整数型缺失值， NA_real_是double型缺失值， NA_character_是字符型缺失值。 在R的向量类型中， integer类型、double类型、logical类型、character类型、还有complex类型和raw类型称为原子类型(atomic types)， 原子类型的向量中元素都是同一基本类型的。 比如， double型向量的元素都是double或者缺失值。 除了原子类型的向量， 在R语言的定义中， 向量还包括后面要讲到的列表（list）， 列表的元素不需要属于相同的基本类型， 而且列表的元素可以不是单一基本类型元素。 用typeof()函数可以返回向量的类型， 列表返回结果为\"list\": typeof(list(&quot;a&quot;, 1L, 1.5)) ## [1] &quot;list&quot; 原子类型的各个元素除了基本类型相同， 还不包含任何嵌套结构，如： c(1, c(2,3, c(4,5))) ## [1] 1 2 3 4 5 R有一个特殊的NULL类型， 这个类型只有唯一的一个NULL值， 表示不存在。 NULL长度为0， 不能有任何属性值。 用is.null()函数判断某个变量是否取NULL。 NULL值可以用来表示类型未知的零长度向量， 如c()没有自变量时返回值就是NULL； 也经常用作函数缺省值， 在函数内用is.null()判断其缺省后再用一定的计算逻辑得到真正的缺省情况下的数值。 要把NULL与NA区分开来， NA是有类型的（integer、double、logical、character等), NA表示存在但是未知。 数据库管理系统中的NULL值相当于R中的NA值。 8.2 类型转换与类型升档 可以用as.xxx()类的函数在不同类型之间进行强制转换。 如 as.numeric(c(FALSE, TRUE)) ## [1] 0 1 as.character(sqrt(1:4)) ## [1] &quot;1&quot; &quot;1.4142135623731&quot; &quot;1.73205080756888&quot; &quot;2&quot; 类型转换也可能是隐含的，比如， 四则运算中数值会被统一转换为double类型， 逻辑运算中运算元素会被统一转换为logical类型。 逻辑值转换成数值时，TRUE转换成1， FALSE转换成0。 在用c()函数合并若干元素时， 如果元素基本类型不同， 将统一转换成最复杂的一个，复杂程度从简单到复杂依次为： logical&lt;integer&lt;double&lt;character。 这种做法称为类型升档，如 c(FALSE, 1L, 2.5, &quot;3.6&quot;) ## [1] &quot;FALSE&quot; &quot;1&quot; &quot;2.5&quot; &quot;3.6&quot; 不同类型参与要求类型相同的运算时， 也会统一转换为最复杂的类型， 也称为类型升档， 如： TRUE + 10 ## [1] 11 paste(&quot;abc&quot;, 1) ## [1] &quot;abc 1&quot; 8.3 属性 除了NULL以外， R的变量都可以看成是对象， 都可以有属性。 在R语言中， 属性是把变量看成对象后， 除了其存储内容（如元素）之外的其它附加信息， 如维数、类属等。 R对象一般都有length和mode两个属性。 常用属性有names, dim，class等。 8.3.1 attributes函数 对象x的所有属性可以用attributes()读取， 如 x &lt;- table(c(1,2,1,3,2,1)); print(x) ## ## 1 2 3 ## 3 2 1 attributes(x) ## $dim ## [1] 3 ## ## $dimnames ## $dimnames[[1]] ## [1] &quot;1&quot; &quot;2&quot; &quot;3&quot; ## ## ## $class ## [1] &quot;table&quot; table()函数用了输出其自变量中每个不同值的出现次数，称为频数。 从上例可以看出， table()函数的结果有三个属性，前两个是dim和dimnames, 这是数组(array)具有的属性； 另一个是class属性，值为\"table\"。 因为x是数组，可以访问如 x[1] ## 1 ## 3 x[&quot;3&quot;] ## 3 ## 1 也可以用attributes()函数修改属性， 如 attributes(x) &lt;- NULL x ## [1] 3 2 1 如上修改后x不再是数组，也不是table。 8.3.2 attr函数 可以用attr(x, \"属性名\")的格式读取或定义x的属性。 如： x &lt;- c(1,3,5) attr(x, &quot;theta&quot;) &lt;- c(0, 1) print(x) ## [1] 1 3 5 ## attr(,&quot;theta&quot;) ## [1] 0 1 可以让向量x额外地保存一个theta属性， 这样的属性常常成为“元数据”(meta data)， 比如， 用来保存数据的说明、模拟数据的真实模型参数，等等。 8.3.3 names属性 有元素名的向量、列表、数据框等都有names属性， 许多R函数的输出本质上也是列表， 所以也有names属性。 用names(x)的格式读取或设定。 如： x &lt;- 1:5 y &lt;- x^2 lmr &lt;- lm(y ~ x) print(names(lmr)) ## [1] &quot;coefficients&quot; &quot;residuals&quot; &quot;effects&quot; &quot;rank&quot; ## [5] &quot;fitted.values&quot; &quot;assign&quot; &quot;qr&quot; &quot;df.residual&quot; ## [9] &quot;xlevels&quot; &quot;call&quot; &quot;terms&quot; &quot;model&quot; 对于没有元素名的向量x，names(x)的返回值是NULL。 8.3.4 dim属性 dim属性的存在表明对象是矩阵或一维、多维数组。 如： x &lt;- matrix(1:12, nrow=3, ncol=4) attr(x, &quot;dim&quot;) # 等同于dim(x) ## [1] 3 4 修改dim属性就将向量转换成矩阵（数组）， 或修改了矩阵的性质， 元素按列次序重排填入新的矩阵。如： x &lt;- 1:4 dim(x) &lt;- c(2,2) x ## [,1] [,2] ## [1,] 1 3 ## [2,] 2 4 R允许dim仅有一个元素， 这对应于一维向量， 与普通的没有dim属性的向量有区别。 另外要注意， 取矩阵子集时如果结果仅有一列或一行， 除非用了drop=FALSE选项， 结果不再有dim属性， 退化成了普通向量。 8.4 类属 R具有一定的面向对象语言特征， 其数据类型有一个class属性， 函数class()可以返回变量类型的类属， 比如 typeof(factor(c(&#39;F&#39;, &#39;M&#39;, &#39;M&#39;, &#39;F&#39;))) ## [1] &quot;integer&quot; mode(factor(c(&#39;F&#39;, &#39;M&#39;, &#39;M&#39;, &#39;F&#39;))) ## [1] &quot;numeric&quot; storage.mode(factor(c(&#39;F&#39;, &#39;M&#39;, &#39;M&#39;, &#39;F&#39;))) ## [1] &quot;integer&quot; class(factor(c(&#39;F&#39;, &#39;M&#39;, &#39;M&#39;, &#39;F&#39;))) ## [1] &quot;factor&quot; class(as.numeric(factor(c(&#39;F&#39;, &#39;M&#39;, &#39;M&#39;, &#39;F&#39;)))) ## [1] &quot;numeric&quot; class属性是特殊的。 如果一个对象具有class属性， 某些所谓“通用函数(generic functions)”会针对这样的对象进行专门的操作， 比如， print()函数在显示向量和回归结果时采用完全不同的格式。 这在其它程序设计语言中称为“重载”(overloading)。 class属性用来支持R的S3风格的类， 常用的有factor, 日期，日期时间， 数据框，tibble。 R还有S4、R6等风格的类。 8.5 str()函数 用print()函数可以显示对象内容。 如果内容很多， 显示行数可能也很多。 用str()函数可以显示对象的类型和主要结构及典型内容。例如 s &lt;- 101:200 attr(s,&#39;author&#39;) &lt;- &#39;李小明&#39; attr(s,&#39;date&#39;) &lt;- &#39;2016-09-12&#39; str(s) ## int [1:100] 101 102 103 104 105 106 107 108 109 110 ... ## - attr(*, &quot;author&quot;)= chr &quot;李小明&quot; ## - attr(*, &quot;date&quot;)= chr &quot;2016-09-12&quot; "],["prog-type-date.html", "9 R日期时间 9.1 R日期和日期时间类型 9.2 从字符串生成日期数据 9.3 日期显示格式 9.4 访问日期时间的组成值 9.5 日期舍入计算 9.6 日期计算 9.7 基本R软件的日期功能 9.8 练习", " 9 R日期时间 9.1 R日期和日期时间类型 R日期可以保存为Date类型， 一般用整数保存，数值为从1970-1-1经过的天数。 R中用一种叫做POSIXct和POSIXlt的特殊数据类型保存日期和时间， 可以仅包含日期部分，也可以同时有日期和时间。 技术上，POSIXct把日期时间保存为从1970年1月1日零时到该日期时间的时间间隔秒数， 所以数据框中需要保存日期时用POSIXct比较合适， 需要显示时再转换成字符串形式； POSIXlt把日期时间保存为一个包含年、月、日、星期、时、分、秒等成分的列表， 所以求这些成分可以从POSIXlt格式日期的列表变量中获得。 日期时间会涉及到所在时区、夏时制等问题， 比较复杂。 基础的R用as.Date()、as.POSIXct()等函数生成日期型和日期时间型， R扩展包lubridate提供了多个方便函数， 可以更容易地生成、转换、管理日期型和日期时间型数据。 library(lubridate) ## Warning: 程辑包&#39;lubridate&#39;是用R版本4.0.3 来建造的 ## ## 载入程辑包：&#39;lubridate&#39; ## The following objects are masked from &#39;package:base&#39;: ## ## date, intersect, setdiff, union 9.2 从字符串生成日期数据 函数lubridate::today()返回当前日期： today() ## [1] &quot;2020-12-28&quot; 函数lubridate::now()返回当前日期时间： now() ## [1] &quot;2020-12-28 08:25:04 CST&quot; 结果显示中出现的CST是时区， 这里使用了操作系统提供的当前时区。 CST不是一个含义清晰的时区， 在不同国家对应不同的时区， 在中国代表中国标准时间（北京时间）。 用lubridate::ymd(), lubridate::mdy(), lubridate::dmy()将字符型向量转换为日期型向量，如： ymd(c(&quot;1998-3-10&quot;, &quot;2018-01-17&quot;, &quot;18-1-17&quot;)) ## [1] &quot;1998-03-10&quot; &quot;2018-01-17&quot; &quot;2018-01-17&quot; mdy(c(&quot;3-10-1998&quot;, &quot;01-17-2018&quot;)) ## [1] &quot;1998-03-10&quot; &quot;2018-01-17&quot; dmy(c(&quot;10-3-1998&quot;, &quot;17-01-2018&quot;)) ## [1] &quot;1998-03-10&quot; &quot;2018-01-17&quot; 在年号只有两位数字时，默认对应到1969-2068范围。 lubridate::make_date(year, month, day)可以从三个数值构成日期向量。 如 make_date(1998, 3, 10) ## [1] &quot;1998-03-10&quot; lubridate包的ymd、mdy、dmy等函数添加hms、hm、h等后缀， 可以用于将字符串转换成日期时间。 如 ymd_hms(&quot;1998-03-16 13:15:45&quot;) ## [1] &quot;1998-03-16 13:15:45 UTC&quot; 结果显示中UTC是时区， UTC是协调世界时(Universal Time Coordinated)英文缩写， 是由国际无线电咨询委员会规定和推荐, 并由国际时间局(BIH)负责保持的以秒为基础的时间标度。 UTC相当于本初子午线(即经度0度)上的平均太阳时， 过去曾用格林威治平均时(GMT)来表示. 北京时间比UTC时间早8小时， 以1999年1月1日0000UTC为例， UTC时间是零点， 北京时间为1999年1月1日早上8点整。 在Date()、as.DateTime()、ymd()等函数中， 可以用tz=指定时区， 比如北京时间可指定为tz=\"Etc/GMT+8\"或 tz=\"Asia/Shanghai\"。 lubridate::make_datetime(year, month, day, hour, min, sec) 可以从最多六个数值组成日期时间， 其中时分秒缺省值都是0。 如 make_datetime(1998, 3, 16, 13, 15, 45.2) ## [1] &quot;1998-03-16 13:15:45 UTC&quot; 用lubridate::as_date()可以将日期时间型转换为日期型，如 as_date(as.POSIXct(&quot;1998-03-16 13:15:45&quot;)) ## [1] &quot;1998-03-16&quot; 用lubridate::as_datetime()可以将日期型数据转换为日期时间型，如 as_datetime(as.Date(&quot;1998-03-16&quot;)) ## [1] &quot;1998-03-16 UTC&quot; 9.3 日期显示格式 用as.character()函数把日期型数据转换为字符型, 如 x &lt;- as.POSIXct(c(&#39;1998-03-16&#39;, &#39;2015-11-22&#39;)) as.character(x) ## [1] &quot;1998-03-16&quot; &quot;2015-11-22&quot; 在as.character()中可以用format选项指定显示格式，如 as.character(x, format=&#39;%m/%d/%Y&#39;) ## [1] &quot;03/16/1998&quot; &quot;11/22/2015&quot; 格式中“%Y”代表四位的公元年号， “%m”代表两位的月份数字， “%d”代表两位的月内日期号。 \"15Mar98\"这样的日期在英文环境中比较常见， 但是在R中的处理比较复杂。 在下面的例子中，R日期被转换成了类似\"Mar98\"这样的格式， 在format选项中用了“%b”代表三英文字母月份缩写， 但是因为月份缩写依赖于操作系统默认语言环境， 需要用Sys.setlocale()函数设置语言环境为\"C\"。示例程序如下 x &lt;- as.POSIXct(c(&#39;1998-03-16&#39;, &#39;2015-11-22&#39;)) old.lctime &lt;- Sys.getlocale(&#39;LC_TIME&#39;) Sys.setlocale(&#39;LC_TIME&#39;, &#39;C&#39;) ## [1] &quot;C&quot; as.character(x, format=&#39;%b%y&#39;) ## [1] &quot;Mar98&quot; &quot;Nov15&quot; Sys.setlocale(&#39;LC_TIME&#39;, old.lctime) ## [1] &quot;Chinese (Simplified)_China.936&quot; format选项中的“%y”表示两位数的年份， 应尽量避免使用两位数年份以避免混淆。 包含时间的转换如 x &lt;- as.POSIXct(&#39;1998-03-16 13:15:45&#39;) as.character(x) ## [1] &quot;1998-03-16 13:15:45&quot; as.character(x, format=&#39;%H:%M:%S&#39;) ## [1] &quot;13:15:45&quot; 这里“%H”代表小时（按24小时制）， “%M”代表两位的分钟数字， “%S”代表两位的秒数。 9.4 访问日期时间的组成值 lubridate包的如下函数可以取出日期型或日期时间型数据中的组成部分： year()取出年 month()取出月份数值 mday()取出日数值 yday()取出日期在一年中的序号，元旦为1 wday()取出日期在一个星期内的序号， 但是一个星期从星期天开始， 星期天为1,星期一为2，星期六为7。 hour()取出小时 minute()取出分钟 second()取出秒 比如, 2018-1-17是星期三， 则 month(as.POSIXct(&quot;2018-1-17 13:15:40&quot;)) ## [1] 1 mday(as.POSIXct(&quot;2018-1-17 13:15:40&quot;)) ## [1] 17 wday(as.POSIXct(&quot;2018-1-17 13:15:40&quot;)) ## [1] 4 lubridate的这些成分函数还允许被赋值， 结果就修改了相应元素的值，如 x &lt;- as.POSIXct(&quot;2018-1-17 13:15:40&quot;) year(x) &lt;- 2000 month(x) &lt;- 1 mday(x) &lt;- 1 x ## [1] &quot;2000-01-01 13:15:40 CST&quot; update()可以对一个日期或一个日期型向量统一修改其组成部分的值， 如 x &lt;- as.POSIXct(&quot;2018-1-17 13:15:40&quot;) y &lt;- update(x, year=2000) y ## [1] &quot;2000-01-17 13:15:40 CST&quot; update()函数中可以用year, month, mday, hour, minute, second等参数修改日期的组成部分。 用lubridate包的功能计算周岁如下： age.int &lt;- function(birth, now){ age &lt;- year(now) - year(birth) sele &lt;- (month(now) * 100 + mday(now) &lt; month(birth) * 100 + mday(birth)) ## sele 是那些没有到生日的人 age[sele] &lt;- age[sele] - 1 age } 9.5 日期舍入计算 lubridate包提供了floor_date(), round_date(), ceiling_date()等函数， 对日期可以用unit=指定一个时间单位进行舍入。 时间单位为字符串， 如seconds, 5 seconds, minutes, 2 minutes, hours, days, weeks, months, years等。 比如，以10 minutes为单位， floor_date()将时间向前归一化到10分钟的整数倍， ceiling_date()将时间向后归一化到10分钟的整数倍， round_date()将时间归一化到最近的10分钟的整数倍， 时间恰好是5分钟倍数时按照类似四舍五入的原则向上取整。 例如 x &lt;- ymd_hms(&quot;2018-01-11 08:32:44&quot;) floor_date(x, unit=&quot;10 minutes&quot;) ## [1] &quot;2018-01-11 08:30:00 UTC&quot; ceiling_date(x, unit=&quot;10 minutes&quot;) ## [1] &quot;2018-01-11 08:40:00 UTC&quot; round_date(x, unit=&quot;10 minutes&quot;) ## [1] &quot;2018-01-11 08:30:00 UTC&quot; 如果单位是星期， 会涉及到一个星期周期的开始是星期日还是星期一的问题。 用参数week_start=7指定开始是星期日， week_start=1指定开始是星期一。 9.6 日期计算 在lubridate的支持下日期可以相减， 可以进行加法、除法。 lubridate包提供了如下的三种与时间长短有关的数据类型： 时间长度(duration)，按整秒计算 时间周期(period)，如日、周 时间区间(interval)，包括一个开始时间和一个结束时间 9.6.1 时间长度 R的POSIXct日期时间之间可以相减，如 d1 &lt;- ymd_hms(&quot;2000-01-01 0:0:0&quot;) d2 &lt;- ymd_hms(&quot;2000-01-02 12:0:5&quot;) di &lt;- d2 - d1; di ## Time difference of 1.500058 days 结果显示与日期之间差别大小有关系， 结果是类型是difftime。 lubridate包提供了duration类型， 处理更方便： as.duration(di) ## [1] &quot;129605s (~1.5 days)&quot; lubridate的dseconds(), dminutes(), dhours(), ddays(), dweeks(), dyears()函数可以直接生成时间长度类型的数据，如 dhours(1) ## [1] &quot;3600s (~1 hours)&quot; lubridate的时间长度类型总是以秒作为单位， 可以在时间长度之间相加， 也可以对时间长度乘以无量纲数，如 dhours(1) + dseconds(5) ## [1] &quot;3605s (~1 hours)&quot; dhours(1)*10 ## [1] &quot;36000s (~10 hours)&quot; 可以给一个日期加或者减去一个时间长度， 结果严格按推移的秒数计算， 如 d2 &lt;- ymd_hms(&quot;2000-01-02 12:0:5&quot;) d2 - dhours(5) ## [1] &quot;2000-01-02 07:00:05 UTC&quot; d2 + ddays(10) ## [1] &quot;2000-01-12 12:00:05 UTC&quot; 时间的前后推移在涉及到时区和夏时制时有可能出现未预料到的情况。 用unclass()函数将时间长度数据的类型转换为普通数值， 如： unclass(dhours(1)) ## [1] 3600 9.6.2 时间周期 时间长度的固定单位是秒， 但是像月、年这样的单位， 因为可能有不同的天数， 所以日历中的时间单位往往没有固定的时长。 lubridate包的seconds(), minutes(), hours(), days()， weeks(), years()函数可以生成以日历中正常的周期为单位的时间长度， 不需要与秒数相联系， 可以用于时间的前后推移。 这些时间周期的结果可以相加、乘以无量纲整数： years(2) + 10*days(1) ## [1] &quot;2y 0m 10d 0H 0M 0S&quot; lubridate的月度周期因为与已有函数名冲突， 所以没有提供， 需要使用lubridate::period(num, units=\"month\")的格式， 其中num是几个月的数值。 为了按照日历进行日期的前后平移， 而不是按照秒数进行日期的前后平移， 应该使用这些时间周期。 例如，因为2016年是闰年， 按秒数给2016-01-01加一年，得到的并不是2017-01-01： ymd(&quot;2016-01-01&quot;) + dyears(1) ## [1] &quot;2016-12-31&quot; 使用时间周期函数则得到预期结果： ymd(&quot;2016-01-01&quot;) + years(1) ## [1] &quot;2017-01-01&quot; 9.6.3 时间区间 lubridate提供了%--%运算符构造一个时间期间。 时间区间可以求交集、并集等。 构造如： d1 &lt;- ymd_hms(&quot;2000-01-01 0:0:0&quot;) d2 &lt;- ymd_hms(&quot;2000-01-02 12:0:5&quot;) din &lt;- (d1 %--% d2); din ## [1] 2000-01-01 UTC--2000-01-02 12:00:05 UTC 对一个时间区间可以用除法计算其时间长度，如 din / ddays(1) ## [1] 1.500058 din / dseconds(1) ## [1] 129605 生成时间区间， 也可以用lubridate::interval(start, end)函数，如 interval(ymd_hms(&quot;2000-01-01 0:0:0&quot;), ymd_hms(&quot;2000-01-02 12:0:5&quot;)) ## [1] 2000-01-01 UTC--2000-01-02 12:00:05 UTC 可以指定时间长度和开始日期生成时间区间， 如 d1 &lt;- ymd(&quot;2018-01-15&quot;) din &lt;- as.interval(dweeks(1), start=d1); din ## [1] 2018-01-15 UTC--2018-01-22 UTC 注意这个时间区间表面上涉及到8个日期， 但是实际长度还是只有7天， 因为每一天的具体时间都是按零时计算， 所以区间末尾的那一天实际不含在内。 用lubridate::int_start()和lubridate::int_end()函数访问时间区间的端点，如： int_start(din) ## [1] &quot;2018-01-15 UTC&quot; int_end(din) ## [1] &quot;2018-01-22 UTC&quot; 可以用as.duration()将一个时间区间转换成时间长度， 用as.period()将一个时间区间转换为可变时长的时间周期个数。 用lubridate::int_shift()平移一个时间区间，如 din2 &lt;- int_shift(din, by=ddays(3)); din2 ## [1] 2018-01-18 UTC--2018-01-25 UTC 用lubridate::int_overlaps()判断两个时间区间是否有共同部分，如 int_overlaps(din, din2) ## [1] TRUE 时间区间允许开始时间比结束时间晚， 用lubridate::int_standardize()可以将时间区间标准化成开始时间小于等于结束时间。 lubridate()现在没有提供求交集的功能，一个自定义求交集的函数如下： int_intersect &lt;- function(int1, int2){ n &lt;- length(int1) int1 &lt;- lubridate::int_standardize(int1) int2 &lt;- lubridate::int_standardize(int2) sele &lt;- lubridate::int_overlaps(int1, int2) inter &lt;- rep(lubridate::interval(NA, NA), n) if(any(sele)){ inter[sele] &lt;- lubridate::interval(pmax(lubridate::int_start(int1[sele]), lubridate::int_start(int2[sele])), pmin(lubridate::int_end(int1[sele]), lubridate::int_end(int2[sele]))) } inter } 测试如： d1 &lt;- ymd(c(&quot;2018-01-15&quot;, &quot;2018-01-18&quot;, &quot;2018-01-25&quot;)) d2 &lt;- ymd(c(&quot;2018-01-21&quot;, &quot;2018-01-23&quot;, &quot;2018-01-30&quot;)) din &lt;- interval(d1, d2); din ## [1] 2018-01-15 UTC--2018-01-21 UTC 2018-01-18 UTC--2018-01-23 UTC ## [3] 2018-01-25 UTC--2018-01-30 UTC int_intersect(rep(din[1], 2), din[2:3]) ## [1] 2018-01-18 UTC--2018-01-21 UTC NA--NA 此自定义函数还可以进一步改成允许两个自变量长度不等的情形。 9.7 基本R软件的日期功能 9.7.1 生成日期和日期时间型数据 Sys.date()返回Date类型的当前日期。 Sys.time()返回POSIXct类型的当前日期时间。 对yyyy-mm-dd或yyyy/mm/dd格式的数据， 可以直接用as.Date()转换为Date类型，如： x &lt;- as.Date(&quot;1970-1-5&quot;); x ## [1] &quot;1970-01-05&quot; as.numeric(x) ## [1] 4 as.Date()可以将多个日期字符串转换成Date类型，如 as.Date(c(&quot;1970-1-5&quot;, &quot;2017-9-12&quot;)) ## [1] &quot;1970-01-05&quot; &quot;2017-09-12&quot; 对于非标准的格式，在as.Date()中可以增加一个format选项， 其中用%Y表示四位数字的年， %m表示月份数字，%d表示日数字。如 as.Date(&quot;1/5/1970&quot;, format=&quot;%m/%d/%Y&quot;) ## [1] &quot;1970-01-05&quot; 用as.POSIXct()函数把年月日格式的日期转换为R的标准日期， 没有时间部分就认为时间在午夜。如 as.POSIXct(c(&#39;1998-03-16&#39;)) ## [1] &quot;1998-03-16 CST&quot; as.POSIXct(c(&#39;1998/03/16&#39;)) ## [1] &quot;1998-03-16 CST&quot; 年月日中间的分隔符可以用减号也可以用正斜杠， 但不能同时有减号又有斜杠。 待转换的日期时间字符串，可以是年月日之后隔一个空格以“时:分:秒”格式带有时间。如 as.POSIXct(&#39;1998-03-16 13:15:45&#39;) ## [1] &quot;1998-03-16 13:15:45 CST&quot; 用as.POSIXct()可以同时转换多项日期时间，如 as.POSIXct(c(&#39;1998-03-16 13:15:45&#39;, &#39;2015-11-22 9:45:3&#39;)) ## [1] &quot;1998-03-16 13:15:45 CST&quot; &quot;2015-11-22 09:45:03 CST&quot; 转换后的日期变量有class属性，取值为POSIXct与POSIXt, 并带有一个tzone（时区）属性。 x &lt;- as.POSIXct(c(&#39;1998-03-16 13:15:45&#39;, &#39;2015-11-22 9:45:3&#39;)) attributes(x) ## $class ## [1] &quot;POSIXct&quot; &quot;POSIXt&quot; ## ## $tzone ## [1] &quot;&quot; 在as.POSIXct()函数中用format参数指定一个日期格式。如 as.POSIXct(&#39;3/13/15&#39;, format=&#39;%m/%d/%y&#39;) ## [1] &quot;2015-03-13 CST&quot; 如果日期仅有年和月，必须添加日（添加01为日即可）才能读入。 比如用’1991-12’表示1991年12月，则如下程序将其读入为’1991-12-01’: as.POSIXct(paste(&#39;1991-12&#39;, &#39;-01&#39;, sep=&#39;&#39;), format=&#39;%Y-%m-%d&#39;) ## [1] &quot;1991-12-01 CST&quot; 又如 old.lctime &lt;- Sys.getlocale(&#39;LC_TIME&#39;) Sys.setlocale(&#39;LC_TIME&#39;, &#39;C&#39;) ## [1] &quot;C&quot; as.POSIXct(paste(&#39;01&#39;, &#39;DEC91&#39;, sep=&#39;&#39;), format=&#39;%d%b%y&#39;) ## [1] &quot;1991-12-01 CST&quot; Sys.setlocale(&#39;LC_TIME&#39;, old.lctime) ## [1] &quot;Chinese (Simplified)_China.936&quot; 把'DEC91'转换成了’1991-12-01’。 如果明确地知道时区， 在as.POSIXct()和as.POSIXlt()中可以加选项tz=字符串。 选项tz的缺省值为空字符串， 这一般对应于当前操作系统的默认时区。 但是，有些操作系统和R版本不能使用默认值， 这时可以为tz指定时区， 比如北京时间可指定为tz='Etc/GMT+8'。如 as.POSIXct(&#39;1949-10-01&#39;, tz=&#39;Etc/GMT+8&#39;) ## [1] &quot;1949-10-01 -08&quot; 9.7.2 取出日期时间的组成值 把一个R日期时间值用as.POSIXlt()转换为POSIXlt类型， 就可以用列表元素方法取出其组成的年、月、日、时、分、秒等数值。 如 x &lt;- as.POSIXct(&#39;1998-03-16 13:15:45&#39;) y &lt;- as.POSIXlt(x) cat(1900+y$year, y$mon+1, y$mday, y$hour, y$min, y$sec, &#39;\\n&#39;) ## 1998 3 16 13 15 45 注意year要加1900，mon要加1。 另外，列表元素wday取值1-6时表示星期一到星期六， 取值0时表示星期天。 对多个日期，as.POSIXlt()会把它们转换成一个列表（列表类型稍后讲述）， 这时可以用列表元素year, mon, mday等取出日期成分。如 x &lt;- as.POSIXct(c(&#39;1998-03-16&#39;, &#39;2015-11-22&#39;)) as.POSIXlt(x)$year + 1900 ## [1] 1998 2015 9.7.3 日期计算 因为Date类型是用数值保存的，所以可以给日期加减一个整数，如： x &lt;- as.Date(&quot;1970-1-5&quot;) x1 &lt;- x + 10; x1 ## [1] &quot;1970-01-15&quot; x2 &lt;- x - 5; x2 ## [1] &quot;1969-12-31&quot; 所有的比较运算都适用于日期类型。 可以给一个日期加减一定的秒数，如 as.POSIXct(c(&#39;1998-03-16 13:15:45&#39;)) - 30 ## [1] &quot;1998-03-16 13:15:15 CST&quot; as.POSIXct(c(&#39;1998-03-16 13:15:45&#39;)) + 10 ## [1] &quot;1998-03-16 13:15:55 CST&quot; 但是两个日期不能相加。 给一个日期加减一定天数， 可以通过加减秒数实现，如 as.POSIXct(c(&#39;1998-03-16 13:15:45&#39;)) + 3600*24*2 ## [1] &quot;1998-03-18 13:15:45 CST&quot; 这个例子把日期推后了两天。 用difftime(time1, time2, units='days')计算time1减去time2的天数， 如 x &lt;- as.POSIXct(c(&#39;1998-03-16&#39;, &#39;2015-11-22&#39;)) c(difftime(x[2], x[1], units=&#39;days&#39;)) ## Time difference of 6460 days 函数结果用c()包裹以转换为数值, 否则会带有单位。 调用difftime()时如果前两个自变量中含有时间部分， 则间隔天数也会带有小数部分。如 x &lt;- as.POSIXct(c(&#39;1998-03-16 13:15:45&#39;, &#39;2015-11-22 9:45:3&#39;)) c(difftime(x[2], x[1], units=&#39;days&#39;)) ## Time difference of 6459.854 days difftime()中units选项还可以取为 'secs', 'mins', 'hours'等。 9.8 练习 设文件dates.csv中包含如下内容： &quot;出生日期&quot;,&quot;发病日期&quot; &quot;1941/3/8&quot;,&quot;2007/1/1&quot; &quot;1972/1/24&quot;,&quot;2007/1/1&quot; &quot;1932/6/1&quot;,&quot;2007/1/1&quot; &quot;1947/5/17&quot;,&quot;2007/1/1&quot; &quot;1943/3/10&quot;,&quot;2007/1/1&quot; &quot;1940/1/8&quot;,&quot;2007/1/1&quot; &quot;1947/8/5&quot;,&quot;2007/1/1&quot; &quot;2005/4/14&quot;,&quot;2007/1/1&quot; &quot;1961/6/23&quot;,&quot;2007/1/2&quot; &quot;1949/1/10&quot;,&quot;2007/1/2&quot; 把这个文件读入为R数据框dates.tab， 运行如下程序定义date1和date2变量: date1 &lt;- dates.tab[,&#39;出生日期&#39;] date2 &lt;- dates.tab[,&#39;发病日期&#39;] 把date1、date2转换为R的POSIXct日期型。 求date1中的各个出生年。 计算发病时的年龄，以周岁论（过生日才算）。 把date2中发病年月转换为’monyy’格式，这里mon是如FEB这样英文三字母缩写， yy是两数字的年份。 对诸如’FEB91’, ’OCT15’这样的年月数据， 假设00—20表示21世纪年份，21—99表示20实际年份。 编写R函数，输入这样的字符型向量， 返回相应的POSIXct格式日期， 具体日期都取为相应月份的1号。 这个习题和后两个习题可以预习函数部分来做。 对R的POSIXct日期，写函数转换成’FEB91’, ’OCT15’这样的年月表示， 假设00—20表示21世纪年份，21—99表示20实际年份。 给定两个POSIXct日期向量birth和work， birth为生日，work是入职日期， 编写R函数， 返回相应的入职周岁整数值（不到生日时周岁值要减一）。 "],["prog-type-fact.html", "10 R因子类型 10.1 因子 10.2 table()函数 10.3 tapply()函数 10.4 forcats包的因子函数 10.5 练习", " 10 R因子类型 10.1 因子 R中用因子代表数据中分类变量, 如性别、省份、职业。 有序因子代表有序量度，如打分结果，疾病严重程度等。 用factor()函数把字符型向量转换成因子，如 x &lt;- c(&quot;男&quot;, &quot;女&quot;, &quot;男&quot;, &quot;男&quot;, &quot;女&quot;) sex &lt;- factor(x) sex ## [1] 男 女 男 男 女 ## Levels: 男 女 attributes(sex) ## $levels ## [1] &quot;男&quot; &quot;女&quot; ## ## $class ## [1] &quot;factor&quot; 因子有class属性，取值为\"factor\"， 还有一个levels(水平值)属性， 此属性可以用levels()函数访问，如 levels(sex) ## [1] &quot;男&quot; &quot;女&quot; 因子的levels属性可以看成是一个映射， 把整数值1,2,\\(\\ldots\\)映射成这些水平值， 因子在保存时会保存成整数值1,2,\\(\\ldots\\)等与水平值对应的编号。 这样可以节省存储空间， 在建模计算的程序中也比较有利于进行数学运算。 事实上， read.csv()函数的默认操作会把输入文件的字符型列自动转换成因子， 这对于性别、职业、地名这样的列是合适的， 但是对于姓名、日期、详细地址这样的列则不合适。 所以，在read.csv()调用中经常加选项stringsAsFactors=FALSE选项禁止这样的自动转换，还可以用colClasses选项逐个指定每列的类型。 用as.numeric()可以把因子转换为纯粹的整数值，如 as.numeric(sex) ## [1] 1 2 1 1 2 因为因子实际保存为整数值， 所以对因子进行一些字符型操作可能导致错误。 用as.character()可以把因子转换成原来的字符型，如 as.character(sex) ## [1] &quot;男&quot; &quot;女&quot; &quot;男&quot; &quot;男&quot; &quot;女&quot; 为了对因子执行字符型操作（如取子串）， 保险的做法是先用as.character()函数强制转换为字符型。 factor()函数的一般形式为 factor(x, levels = sort(unique(x), na.last = TRUE), labels, exclude = NA, ordered = FALSE) 可以用选项levels自行指定各水平值, 不指定时由x的不同值来求得。 可以用选项labels指定各水平的标签, 不指定时用各水平值的对应字符串。 可以用exclude选项指定要转换为缺失值(NA)的元素值集合。 如果指定了levels, 则当自变量x的某个元素等于第\\(j\\)个水平值时输出的因子对应元素值取整数\\(j\\), 如果该元素值没有出现在levels中则输出的因子对应元素值取NA。 ordered取真值时表示因子水平是有次序的(按编码次序)。 在使用factor()函数定义因子时， 如果知道自变量元素的所有可能取值， 应尽可能使用levels=参数指定这些不同可能取值， 这样， 即使某个取值没有出现， 此变量代表的含义和频数信息也是完整的。 自己指定levels=的另一好处是可以按正确的次序显示因子的分类统计值。 因为一个因子的levels属性是该因子独有的， 所以合并两个因子有可能造成错误。如 li1 &lt;- factor(c(&#39;男&#39;, &#39;女&#39;)) li2 &lt;- factor(c(&#39;男&#39;, &#39;男&#39;)) c(li1, li2) ## [1] 1 2 1 1 结果不再是因子。 正确的做法是 factor(c(as.character(li1), as.character(li2))) ## [1] 男 女 男 男 ## Levels: 男 女 即恢复成字符型后合并， 然后再转换为因子。 在合并两个数据框时也存在这样的问题。 当然，如果在定义li1和li2 时都用了levels=c('男', '女')选项， c(li1, li2)也能给出正确结果。 10.2 table()函数 用table()函数统计因子各水平的出现次数（称为频数或频率）。 也可以对一般的向量统计每个不同元素的出现次数。 如 table(sex) ## sex ## 男 女 ## 3 2 对一个变量用table函数计数的结果是一个特殊的有元素名的向量， 元素名是自变量的不同取值， 结果的元素值是对应的频数。 单个因子或单个向量的频数结果可以用向量的下标访问方法取出单个频数或若干个频数的子集。 10.3 tapply()函数 可以按照因子分组然后每组计算另一变量的概括统计。 如 h &lt;- c(165, 170, 168, 172, 159) tapply(h, sex, mean) ## 男 女 ## 168.3333 164.5000 这里第一自变量h与与第二自变量sex是等长的， 对应元素分别为同一人的身高和性别， tapply()函数分男女两组计算了身高平均值。 10.4 forcats包的因子函数 library(forcats) 在分类变量类数较多时，往往需要对因子水平另外排序、合并等， forcats包提供了一些针对因子的方便函数。 forcats::fct_reorder()可以根据不同因子水平分成的组中另一数值型变量的统计量值排序。 如： set.seed(1) fac &lt;- sample(c(&quot;red&quot;, &quot;green&quot;, &quot;blue&quot;), 30, replace=TRUE) fac &lt;- factor(fac, levels=c(&quot;red&quot;, &quot;green&quot;, &quot;blue&quot;)) x &lt;- round(100*(10+rt(30,2))) res1 &lt;- tapply(x, fac, sd); res1 ## red green blue ## 370.9222 138.3185 1129.2587 barplot(res1) 如果希望按照统计量次序对因子排序， 可以用forcats::fct_reorder()函数， 如 fac2 &lt;- fct_reorder(fac, x, sd) res2 &lt;- tapply(x, fac2, sd) barplot(res2) 新的因子fac2的因子水平次序已经按照变量x的标准差从小到大排列。 有时在因子水平数较多时仅想将特定的一个或几个水平次序放到因子水平最前面， 可以用forcats::fct_relevel()函数， 如： levels(fac) ## [1] &quot;red&quot; &quot;green&quot; &quot;blue&quot; fac3 &lt;- fct_relevel(fac, &quot;blue&quot;); levels(fac3) ## [1] &quot;blue&quot; &quot;red&quot; &quot;green&quot; fct_relevel()第一个参数是要修改次序的因子， 后续可以有多个字符型参数表示要提前的水平。 forcats::fct_reorder2(f, x, y)也调整因子f的水平的次序， 但是根据与每组中最大的x值相对应的y值大小调整次序， 这样在作多个因子水平对应的曲线图时可以比较容易地区分多条曲线。 forcats::fct_recode()可以修改每个水平的名称， 如： fac4 &lt;- fct_recode( fac, &quot;红&quot;=&quot;red&quot;, &quot;绿&quot;=&quot;green&quot;, &quot;蓝&quot;=&quot;blue&quot;) table(fac4) ## fac4 ## 红 绿 蓝 ## 13 10 7 fct_recode()在修改水平名时允许多个旧水平对应到一个新水平， 从而合并原来的水平。 如果合并很多， 可以用fct_collapse()函数， 如 compf &lt;- fct_collapse( comp, &quot;其它&quot;=c(&quot;&quot;, &quot;无名&quot;, &quot;无应答&quot;), &quot;联想&quot;=c(&quot;联想&quot;, &quot;联想集团&quot;), &quot;百度&quot;=c(&quot;百度&quot;, &quot;百度集团&quot;) ) 如果某个因子频数少的水平很多， 在统计时有过多水平不易展示主要的类别， 可以用forcats::fct_lump(f)合并， 缺省地从最少的类合并一直到“其它”类超过其它最小的类之前， 可以用n=参数指定要保留多少个类。 10.5 练习 设文件class.csv中包含如下内容: name,sex,age,height,weight Alice,F,13,56.5,84 Becka,F,13,65.3,98 Gail,F,14,64.3,90 Karen,F,12,56.3,77 Kathy,F,12,59.8,84.5 Mary,F,15,66.5,112 Sandy,F,11,51.3,50.5 Sharon,F,15,62.5,112.5 Tammy,F,14,62.8,102.5 Alfred,M,14,69,112.5 Duke,M,14,63.5,102.5 Guido,M,15,67,133 James,M,12,57.3,83 Jeffrey,M,13,62.5,84 John,M,12,59,99.5 Philip,M,16,72,150 Robert,M,12,64.8,128 Thomas,M,11,57.5,85 William,M,15,66.5,112 用如下程序把该文件读入为R数据框d.class, 其中的sex列已经自动转换为因子。 取出其中的sex和age列到变量sex和age中 d.class &lt;- read.csv(&#39;class.csv&#39;, header=TRUE) sex &lt;- d.class[,&#39;sex&#39;] age &lt;- d.class[,&#39;age&#39;] 统计并显示列出sex的不同值频数； 分男女两组分别求年龄最大值； 把sex变量转换为一个新的因子，F显示成“Female”，M显示成“Male”。 "],["prog-type-list.html", "11 列表类型 11.1 列表 11.2 列表元素访问 11.3 列表类型转换 11.4 返回列表的函数示例–strsplit()", " 11 列表类型 11.1 列表 R中列表(list)类型来保存不同类型的数据。 一个主要目的是提供R分析结果输出包装： 输出一个变量， 这个变量包括回归系数、预测值、残差、检验结果等等一系列不能放到规则形状数据结构中的内容。 实际上，数据框也是列表的一种， 但是数据框要求各列等长， 而列表不要求。 列表可以有多个元素， 但是与向量不同的是， 列表的不同元素的类型可以不同， 比如， 一个元素是数值型向量， 一个元素是字符串， 一个元素是标量， 一个元素是另一个列表。 定义列表用函数list(), 如 rec &lt;- list(name=&quot;李明&quot;, age=30, scores=c(85, 76, 90)) rec ## $name ## [1] &quot;李明&quot; ## ## $age ## [1] 30 ## ## $scores ## [1] 85 76 90 用typeof()函数判断一个列表， 返回结果为list。 可以用is.list()函数判断某个对象是否列表类型。 11.2 列表元素访问 列表的一个元素也可以称为列表的一个“变量”， 单个列表元素必须用两重方括号格式访问，如 rec[[3]] ## [1] 85 76 90 rec[[3]][2] ## [1] 76 rec[[&quot;age&quot;]] ## [1] 30 列表的单个元素也可以用$格式访问，如 rec$age ## [1] 30 如果使用单重方括号对列表取子集， 结果还是列表而不是列表元素，如 rec[3] ## $scores ## [1] 85 76 90 is.list(rec[3]) ## [1] TRUE 列表一般都应该有元素名， 元素名可以看成是变量名， 列表中的每个元素看成一个变量。 用names()函数查看和修改元素名。 如 names(rec) ## [1] &quot;name&quot; &quot;age&quot; &quot;scores&quot; names(rec)[names(rec)==&quot;scores&quot;] &lt;- &quot;三科分数&quot; names(rec) ## [1] &quot;name&quot; &quot;age&quot; &quot;三科分数&quot; rec[[&quot;三科分数&quot;]] ## [1] 85 76 90 可以修改列表元素内容。 如 rec[[&quot;三科分数&quot;]][2] &lt;- 0 print(rec) ## $name ## [1] &quot;李明&quot; ## ## $age ## [1] 30 ## ## $三科分数 ## [1] 85 0 90 直接给列表不存在的元素名定义元素值就添加了新元素， 而且不同于使用向量，对于列表而言这是很正常的做法，比如 rec[[&quot;身高&quot;]] &lt;- 178 print(rec) ## $name ## [1] &quot;李明&quot; ## ## $age ## [1] 30 ## ## $三科分数 ## [1] 85 0 90 ## ## $身高 ## [1] 178 把某个列表元素赋值为NULL就删掉这个元素。 如 rec[[&quot;age&quot;]] &lt;- NULL print(rec) ## $name ## [1] &quot;李明&quot; ## ## $三科分数 ## [1] 85 0 90 ## ## $身高 ## [1] 178 在list()函数中允许定义元素为NULL，这样的元素是存在的，如： li &lt;- list(a=120, b=&quot;F&quot;, c=NULL); li ## $a ## [1] 120 ## ## $b ## [1] &quot;F&quot; ## ## $c ## NULL 但是，要把已经存在的元素修改为NULL值而不是删除此元素， 或者给列表增加一个取值为NULL的元素， 这时需要用单重的方括号取子集， 这样的子集会保持其列表类型， 给这样的子列表赋值为list(NULL)，如： li[&quot;b&quot;] &lt;- list(NULL) li[&quot;d&quot;] &lt;- list(NULL) li ## $a ## [1] 120 ## ## $b ## NULL ## ## $c ## NULL ## ## $d ## NULL 11.3 列表类型转换 用as.list()把一个其它类型的对象转换成列表； 用unlist()函数把列表转换成基本向量。如 li1 &lt;- as.list(1:3) li1 ## [[1]] ## [1] 1 ## ## [[2]] ## [1] 2 ## ## [[3]] ## [1] 3 li2 &lt;- list(x=1, y=c(2,3)) unlist(li2) ## x y1 y2 ## 1 2 3 11.4 返回列表的函数示例–strsplit() strsplit()输入一个字符型向量并指定一个分隔符， 返回一个项数与字符型向量元素个数相同的列表， 列表每项对应于字符型向量中一个元素的拆分结果。 如 x &lt;- c(&quot;10, 8, 7&quot;, &quot;5, 2, 2&quot;, &quot;3, 7, 8&quot;, &quot;8, 8, 9&quot;) res &lt;- strsplit(x, &quot;,&quot;); res ## [[1]] ## [1] &quot;10&quot; &quot; 8&quot; &quot; 7&quot; ## ## [[2]] ## [1] &quot;5&quot; &quot; 2&quot; &quot; 2&quot; ## ## [[3]] ## [1] &quot;3&quot; &quot; 7&quot; &quot; 8&quot; ## ## [[4]] ## [1] &quot;8&quot; &quot; 8&quot; &quot; 9&quot; 为了把拆分结果进一步转换成一个数值型矩阵， 可以使用sapply()函数如下： t(sapply(res, as.numeric)) ## [,1] [,2] [,3] ## [1,] 10 8 7 ## [2,] 5 2 2 ## [3,] 3 7 8 ## [4,] 8 8 9 sapply()函数是apply类函数之一， 稍后再详细进行讲解。 "],["prog-type-matrix.html", "12 R矩阵和数组 12.1 R矩阵 12.2 矩阵子集 12.3 cbind()和rbind()函数 12.4 矩阵运算 12.5 逆矩阵与线性方程组求解 12.6 apply()函数 12.7 多维数组", " 12 R矩阵和数组 12.1 R矩阵 矩阵用matrix函数定义，实际存储成一个向量，根据保存的行数和列数对应到矩阵的元素， 存储次序为按列存储。 定义如 A &lt;- matrix(11:16, nrow=3, ncol=2); print(A) ## [,1] [,2] ## [1,] 11 14 ## [2,] 12 15 ## [3,] 13 16 B &lt;- matrix(c(1,-1, 1,1), nrow=2, ncol=2, byrow=TRUE); print(B) ## [,1] [,2] ## [1,] 1 -1 ## [2,] 1 1 matrix()函数把矩阵元素以一个向量的形式输入， 用nrow和ncol规定行数和列数，向量元素填入矩阵的缺省次序是按列填入， 用byrow=TRUE选项可以转换成按行填入。 用nrow()和ncol()函数可以访问矩阵的行数和列数，如 nrow(A) ## [1] 3 ncol(A) ## [1] 2 矩阵有一个dim属性，内容是两个元素的向量， 两个元素分别为矩阵的行数和列数。dim属性可以用dim()函数访问。如 attributes(A) ## $dim ## [1] 3 2 dim(A) ## [1] 3 2 函数t(A)返回A的转置。 12.2 矩阵子集 用A[1,]取出A的第一行，变成一个普通向量。 用A[,1]取出A的第一列，变成一个普通向量。 用A[c(1,3),1:2]取出指定行、列对应的子矩阵。 如 A ## [,1] [,2] ## [1,] 11 14 ## [2,] 12 15 ## [3,] 13 16 A[1,] ## [1] 11 14 A[,1] ## [1] 11 12 13 A[c(1,3), 1:2] ## [,1] [,2] ## [1,] 11 14 ## [2,] 13 16 用colnames()函数可以给矩阵每列命名， 也可以访问矩阵列名， 用rownames()函数可以给矩阵每行命名， 也可以访问矩阵行名。如 colnames(A) &lt;- c(&#39;X&#39;, &#39;Y&#39;) rownames(A) &lt;- c(&#39;a&#39;, &#39;b&#39;, &#39;c&#39;) A ## X Y ## a 11 14 ## b 12 15 ## c 13 16 矩阵可以有一个dimnames属性， 此属性是两个元素的列表（列表见稍后部分的介绍）， 两个元素分别为矩阵的行名字符型向量与列名字符型向量。 如果仅有其中之一，缺失的一个取为NULL。 有了列名、行名后，矩阵下标可以用字符型向量， 如 A[,&#39;Y&#39;] ## a b c ## 14 15 16 A[&#39;b&#39;,] ## X Y ## 12 15 A[c(&#39;a&#39;, &#39;c&#39;), &#39;Y&#39;] ## a c ## 14 16 注意在对矩阵取子集时， 如果取出的子集仅有一行或仅有一列， 结果就不再是矩阵而是变成了R向量， R向量既不是行向量也不是列向量。 如果想避免这样的规则起作用， 需要在方括号下标中加选项drop=FALSE， 如 A[,1,drop=FALSE] ## X ## a 11 ## b 12 ## c 13 取出了A的第一列， 作为列向量取出， 所谓列向量实际是列数等于1的矩阵。 如果用常量作为下标， 其结果维数是确定的，不会出问题； 如果用表达式作为下标， 则表达式选出零个、一个、多个下标， 结果维数会有不同， 加drop=FALSE则是安全的做法。 矩阵也可以用逻辑下标取子集，比如 A ## X Y ## a 11 14 ## b 12 15 ## c 13 16 A[A[,1]&gt;=2,&#39;Y&#39;] ## a b c ## 14 15 16 矩阵本质上是一个向量添加了dim属性， 实际保存还是保存成一个向量， 其中元素的保存次序是按列填入， 所以， 也可以向对一个向量取子集那样， 仅用一个正整数向量的矩阵取子集。如 A ## X Y ## a 11 14 ## b 12 15 ## c 13 16 A[c(1,3,5)] ## [1] 11 13 15 为了挑选矩阵的任意元素组成的子集而不是子矩阵， 可以用一个两列的矩阵作为下标， 矩阵的每行的两个元素分别指定一个元素的行号和列号。 如 ind &lt;- matrix(c(1,1, 2,2, 3,2), ncol=2, byrow=TRUE) A ## X Y ## a 11 14 ## b 12 15 ## c 13 16 ind ## [,1] [,2] ## [1,] 1 1 ## [2,] 2 2 ## [3,] 3 2 A[ind] ## [1] 11 15 16 用c(A)或A[]返回矩阵A的所有元素。 如果要修改矩阵A的所有元素， 可以对A[]赋值。 对矩阵A，diag(A)访问A的主对角线元素组成的向量。 另外，若x为正整数值标量，diag(x)返回x阶单位阵； 若x为长度大于1的向量， diag(x)返回以x的元素为主对角线元素的对角矩阵。 12.3 cbind()和rbind()函数 若x是向量，cbind(x)把x变成列向量， 即列数为1的矩阵， rbind(x)把x变成行向量。 若x1, x2, x3是等长的向量， cbind(x1, x2, x3)把它们看成列向量并在一起组成一个矩阵。 cbind()的自变量可以同时包含向量与矩阵，向量的长度必须与矩阵行数相等。 如 cbind(c(1,2), c(3,4), c(5,6)) ## [,1] [,2] [,3] ## [1,] 1 3 5 ## [2,] 2 4 6 cbind(A, c(1,-1,10)) ## X Y ## a 11 14 1 ## b 12 15 -1 ## c 13 16 10 cbind()的自变量中也允许有标量， 这时此标量被重复使用。 如 cbind(1, c(1,-1,10)) ## [,1] [,2] ## [1,] 1 1 ## [2,] 1 -1 ## [3,] 1 10 rbind()用法类似， 可以等长的向量看成行向量上下摞在一起， 可以是矩阵与长度等于矩阵列数的向量上下摞在一起， 向量长度为1也可以。 12.4 矩阵运算 12.4.1 四则运算 矩阵可以与标量作四则运算，结果为每个元素进行相应运算，如 A ## X Y ## a 11 14 ## b 12 15 ## c 13 16 C1 &lt;- A + 2; C1 ## X Y ## a 13 16 ## b 14 17 ## c 15 18 C2 &lt;- A / 2; C2 ## X Y ## a 5.5 7.0 ## b 6.0 7.5 ## c 6.5 8.0 当运算为矩阵乘以一个标量时， 就是线性代数中的矩阵的数乘运算。 两个同形状的矩阵进行加、减运算， 即对应元素相加、相减， 用A + B，A - B表示，如 C1 + C2 ## X Y ## a 18.5 23.0 ## b 20.0 24.5 ## c 21.5 26.0 C1 - C2 ## X Y ## a 7.5 9.0 ## b 8.0 9.5 ## c 8.5 10.0 这就是线性代数中矩阵的加、减运算。 对两个同形状的矩阵， 用*表示两个矩阵对应元素相乘(注意这不是线性代数中的矩阵乘法)， 用/表示两个矩阵对应元素相除。 如 C1 * C2 ## X Y ## a 71.5 112.0 ## b 84.0 127.5 ## c 97.5 144.0 C1 / C2 ## X Y ## a 2.363636 2.285714 ## b 2.333333 2.266667 ## c 2.307692 2.250000 12.4.2 矩阵乘法 用%*%表示矩阵乘法而不是用*表示， 注意矩阵乘法要求左边的矩阵的列数等于右边的矩阵的行数。 如 A ## X Y ## a 11 14 ## b 12 15 ## c 13 16 B ## [,1] [,2] ## [1,] 1 -1 ## [2,] 1 1 C3 &lt;- A %*% B; C3 ## [,1] [,2] ## a 25 3 ## b 27 3 ## c 29 3 12.4.3 向量与矩阵相乘 矩阵与向量进行乘法运算时， 向量按需要解释成列向量或行向量。 当向量左乘矩阵时，看成行向量； 当向量右乘矩阵时，看成列向量。 如 B ## [,1] [,2] ## [1,] 1 -1 ## [2,] 1 1 c(1,1) %*% B ## [,1] [,2] ## [1,] 2 0 B %*% c(1,1) ## [,1] ## [1,] 0 ## [2,] 2 c(1,1) %*% B %*% c(1,1) ## [,1] ## [1,] 2 注意矩阵乘法总是给出矩阵结果， 即使此矩阵已经退化为行向量、列向量甚至于退化为标量也是一样。 如果需要，可以用c()函数把一个矩阵转换成按列拉直的向量。 12.4.4 内积 设x, y是两个向量， 计算向量内积， 可以用sum(x*y)表示。 设\\(A\\), \\(B\\)是两个矩阵， \\(A^T B\\)是广义的内积， 也称为叉积(crossprod)， 结果是一个矩阵， 元素为\\(A\\)的每列与\\(B\\)的每列计算内积的结果。 \\(A^T B\\)在R中可以表示为crossprod(A, B), \\(A^T A\\)可以表示为crossprod(A)。 要注意的是，crossprod()的结果总是矩阵， 所以计算两个向量的内积用sum(x,y)而不用crossprod(x,y)。 12.4.5 外积 R向量支持外积运算， 记为%o%, 结果为矩阵。 x %o% y的第\\(i\\)行第\\(j\\)列元素等于x[i]乘以y[j]。 如 c(1,2,3) %o% c(1, -1) ## [,1] [,2] ## [1,] 1 -1 ## [2,] 2 -2 ## [3,] 3 -3 这种运算还可以推广到x的每一元素与y的每一元素进行其它的某种运算， 而不限于乘积运算，可以用outer(x,y,f)完成， 其中f是某种运算，或者接受两个自变量的函数。 12.5 逆矩阵与线性方程组求解 用solve(A)求A的逆矩阵，如 solve(B) ## [,1] [,2] ## [1,] 0.5 0.5 ## [2,] -0.5 0.5 用solve(A,b)求解线性方程组\\(A x = b\\)中的\\(x\\), 如 solve(B, c(1,2)) ## [1] 1.5 0.5 求解了线性方程组 \\[ \\left(\\begin{array}{rr} 1 &amp; -1 \\\\ 1 &amp; 1 \\end{array} \\right) x = \\left(\\begin{array}{r} 1 \\\\ 2 \\end{array} \\right) \\] 12.6 apply()函数 apply(A, 2, FUN)把矩阵A的每一列分别输入到函数FUN中， 得到对应于每一列的结果，如 D &lt;- matrix(c(6,2,3,5,4,1), nrow=3, ncol=2); D ## [,1] [,2] ## [1,] 6 5 ## [2,] 2 4 ## [3,] 3 1 apply(D, 2, sum) ## [1] 11 10 apply(A, 1, FUN)把矩阵A的每一行分别输入到函数FUN中， 得到与每一行对应的结果，如 apply(D, 1, mean) ## [1] 5.5 3.0 2.0 如果函数FUN返回多个结果， 则apply(A, 2, FUN)结果为矩阵， 矩阵的每一列是输入矩阵相应列输入到FUN的结果， 结果列数等于A的列数。如 apply(D, 2, range) ## [,1] [,2] ## [1,] 2 1 ## [2,] 6 5 如果函数FUN返回多个结果， 为了对每行计算FUN的结果， 结果存入一个与输入的矩阵行数相同的矩阵， 应该用t(apply(A, 1, FUN))的形式， 如 t(apply(D, 1, range)) ## [,1] [,2] ## [1,] 5 6 ## [2,] 2 4 ## [3,] 1 3 12.7 多维数组 矩阵是多维数组(array)的特例。 矩阵是\\(x_{ij}, i=1,2,\\dots,n,\\; j=1,2,\\dots,m\\)这样的两下标数据的存贮格式， 三维数组是\\(x_{ijk}, i=1,2,\\dots,n,\\; j=1,2,\\dots,m,\\; k=1,2,\\dots,p\\)这样的三下标数据的存贮格式， \\(s\\)维数组则是有\\(s\\)个下标的数据的存贮格式。 实际上， 给一个向量添加一个dim属性就可以把它变成多维数组。 多维数组的一般定义语法为 数组名 &lt;- array(数组元素, dim=c(第一下标个数, 第二下标个数, ..., 第s下标个数)) 其中数组元素的填入次序是第一下标变化最快， 第二下标次之， 最后一个下标是变化最慢的。 这种次序称为FORTRAN次序。 下面是一个三维数组定义例子。 ara &lt;- array(1:24, dim=c(2,3,4)); ara ## , , 1 ## ## [,1] [,2] [,3] ## [1,] 1 3 5 ## [2,] 2 4 6 ## ## , , 2 ## ## [,1] [,2] [,3] ## [1,] 7 9 11 ## [2,] 8 10 12 ## ## , , 3 ## ## [,1] [,2] [,3] ## [1,] 13 15 17 ## [2,] 14 16 18 ## ## , , 4 ## ## [,1] [,2] [,3] ## [1,] 19 21 23 ## [2,] 20 22 24 这样的数组保存了\\(x_{ijk}, i=1,2,\\; j=1,2,3,\\; k=1,2,3,4\\)。 三维数组ara可以看成是4个\\(2 \\times 3\\)矩阵。 取出其中一个如ara[,,2](取出第二个矩阵) ara[,,2] ## [,1] [,2] [,3] ## [1,] 7 9 11 ## [2,] 8 10 12 多维数组可以利用下标进行一般的子集操作， 比如ara[,2, 2:3] 是\\(x_{ijk}, i=1,2,\\; j=2,\\; k=2,3\\)的值， 结果是一个\\(2 \\times 2\\)矩阵: ara[,2,2:3] ## [,1] [,2] ## [1,] 9 15 ## [2,] 10 16 多维数组在取子集时如果某一维下标是标量， 则结果维数会减少， 可以在方括号内用drop=FALSE选项避免这样的规则发生作用。 类似于矩阵， 多维数组可以用一个矩阵作为下标， 如果是三维数组，矩阵就需要有3列， 四维数组需要用4列矩阵。 下标矩阵的每行对应于一个数组元素。 "],["prog-type-df.html", "13 数据框 13.1 数据框 13.2 数据框内容访问 13.3 数据框的行名 13.4 数据框与矩阵的区别 13.5 tidyr::expand_grid()函数 13.6 tibble类型 13.7 练习", " 13 数据框 13.1 数据框 统计分析中最常见的原始数据形式是类似于数据库表或Excel数据表的形式。 这样形式的数据在R中叫做数据框(data.frame)。 数据框类似于一个矩阵，有\\(n\\)行、\\(p\\)列， 但各列允许有不同类型：数值型向量、因子、字符型向量、日期时间向量。 同一列的数据类型相同。 在R中数据框是一个特殊的列表， 其每个列表元素都是一个长度相同的向量。 事实上，数据框还允许一个元素是一个矩阵， 但这样会使得某些读入数据框的函数发生错误。 函数data.frame()可以生成数据框，如 d &lt;- data.frame( name=c(&quot;李明&quot;, &quot;张聪&quot;, &quot;王建&quot;), age=c(30, 35, 28), height=c(180, 162, 175), stringsAsFactors=FALSE) print(d) ## name age height ## 1 李明 30 180 ## 2 张聪 35 162 ## 3 王建 28 175 data.frame()函数会将字符型列转换成因子， 加选项stringsAsFactors=FALSE可以避免这样的转换。 如果数据框的某一列为常数， 可以在data.frame()调用中仅给该列赋一个值， 生成的结果会自动重复这个值使得该列与其他列等长。 nrow(d)求d的行数， ncol(d)或length(d)求d的列数。 数据框每列叫做一个变量， 每列都有名字，称为列名或变量名， 可以用names()函数和colnames()函数访问。 如 names(d) ## [1] &quot;name&quot; &quot;age&quot; &quot;height&quot; colnames(d) ## [1] &quot;name&quot; &quot;age&quot; &quot;height&quot; 给names(d)或colnames(d)赋值可以修改列名。 用as.data.frame(x)可以把x转换成数据框。 如果x是一个向量， 转换结果是以x为唯一一列的数据框。 如果x是一个列表并且列表元素都是长度相同的向量， 转换结果中每个列表变成数据框的一列。 如果x是一个矩阵，转换结果把矩阵的每列变成数据框的一列。 数据框是一个随着R语言前身S语言继承下来的概念， 现在已经有一些不足之处， tibble包提供了tibble类， 这是数据框的一个改进版本。 13.2 数据框内容访问 数据框可以用矩阵格式访问，如 d[2,3] ## [1] 162 访问单个元素。 d[[2]] ## [1] 30 35 28 访问第二列，结果为向量。 d[,2] ## [1] 30 35 28 也访问第二列，但是这种作法与tibble不兼容， 所以应避免使用。 按列名访问列可用如 d[[&quot;age&quot;]] ## [1] 30 35 28 d[,&quot;age&quot;] ## [1] 30 35 28 d$age ## [1] 30 35 28 其中第二种做法与tibble不兼容，应避免使用。 因为数据框的一行不一定是相同数据类型， 所以数据框的一行作为子集， 结果还是数据框，而不是向量。如 x &lt;- d[2,]; x ## name age height ## 2 张聪 35 162 is.data.frame(x) ## [1] TRUE 可以同时取行子集和列子集，如 d[1:2, &quot;age&quot;] ## [1] 30 35 d[1:2, c(&quot;age&quot;, &quot;height&quot;)] ## age height ## 1 30 180 ## 2 35 162 d[d[,&quot;age&quot;]&gt;=30,] ## name age height ## 1 李明 30 180 ## 2 张聪 35 162 与矩阵类似地是， 用如d[,\"age\"], d[,2]这样的方法取出的数据框的单个列是向量而不再是数据框。 但是，如果取出两列或者两列以上， 结果则是数据框。 如果取列子集时不能预先知道取出的列个数， 则子集结果有可能是向量也有可能是数据框， 容易造成后续程序错误。 对一般的数据框， 可以在取子集的方括号内加上drop=FALSE选项， 确保取列子集的结果总是数据框。 数据框的改进类型tibble在取出列子集时保持为tibble格式。 对数据框变量名按照字符串与集合进行操作可以实现复杂的列子集筛选。 13.3 数据框的行名 数据框每一行可以有行名， 这在原始的S语言和传统的R语言中是重要的技术， 但是在改进类型tibble中则取消了行名， 需要用列名实现功能一般改用left_join()函数实现。 比如，每一行定义行名为身份证号，则可以唯一识别各行。 下面的例子以姓名作为行名: rownames(d) &lt;- d$name d$name &lt;- NULL d ## age height ## 李明 30 180 ## 张聪 35 162 ## 王建 28 175 用数据框的行名可以建立一个值到多个值的对应表。 比如，有如下的数据框： dm &lt;- data.frame( &quot;年级&quot;=1:6, &quot;出游&quot;=c(0, 2, 2, 2, 2, 1), &quot;疫苗&quot;=c(T, F, F, F, T, F) ) 其中“出游”是每个年级安排的出游次数， “疫苗”是该年级有全体无计划免疫注射。 把年级变成行名，可以建立年级到出游次数与疫苗注射的对应表： rownames(dm) &lt;- dm[[&quot;年级&quot;]] dm[[&quot;年级&quot;]] &lt;- NULL 这样，假设某个社区的小学中抽取的4个班的年级为 c(2,1,1,3)， 其对应的出游和疫苗注射信息可查询如下： ind &lt;- c(2,1,1,3) dm[as.character(ind),] ## 出游 疫苗 ## 2 2 FALSE ## 1 0 TRUE ## 1.1 0 TRUE ## 3 2 FALSE 结果中包含了不必要也不太合适的行名，可以去掉，以上程序改成： ind &lt;- c(2,1,1,3) xx &lt;- dm[as.character(ind),] rownames(xx) &lt;- NULL xx ## 出游 疫苗 ## 1 2 FALSE ## 2 0 TRUE ## 3 0 TRUE ## 4 2 FALSE 如果要从多个值建立映射， 比如，从省名与县名映射到经度、纬度， 可以预先用paste()函数把省名与县名合并在一起， 中间以适当字符（如`-``)分隔， 以这样的合并字符串为行名。 实际上，这个例子可以不用行名而是用match()函数实现。 match(x, table)对x的每个元素返回其在table中出现的位置序号。 找不到的元素返回NA。 如： match(c(12, 15), 11:14) ## [1] 2 NA 对于上面的学校年级信息查询的例子， 可以首先查找每个班对应的年级在数据框中的行序号， 然后再返回这些行组成的数据框： dm &lt;- data.frame( &quot;年级&quot;=1:6, &quot;出游&quot;=c(0, 2, 2, 2, 2, 1), &quot;疫苗&quot;=c(T, F, F, F, T, F) ) ind &lt;- match(c(2,1,1,3), dm[[&quot;年级&quot;]]); ind ## [1] 2 1 1 3 dm[ind,] ## 年级 出游 疫苗 ## 2 2 2 FALSE ## 1 1 0 TRUE ## 1.1 1 0 TRUE ## 3 3 2 FALSE 对于代替数据框的tibble类型， 如果要实现行名的功能， 可以将行名作为单独的一列， 然后用dplyr包的inner_join()、left_join()、full_join()等函数横向合并数据集。 参见26.19。 13.4 数据框与矩阵的区别 数据框不能作为矩阵参加矩阵运算。 需要时，可以用as.matrix()函数转换数据框或数据框的子集为矩阵。 如 d2 &lt;- as.matrix(d[,c(&quot;age&quot;, &quot;height&quot;)]) d3 &lt;- crossprod(d2); d3 ## age height ## age 2909 15970 ## height 15970 89269 这里crossprod(A)表示\\(A^T A\\)。 13.5 tidyr::expand_grid()函数 可以用数据框保存试验结果， 对有多个因素的试验， 往往需要生成多个因素完全搭配并重复的表格。 tidyr包的函数expand_grid()可以生成这样的重复模式。 比如，下面的例子： d4 &lt;- tidyr::expand_grid( group=1:3, subgroup=1:2, obs=1:2) print(d4) ## # A tibble: 12 x 3 ## group subgroup obs ## &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 1 1 1 ## 2 1 1 2 ## 3 1 2 1 ## 4 1 2 2 ## 5 2 1 1 ## 6 2 1 2 ## 7 2 2 1 ## 8 2 2 2 ## 9 3 1 1 ## 10 3 1 2 ## 11 3 2 1 ## 12 3 2 2 结果的数据框d有三个变量: group是大组，共分3个大组，每组4个观测； subgroup是子组，在每个大组内分为2个子组，每个子组2个观测。 共有\\(3 \\times 2 \\times 2 = 12\\)个观测（行）。 13.6 tibble类型 tibble类型是一种改进的数据框。 readr包的read_csv()函数是read.csv()函数的一个改进版本， 它将CSV文件读入为tibble类型，如文件class.csv的读入: library(tibble) library(readr) t.class &lt;- read_csv(&quot;class.csv&quot;) ## Parsed with column specification: ## cols( ## name = col_character(), ## sex = col_character(), ## age = col_double(), ## height = col_double(), ## weight = col_double() ## ) t.class ## # A tibble: 19 x 5 ## name sex age height weight ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Alice F 13 56.5 84 ## 2 Becka F 13 65.3 98 ## 3 Gail F 14 64.3 90 ## 4 Karen F 12 56.3 77 ## 5 Kathy F 12 59.8 84.5 ## 6 Mary F 15 66.5 112 ## 7 Sandy F 11 51.3 50.5 ## 8 Sharon F 15 62.5 112. ## 9 Tammy F 14 62.8 102. ## 10 Alfred M 14 69 112. ## 11 Duke M 14 63.5 102. ## 12 Guido M 15 67 133 ## 13 James M 12 57.3 83 ## 14 Jeffrey M 13 62.5 84 ## 15 John M 12 59 99.5 ## 16 Philip M 16 72 150 ## 17 Robert M 12 64.8 128 ## 18 Thomas M 11 57.5 85 ## 19 William M 15 66.5 112 tibble类型的类属依次为tbl_df, tbl, data.frame： class(t.class) ## [1] &quot;spec_tbl_df&quot; &quot;tbl_df&quot; &quot;tbl&quot; &quot;data.frame&quot; 用as_tibble()可以将一个数据框转换为tibble, dplyr包提供了filter()、select()、arrange()、mutate() 等函数用来对tibble选取行子集、列子集，排序、修改或定义新变量，等等。 见26。 可以用tibble()函数生成小的tibble，如 t.bp &lt;- tibble( `序号`=c(1,5,6,9,10,15), `收缩压`=c(145, 110, &quot;未测&quot;, 150, &quot;拒绝&quot;, 115)) t.bp ## # A tibble: 6 x 2 ## 序号 收缩压 ## &lt;dbl&gt; &lt;chr&gt; ## 1 1 145 ## 2 5 110 ## 3 6 未测 ## 4 9 150 ## 5 10 拒绝 ## 6 15 115 在调用tibble()函数时， 定义在后面的列可以调用前面的列的值。 用tribble可以按类似于CSV格式输入一个tibble, 如 t.bp2 &lt;- tribble( ~`序号`,~`收缩压`, 1,145, 5,110, 6,NA, 9,150, 10,NA, 15,115 ) t.bp2 ## # A tibble: 6 x 2 ## 序号 收缩压 ## &lt;dbl&gt; &lt;dbl&gt; ## 1 1 145 ## 2 5 110 ## 3 6 NA ## 4 9 150 ## 5 10 NA ## 6 15 115 注意tribble()中数据每行末尾也需要有逗号， 最后一行末尾没有逗号。 这比较适用于在程序中输入小的数据集。 一列中混杂数值型和字符型会出错。 tibble与数据框的一大区别是在显示时不自动显示所有内容， 这样可以避免显示很大的数据框将命令行的所有显示都充满。 没有显示的列的列名会罗列在显示下方， 显示时每列的类型同时显示，也会显示tibble的行列数。 可以在print()用n=和width=选项指定要显示的行数和列数。 tibble在生成或输入时不自动将字符型列转换为因子。 另外，用单重的方括号取列子集时， 即使仅取一列， 从tibble取出的一列结果仍是tibble而不是向量， 这时应使用双方括号格式或$格式。 因为这个原因有些原来的程序输入tibble会出错， 这时可以用as.data.frame()转换成数据框。 如： t.bp[,&quot;收缩压&quot;] ## # A tibble: 6 x 1 ## 收缩压 ## &lt;chr&gt; ## 1 145 ## 2 110 ## 3 未测 ## 4 150 ## 5 拒绝 ## 6 115 t.bp[[&quot;收缩压&quot;]] ## [1] &quot;145&quot; &quot;110&quot; &quot;未测&quot; &quot;150&quot; &quot;拒绝&quot; &quot;115&quot; tibble在定义时不需要列名为合法变量名， 但是作为变量名使用时需要用反单撇号包裹。 tibble不支持行名(rownames)， 有行名的数据框用as_tibble()转换为tibble时， 可以用rownames=\"变量名\"选项将行名转换成tibble的一列， 该列的变量名由选项值确定。 原来用行名完成的功能， 可以改用dplyr包的left_join()等函数， 这些函数进行数据框的横向连接。 详见26。 实际上，旧式数据框支持行名，有如下的缺点： 行名本身往往也是有效的数据，如身份证号， 将有效数据以数据框中的列和行名两种不同形式保存， 增加了复杂度； 为了使用某些变量辨识不同的行（观测）， 行名也具有局限性： 行名必须是相互不同的， 必须是字符型， 而用来区分各个观测的变量有可能有多个， 也可能不是字符型。 行名要求互不相同是有局限性的， 如果用来辨识各行的变量有重复值， 就可以构成对各行的一种自然的分组。 tibble类型允许其中的列是列表类型， 这样， 该列的每个元素就可以是复杂类型， 比如建模结果（列表）， 元素之间可以保存不等长的值。 如： tibble(x = 1:3, y = list(1, 1:2, 1:3)) ## # A tibble: 3 x 2 ## x y ## &lt;int&gt; &lt;list&gt; ## 1 1 &lt;dbl [1]&gt; ## 2 2 &lt;int [2]&gt; ## 3 3 &lt;int [3]&gt; 13.7 练习 假设class.csv已经读入为R数据框d.class, 其中的sex列已经自动转换为因子。 显示d.class中年龄至少为15的行子集； 显示女生且年龄至少为15的学生姓名和年龄； 取出数据框中的age变量赋给变量x。 "],["prog-type-ws.html", "14 工作空间和变量赋值 14.1 工作空间 14.2 非法变量名 14.3 变量赋值与绑定 14.4 环境", " 14 工作空间和变量赋值 14.1 工作空间 R把在命令行定义的变量都保存到工作空间中， 在退出R时可以选择是否保存工作空间。 这也是R与其他如C、Java这样的语言的区别之一。 用ls()命令可以查看工作空间中的内容。 随着多次在命令行使用R， 工作空间的变量越来越多， 使得重名的可能性越来越大， 而且工作空间中变量太多也让我们不容易查看其内容。 在命令行定义的变量称为“全局变量”， 在编程实际中， 全局变量是需要慎用的。 可以用rm()函数删除工作空间中的变量，格式如 rm(d, h, name, rec, sex, x) 要避免工作空间杂乱， 最好的办法还是所有的运算都写到自定义函数中。 自定义函数中定义的变量都是临时的， 不会保存到工作空间中。 这样，仅需要时才把变量值在命令行定义， 这样的变量一般是读入的数据或自定义的函数 （自定义函数也保存在工作空间中）。 可以定义如下的sandbox()函数： sandbox &lt;- function(){ cat(&#39;沙盘：接连的空行回车可以退出。\\n&#39;) browser() } 运行sandbox()函数，将出现如下的browser命令行： 沙盘：接连的空行回车可以退出。 Called from: sandbox() Browse[1]&gt; 提示符变成了“Browser[n]”，其中n代表层次序号。 在这样的browser命令行中随意定义变量， 定义的变量不会保存到工作空间中。 用“Q”命令可以退出这个沙盘环境， 接连回车也可以退出。 14.2 非法变量名 R的变量名要求由字母、数字、下划线、小数点组成， 开头不能是数字、下划线、小数点， 中间不能使用空格、减号、井号等特殊符号， 变量名不能与if、NA等保留字相同。 有时为了与其它软件系统兼容， 需要使用不符合规则的变量名， 这只要将变量名两边用反向单撇号“`”保护， 如： `max score` &lt;- 100 99 + `max score` ## [1] 199 如果变量名（元素名、列名等）是以字符串形式使用， 就不需要用“`”保护。如： x &lt;- c(&quot;score a&quot;=85, &quot;score b&quot;=66) x ## score a score b ## 85 66 14.3 变量赋值与绑定 本小节内容技术上比较复杂， 初学者可以略过。 在R中赋值本质上是把一个存储的对象与一个变量名“绑定”(bind)在一起， 比如： x &lt;- c(1,2,3) 并不是像C++、JAVA等语言那样， x代表某个存储位置， “x &lt;- c(1,2,3)”代表将1到3这些值存储到x所指向的存储位置。 实际上，&lt;-右边的c(1,2,3)是一个表达式， 其结果为一个R对象(object)， 而x只是一个变量名， 并没有固定的类型、固定的存储位置， 赋值的结果是将x绑定到值为(1,2,3)的R对象上。 R对象有值，但不必有对应的变量名； 变量名必须经过绑定才有对应的值和存储位置。 这样，同一个R对象可以被两个或多个变量名绑定。 对于基本的数据类型如数值型向量， 两个指向相同对象的变量当一个变量被修改时自动制作副本。 tracemem(x)可以显示变量名x绑定的地址并在其被制作副本时显示地址变化。 如： x &lt;- c(1,2,3) cat(tracemem(x), &quot;\\n&quot;) ## &lt;0000000018288290&gt; y &lt;- x # 这时y和x绑定到同一R对象 cat(tracemem(y), &quot;\\n&quot;) ## &lt;0000000018288290&gt; y[3] &lt;- 0 # 这时y制作了副本 ## tracemem[0x0000000018288290 -&gt; 0x00000000183c5190]: eval eval withVisible withCallingHandlers handle timing_fn evaluate_call &lt;Anonymous&gt; evaluate in_dir block_exec call_block process_group.block process_group withCallingHandlers process_file &lt;Anonymous&gt; &lt;Anonymous&gt; do.call eval eval eval eval eval.parent local x ## [1] 1 2 3 y ## [1] 1 2 0 untracemem(x); untracemem(y) 可见y &lt;- x并没有制作副本， 但是修改y[3]值时就对y制作了副本。 如果某个变量名所指向的对象没有被其他变量名绑定， 则修改其元素值并不需要制作副本，如： x &lt;- c(1,2,3) cat(tracemem(x), &quot;\\n&quot;) ## &lt;00000000188C09D0&gt; x[3] &lt;- 0 ## tracemem[0x00000000188c09d0 -&gt; 0x000000001895b270]: eval eval withVisible withCallingHandlers handle timing_fn evaluate_call &lt;Anonymous&gt; evaluate in_dir block_exec call_block process_group.block process_group withCallingHandlers process_file &lt;Anonymous&gt; &lt;Anonymous&gt; do.call eval eval eval eval eval.parent local x ## [1] 1 2 0 untracemem(x) 在调用函数时， 如果函数内部不修改自变量的元素值， 输入的自变量并不制作副本， 而是直接被函数使用实参绑定的对象。 如： x &lt;- c(1,2,3) cat(tracemem(x), &quot;\\n&quot;) ## &lt;0000000018DA05A0&gt; f &lt;- function(v){ return(v) } z &lt;- f(x) cat(tracemem(z), &quot;\\n&quot;) ## &lt;0000000018DA05A0&gt; untracemem(x); untracemem(z) 从上面的例子可以看出， 函数f以x为实参， 但不修改x的元素， 不会生成x的副本， 返回的值是x指向的对象本身， 再次赋值给z， 也不制作副本， z和x绑定到同一对象。 如果函数内部修改自变量的元素值， 则输入的自变量也会制作副本。 如： x &lt;- c(1,2,3) cat(tracemem(x), &quot;\\n&quot;) ## &lt;000000001931EE70&gt; f2 &lt;- function(v){ v[1] &lt;- -999; return(v) } z &lt;- f2(x) ## tracemem[0x000000001931ee70 -&gt; 0x00000000193d8880]: f2 eval eval withVisible withCallingHandlers handle timing_fn evaluate_call &lt;Anonymous&gt; evaluate in_dir block_exec call_block process_group.block process_group withCallingHandlers process_file &lt;Anonymous&gt; &lt;Anonymous&gt; do.call eval eval eval eval eval.parent local cat(tracemem(z), &quot;\\n&quot;) ## &lt;00000000193D8880&gt; untracemem(x); untracemem(z) 从程序输出看， 函数f2()以x为实参， 并修改x的内部元素， 就制作了x的副本， 返回的结果赋给变量z， 绑定的是修改后的副本。 如果在函数中对自变量重新赋值， 这实际是重新绑定， 也不会制作输入的实参的副本。 如果修改y的元素值时还修改了其存储类型， 比如整型改为浮点型， 则会先制作y的副本， 然后制作类型改变后的副本， 然后再修改其中的元素值。 在当前的R语言中， 一个对象的引用（如绑定的变量名）个数， 只区分0个、1个或多个这三种情况。 在没有引用时， R的垃圾收集器会定期自动清除这些对象。 rm(x)只是删除绑定， 并不会马上清除x绑定的对象。 如果已经有多个引用， 即使是只有2个， 减少一个引用也还是“多个”状态， 不会变成1个。 垃圾收集器是在R程序要求分配新的对象空间时自动运行的， R函数gc()可以要求马上运行垃圾收集器， 并返回当前程序用道的存储量； lobstr包的mem_used()函数则报告当前会话内存字节数。 在上面的示例中， 用了基本类型的向量讲解是否制作副本。 考虑其它类型的复制。 如果x是一个有5个元素的列表， 则y &lt;- x使得y和x指向同一个列表对象。 但是， 列表对象的每个元素实际上也相当于一个绑定， 每个元素指向一个元素值对象。 所以如果修改y：y[[3]] &lt;- 0， 这时列表y首先被制作了副本， 但是每个元素指向的元素值对象不变， 仍与x的各个元素指向的对象相同； 然后， y[[3]]指向的元素值进行了重新绑定， 不再指向x[[3]]， 而是指向新的保存了值0的对象， 但y的其它元素指向的对象仍与x公用。 列表的这种复制方法称为浅拷贝， 表格对象及各个元素绑定被复制， 但各个元素指向（保存）的对象不变。 这种做法节省空间也节省运行时间。 在R的3.1.0之前则用的深拷贝方法， 即复制列表时连各个元素保存的值也制作副本。 如果x是一个数据框， 这类似于一个列表， 每个变量相当于一个列表元素， 数据框的每一列实际绑定到一个对象上。 如果y &lt;- x， 则修改y的某一列会对y进行浅拷贝， 然后仅该列被制作了副本并被修改， 其它未修改的列仍与x共用值对象。 但是如果修改数据框y的一行， 因为这涉及到所有列， 所以整个数据框的所有列都会制作副本。 对于字符型向量， 实际上R程序的所有字符型常量都会建立一个全局字符串池， 这样有许多重复值时可以节省空间。 用lobstr包的obj_size()函数可以求变量的存储大小， 如obj_size(x)， 也可以求若干个变量的总大小， 如obj_size(x,y)。 因为各种绑定到同一对象的可能性， 所以变量的存储大小可能会比想象要少， 比如， 共用若干列的两个数据框， 字符型向量， 等等。 基本R软件的object.size()则不去检查是否有共享对象， 所以对列表等变量的存储大小估计可能会偏高。 从R 3.5.0版开始，1:n这种对象仅保存其开始值和结束值。 在自定义函数时， 自变量通常是按引用使用的， 函数内部仅使用自变量的值而不对其进行修改时不会制作副本， 但是如果函数内部修改了自变量的值， 就会制作副本， 当自变量的存储很大而且返回调用这个函数时就会造成运行速度缓慢。 在函数内应慎重修改自变量的值。 在循环中修改数据框的列， 也会造成反复的复制。 14.4 环境 前面讲的工作空间就是一个环境， 称为“全局环境”。 环境可以认为是包含了变量绑定和函数定义的一个对象， 对环境的修改都不会制作副本。 一般我们只需要用到全局环境， 在自定义函数的运行过程中会有一个局部的运行环境， 但是在函数内定义的嵌套函数可以带有其定义处的环境， 这样可以实现有历史记忆的函数， 类似于其它面向对象程序设计语言如C++等， 对象可以同时有状态（变量成员）和适用操作（方法成员）。 环境的应用将在“函数进阶”部分讲到内嵌函数、函数工厂时详细讲解。 "],["prog-io.html", "15 R输入输出 15.1 输入输出的简单方法 15.2 读取CSV文件 15.3 Excel表访问 15.4 文件访问 15.5 中文编码问题 15.6 目录和文件管理 15.7 SQL数据库访问", " 15 R输入输出 15.1 输入输出的简单方法 15.1.1 简单的输出 用print()函数显示某个变量或表达式的值， 如 x &lt;- 1.234 print(x) ## [1] 1.234 y &lt;- c(1,3,5) print(y[2:3]) ## [1] 3 5 在命令行使用R时， 直接以变量名或表达式作为命令可以起到用print()函数显示的相同效果。 用cat()函数把字符串、变量、表达式连接起来显示， 其中变量和表达式的类型一般是标量或向量，不能是矩阵、列表等复杂数据。 如 cat(&quot;x =&quot;, x, &quot;\\n&quot;) ## x = 1.234 cat(&quot;y =&quot;, y, &quot;\\n&quot;) ## y = 1 3 5 注意cat()显示中需要换行需要在自变量中包含字符串\"\\n\"， 即换行符。 cat()默认显示在命令行窗口， 为了写入指定文件中， 在cat()调用中用file=选项， 这时如果已有文件会把原有内容覆盖， 为了在已有文件时不覆盖原有内容而是在末尾添加， 在cat()中使用append=TRUE选项。 如: cat(&quot;=== 结果文件 ===\\n&quot;, file=&quot;res.txt&quot;) cat(&quot;x =&quot;, x, &quot;\\n&quot;, file=&quot;res.txt&quot;, append=TRUE) 函数sink()可以用来把命令行窗口显示的运行结果转向保存到指定的文本文件中， 如果希望保存到文件的同时也在命令行窗口显示， 使用split=TRUE选项。如 sink(&quot;allres.txt&quot;, split=TRUE) 为了取消这样的输出文件记录， 使用不带自变量的sink()调用，如 sink() 在R命令行环境中定义的变量、函数会保存在工作空间中， 并在退出R会话时可以保存到硬盘文件中。 用save()命令要求把指定的若干个变量（直接用名字，不需要表示成字符串） 保存到用file=指定的文件中， 随后可以用load()命令恢复到工作空间中。 虽然允许保存多个变量到同一文件中， 但尽可能仅保存一个变量， 而且使用变量名作为文件名。 用save()保存的R特殊格式的文件是通用的， 不依赖于硬件和操作系统。 如 save(scores, file=&quot;scores.RData&quot;) load(&quot;scores.RData&quot;) 保存多个变量，如x, zeta，命令如： save(x, zeta, file=&quot;myvars20200315.RData&quot;) 或 save(list = c(&quot;x&quot;, &quot;zeta&quot;), file=&quot;myvars20200315.RData&quot;) 对于一个数据框， 可以用write.csv()或readr::write_csv()将其保存为逗号分隔的文本文件， 这样的文件可以很容易地被其它软件识别访问， 如Microsoft Excel软件可以很容易地把这样的文件读成电子表格。 用如 da &lt;- tibble(&quot;name&quot;=c(&quot;李明&quot;, &quot;刘颖&quot;, &quot;张浩&quot;), &quot;age&quot;=c(15, 17, 16)) write_csv(da, path=&quot;mydata.csv&quot;) 结果生成的mydata.csv文件内容如下： name,age 李明,15 刘颖,17 张浩,16 但是，在Microsoft的中文版Windows操作系统中， 默认编码是GB编码， 用write_csv()生成的CSV文件总是使用UTF-8编码， 系统中的MS Office 软件不能自动识别这样编码的CSV文件， 可以改用write_csv_excel()函数； 基本R的write.csv()函数不存在这个问题。 15.1.2 简单的输入 用scan()函数可以输入文本文件中的数值向量， 文件名用file=选项给出。 文件中数值之间以空格分开。如 cat(1:12, &quot;\\n&quot;, file=&quot;d:/work/x.txt&quot;) x &lt;- scan(&quot;d:/work/x.txt&quot;) 程序中用全路径给出了输入文件位置， 注意路径中用了正斜杠/作为分隔符， 如果在MS Windows环境下使用\\作为分隔符， 在R的字符串常量中\\必须写成\\\\。 如果scan()中忽略输入文件参数， 此函数将从命令行读入数据。 可以在一行用空格分开多个数值， 可以用多行输入直到空行结束输入。 这样的方法也可以用来读入矩阵。 设文件mat.txt包含如下矩阵内容: 3 4 2 5 12 10 7 8 6 1 9 11 可以先把文件内容读入到一个R向量中， 再利用matrix()函数转换成矩阵， 注意要使用byrow=TRUE选项， 而且只要指定ncol选项， 可以忽略nrow选项。如 M &lt;- matrix(scan(&quot;mat.txt&quot;, quiet=TRUE), ncol=3, byrow=TRUE) M scan()中的quite=TRUE选项使得读入时不自动显示读入的数值项数。 上面读入数值矩阵的方法在数据量较大的情形也可以使用， 与之不同的是， read.table()或readr::read_table()函数也可以读入这样的数据， 但是会保存成数据框而不是矩阵， 而且read.table()函数在读入大规模的矩阵时效率很低。 15.2 读取CSV文件 15.2.1 CSV格式 对于保存在文本文件中的电子表格数据， R可以用read.csv(), read.table(), read.delim(), read.fwf()等函数读入, 但是建议在readr包的支持下用read_csv(), read_table2(), read_delim(), read_fwf()等函数读入， 这些将读入的数据框保存为tibble类型， tibble是数据框的一个变种， 改善了数据框的一些不适当的设计。 readr的读入速度比基本R软件的read.csv()等函数的速度快得多， 速度可以相差10倍， 也不自动将字符型列转换成因子， 不自动修改变量名为合法变量名， 不设置行名。 对于中小规模的数据， CSV格式作为文件交换格式比较合适， 兼容性强， 各种数据管理软件与统计软件都可以很容易地读入和生成这样格式的文件， 但是特别大型的数据读入效率很低。 CSV格式的文件用逗号分隔开同一行的数据项， 一般第一行是各列的列名（变量名）。 对于数值型数据， 只要表示成数值常量形式即可。 对于字符型数据， 可以用双撇号包围起来， 也可以不用撇号包围。 但是， 如果数据项本身包含逗号， 就需要用双撇号包围。 例如，下面是一个名为testcsv.csv的文件内容， 其中演示了内容中有逗号、有双撇号的情况。 id,words 1,&quot;PhD&quot; 2,Master&#39;s degree 3,&quot;Bond,James&quot; 4,&quot;A &quot;&quot;special&quot;&quot; gift&quot; 为读入上面的内容，只要用如下程序: d &lt;- read_csv(&quot;testcsv.csv&quot;) 读入的数据框显示如下: # A tibble: 4 × 2 id words &lt;int&gt; &lt;chr&gt; 1 1 PhD 2 2 Master&#39;s degree 3 3 Bond,James 4 4 A &quot;special&quot; gift 15.2.2 从字符串读入 read_csv()还可以从字符串读入一个数据框，如 d.small &lt;- read_csv(&quot;name,x,y John, 33, 95 Kim, 21, 64 Sandy, 49, 100 &quot;) d.small ## # A tibble: 3 x 3 ## name x y ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 John 33 95 ## 2 Kim 21 64 ## 3 Sandy 49 100 15.2.3 read_csv选项 read_csv()的skip=选项跳过开头的若干行。 当数据不包含列名时， 只要指定col_names=FALSE， 变量将自动命名为X1, X2, ...， 也可以用col_names=指定各列的名字，如 d.small &lt;- read_csv(&quot;John, 33, 95 Kim, 21, 64 Sandy, 49, 100 &quot;, col_names=c(&quot;name&quot;, &quot;x&quot;, &quot;y&quot;) ) d.small ## # A tibble: 3 x 3 ## name x y ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 John 33 95 ## 2 Kim 21 64 ## 3 Sandy 49 100 15.2.4 编码设置 CSV文件是文本文件，是有编码问题的， 尤其是中文内容的文件。 readr包的默认编码是UTF-8编码。 例如，文件bp.csv以GBK编码（有时称为GB18030编码， 这是中文Windows所用的中文编码）保存了如下内容： 序号,收缩压 1,145 5,110 6, 未测 9,150 10, 拒绝 15,115 如果直接用read_csv()： d &lt;- read_csv(&quot;bp.csv&quot;) 可能在读入时出错，或者访问时出错。 为了读入用GBK编码的中文CSV文件， 需要利用locale参数和locale()函数： d &lt;- read_csv(&quot;bp.csv&quot;, locale=locale(encoding=&quot;GBK&quot;)) ## Parsed with column specification: ## cols( ## 序号 = col_double(), ## 收缩压 = col_character() ## ) d ## # A tibble: 6 x 2 ## 序号 收缩压 ## &lt;dbl&gt; &lt;chr&gt; ## 1 1 145 ## 2 5 110 ## 3 6 未测 ## 4 9 150 ## 5 10 拒绝 ## 6 15 115 15.2.5 缺失值设置 read_csv()将空缺的值读入为缺失值， 将“NA”也读入为缺失值。 可以用na=选项改变这样的设置。 也可以将带有缺失值的列先按字符型原样读入， 然后再进行转换。 比如，上面的bp.csv文件中， 先将血压列按字符型读入， 再增加一列转换为数值型的列， 非数值转换为NA: d &lt;- read_csv(&quot;bp.csv&quot;, locale=locale(encoding=&quot;GBK&quot;)) ## Parsed with column specification: ## cols( ## 序号 = col_double(), ## 收缩压 = col_character() ## ) d[[&quot;收缩压数值&quot;]] &lt;- as.numeric(d[[&quot;收缩压&quot;]]) ## Warning: 强制改变过程中产生了NA d ## # A tibble: 6 x 3 ## 序号 收缩压 收缩压数值 ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 1 145 145 ## 2 5 110 110 ## 3 6 未测 NA ## 4 9 150 150 ## 5 10 拒绝 NA ## 6 15 115 115 15.2.6 各列类型设置 对每列的类型， readr用前1000行猜测合理的类型， 并在读取后显示猜测的每列类型。 但是有可能类型改变发生在1000行之后。 col_types选项可以指定每一列的类型， 如\"col_double()\", \"col_integer()\", \"col_character()\", \"col_factor()\", \"col_date()\", \"col_datetime\"等。 cols()函数可以用来规定各列类型， 并且有一个.default参数指定缺省类型。 对因子，需要在col_factor()中用lelvels=指定因子水平。 可以复制readr猜测的类型作为col_types的输入， 这样当数据变化时不会因为偶尔猜测错误而使得程序出错。如 d &lt;- read_csv(&quot;bp.csv&quot;, locale=locale(encoding=&quot;GBK&quot;), col_types=cols( `序号` = col_integer(), `收缩压` = col_character() )) d ## # A tibble: 6 x 2 ## 序号 收缩压 ## &lt;int&gt; &lt;chr&gt; ## 1 1 145 ## 2 5 110 ## 3 6 未测 ## 4 9 150 ## 5 10 拒绝 ## 6 15 115 当猜测的文件类型有问题的时候， 可以先将所有列都读成字符型， 然后用type_convert()函数转换， 如： d &lt;- read_csv(&quot;filename.csv&quot;, col_types=cols(.default = col_character())) d &lt;- type_convert(d) 读入有错时，对特大文件可以先少读入一些行， 用nmax=可以指定最多读入多少行。 调试成功后再读入整个文件。 15.2.7 因子类型设置 设文件class.csv内容如下： name,sex,age,height,weight Alice,F,13,56.5,84 Becka,F,13,65.3,98 Gail,F,14,64.3,90 Karen,F,12,56.3,77 Kathy,F,12,59.8,84.5 Mary,F,15,66.5,112 Sandy,F,11,51.3,50.5 Sharon,F,15,62.5,112.5 Tammy,F,14,62.8,102.5 Alfred,M,14,69,112.5 Duke,M,14,63.5,102.5 Guido,M,15,67,133 James,M,12,57.3,83 Jeffrey,M,13,62.5,84 John,M,12,59,99.5 Philip,M,16,72,150 Robert,M,12,64.8,128 Thomas,M,11,57.5,85 William,M,15,66.5,112 最简单地用read_csv()读入上述CSV文件，程序如: d.class &lt;- read_csv(&quot;class.csv&quot;) ## Parsed with column specification: ## cols( ## name = col_character(), ## sex = col_character(), ## age = col_double(), ## height = col_double(), ## weight = col_double() ## ) 从显示看出， 读入后显示了每列的类型。 对性别变量，没有自动转换成因子， 而是保存为字符型。 为了按自己的要求转换各列类型， 用了read_csv()的coltypes=选项和cols()函数如下： d.class &lt;- read_csv( &quot;class.csv&quot;, col_types=cols( .default = col_double(), name=col_character(), sex=col_factor(levels=c(&quot;M&quot;, &quot;F&quot;)) )) str(d.class) ## Classes &#39;spec_tbl_df&#39;, &#39;tbl_df&#39;, &#39;tbl&#39; and &#39;data.frame&#39;: 19 obs. of 5 variables: ## $ name : chr &quot;Alice&quot; &quot;Becka&quot; &quot;Gail&quot; &quot;Karen&quot; ... ## $ sex : Factor w/ 2 levels &quot;M&quot;,&quot;F&quot;: 2 2 2 2 2 2 2 2 2 1 ... ## $ age : num 13 13 14 12 12 15 11 15 14 14 ... ## $ height: num 56.5 65.3 64.3 56.3 59.8 66.5 51.3 62.5 62.8 69 ... ## $ weight: num 84 98 90 77 84.5 ... ## - attr(*, &quot;spec&quot;)= ## .. cols( ## .. .default = col_double(), ## .. name = col_character(), ## .. sex = col_factor(levels = c(&quot;M&quot;, &quot;F&quot;), ordered = FALSE, include_na = FALSE), ## .. age = col_double(), ## .. height = col_double(), ## .. weight = col_double() ## .. ) 其中str()函数可以显示数据框的行数(obs.)和变量数(variables)， 以及每个变量（列）的类属等信息。 15.2.8 读入日期 设文件dates.csv中包含如下内容，并设其文件编码为GBK: 序号,出生日期,发病日期 1,1941/3/8,2007/1/1 2,1972/1/24,2007/1/1 3,1932/6/1,2007/1/1 4,1947/5/17,2007/1/1 5,1943/3/10,2007/1/1 6,1940/1/8,2007/1/1 7,1947/8/5,2007/1/1 8,2005/4/14,2007/1/1 9,1961/6/23,2007/1/2 10,1949/1/10,2007/1/2 可以先把日期当作字符串读入: d.dates &lt;- read_csv(&#39;dates.csv&#39;, locale=locale(encoding=&quot;GBK&quot;)) ## Parsed with column specification: ## cols( ## 序号 = col_double(), ## 出生日期 = col_character(), ## 发病日期 = col_character() ## ) 然后用lubridate::ymd()函数转换为R日期类型： d.dates[[&quot;出生日期ct&quot;]] &lt;- lubridate::ymd( d.dates[[&quot;出生日期&quot;]], tz=&#39;Etc/GMT+8&#39;) d.dates[[&quot;发病日期ct&quot;]] &lt;- lubridate::ymd( d.dates[[&quot;发病日期&quot;]], tz=&#39;Etc/GMT+8&#39;) 也可以用R本身的as.POSIXct函数转换： d.dates[[&quot;出生日期ct&quot;]] &lt;- as.POSIXct( d.dates[[&quot;出生日期&quot;]], format=&#39;%Y/%m/%d&#39;, tz=&#39;Etc/GMT+8&#39;) d.dates[[&quot;发病日期ct&quot;]] &lt;- as.POSIXct( d.dates[[&quot;发病日期&quot;]], format=&#39;%Y/%m/%d&#39;, tz=&#39;Etc/GMT+8&#39;) 这时保存的是POSIXct类型。 经过转换后的数据为: knitr::kable(d.dates) 序号 出生日期 发病日期 出生日期ct 发病日期ct 1 1941/3/8 2007/1/1 1941-03-08 2007-01-01 2 1972/1/24 2007/1/1 1972-01-24 2007-01-01 3 1932/6/1 2007/1/1 1932-06-01 2007-01-01 4 1947/5/17 2007/1/1 1947-05-17 2007-01-01 5 1943/3/10 2007/1/1 1943-03-10 2007-01-01 6 1940/1/8 2007/1/1 1940-01-08 2007-01-01 7 1947/8/5 2007/1/1 1947-08-05 2007-01-01 8 2005/4/14 2007/1/1 2005-04-14 2007-01-01 9 1961/6/23 2007/1/2 1961-06-23 2007-01-02 10 1949/1/10 2007/1/2 1949-01-10 2007-01-02 也可以用R本身的as.Date函数转换： d.dates[[&quot;出生日期ct&quot;]] &lt;- as.Date( d.dates[[&quot;出生日期&quot;]], format=&#39;%Y/%m/%d&#39;) d.dates[[&quot;发病日期ct&quot;]] &lt;- as.Date( d.dates[[&quot;发病日期&quot;]], format=&#39;%Y/%m/%d&#39;) 这时保存的是Date类型。 上面将日期先读入为字符型再转换是比较保险的做法。 还可以直接在read_csv()函数中指定某列为col_date()： d.dates &lt;- read_csv( &#39;dates.csv&#39;, locale=locale(encoding=&quot;GBK&quot;), col_types=cols( `序号`=col_integer(), `出生日期`=col_date(format=&quot;%Y/%m/%d&quot;), `发病日期`=col_date(format=&quot;%Y/%m/%d&quot;) )) print(d.dates) ## # A tibble: 10 x 3 ## 序号 出生日期 发病日期 ## &lt;int&gt; &lt;date&gt; &lt;date&gt; ## 1 1 1941-03-08 2007-01-01 ## 2 2 1972-01-24 2007-01-01 ## 3 3 1932-06-01 2007-01-01 ## 4 4 1947-05-17 2007-01-01 ## 5 5 1943-03-10 2007-01-01 ## 6 6 1940-01-08 2007-01-01 ## 7 7 1947-08-05 2007-01-01 ## 8 8 2005-04-14 2007-01-01 ## 9 9 1961-06-23 2007-01-02 ## 10 10 1949-01-10 2007-01-02 15.2.9 其它函数 除了read_csv()函数以外， R扩展包readr还提供了其它的从文本数据读入数据框的函数， 如read_table2(), read_tsv(), read_fwf()等。 这些函数读入的结果保存为tibble。 read_table2()读入用空格作为间隔的文本文件， 同一行的两个数据项之间可以用一个或多个空格分隔， 不需要空格个数相同， 也不需要上下对齐。 read_tsv()读入用制表符分隔的文件。 read_fwf()读入上下对齐的文本文件。 另外， read_lines()函数将文本文件各行读入为一个字符型向量。 read_file()将文件内容读入成一整个字符串， read_file_raw()可以不管文件编码将文件读入为一个二进制字符串。 对特别大的文本格式数据， data.table扩展包的fread()读入速度更快。 readr包的write_excel_csv()函数将tibble保存为csv文件， 总是使用UTF-8编码，结果可以被MS Office读取。 文本格式的文件都不适用于大型数据的读取与保存。 大型数据可以通过数据库接口访问， 可以用R的save()和load()函数按照R的格式访问， 还有一些特殊的针对大数据集的R扩展包。 15.3 Excel表访问 15.3.1 借助于文本格式 为了把Microsoft Excel格式的数据读入到R中， 最容易的办法是在Excel软件中把数据表转存为CSV格式， 然后用read.csv()读取。 为了把R的数据框保存为Excel格式， 只要用write.csv()把数据框保存成CSV格式，然后在Excel中打开即可。 例如，下面的程序演示了write.csv()的使用: d1 &lt;- tibble(&quot;学号&quot;=c(&quot;101&quot;, &quot;103&quot;, &quot;104&quot;), &quot;数学&quot;=c(85, 60, 73), &quot;语文&quot;=c(90, 78, 80)) write.csv(d1, file=&quot;tmp1.csv&quot;, row.names=FALSE) 保存在文件中的结果显示如下： 学号,数学,语文 101,85,90 103,60,78 104,73,80 15.3.2 使用剪贴板 为了把Excel软件中数据表的选中区域读入到R中， 可以借助于剪贴板。 在Excel中复制选中的区域，然后在R中用如 myDF &lt;- read.delim(&quot;clipboard&quot;) 就可以把选中部分转换成一个R的数据框。 如果复制的区域不含列名， 应加上header=FALSE选项。 这种方法也可以从R中复制数据到在Excel中打开的电子表格中， 例如 write.table(iris, file=&quot;clipboard&quot;, sep = &quot;\\t&quot;, col.names = NA) 首先把指定的数据框（这里是iris）写入到了剪贴板， 然后在用Excel软件打开的工作簿中只要粘贴就可以。 上述程序中write.table()函数把指定的数据框写入到指定的文件中, 其中的col.names=NA选项是一个特殊的约定， 这时保存的文件中第一行是列名， 如果有行名的话，行名所在的列对应的列名是空白的（但是存在此项）。 如果从R中复制数据框到打开的Excel文件中时不带行名， 但是带有列名，可以写这样一个通用函数 write.clipboard &lt;- function(df){ write.table(df, file=&quot;clipboard&quot;, sep=&quot;\\t&quot;, row.names=FALSE) } 15.3.3 利用readxl扩展包 readxl扩展包的readxl()函数利用独立的C和C++库函数读入.xls和.xlsx格式的Excel文件。一般格式为 read_excel(path, sheet = 1, col_names = TRUE, col_types = NULL, na = &quot;&quot;, skip = 0) 结果返回读入的表格为一个数据框。 各个自变量为： path: 要读入的Excel文件名，可以是全路径，路径格式要符合所用操作系统要求。 sheet: 要读入哪一个工作簿(sheet)，可以是整数序号，也可以是工作簿名称的字符串。 col_names: 是否用第一行内容作为列名，缺省为是。 col_types: 可以在读入时人为指定各列的数据类型，缺省时从各列内容自动判断，有可能会不够准确。人为指定时，指定一个对应于各列的字符型向量，元素可取值为: blank: 自动判断该列； numeric: 数值型； date: 日期； text: 字符型。 writexl扩展包可以用来将数据框保存为Excel格式。 除了readxl和writexl扩展包， XLConnect, xlsx, tidyxl也可以进行与Excel文件或者Excel软件的交互。 15.4 文件访问 15.4.1 连接 输入输出可以针对命令行，针对文件，R支持扩展的文件类型， 称为“连接(connection)”。 函数file()生成到一个普通文件的连接， 函数url()生成一个到指定的URL的连接， 函数gzfile, bzfile, xzfile, unz支持对 压缩过的文件的访问（不是压缩包，只对一个文件压缩）。这些函数大概的用法如下： file(&quot;path&quot;, open=&quot;&quot;, blocking=T, encoding = getOption(&quot;encoding&quot;), raw = FALSE) url(description, open = &quot;&quot;, blocking = TRUE, encoding = getOption(&quot;encoding&quot;)) textConnection(description, open=&quot;r&quot;, local = FALSE, encoding = c(&quot;&quot;, &quot;bytes&quot;, &quot;UTF-8&quot;)) gzfile(description, open = &quot;&quot;, encoding = getOption(&quot;encoding&quot;), compression = 6) bzfile(description, open = &quot;&quot;, encoding = getOption(&quot;encoding&quot;), compression = 9) xzfile(description, open = &quot;&quot;, encoding = getOption(&quot;encoding&quot;), compression = 6) unz(description, filename, open = &quot;&quot;, encoding = getOption(&quot;encoding&quot;)) 生成连接的函数不自动打开连接。 给定一个未打开的连接， 读取函数从中读取时会自动打开连接， 函数结束时自动关闭连接。 用open()函数打开连接，返回一个句柄； 生成连接时可以用open参数要求打开连接。 要多次从一个连接读取时就应该先打开连接， 读取完毕用close函数关闭。 函数textConnection()打开一个字符串用于读写。 在生成连接与打开连接的函数中用open参数指定打开方式， 取值为： r—文本型只读; w—文本型只写; a—文本型末尾添加; rb—二进制只读; wb—二进制只写; ab—二进制末尾添加; r+或r+b—允许读和写; w+或w+b—允许读和写，但刚打开时清空文件; a+或a+b—末尾添加并允许读。 15.4.2 文本文件访问 函数readLines()、readr::read_lines()、scan()可以从一个文本型连接读取。 给定一个打开的连接con或文件名， 用readLines函数可以把文件各行读入为字符型向量的各个元素， 不包含文件中用来分开各行的换行标志。 可以指定要读的行数。 如 ll &lt;- readLines(&quot;class.csv&quot;) print(head(ll, 3)) ## [1] &quot;name,sex,age,height,weight&quot; &quot;Alice,F,13,56.5,84&quot; ## [3] &quot;Becka,F,13,65.3,98&quot; 用readr包的read_lines()如： ll &lt;- readr::read_lines(&quot;class.csv&quot;) print(head(ll, 3)) ## [1] &quot;name,sex,age,height,weight&quot; &quot;Alice,F,13,56.5,84&quot; ## [3] &quot;Becka,F,13,65.3,98&quot; 用writeLines函数可以把一个字符型向量各元素作为不同行写入一个文本型连接。如 vnames &lt;- strsplit(ll, &quot;,&quot;)[[1]] writeLines(vnames, &quot;class-names.txt&quot;) 其中的第二参数应该是一个打开的文本型写入连接， 但是可以直接给出一个要写入的文件名。 用readr包的write_lines(): readr::write_lines(vnames, &quot;class-names.txt&quot;) 用scan函数读入用空格和空行分隔的字符串向量： vnames &lt;- scan( &quot;class-names.txt&quot;, what=character(), quiet=TRUE) vnames ## [1] &quot;name&quot; &quot;sex&quot; &quot;age&quot; &quot;height&quot; &quot;weight&quot; 15.4.3 文本文件分批读写 readLines()、readr::read_lines()、 writeLines()、readr::write_lines()支持分批读写。 这需要预先打开要读取和写入的文件， 所有内容都处理一遍以后关闭读取和写入的文件。 使用file()函数打开文件用于读写， 使用close()函数关闭打开的文件。 打开文件时可以用encoding=指定编码， 但是readr::read_lines()不支持分批读入。 下面的程序每次从class.csv读入至多10行， 不加处理地写入tmp.csv中， 使用readLines()和writeLines(): fin &lt;- file(&quot;class.csv&quot;, &quot;rt&quot;) fout &lt;- file(&quot;tmp.csv&quot;, &quot;wt&quot;) repeat{ lines &lt;- readLines(fin, n=10) cat(&quot;Read&quot;, length(lines), &quot;lines.&quot;, &quot;\\n&quot;) if(length(lines)==0) break writeLines(lines, fout) } close(fout) close(fin) readr::read_lines()尽管文档中可以从一个文件连接读入， 但经测试发现不支持。 readr::write_lines()可以用append=TRUE选项向一个文件分批写出。 15.4.4 二进制文件访问 函数save用来保存R变量到文件， 函数load用来从文件中读取保存的R变量。 函数readBin和writeBin对R变量进行二进制文件存取。 如果要访问其它软件系统的二进制文件， 请参考R手册中的“R Data Import/Export Manual”。 15.4.5 字符型连接 函数textConnection打开一个字符串用于读取或写入， 是很好用的一个R功能。 可以把一个小文件存放在一个长字符串中， 然后用textConnection读取，如 fstr &lt;- &quot;name,score 王芳,78 孙莉,85 张聪,80 &quot; d &lt;- read.csv(textConnection(fstr), header=T) print(d) 读取用的textConnection的参数是一个字符型变量。 在整理输出结果时，经常可以向一个字符型变量连接写入， 最后再输出整个字符串值。 例如： tc &lt;- textConnection(&quot;sres&quot;, open=&quot;w&quot;) cat(&quot;Trial of text connection.\\n&quot;, file=tc) cat(1:10, &quot;\\n&quot;, file=tc, append=T) close(tc) print(sres) 注意写入用的textConnection 的第一个参数是保存了将要写入的字符型变量名的字符串， 而不是变量名本身， 第二个参数表明是写入操作， 使用完毕需要用close关闭。 15.5 中文编码问题 读写文本格式的数据， 或者用readLines()、readr::read_lines()读写文本文件， 可能会遇到中文编码不匹配的问题。 这里总结一些常用解决方法， 所用的操作系统为中文Windows10, 在RStudio中运行，R版本为3.4.3。 常见的中文编码有GBK(或GB18030, GB)， UTF-8， UTF-8有BOM标志等。 可以用iconvlist()查看R支持的编码名称。 假设有如下的含有中文的文件： 序号,收缩压 1,145 5,110 6, 未测 9,150 10, 拒绝 15,115 这个文件是在中文版MS Office的Excel软件中输入后， 用Office的“文件——另存为——.csv格式”生成的， 结果的编码是GBK编码， 或GB18030编码。 文件下载： bp.csv 我们用工具软件将其转换成UTF-8无BOM格式，下载链接： bp-utf8nobom.csv 转为UTF-8有BOM格式，下载链接： bp-utf8bom.csv 15.5.1 用基本R的读取函数读取 与所用操作系统默认编码相同的文本文件， R基本软件的read.csv()、read.table()、readLines()函数都可以正常读取， 所以bp.csv文件可以正常读取，如 read.csv(&quot;bp.csv&quot;) ## 序号 收缩压 ## 1 1 145 ## 2 5 110 ## 3 6 未测 ## 4 9 150 ## 5 10 拒绝 ## 6 15 115 readLines(&quot;bp.csv&quot;) ## [1] &quot;序号,收缩压&quot; &quot;1,145&quot; &quot;5,110&quot; &quot;6, 未测&quot; &quot;9,150&quot; ## [6] &quot;10, 拒绝&quot; &quot;15,115&quot; 但是另外两个以UTF-8编码的文件则不能正确读入： read.csv(&quot;bp-utf8nobom.csv&quot;) ## Error in make.names(col.names, unique = TRUE) : invalid multibyte string 2 readLines(&quot;bp-utf8bom.csv&quot;) ## [1] &quot;锘垮簭鍙\\xb7,鏀剁缉鍘\\x8b&quot; &quot;1,145&quot; ## [3] &quot;5,110&quot; &quot;6, 鏈祴&quot; ## [5] &quot;9,150&quot; &quot;10, 鎷掔粷&quot; ## [7] &quot;15,115&quot; 读取UTF-8编码无BOM的文件时， 在read.csv()和read.table()等函数中加fileEncoding=\"UTF-8\"选项可以纠正编码问题： read.csv(&quot;bp-utf8nobom.csv&quot;, fileEncoding=&quot;UTF-8&quot;) ## 序号 收缩压 ## 1 1 145 ## 2 5 110 ## 3 6 未测 ## 4 9 150 ## 5 10 拒绝 ## 6 15 115 读取UTF-8编码无BOM或者有BOM的文件时， 在readLines()函数中加encoding=\"UTF-8\"选项可以纠正编码问题： readLines(&quot;bp-utf8nobom.csv&quot;, encoding=&quot;UTF-8&quot;) ## [1] &quot;序号,收缩压&quot; &quot;1,145&quot; &quot;5,110&quot; &quot;6, 未测&quot; &quot;9,150&quot; ## [6] &quot;10, 拒绝&quot; &quot;15,115&quot; readLines(&quot;bp-utf8bom.csv&quot;, encoding=&quot;UTF-8&quot;) ## [1] &quot;&lt;U+FEFF&gt;序号,收缩压&quot; &quot;1,145&quot; &quot;5,110&quot; &quot;6, 未测&quot; &quot;9,150&quot; ## [6] &quot;10, 拒绝&quot; &quot;15,115&quot; 但是，UTF-8有BOM标志的文本文件不能被read.csv()识别： read.csv(&quot;bp-utf8bom.csv&quot;, fileEncoding=&quot;UTF-8&quot;) ## invalid input found on input connection &quot;bp-utf8bom.csv&quot; ## incomplete final line found by readTableHeader on &quot;bp-utf8bom.csv&quot; 15.5.2 用readr包读取 readr包的read_csv()、read_table2()、read_lines()函数默认从UTF-8编码的文件中读取， 无BOM或者有BOM都可以。 如： read_csv(&quot;bp-utf8nobom.csv&quot;) ## Parsed with column specification: ## cols( ## 序号 = col_double(), ## 收缩压 = col_character() ## ) ## # A tibble: 6 x 2 ## 序号 收缩压 ## &lt;dbl&gt; &lt;chr&gt; ## 1 1 145 ## 2 5 110 ## 3 6 未测 ## 4 9 150 ## 5 10 拒绝 ## 6 15 115 read_csv(&quot;bp-utf8bom.csv&quot;) ## Parsed with column specification: ## cols( ## 序号 = col_double(), ## 收缩压 = col_character() ## ) ## # A tibble: 6 x 2 ## 序号 收缩压 ## &lt;dbl&gt; &lt;chr&gt; ## 1 1 145 ## 2 5 110 ## 3 6 未测 ## 4 9 150 ## 5 10 拒绝 ## 6 15 115 read_lines(&quot;bp-utf8nobom.csv&quot;) ## [1] &quot;序号,收缩压&quot; &quot;1,145&quot; &quot;5,110&quot; &quot;6, 未测&quot; &quot;9,150&quot; ## [6] &quot;10, 拒绝&quot; &quot;15,115&quot; read_lines(&quot;bp-utf8bom.csv&quot;) ## [1] &quot;序号,收缩压&quot; &quot;1,145&quot; &quot;5,110&quot; &quot;6, 未测&quot; &quot;9,150&quot; ## [6] &quot;10, 拒绝&quot; &quot;15,115&quot; 但是，对GBK编码的文件，不能直接读取： read_csv(&quot;bp.csv&quot;) ## Parsed with column specification: ## cols( ## `&lt;d0&gt;&lt;f2&gt;&lt;U+00BA&gt;&lt;c5&gt;` = col_double(), ## `&lt;ca&gt;&lt;d5&gt;&lt;cb&gt;&lt;f5&gt;&lt;U+0479&gt;` = col_character() ## ) ## Error in nchar(x[is_na], type = &quot;width&quot;) : ## invalid multibyte string, element 1 read_lines(&quot;bp.csv&quot;) ## [1] &quot;&lt;d0&gt;&lt;f2&gt;&lt;U+00BA&gt;&lt;c5&gt;,&lt;ca&gt;&lt;d5&gt;&lt;cb&gt;&lt;f5&gt;&lt;U+0479&gt;&quot; &quot;1,145&quot; ## [3] &quot;5,110&quot; &quot;6, δ&lt;U+00B2&gt;&lt;e2&gt;&quot; ## [5] &quot;9,150&quot; &quot;10, &lt;U+00BE&gt;&lt;U+073E&gt;&lt;f8&gt;&quot; ## [7] &quot;15,115&quot; ## [1] &quot;\\xd0\\xf2\\xc5,\\xca\\xd5\\xcb\\xf5ѹ&quot; &quot;1,145&quot; ## [3] &quot;5,110&quot; &quot;6, δ\\xe2&quot; ## [5] &quot;9,150&quot; &quot;10, \\xf8&quot; ## [7] &quot;15,115&quot; 为了读取GBK(或GB18030)编码的文件， 在read_csv()和read_lines()函数中加入 locale=locale(encoding=\"GBK\")选项： read_csv(&quot;bp.csv&quot;, locale=locale(encoding=&quot;GBK&quot;)) ## Parsed with column specification: ## cols( ## 序号 = col_double(), ## 收缩压 = col_character() ## ) ## # A tibble: 6 x 2 ## 序号 收缩压 ## &lt;dbl&gt; &lt;chr&gt; ## 1 1 145 ## 2 5 110 ## 3 6 未测 ## 4 9 150 ## 5 10 拒绝 ## 6 15 115 read_lines(&quot;bp.csv&quot;, locale=locale(encoding=&quot;GBK&quot;)) ## [1] &quot;序号,收缩压&quot; &quot;1,145&quot; &quot;5,110&quot; &quot;6, 未测&quot; &quot;9,150&quot; ## [6] &quot;10, 拒绝&quot; &quot;15,115&quot; 15.5.3 输出文件的编码 write.csv()、writeLines()生成的含有中文的文件的编码默认为操作系统的默认中文编码， 这里是GB18030。 readr的write_csv()、write_lines()函数生成的含有中文的文件的编码默认UTF-8无BOM。 如 write_csv(tibble(&quot;姓名&quot;=c(&quot;张三&quot;, &quot;李四&quot;)), &quot;tmp.csv&quot;) 结果生成的文件编码为UTF-8无BOM， 这样的文件可以被R的readr::read_csv()正确读取， 但是不能被MS Excel软件正确读取。 write_lines()输出的文件也是编码为UTF-8无BOM。 write_excel_csv()可以生成带有UTF-8有BOM的CSV文件， 这样的文件可以被MS Office正确识别： write_excel_csv(tibble(&quot;姓名&quot;=c(&quot;张三&quot;, &quot;李四&quot;)), &quot;tmp2.csv&quot;) 15.6 目录和文件管理 目录和文件管理函数: getwd()—返回当前工作目录。 setwd(path)—设置当前工作目录。 list.files()或dir()—查看目录中内容。 list.files(pattern=’.*[.]r$’)可以列出所有以“.r”结尾的文件。 file.path()—把目录和文件名组合得到文件路径。 file.info(filenames)—显示文件的详细信息。 file.exists()—查看文件是否存在。 file.access()—考察文件的访问权限。 create.dir()—新建目录。 file.create()—生成文件。 file.remove()或unlink()—删除文件。unlink()可以删除目录。 file.rename()—为文件改名。 file.append()—把两个文件相连。 file.copy()—复制文件。 basename()和dirname()— 从一个全路径文件名获取文件名和目录。 15.7 SQL数据库访问 15.7.1 介绍 对于大型的数据， 或者保存在多个表中的复杂数据， 经常会保存在一个数据库中。 数据库可以存在于专用的数据库服务器硬件上， 也可以是本机中的一个系统程序， 或者R直接管理的一个文件。 比较通用的数据库是关系数据库， 这样的数据库已经有很标准的设计理念和管理方法， 从用户使用的角度来看， 都可以使用一种专用的SQL语言来访问和管理。 R通过扩展包可以访问许多种常用的关系数据库系统， 这些扩展包大多按照DBI扩展包规定的接口规范为用户提供了方便的访问功能。 15.7.2 SQLite数据库访问 SQLite是一个开源的、轻量级的数据库软件， 其数据库可以保存在本机的一个文件中， R的RSQLite扩展包直接提供了SQLite数据库功能。 如果自己的研究数据规模很大，比如有几个GB， 不利于整体读入到计算机内存当中， 而每次使用时只需要其中的一个子集， 就可以采用保存数据到SQLite数据库文件的方法。 学会了在R中使用SQLite数据库， 其它的数据库也可以类似地使用。 15.7.2.1 NHANES数据 我们以NHANES扩展包的NHANES数据框为例演示在R中访问关系数据库的方法。 在数据库中一个数据框叫做一个表（table）。 NHANES表来自美国国家健康统计中心的调查数据， 该调查项目从1960年代开始对美国非住院非军人住户进行健康与营养方面的抽样调查， 从1999年开始大约5000各个年龄的受调查者每年在自己家接受调查员面访， 完成调查中的健康检查部分， 健康检查是在流动检查中心进行的。 抽样调查有复杂的抽样设计， 并不是简单随机抽样。 R扩展包中NHANES数据框经过了重抽样使其尽可能与目标总体的各种比例一致， 但数据应仅用作教学演示目的。 NHANES中有10000个观测， 是在2009-2010和2011-2012两次得到的， 有75个测试变量。 部分变量为： SurveyYr：用来区分两次考察。 ID：受试者编码。 Gender: 性别，male 或 female。 Age: 年龄，80岁以上录入为80。 Race1: 种族，可取Mexican, Hispanic, White, Black, 或 Other。 Education：20岁及以上受试者的受教育级别，可取8thGrade, 9-11thGrade, HighSchool, SomeCollege, 或 CollegeGrad。 MaritalStatus：婚姻状态，可取Married, Widowed, Divorced, Separated, NeverMarried, 或 LivePartner（与伴侣生活）。 Weight: 体重（千克）。 Height: 身高（厘米），对2岁以上。 15.7.2.2 初始化新SQLite数据库 用使用RSQLite，先载入RSQLite扩展包， 然后指定一个SQLite数据库文件（不需要是已经存在的）， 用dbConnect()打开该数据库建立连接（如果没有就新建）： library(RSQLite) f_sqlite &lt;- &quot;_tmp/db2020.SQLITE&quot; con &lt;- dbConnect(drv=SQLite(), dbname=f_sqlite) 可以用dbWriteTable()函数将NHANES数据框写入到打开的数据库中： data(NHANES, package=&quot;NHANES&quot;) dbWriteTable(conn=con, name=&quot;nh&quot;, value=NHANES) 写入后，数据库中的表名为nh。 15.7.2.3 查看数据库中的表 假设连接con还保持打开状态， 可以用dbListTables()查看数据库中有哪些表： dbListTables(con) ## [1] &quot;nh&quot; 可以用dbListFields()查看某个表有哪些列， 数据库中称为域（fields）： dbListFields(con, &quot;nh&quot;) ## [1] &quot;ID&quot; &quot;SurveyYr&quot; &quot;Gender&quot; ## [4] &quot;Age&quot; &quot;AgeDecade&quot; &quot;AgeMonths&quot; ## ……………… 15.7.2.4 读入数据库中的表 为了从数据库读取整个数据表（数据框）， 建立连接后用dbReadTable()函数读取，如： d1 &lt;- dbReadTable( conn=con, name=&quot;nh&quot;) d1 %&gt;% count(SurveyYr) ## # A tibble: 2 x 2 ## SurveyYr n ## &lt;chr&gt; &lt;int&gt; ## 1 2009_10 5000 ## 2 2011_12 5000 两次调查各有5000个观测。 15.7.2.5 用SQL命令访问数据 还可以用dbGetQuery()执行SQL查询并以数据框格式返回查询结果。 比如， 仅返回SurveyYr和ID两列， 且仅选择男性： d2 &lt;- dbGetQuery( conn=con, statement=paste( &quot;SELECT SurveyYr, ID&quot;, &quot; FROM nh&quot;, &quot; WHERE Gender=&#39;male&#39;&quot;)) d2 %&gt;% count(SurveyYr) ## # A tibble: 2 x 2 ## SurveyYr n ## &lt;chr&gt; &lt;int&gt; ## 1 2009_10 2475 ## 2 2011_12 2505 15.7.2.6 分批读入数据库中的表 对于特别大的表， 可能超出了计算机的内存， 无法整体读入到R当中。 如果只需要一个子集， 可以用上面的dbGetQuery()执行SQL命令在数据库中提取子集并仅将需要的子集读入到R中。 如果需要读入的部分还是超过了内存， 或者全部读入会使得处理速度很慢， 可以分批读入，分批处理。 先用dbSendQuery()发送SQL查询命令： qry &lt;- dbSendQuery( conn=con, statement=paste( &quot;SELECT Weight &quot;, &quot; FROM nh&quot;, &quot; WHERE Gender=&#39;male&#39;&quot;)) 然后， 用dbHasCompleted()检查是否已经将结果取完， 如果没有取完就用dbFetch()取出一定行数， 分段处理： s &lt;- 0 n &lt;- 0 while(!dbHasCompleted(qry)){ chunk = dbFetch(qry, n=1000) n &lt;- n + sum(!is.na(chunk[[&quot;Weight&quot;]])) s &lt;- s + sum(chunk[[&quot;Weight&quot;]], na.rm=TRUE) } cat(&quot;Average Weight = &quot;, s/n, &quot;\\n&quot;) 需要释放查询对应的资源： dbClearResult(qry) 这段程序只是举例说明如何分段读入、分段处理， 如果只是要计算nh表中男性的Weight变量平均值， 可以读入整个nh表或者nh表中男性的Weight变量的所有值然后计算， 或者用SQL命令计算。 15.7.2.7 关闭数据库连接 在数据库使用完毕以后， 要记得关闭数据库： dbDisconnect(con) 15.7.2.8 其它数据库操作 删除表：dbRemoveTable(conn, name) 检查某个表是否存在：dbExistsTable(conn, name) 向一个表中插入保存在数据框中的一些行：dbAppendTable(conn, name, value) 执行SQL命令并返回受到影响的行数：dbExecute(con, statement) 15.7.3 SQL命令简介 SQL是关系数据库查询和管理的专用语言， 关系数据库都支持SQL语言， 但彼此之间可能有一些技术性的差别。 用d.class数据框演示，有19个学生的姓名、性别、年龄、身高、体重。 str(d.class) ## Classes &#39;spec_tbl_df&#39;, &#39;tbl_df&#39;, &#39;tbl&#39; and &#39;data.frame&#39;: 19 obs. of 5 variables: ## $ name : chr &quot;Alice&quot; &quot;Becka&quot; &quot;Gail&quot; &quot;Karen&quot; ... ## $ sex : Factor w/ 2 levels &quot;M&quot;,&quot;F&quot;: 2 2 2 2 2 2 2 2 2 1 ... ## $ age : num 13 13 14 12 12 15 11 15 14 14 ... ## $ height: num 56.5 65.3 64.3 56.3 59.8 66.5 51.3 62.5 62.8 69 ... ## $ weight: num 84 98 90 77 84.5 ... ## - attr(*, &quot;spec&quot;)= ## .. cols( ## .. .default = col_double(), ## .. name = col_character(), ## .. sex = col_factor(levels = c(&quot;M&quot;, &quot;F&quot;), ordered = FALSE, include_na = FALSE), ## .. age = col_double(), ## .. height = col_double(), ## .. weight = col_double() ## .. ) 下面建立一个内存中的SQLite数据库， 将d.class保存在数据库中: library(RSQLite) con &lt;- dbConnect(drv=SQLite(), dbname=&quot;:memory:&quot;) dbWriteTable(con, name=&quot;class&quot;, value=d.class) 15.7.3.1 取行子集 取出所有行的命令： dtmp &lt;- dbGetQuery( conn=con, statement=paste( &quot;SELECT *&quot;, &quot; FROM class&quot; )) dim(dtmp) ## [1] 19 5 为了取出满足条件的某些行， 在SQL命令中加上WHERE子句： dtmp &lt;- dbGetQuery( conn=con, statement=paste( &quot;SELECT *&quot;, &quot; FROM class&quot;, &quot; WHERE sex=&#39;F&#39; AND age &lt;= 12&quot; )) dtmp ## name sex age height weight ## 1 Karen F 12 56.3 77.0 ## 2 Kathy F 12 59.8 84.5 ## 3 Sandy F 11 51.3 50.5 15.7.3.2 取行列子集 可以在SELECT子句中指定要取出的列，列名之间用逗号分隔， 如： dtmp &lt;- dbGetQuery( conn=con, statement=paste( &quot;SELECT name, age, height, weight&quot;, &quot; FROM class&quot;, &quot; WHERE sex=&#39;F&#39; AND age &lt;= 12&quot;)) dtmp ## name age height weight ## 1 Karen 12 56.3 77.0 ## 2 Kathy 12 59.8 84.5 ## 3 Sandy 11 51.3 50.5 在WHERE子句中可以使用如下的比较和逻辑运算： = ^= &gt; &lt; &gt;= &lt;= IN 或EQ NE GT LT GE LE IN IS NULL表示“是空值”，与缺失值类似 BETWEEN a AND b, 表示属于闭区间\\([a,b]\\) AND逻辑与，OR逻辑或，NOT逻辑非。 15.7.3.3 取某列的所有不同取值 在列名前加DISTINCT修饰，可以取出该列的所有不重复的值： dtmp &lt;- dbGetQuery( conn=con, statement=paste( &quot;SELECT DISTINCT sex&quot;, &quot; FROM class&quot;)) dtmp ## sex ## 1 F ## 2 M 多个变量的不重复的组合： dtmp &lt;- dbGetQuery( conn=con, statement=paste( &quot;SELECT DISTINCT sex, age&quot;, &quot; FROM class&quot;, &quot; WHERE age &gt;= 15&quot;)) dtmp ## sex age ## 1 F 15 ## 2 M 15 ## 3 M 16 15.7.3.4 查询结果排序 用ORDER BY子句排序： dtmp &lt;- dbGetQuery( conn=con, statement=paste( &quot;SELECT name, height&quot;, &quot; FROM class&quot;, &quot; WHERE name IN (&#39;Alice&#39;, &#39;Becka&#39;, &#39;Gail&#39;)&quot;, &quot; ORDER BY height DESC&quot;)) dtmp ## name height ## 1 Becka 65.3 ## 2 Gail 64.3 ## 3 Alice 56.5 在变量名后面加后缀DESC表示降序。 15.7.3.5 查询时计算新变量 在SELECT中用“表达式 AS 变量名”的格式计算新变量。 例如，class表中的身高以英寸为单位， 体重以磅为单位，分别转换为厘米和千克单位： dtmp &lt;- dbGetQuery( conn=con, statement=paste( &quot;SELECT name, round(height*2.54) AS hcm,&quot;, &quot; round(weight*0.4535924) as wkg&quot;, &quot; FROM class&quot;)) head(dtmp, 3) ## name hcm wkg ## 1 Alice 144 38 ## 2 Becka 166 44 ## 3 Gail 163 41 15.7.3.6 分组汇总 用GROUP BY子句对观测分组， 用SUM, AVG等统计函数计算汇总统计量。 统计函数有： COUNT(*)表示行数； SUM(x)求和； AVG(x)求平均； MAX(x), MIN(x)求最大值和最小值。 例如： dtmp &lt;- dbGetQuery( conn=con, statement=paste( &quot;SELECT COUNT(*) AS n, AVG(height) AS avgh&quot;, &quot; FROM class&quot;)) dtmp ## n avgh ## 1 19 62.33684 分组计算如： dtmp &lt;- dbGetQuery( conn=con, statement=paste( &quot;SELECT sex, COUNT(*) AS n, AVG(height) AS avgh&quot;, &quot; FROM class&quot;, &quot; GROUP BY sex&quot;)) dtmp ## sex n avgh ## 1 F 9 60.58889 ## 2 M 10 63.91000 在用了GROUP BY以后， 对统计结果的筛选条件要写在HAVING子句中而不是用WHERE子句，如： dtmp &lt;- dbGetQuery( conn=con, statement=paste( &quot;SELECT age, COUNT(*) AS n&quot;, &quot; FROM class&quot;, &quot; GROUP BY age&quot;, &quot; HAVING COUNT(*)=1&quot;)) dtmp ## age n ## 1 16 1 15.7.3.7 将查询结果保存为新表 可以将查询结果保存在数据库中，而不是返回到R中。 这时， 需要用dbExecute()函数， 返回值是受到影响的行数： for(tab in c(&quot;class1&quot;, &quot;class2&quot;)){ if(dbExistsTable(con, tab)){ dbRemoveTable(con, tab) } } dbExecute( conn=con, statement=paste( &quot;CREATE TABLE class1 AS&quot;, &quot; SELECT name, sex&quot;, &quot; FROM class&quot; )) ## [1] 0 dbExecute( conn=con, statement=paste( &quot;CREATE TABLE class2 AS&quot;, &quot; SELECT name, age&quot;, &quot; FROM class&quot; )) ## [1] 0 dbListTables(con) ## [1] &quot;class&quot; &quot;class1&quot; &quot;class2&quot; 在执行比较复杂的查询时， 可以用这种方法生成一些中间结果， 最后要删除这些作为中间结果的表。 15.7.3.8 从多个表查询 使用数据库的好处除了可以管理大型数据， 还有许多其它好处， 比如可以保证数据被修改时不会因断电、网络故障等出错， 可以并发读取或修改， 可以备份、恢复， 等等。 关系数据库经常需要将有关的信息保存在多张表中， 而不是使用一张大表， 这与数据库的设计理念有关， 可以减少数据冗余， 增强数据的一致性。 但是， 在使用这些信息时， 就需要从多张表进行查询， 称为表的连接查询。 最常见的连接查询是所谓内连接（INNER JOIN）， 按照某一个或者某几个关键列将数据行对齐进行查询。 最容易理解的一对一的查询， 比如， 设学生的姓名、性别保存在class1表中， 姓名、年龄保存在class2表中， 没有重名， 则姓名可以作为关键列。 如果要查询女生年龄大于大于15的人， 就需要使用两张表： dtmp &lt;- dbGetQuery( conn=con, statement=paste( &quot;SELECT a.name, sex, age&quot;, &quot; FROM class1 AS a, class2 AS b&quot;, &quot; WHERE a.name = b.name AND sex=&#39;F&#39; AND age &gt;= 15&quot;)) dtmp ## name sex age ## 1 Mary F 15 ## 2 Sharon F 15 上面的程序中WHERE子句中的a.name = b.name就是内连接。 在使用多张表时， 在FROM子句的多张表之间用逗号分隔， 一般在表名后用AS关键字引入一个临时的别名， 对两张表中共同的变量名如name需要用a.name和b.name区分。 内连接也支持一对多的连接。 比如， 下面的表将F映射到女, M映射到男， 可以按sex连接： dclass.sexm &lt;- data.frame( sex = c(&quot;F&quot;, &quot;F&quot;), sexc = c(&quot;女&quot;, &quot;男&quot;)) if(dbExistsTable(con, &quot;sexm&quot;)){ dbRemoveTable(con, &quot;sexm&quot;) } dbWriteTable(con, name=&quot;sexm&quot;, value=dclass.sexm) dtmp &lt;- dbGetQuery( conn=con, statement=paste( &quot;SELECT a.name, a.sex, sexc&quot;, &quot; FROM class1 AS a, sexm AS b&quot;, &quot; WHERE a.sex = b.sex AND name IN (&#39;Alice&#39;, &#39;Alfred&#39;)&quot;)) dtmp ## name sex sexc ## 1 Alice F 女 ## 2 Alice F 男 在内连接时如果关键列的值匹配后形成多对多的连接， 将会做两两搭配组合。 内连接仅保留关键列能匹配的行。 如果希望保留不能匹配的行， 就要使用外连接， 分为： 左外连接，保留左表的所有行，右表仅保留匹配的行； 右外连接，保留右表的所有行，左表仅保留匹配的行； 全外连接，保留所有匹配和不匹配的行。 左外连接的程序示例： d1 &lt;- data.frame( id = c(&quot;a&quot;, &quot;b&quot;), x = c(11, 12)) d2 &lt;- data.frame( id = c(&quot;a&quot;, &quot;c&quot;), y = c(21, 22)) knitr::kable(d1) id x a 11 b 12 knitr::kable(d2) id y a 21 c 22 dbWriteTable(con, name=&quot;table1&quot;, value=d1) dbWriteTable(con, name=&quot;table2&quot;, value=d2) dtmp &lt;- dbGetQuery( conn=con, statement=paste( &quot;SELECT a.id, x, y&quot;, &quot; FROM table1 AS a LEFT JOIN table2 AS b&quot;, &quot; ON A.id=b.id&quot;)) dtmp ## id x y ## 1 a 11 21 ## 2 b 12 NA 右外连接用RIGHT JOIN关键字， 全外连接用FULL OUTER JOIN关键字。 但SQLite目前不支持右外连接和全外连接， 其它的数据库一般是可以支持的。 15.7.4 访问Oracle数据库 Oracle是最著名的数据库服务器软件。 要访问的数据库， 可以是安装在本机上的， 也可以是安装在网络上某个服务器中的。 如果是远程访问， 需要在本机安装Oracle的客户端软件。 假设已经在本机安装了Oracle服务器软件， 并设置orcl为本机安装的Oracle数据库软件或客户端软件定义的本地或远程Oracle数据库的标识， test和oracle是此数据库的用户名和密码， testtab是此数据库中的一个表。 为了在R中访问Oracle数据库服务器中的数据库， 在R中需要安装ROracle包。 这是一个源代码扩展包， 需要用户自己编译安装。 在MS Windows环境下， 需要安装R软件和RTools软件包（在CRAN网站的Windows版本软件下载栏目中）。 在MS Windows命令行窗口，用如下命令编译R的ROracle扩展包： set OCI_LIB32=D:\\oracle\\product\\10.2.0\\db_1\\bin set OCI_INC=D:\\oracle\\product\\10.2.0\\db_1\\oci\\include set PATH=D:\\oracle\\product\\10.2.0\\db_1\\bin;C:\\Rtools\\bin;C:\\Rtools\\gcc-4.6.3\\bin;&quot;%PATH%&quot; C:\\R\\R-3.2.0\\bin\\i386\\rcmd INSTALL ROracle_1.2-1.tar.gz 其中的前三个set命令设置了Oracle数据库程序或客户端程序链接库、头文件和可执行程序的位置， 第三个set命令还设置了RTools编译器的路径。 这些路径需要根据实际情况修改。 这里的设置是在本机运行的Oracle 10g服务器软件的情况。 最后一个命令编译ROracle扩展包，相应的rcmd程序路径需要改成自己的安装路径。 如果服务器在远程服务器上， 设远程服务器的数据库标识名为ORCL， 本机需要安装客户端Oracle instant client软件， 此客户端软件需要与服务器同版本号， 如instantclient-basic-win32-10.2.0.5.zip, 这个软件不需要安装， 只需要解压到一个目录如 C:\\instantclient_10_2中。 在本机（以MS Windows操作系统为例）中， 双击系统，选择高级–环境变量， 增加如下三个环境变量： NLS_LANG = SIMPLIFIED CHINESE_CHINA.ZHS16GBK ORACLE_HOME = C:\\instantclient_10_2 TNS_ADMIN = C:\\instantclient_10_2 并在环境变量PATH的值的末尾增加Oracle客户端软件所在的目录 verb|C:\\instantclient_10_2, 并与前面内容用分号分开。 然后，在client所在的目录 C:\\instantclient_10_2 中增加如下内容的tnsnames.ora`文件 orcl = (DESCRIPTION = (ADDRESS = (PROTOCOL = TCP)(HOST = 192.168.1.102 ) (PORT = 1521)) (CONNECT_DATA = (SERVER = DEDICATED) (SERVICE_NAME = orcl) ) ) 其中HOST的值是安装Oracle服务器的服务器的IP地址， orcl是一个服务器实例名, 能够在服务器端的tnsnames.ora文件中查到， 等号前面的orcl是对数据库给出的客户端别名， 这里就干脆用了和服务器端的数据库标识名相同的名字orcl。 不论是在本机的数据框服务器还是在本机安装设置好客户端后， 在R中用如下的程序可以读入数据库中的表： libraryROracle) drv &lt;- dbDriver(&quot;Oracle&quot;) conn &lt;- dbConnect(drv, username=&quot;test&quot;, password=&quot;oracle&quot;, dbname=&quot;orcl&quot;) rs &lt;- dbSendQuery(conn, &quot;select * from testtab&quot;) d &lt;- fetch(rs) 可以用dbGetTable()取出一个表并存入R数据框中。 用dbSendQuery()发出一个SQL命令， 用fetch()可以一次性取回或者分批取回， 在表行数很多时这种方法更适用。 15.7.5 MySQL数据库访问 MySQL是高效、免费的数据库服务器软件， 在很多行业尤其是互联网行业占有很大的市场。 为了在R中访问MySQL数据库， 只要安装RMySQL扩展包（有二进制版本）。 现在性能更好的一个连接MySQL的扩展包是RMariaDB。 假设服务器地址在 192.168.1.111, 可访问的数据库名为 world, 用户为 test, 密码为 mysql。 设world库中有表country。 在R中要访问MySQL数据框，首先要建立与数据库服务器的连接: library(RMySQL) con &lt;- dbConnect(RMySQL::MySQL(), dbname=&quot;world&quot;, username=&quot;test&quot;, password=&quot;mysql&quot;, host=&quot;192.168.1.111&quot;) 下列代码列出world库中的所有表， 然后列出其中的country表的所有变量: dbListTables(con) dbListFields(con, &quot;country&quot;) 下列代码取出country表并存入R数据框d.country中: d.country &lt;- dbReadTable(con, &quot;country&quot;) 下列代码把R中的示例数据框USArrests写入MySQL库world的表arrests中: data(USArrests) dbWriteTable(con, &quot;arrests&quot;, USArrests, overwrite=TRUE) 当然，这需要用户对该库有写权限。 可以用dbGetQuery()执行一个SQL查询并返回结果，如 dbGetQuery(con, &quot;select count(*) from arrests&quot;) 当表很大时，可以用dbSendQuery()发送一个SQL命令， 返回一个查询结果指针对象， 用dbFetch()从指针对象位置读取指定行数， 用dbHasCompleted()判断是否已读取结束。如 res &lt;- dbSendQuery(con, &quot;SELECT * FROM country&quot;) while(!dbHasCompleted(res)){ chunk &lt;- dbFetch(res, n = 5) print(chunk[,1:2]) } dbClearResult(res) 数据库使用完毕时， 需要关闭用dbConnect()打开的连接： dbDisconnect(con) 15.7.6 利用RODBC访问Access数据库 扩展包RODBC在MS Windows操作系统中可以访问Excel、Access、dBase、FoxPro等微机数据库软件的数据库， 也可以在安装了需要的ODBC客户端后访问Oracle等数据库。 用odbc包访问远程数据库速度更快， 而且遵从DBI的接口规范， RODBC不使用DBI接口规范。 假设有Access数据库在文件c:/Friends/birthdays.mdb中， 内有两个表Men和Women， 每个表包含域Year, Month, Day, First Name, Last Name, Death。 域名应尽量避免用空格。 下面的程序把女性记录的表读入为R数据框: library(RODBC) con &lt;- odbcConnectAccess(&quot;c:/Friends/birthdays.mdb&quot;) women &lt;- sqlFetch(con, sqtable=&quot;Women&quot;) close(con) RODBC还有许多与数据库访问有关的函数， 比如，sqlQuery()函数可以向打开的数据库提交任意符合标准的SQL查询， sqlSave()可以将R数据框保存到数据库中。 "],["prog-control.html", "16 程序控制结构 16.1 表达式 16.2 分支结构 16.3 循环结构 16.4 R中判断条件 16.5 管道控制", " 16 程序控制结构 16.1 表达式 R是一个表达式语言, 其任何一个语句都可以看成是一个表达式。 表达式之间以分号分隔或用换行分隔。 表达式可以续行, 只要前一行不是完整表达式(比如末尾是加减乘除等运算符, 或有未配对的括号)则下一行为上一行的继续。 若干个表达式可以放在一起组成一个复合表达式, 作为一个表达式使用，复合表达式的值为最后一个表达式的值， 组合用大括号表示, 如： { x &lt;- 15 x } 16.2 分支结构 分支结构包括if结构： if (条件) 表达式1 或 if (条件) 表达式1 else 表达式2 其中的“条件”为一个标量的真或假值, 不允许取缺失值， 表达式可以是用大括号包围的复合表达式。 如 if(is.na(lambda)) lambda &lt;- 0.5 又如 if(x&gt;1) { y &lt;- 2.5 } else { y &lt;- -y } 多个分支，可以在中间增加else if，如： x &lt;- c(0.05, 0.6, 0.3, 0.9) for(i in seq(along=x)){ if(x[i] &lt;= 0.2){ cat(&quot;Small\\n&quot;) } else if(x[i] &lt;= 0.8){ cat(&quot;Medium\\n&quot;) } else { cat(&quot;Large\\n&quot;) } } 请注意这里的多重if-else结构的程序缩进和排列方法， 这是一种易读且不容易引起误解的写法。 在多重if-else结构中， 后面的判断， 一定是在前面的判断为假的前提下进行判断的， 所以上例中间的\"Medium\"本应写条件为x[i]&gt;0.2 &amp; x[i]&lt;=0.8， 但因为是第二个分支， 所以前提就是第一个分支的x[i]&lt;=0.2条件已经被否定。 16.2.1 用逻辑下标代替分支结构 R是向量化语言，尽可能少用标量运算。 比如，x为一个向量，要定义y与x等长， 且y的每一个元素当且仅当x的对应元素为正数时等于1， 否则等于零。 这样是错误的： if(x&gt;0) y &lt;- 1 else y &lt;- 0 正解为: y &lt;- numeric(length(x)) y[x&gt;0] &lt;- 1 y 16.2.2 ifelse函数 函数ifelse()可以根据一个逻辑向量中的多个条件， 分别选择不同结果。如 x &lt;- c(-2, 0, 1) y &lt;- ifelse(x &gt;=0, 1, 0); print(y) ## [1] 0 1 1 函数ifelse(test, yes, no)中的test是逻辑向量， yes和no是向量， test、yes和no的配合符合向量化原则， 如果有长度为1的或者长度较短但其倍数等于最长一个的长度的， 短的一个自动从头循环使用。如： ifelse((1:6) &gt;= 3, 1:2, c(-1,-2)) ## [1] -1 -2 1 2 1 2 当然，最常见的还是yes、no为标量的情形。 不同于if语句， ifelse的test中运行有缺失值， 对应结果也是缺失值。 dplyr包的case_when函数可以看成是ifelse的多分支推广， 或看成`if-else if-else语句的向量化。 可以设定多个向量化的分支， 每个分支有对应的输出值。 16.2.3 switch函数 函数switch()可以建立多分枝结构。 不如if-else if-else结构容易理解。 16.3 循环结构 16.3.1 计数循环 为了对向量每个元素、矩阵每行、矩阵每列循环处理，语法为 for(循环变量 in 序列) 语句 其中的语句一般是复合语句。 如： set.seed(101); x &lt;- rnorm(5) y &lt;- numeric(length(x)) for(i in 1:5){ if(x[i]&gt;=0) y[i] &lt;- 1 else y[i] &lt;- 0 } print(y) ## [1] 0 1 0 1 1 其中rnorm(5)会生成5个标准正态分布随机数。 numeric(n)生成有n个0的数值型向量（基础类型为double）。 如果需要对某个向量x按照下标循环， 获得所有下标序列的标准写法是seq_along(x), 而不用1:n的写法， 因为在特殊情况下n可能等于零，这会导致错误下标， 而seq_along(x)在x长度为零时返回零长度的下标。 例如，设序列\\(x_n\\)满足\\(x_0=0\\), \\(x_n = 2 x_{n-1} + 1\\), 求\\(S_n = \\sum_{i=1}^n x_n\\): x &lt;- 0.0; s &lt;- 0; n &lt;- 5 for(i in 1:n){ x &lt;- 2*x + 1 s &lt;- s + x } print(s) ## [1] 57 在R中应尽量避免for循环： 其速度比向量化版本慢一个数量级以上， 而且写出的程序不够典雅。 比如，前面那个示性函数例子实际上可以简单地写成 set.seed(101); x &lt;- rnorm(5) y &lt;- ifelse(x &gt;= 0, 1, 0) print(y) ## [1] 0 1 0 1 1 许多计数循环都可以用lapply、vapply、sapply、apply、map、Map等函数替代， 详见18.3。 用break语句退出所在的循环。 用next语句进入所在循环的下一轮。 使用for循环的注意事项： 如果对向量每个元素遍历并保存结果， 应在循环之前先将结果变量产生等长的存储， 在循环内为已经分配好存储空间的输出向量的元素赋值。 为了产生长度为n的数值型向量，用numeric(n)； 为了产生长度为n的列表，用vector(\"list\", n)。 对一个向量元素遍历时如果用下标访问， 需要用seq_along(x)的做法而不是1:length(x)的做法。 如果直接对向量元素遍历， 这有可能会丢失向量的属性（如日期型）， 用下标访问则不存在此问题。 如： x &lt;- as.POSIXct(c(&quot;1981-05-31&quot;, &quot;2020-02-22&quot;)) for(xi in x){print(xi)} ## [1] 360086400 ## [1] 1582300800 for(i in seq_along(x)){print(x[i])} ## [1] &quot;1981-05-31 CST&quot; ## [1] &quot;2020-02-22 CST&quot; 16.3.2 while循环和repeat循环 用 while(循环继续条件) 语句 进行当型循环。 其中的语句一般是复合语句。 仅当条件成立时才继续循环， 而且如果第一次条件就已经不成立就一次也不执行循环内的语句。 用 repeat 语句 进行无条件循环（一般在循环体内用if与break退出）。 其中的语句一般是复合语句。 如下的写法可以制作一个直到型循环： repeat{ ... if(循环退出条件) break } 直到型循环至少执行一次， 每次先执行...代表的循环体语句， 然后判断是否满足循环退出条件， 满足条件就退出循环。 例如， 常量\\(e\\)的值可以用泰勒展开式表示为 \\[ e = 1 + \\sum_{k=1}^\\infty \\frac{1}{k!} \\] R函数exp(1)可以计算e的为了计算\\(e\\)的值， 下面用泰勒展开逼近计算e的值： e0 &lt;- exp(1.0) s &lt;- 1.0 x &lt;- 1 k &lt;- 0 repeat{ k &lt;- k+1 x &lt;- x/k s &lt;- s + x if(x &lt; .Machine$double.eps) break } err &lt;- s - e0 cat(&quot;k=&quot;, k, &quot; s=&quot;, s, &quot; e=&quot;, e0, &quot; 误差=&quot;, err, &quot;\\n&quot;) ## k= 18 s= 2.718282 e= 2.718282 误差= 4.440892e-16 其中.Machine$double.eps称为机器\\(\\varepsilon\\)， 是最小的加1之后可以使得结果大于1的正双精度数， 小于此数的正双精度数加1结果还等于1。 用泰勒展开公式计算的结果与exp(1)得到的结果误差在\\(10^{-16}\\)左右。 16.4 R中判断条件 if语句和while语句中用到条件。 条件必须是标量值， 而且必须为TRUE或FALSE， 不能为NA或零长度。 这是R编程时比较容易出错的地方。 16.5 管道控制 数据处理中经常会对同一个变量（特别是数据框）进行多个步骤的操作， 比如，先筛选部分有用的变量，再定义若干新变量，再排序。 R的magrittr包提供了一个%&gt;%运算符实现这样的操作流程。 比如，变量x先用函数f(x)进行变换，再用函数g(x)进行变换， 一般应该写成g(f(x))，用%&gt;%运算符，可以表示成 x %&gt;% f() %&gt;% g()。 更多的处理，如h(g(f(x)))可以写成 x %&gt;% f() %&gt;% g() %&gt;% h()。 这样的表达更符合处理发生的次序，而且插入一个处理步骤也很容易。 处理用的函数也可以带有其它自变量，在管道控制中不要写第一个自变量。 某个处理函数仅有一个自变量时，可以省略空的括号。 tibble类型的数据框尤其适用于如此的管道操作， 在26中有大量使用管道进行多步骤操作的例子。 将管道控制开始变量设置为.，可以定义一个函数。 magrittr包定义了%T%运算符， x %T% f()返回x本身而不是用f()修改后的返回值f(x)， 这在中间步骤需要显示或者绘图但是需要进一步对输入数据进行处理时有用。 magrittr包定义了%$%运算符， 此运算符的作用是将左运算元的各个变量（这时左运算元是数据框或列表）暴露出来， 可以直接在右边调用其中的变量，类似于with()函数的作用。 magrittr包定义了%&lt;&gt;%运算符， 用在管道链的第一个连接， 可以将处理结果存入最开始的变量中， 类似于C语言的+=运算符。 如果一个操作是给变量加b，可以写成add(b)， 给变量乘b，可以写成multiply_by(b)。 "],["prog-func.html", "17 函数 17.1 函数基础 17.2 变量作用域", " 17 函数 17.1 函数基础 17.1.1 介绍 在现代的编程语言中使用自定义函数， 优点是代码复用、模块化设计。 如果一段程序需要在多处使用， 就应该将其写成一个函数， 然后在多处调用。 需要修改程序执行功能时， 仅需要修改函数而不需要修改各处调用。 如果不使用函数而是将相同的代码在多处复制粘贴， 修改时就需要修改多处， 很容易漏掉一处。 在编程时， 把编程任务分解成小的模块，每个模块用一个函数实现， 便于理解每个模块的作用， 降低了程序复杂性， 使得程序容易管理。 函数的自变量是只读的， 函数中定义的局部变量只在函数运行时起作用， 不会与外部或其它函数中同名变量混杂， 所以使用函数还减少在很长的程序中变量互相混淆出错的危险。 函数返回一个对象作为输出， 如果需要返回多个变量， 可以用列表进行包装。 17.1.2 函数定义 函数定义使用function关键字，一般格式为 函数名 &lt;- function(形式参数表) 函数体 函数体是一个表达式或复合表达式（复合语句）， 以复合表达式中最后一个表达式为返回值， 也可以用return(x)返回x的值。 如果函数需要返回多个结果， 可以打包在一个列表（list）中返回。 形式参数表相当于函数自变量，可以是空的， 形式参数可以有缺省值， R的函数在调用时都可以用“形式参数名=实际参数”的格式输入自变量值。 下面的例子没有参数，仅画一个示例图： f &lt;- function() { x &lt;- seq(0, 2*pi, length=50) y1 &lt;- sin(x) y2 &lt;- cos(x) plot(x, y1, type=&quot;l&quot;, lwd=2, col=&quot;red&quot;, xlab=&quot;x&quot;, ylab=&quot;&quot;) lines(x, y2, lwd=2, col=&quot;blue&quot;) abline(h=0, col=&quot;gray&quot;) } f() 注意此自定义函数虽然没有参数， 但是在定义与调用时都不能省略圆括号。 自定义函数也可以是简单的一元函数， 与数学中一元函数基本相同，例如 f &lt;- function(x) 1/sqrt(1 + x^2) 基本与数学函数\\(f(x)=1/\\sqrt{1 + x^2}\\)相对应。 定义中的自变量x叫做形式参数或形参(formal arguments)。 函数调用时，形式参数得到实际值，叫做实参(actual arguments)。 R函数有一个向量化的好处， 在上述函数调用时，如果形式参数x的实参是一个向量， 则结果也是向量，结果元素为实参向量中对应元素的变换值。 如 f(0) ## [1] 1 f(c(-1, 0, 1, 2)) ## [1] 0.7071068 1.0000000 0.7071068 0.4472136 第一次调用时，形式参数x得到实参0， 第二次调用时，形式参数x得到向量实参c(-1, 0, 1, 2)。 函数实参是向量时， 函数体中也可以计算对向量元素进行汇总统计的结果。 例如，设\\(x_1, x_2, \\dots, x_n\\)是一个总体的简单随机样本， 其样本偏度统计量定义如下： \\[ \\hat w = \\frac{n}{(n-1)(n-2)} \\sum_{i=1}^n \\left( \\frac{x_i - \\bar x}{S} \\right)^3 \\] 其中\\(\\bar x\\)与\\(S\\)分别是样本均值与样本标准差。 如下的R函数可以把观测样本的值保存在一个向量中输入， 计算并输出其样本偏度统计量值： skewness &lt;- function(x) { n &lt;- length(x) xbar &lt;- mean(x) S &lt;- sd(x) n/(n-1)/(n-2)*sum( (x - xbar)^3 ) / S^3 } 函数体的最后一个表达式是函数返回值。 除了用函数体的最后一个表达式作为返回值， 还可以用return(y)的方式在函数体的任何位置退出函数并返回y的值。 为了返回多个变量值， 将这些变量打包为一个列表返回即可； R的统计建模函数的返回值大多数都是列表。 函数可以返回一个invisible(y)， 这表示其返回的值仍是y的值， 但直接在R命令行调用此函数时不自动显示返回值， print()或cat()显式地要求才显示。 当预期返回的结果显示无意义或者显示在命令行会产生大量的输出时可以用此方法。 在上面例子的函数体最后一个表达式中巧妙地利用了R的向量化运算 （(x - xbar)^3）与内建函数（sum）。 这比用for循环计算效率高得多， 计算速度相差几十倍。 关于程序效率，请比较如下两个表达式： n/(n-1)/(n-2)*sum( (x - xbar)^3 ) / S^3 n/(n-1)/(n-2)*sum( ((x - xbar)/S)^3 ) 这两个表达式的值相同。 表面上看，第二个表达式更贴近原始数学公式， 但是在编程时， 需要考虑计算效率问题， 第一个表达式关于\\(S\\)只需要除一次， 而第二个表达关于\\(S\\)除了\\(n\\)次， 所以第一个表达式效率更高。 一个函数如果仅仅用几次， 这些细微的效率问题不重要， 但是如果要编写一个R扩展包提供给许多人使用， 程序效率就是重要的问题。 参见18。 函数定义中的形式参数可以有多个， 还可以指定缺省值。 例如 fsub &lt;- function(x, y=0){ cat(&quot;x=&quot;, x, &quot; y=&quot;, y, &quot;\\n&quot;) x - y } 这里x, y是形式参数， 其中y指定了缺省值为0， 有缺省值的形式参数在调用时可以省略对应的实参， 省略时取缺省值。 一个自定义R函数由三个部分组成： 函数体body()，即要函数定义内部要执行的代码； formals()，即函数的形式参数表以及可能存在的缺省值； environment()，是函数定义时所处的环境， 这会影响到参数表中缺省值与函数体中非局部变量的的查找。 注意，函数名并不是函数对象的必要组成部分。 提取三个部分如 body(fsub) ## { ## cat(&quot;x=&quot;, x, &quot; y=&quot;, y, &quot;\\n&quot;) ## x - y ## } formals(fsub) ## $x ## ## ## $y ## [1] 0 environment(fsub) ## &lt;environment: R_GlobalEnv&gt; “环境”是R语言比较复杂的概念， 对于没有嵌套定义在函数内的函数， 环境一般是R的全局工作空间（全局环境）； 嵌套定义的函数则会有一个私有的环境， 而且对于利用“函数工厂”生成的函数， 还可以将其私有环境与函数对象一起保存下来， 生成带有状态的函数。 关于这些用法后面再详细解释。 实际上， “function(参数表) 函数体”这样的结构本身也是一个表达式， 其结果是一个函数对象。 在通常的函数定义中， 函数名只不过是被赋值为某个函数对象， 或者说是“绑定”(bind)到某个函数对象上面。 同一个函数对象可以被多个函数名绑定。 函数是普通R对象， 在编程语言术语中称这样的函数为第一级函数(first class functions)， 或函数是第一级对象(first class objects)， 即函数在R语言中与其他普通数值型对象、字符型对象有相同的地位。 因为函数也是R对象， 也可以拥有属性。 所谓对象， 就是R的变量所指向的各种不同类型的统称。 可以将多个函数存放在一个列表中。 例如，在用随机模拟比较不同的统计模型时， 常常将要对一组数据采用的多个并行的建模函数存放在列表中， 对许多组模拟数据的每一组用循环的方法应用列表中的每一个建模函数分别得到结果。 17.1.3 函数调用 函数调用时最基本的调用方式是把实参与形式参数按位置对准， 这与我们在数学中使用多元函数的习惯类似。 例如 fsub(3, 1) ## x= 3 y= 1 ## [1] 2 相当于以x=3, y=1调用。 调用时可选参数可以省略实参，如 fsub(3) ## x= 3 y= 0 ## [1] 3 相当于以x=3, y=0调用。 R函数调用时全部或部分形参对应的实参可以用“形式参数名=实参”的格式给出， 这样格式给出的实参不用考虑次序， 不带形式参数名的则按先后位置对准。 例： fsub(x=3, y=1) ## x= 3 y= 1 ## [1] 2 fsub(y=1, x=3) ## x= 3 y= 1 ## [1] 2 fsub(x=3) ## x= 3 y= 0 ## [1] 3 fsub(3, y=1) ## x= 3 y= 1 ## [1] 2 fsub(1, x=3) ## x= 3 y= 1 ## [1] 2 fsub(x=3, 1) ## x= 3 y= 1 ## [1] 2 在调用函数时， 如果以“形参名=实参值”的格式输入参数， 则“形参名”与定义时的形参名完全匹配时最优先采用； 如果“形参名”是定义时的形参名的前一部分子串， 即部分匹配， 这时调用表中如果没有其它部分匹配， 也可以输入到对应的完整形参名的参数中； 按位置匹配是最后才进行的。 有缺省值的形参在调用时可省略。 形参的部分匹配虽然可以节省一丁点儿键入工作量， 但是很不严谨， 容易出错， 所以应避免使用。 现在不能关闭这种语法， 可以用 options(warnPartialMatchArgs = TRUE) 在使用了这种调用方法时发出警告信息。 作为好的程序习惯， 调用R函数时， 如果既有按位置对应的参数又有带名参数， 应仅有一个或两个是按位置对应的， 按位置对应的参数都写在前面， 带名参数写在后面， 按位置对应的参数在参数表中的位置应与定义时的位置一致。 在定义函数时，没有缺省值的参数写在前面， 有缺省值的参数写在后面。 不遵守这样的约定容易使得程序被误读， 有时会在运行时匹配错位。 R的形参、实参对应关系可以写成一个列表， 如fsub(3, y=1)中的对应关系可以写成列表 list(3, y=1)， 如果调用函数的形参、实参对应关系保存在列表中， 可以用函数do.call()来表示函数调用，如 do.call(fsub, list(3, y=1)) 与 fsub(3, y=1) 效果相同。 函数的复合调用，如\\(\\sin \\sqrt{x}\\)， 可以写成sin(sqrt(x))。 在magrittr包中定义了一个管道运算符“%&gt;%”， 可以使得这种复合调用按照正常的执行次序来写， 变成 x %&gt;% sqrt() %&gt;% sin() 复合调用的函数也可以带有选项， 比如\\(\\sum_{i=a}^b \\sqrt{i}\\)， 用普通复合方法写成 sum(sqrt(seq(a, b))) 可以用`%&gt;%写成： a %&gt;% seq(to=b) %&gt;% sqrt() %&gt;% sum() 在自变量比较简单时这种写法的优势不明显， 在对数据框或tibble进行多步骤的筛选、变换时， 总是将变换的中间结果数据框传递给下一个步骤， 这种写法能清楚地展示处理是如何一步一步执行的。 17.1.4 递归调用 在函数内调用自己叫做递归调用。 递归调用可以使得许多程序变得简单， 但是往往导致程序效率很低， 需谨慎使用。 R中在递归调用时， 最好用 Recall 代表调用自身， 这样保证函数即使被改名（在R中函数是一个对象， 改名后仍然有效）递归调用仍指向原来定义。 斐波那契数列是如下递推定义的数列： \\[ \\begin{aligned} &amp; x_0 = 0, \\quad x_1 = 1 \\\\ &amp; x_n = x_{n-2} + x_{n-1} \\end{aligned} \\] 这个数列可以用如下递归程序自然地实现： fib1 &lt;- function(n){ if(n == 0) return(0) else if(n == 1) return(1) else if(n &gt;=2 ) { Recall(n-1) + Recall(n-2) } } for(i in 0:10) cat(&quot;i =&quot;, i, &quot; x[i] =&quot;, fib1(i), &quot;\\n&quot;) ## i = 0 x[i] = 0 ## i = 1 x[i] = 1 ## i = 2 x[i] = 1 ## i = 3 x[i] = 2 ## i = 4 x[i] = 3 ## i = 5 x[i] = 5 ## i = 6 x[i] = 8 ## i = 7 x[i] = 13 ## i = 8 x[i] = 21 ## i = 9 x[i] = 34 ## i = 10 x[i] = 55 17.1.5 向量化 自定义的函数，如果其中的计算都是向量化的， 那么函数自动地可以接受向量作为输入，结果输出向量。 比如，将每个元素都变成原来的平方的函数: f &lt;- function(x){ x^2 } 如果输入一个向量，结果也是向量，输出的每个元素是输入的对应元素的相应的平方值。 但是，如下的分段函数： \\[ g(x) = \\begin{cases} x^2 , &amp; |x| \\leq 1, \\\\ 1, &amp; |x| &gt; 1 \\end{cases} \\] 其一元函数版本可以写成 g &lt;- function(x){ if(abs(x) &lt;= 1) { y &lt;- x^2 } else { y &lt;- 1 } y } 但是这个函数不能处理向量输入，因为if语句的条件必须是标量条件。 一个容易想到的修改是 gv &lt;- function(x){ y &lt;- numeric(length(x)) sele &lt;- abs(x) &lt;= 1 y[sele] &lt;- x[sele]^2 y[!sele] &lt;- 1.0 y } 或者 gv &lt;- function(x){ ifelse(abs(x) &lt;= 1, x^2, 1) } 对于没有这样简单做法的问题，可以将原来的逻辑包在循环中，如 gv &lt;- function(x){ y &lt;- numeric(length(x)) for(i in seq(along=x)){ if(abs(x[i]) &lt;= 1) { y[i] &lt;- x[i]^2 } else { y[i] &lt;- 1 } } y } 函数Vectorize可以将这样的操作自动化。如 g &lt;- function(x){ if(abs(x) &lt;= 1) { y &lt;- x^2 } else { y &lt;- 1 } y } gv &lt;- Vectorize(g) gv(c(-2, -0.5, 0, 0.5, 1, 1.5)) ## [1] 1.00 0.25 0.00 0.25 1.00 1.00 还可以使用purrr::map()或基本R的lapply()等泛函实现对各个元素的函数变换。 参见19.7。 17.1.6 无名函数 R允许使用没有函数名的函数对象, lapply类的函数经常使用无名的函数对象作为输入。 例如： vapply(iris[,1:4], function(x) max(x) - min(x), 0.0) ## Sepal.Length Sepal.Width Petal.Length Petal.Width ## 3.6 2.4 5.9 2.4 d &lt;- scale(Filter(function(x) is.numeric(x), iris)) integrate(function(x) sin(x)^2, 0, pi) ## 1.570796 with absolute error &lt; 1.7e-14 iris是R中的一个例子数据框，有150个观测， 前4个变量是数值型的， 最后一个变量Species是有三个水平的因子。 第一个语句对前4列分别计算极差。 第二个语句用Filter删选出iris数据框中的数值型列（即前4列）， 然后对这些列进行标准化（减去列均值、除以列标准差）， 保存到变量d中。 第三个语句用数值积分方法计算\\(\\int_0^{\\pi} \\sin^2(x) \\,dx\\)。 三个语句都用到了无名函数。 lapply这样的函数称为“泛函”， 参见19.7。 17.2 变量作用域 函数中变量的作用域， 是指在函数中用到的变量名如何找到对应的值， 以及如何确定某个变量绑定适用的范围。 17.2.1 全局变量和工作空间 在所有函数外面（如R命令行）定义的变量是全局变量。 在命令行定义的所有变量都保存在工作空间 （workspace）， 也称为全局环境中。 在RStudio的Environment窗格可以看到“Global Environment”的内容， 分为数据框(Data)、其它变量(Values)和函数(Functions)三类。 在命令行可以用ls()查看工作空间内容。 ls()中加上pattern选项可以指定只显示符合一定命名模式的变量，如 ls(pattern=&quot;^tmp[.]&quot;) 显示所有以tmp.开头的变量。 用object.size()函数查看变量占用存储大小， 单位为字节。 因为R的函数调用时可以读取工作空间中的全局变量值， 工作空间中过多的变量会引起莫名其妙的程序错误。 用rm()函数删除指定的变量， 比如 rm(x, z41) rm()中还可以用list参数指定一个要删除的变量名表。如 rm(list=ls(pattern=&quot;^tmp[.]&quot;)) 用save()函数保存工作空间中选择的某些变量； 用load()函数载入保存在文件中的变量。 如 save(my.large.data, file=&quot;my-large-data.RData&quot;) load(&quot;my-large-data.RData&quot;) 实际上，R的工作空间是R的变量搜索路径中的一层， 大体相当于全局变量空间。 R的已启用的软件包中的变量以及用命令引入的变量也在这个搜索路径中。 用search()返回当前的搜索路径。 17.2.2 局部变量 在一般计算机语言中， “变量”实际是计算机内存中的一段存储空间， 但是R中略微复杂一些， R的变量实际是指向R对象的引用， 称为“绑定”。 在较简单的函数定义中大体上可以将R变量看成是对应的存储空间。 函数的参数（自变量）在定义时并没有对应的存储空间， 所以也称函数定义中的参数为“形式参数”。 函数的形式参数在调用时被赋值为实参值（这是一般情形）， 形参变量和函数体内被赋值的变量都是局部的。 这一点符合函数式编程(functional programming)的要求。 所谓局部变量， 就是仅在函数运行时才存在， 一旦退出函数就不存在的变量。 17.2.2.1 自变量的局部性 在函数被调用时， 形式参数（自变量）被赋值为实际的值（称为实参）， 如果实参是变量， 形式参数可以看作实参的一个副本， 除了极少数的特例（如环境）， 在函数内部对形式参数作任何修改在函数运行完成后都不影响原来的实参变量， 而且函数运行完毕后形式参数不再与实际的存储空间联系。 在下例中， 在命令行定义了全局变量xv, xl, 然后作为函数f()的自变量值（实参）输入到函数中， 函数中对两个形式参数作了修改， 函数结束后实参变量xv, xl并未被修改，形参变量也消失了。 例子程序如下： xv &lt;- c(1,2,3) xl &lt;- list(a=11:15, b=&quot;James&quot;) if(exists(&quot;x&quot;)) rm(x) f &lt;- function(x, y){ cat(&quot;输入的 x=&quot;, x, &quot;\\n&quot;) x[2] &lt;- -1 cat(&quot;函数中修改后的 x=&quot;, x, &quot;\\n&quot;) cat(&quot;输入的y为:\\n&quot;); print(y) y[[2]] &lt;- &quot;Mary&quot; cat(&quot;函数中修改过的y为:\\n&quot;); print(y) } f(xv, xl) ## 输入的 x= 1 2 3 ## 函数中修改后的 x= 1 -1 3 ## 输入的y为: ## $a ## [1] 11 12 13 14 15 ## ## $b ## [1] &quot;James&quot; ## ## 函数中修改过的y为: ## $a ## [1] 11 12 13 14 15 ## ## $b ## [1] &quot;Mary&quot; ## cat(&quot;函数运行完毕后原来变量xv不变：&quot;, xv, &quot;\\n&quot;) ## 函数运行完毕后原来变量xv不变： 1 2 3 cat(&quot;函数运行完毕后原来变量xl不变：:\\n&quot;); print(xl) ## 函数运行完毕后原来变量xl不变：: ## $a ## [1] 11 12 13 14 15 ## ## $b ## [1] &quot;James&quot; ## cat(&quot;函数运行完毕后形式参数x不存在：:\\n&quot;); print(x) ## 函数运行完毕后形式参数x不存在：: ## Error in print(x) : object &quot;x&quot; not found R语言的这种特点对于传递超大的数据是不利的， 所以R中会容纳超大数据的类型往往设计成修改副本时不占用不必要的额外存储空间， 比如，tibble类型就有这样的特点。 17.2.2.2 修改自变量 为了修改某个自变量， 在函数内修改其值并将其作为函数返回值， 赋值给原变量。 比如定义了如下函数： f &lt;- function(x, inc=1){ x &lt;- x + inc x } 调用如 x &lt;- 100 cat(&quot;原始 x=&quot;, x, &quot;\\n&quot;) ## 原始 x= 100 x &lt;- f(x) cat(&quot;修改后 x=&quot;, x, &quot;\\n&quot;) ## 修改后 x= 101 17.2.2.3 函数内的局部变量 在函数内部用赋值定义的变量都是局部变量， 即使在工作空间中有同名的变量， 此变量在函数内部被赋值时就变成了局部变量， 原来的全局变量不能被修改。 这种规则称为掩藏(masking)。 之所以如此， 是因为赋值本质上是“绑定”， 函数内部属于与工作空间（全局环境）不同的另一个环境， 一个变量一旦在函数内被重新绑定， 它就变成了仅在函数内部能被访问的变量， 即局部变量， 与原来在工作空间中同名的变量也没有关系了。 局部变量在函数运行结束后就会消失。 如 if(&quot;x&quot; %in% ls()) rm(x) f &lt;- function(){ x &lt;- 123 cat(&quot;函数内：x = &quot;, x, &quot;\\n&quot;) } f() cat(&quot;函数运行完毕后：x=&quot;, x, &quot;\\n&quot;) ## 函数内：x = 123 &gt; cat(&quot;函数运行完毕后：x=&quot;, x, &quot;\\n&quot;) ## Error in cat(&quot;函数运行完毕后：x=&quot;, x, &quot;\\n&quot;) : object &quot;x&quot; not found 再比如， 下面的函数试图知道自己被调用了多少次， 但是因为每次函数调用完毕局部变量就消失， 再次调用时的局部变量已经对应到全新的存储空间， 所以如下的程序不能达到目的： f &lt;- function(){ if(!exists(&quot;runTimes&quot;)){ runTimes &lt;- 1 } else { runTimes &lt;- runTimes + 1 } print(runTimes) } f() ## [1] 1 f() ## [1] 1 虽然这个问题可以利用将调用次数保存在全局变量中解决， 但是应尽可能少用全局变量； 用R的闭包(closure)可以比较完美地解决这样的问题。 17.2.3 在函数内访问全局变量 函数内部可以读取全局变量的值，但一般不能修改全局变量的值。 在现代编程指导思想中， 全局变量容易造成不易察觉的错误， 应谨慎使用， 当然，也不是禁止使用， 有些应用中不使用全局变量会使得程序更复杂且低效。 在下面的例子中， 在命令行定义了全局变量x.g， 在函数f()读取了全局变量的值， 但是在函数内给这样的变量赋值， 结果得到的变量就变成了局部变量， 全局变量本身不被修改： x.g &lt;- 9999 f &lt;- function(x){ cat(&quot;函数内读取：全局变量 x.g = &quot;, x.g, &quot;\\n&quot;) x.g &lt;- -1 cat(&quot;函数内对与全局变量同名的变量赋值： x.g = &quot;, x.g, &quot;\\n&quot;) } f() ## 函数内读取：全局变量 x.g = 9999 ## 函数内对与全局变量同名的变量赋值： x.g = -1 cat(&quot;退出函数后原来的全局变量不变： x.g =&quot;, x.g, &quot;\\n&quot;) ## 退出函数后原来的全局变量不变： x.g = 9999 在函数内部如果要修改全局变量的值，用 &lt;&lt;-代替&lt;-进行赋值。如 x.g &lt;- 9999 f &lt;- function(x){ cat(&quot;函数内读取：全局变量 x.g = &quot;, x.g, &quot;\\n&quot;) x.g &lt;&lt;- -1 cat(&quot;函数内用&quot;&lt;&lt;-&quot;对全局变量变量赋值： x.g = &quot;, x.g, &quot;\\n&quot;) } f() ## 函数内读取：全局变量 x.g = 9999 ## 对全局变量变量赋值： x.g = -1 cat(&quot;退出函数后原来的全局变量被修改了： x.g =&quot;, x.g, &quot;\\n&quot;) ## 退出函数后原来的全局变量被修改了： x.g = -1 后面将进一步解释函数在嵌套定义时&lt;&lt;-的不同含义。 "],["prog-prof.html", "18 R程序效率 18.1 R的运行效率 18.2 向量化编程 18.3 减少显式循环 18.4 避免制作副本 18.5 R的计算函数 18.6 并行计算", " 18 R程序效率 18.1 R的运行效率 R是解释型语言，在执行单个运算时， 效率与编译代码相近； 在执行迭代循环时， 效率较低， 与编译代码的速度可能相差几十倍。 在循环中对变量进行修改尤其低效， 因为R在修改某些数据类型的子集时会复制整个数据对象。 R以向量、矩阵为基础运算单元， 在进行向量、矩阵运算时效率很高， 应尽量采用向量化编程。 另外，R语言的设计为了方便进行数据分析和统计建模， 有意地使语言特别灵活， 比如， 变量为动态类型而且内容可修改， 变量查找在当前作用域查找不到可以向上层以及扩展包中查找， 函数调用时自变量仅在使用其值时才求值（懒惰求值）， 这样的设计都为运行带来了额外的负担， 使得运行变慢。 在计算总和、元素乘积或者每个向量元素的函数变换时， 应使用相应的函数，如sum, prod, sqrt, log等。 对于从其它编程语言转移到R语言的学生， 如果不细究R特有的编程模式， 编制的程序可能效率比正常R程序慢上几十倍， 而且繁琐冗长。 为了提高R程序的运行效率， 需要尽可能利用R的向量化特点， 尽可能使用已有的高效函数， 还可以把运行速度瓶颈部分改用C++、FORTRAN等编译语言实现， 可以用R的profiler工具查找运行瓶颈。 对于大量数据的长时间计算， 可以借助于现代的并行计算工具。 对已有的程序， 仅在运行速度不满意时才需要进行改进， 否则没必要花费宝贵的时间用来节省几秒钟的计算机运行时间。 要改善运行速度， 首先要找到运行的瓶颈， 这可以用专门的性能分析（profiling）功能实现。 R软件中的Rprof()函数可以执行性能分析的数据收集工作， 收集到的性能数据用summaryRprof()函数可以显示运行最慢的函数。 如果使用RStudio软件，可以用Profile菜单执行性能数据收集与分析， 可以在图形界面中显示程序中哪些部分运行花费时间最多。 在改进已有程序的效率时， 第一要注意的就是不要把原来的正确算法改成一个速度更快但是结果错误的算法。 这个问题可以通过建立试验套装， 用原算法与新算法同时试验看结果是否一致来避免。 多种解决方案的正确性都可以这样保证， 也可以比较多种解决方案的效率。 本章后面部分描述常用的改善性能的方法。 对于涉及到大量迭代的算法，如果用R实现性能太差不能满足要求， 可以改成C++编码，用Rcpp扩展包连接到R中。 Rcpp扩展包的使用将单独讲授。 R的运行效率也受到内存的影响， 占用内存过多的算法有可能受到物理内存大小限制无法运行， 过多复制也会影响效率。 如果要实现一个比较单纯的不需要利用R已有功能的算法， 发现用R计算速度很慢的时候， 也可以考虑先用Julia语言实现。 Julia语言设计比R更先进，运算速度快得多， 运算速度经常能与编译代码相比， 缺点是刚刚诞生几年的时间， 可用的软件包还比较少。 18.2 向量化编程 18.2.1 示例1 假设要计算如下的统计量： \\[ w = \\frac{1}{n} \\sum_{i=1}^n | x_i - \\hat m |, \\] 其中\\(x_1, x_2, \\dots, x_n\\)是某总体的样本， \\(\\hat m\\)是样本中位数。 用传统的编程风格， 把这个统计量的计算变成一个R函数，可能会写成： f1 &lt;- function(x){ n &lt;- length(x) mhat &lt;- median(x) s &lt;- 0.0 for(i in 1:n){ s &lt;- s + abs(x[i] - mhat) } s &lt;- s/n return(s) } 用R的向量化编程，函数体只需要一个表达式： f2 &lt;- function(x) mean( abs(x - median(x)) ) 其中x - median(x)利用了向量与标量运算结果是向量每个元素与标量运算的规则， abs(x - median(x))利用了abs()这样的一元函数如果以向量为输入就输出每个元素的函数值组成的向量的规则，mean(...)避免了求和再除以n的循环也不需要定义多余的变量n。 显然，第二种做法的程序比第一种做法简洁的多， 如果多次重复调用， 第二种做法的计算速度比第一种要快几十倍甚至上百倍。 在R中， 用system.time()函数可以求某个表达式的计算时间， 返回结果的第3项是流逝时间。 下面对x采用10000个随机数， 并重复计算1000次，比较两个程序的效率： nrep &lt;- 1000 x &lt;- runif(10000) y1 &lt;- numeric(nrep); y2 &lt;- y1 system.time(for(i in 1:nrep) y1[i] &lt;- f1(x) )[3] ## elapsed ## 10.08 system.time(for(i in 1:nrep) y1[i] &lt;- f2(x) )[3] ## elapsed ## 0.48 速度相差二十倍以上。 有一个R扩展包microbenchmark可以用来测量比较两个表达式的运行时间。 如: x &lt;- runif(10000) microbenchmark::microbenchmark( f1(x), f2(x) ) ## Unit: microseconds ## expr min lq mean median uq max neval cld ## f1(x) 2301.9 2386.75 3064.035 2466.85 3273 11499.9 100 b ## f2(x) 400.6 421.25 548.897 436.55 559 4940.8 100 a 就平均运行时间（单位：毫秒）来看，f2()比f1()快大约30倍。 18.2.2 示例2 假设要编写函数计算 \\[ \\begin{aligned} f(x) = \\begin{cases} 1 &amp; x \\geq 0, \\\\ 0 &amp; \\text{其它} \\end{cases} \\end{aligned} \\] 利用传统思维，程序写成 f1 &lt;- function(x){ n &lt;- length(x) y &lt;- numeric(n) for(i in seq_along(x)){ if(x[i] &gt;= 0) y[i] &lt;- 1 else y[i] &lt;- 0 } y } 实际上，y &lt;- numeric(n)使得y的每个元素都初始化为0， 所以程序中else y[i] &lt;- 0可以去掉。 利用向量化与逻辑下标，程序可以写成: f2 &lt;- function(x){ n &lt;- length(x) y &lt;- numeric(n) y[x &gt;= 0] &lt;- 1 y } 但是，利用R中内建函数ifelse()， 可以把函数体压缩到仅用一个语句： f3 &lt;- function(x) ifelse(x &gt;= 0, 1, 0) 18.2.3 示例3 考虑一个班的学生存在生日相同的概率。 假设一共有365个生日(只考虑月、日)。 设一个班有n个人, 当n大于365时{至少两个人有生日相同}是必然事件(概率等于1)。 当\\(n\\)小于等于365时： \\[ \\begin{aligned} &amp; P(\\text{至少有两人同生日}) \\\\ =&amp; 1 - P(\\text{$n$个人生日彼此不同}) \\\\ =&amp; 1 - \\frac{365\\times 364\\times\\cdots\\times(365 - (n-1))}{365^n} \\\\ =&amp; 1 - \\frac{365-0}{365} \\cdot \\frac{365-1}{365} \\cdots \\frac{365 - (n-1)}{365} \\end{aligned} \\] 对\\(n=1,2,\\dots, 365\\)来计算对应的概率。 完全用循环（两重循环），程序写成： f1 &lt;- function(){ ny &lt;- 365 x &lt;- numeric(ny) for(n in 1:ny){ s &lt;- 1 for(j in 0:(n-1)){ s &lt;- s * (365-j)/365 } x[n] &lt;- 1 - s } x } 注意， 不能先计算\\(365\\times 364\\times\\cdots\\times(365 - (n-1))\\) 和\\(365^n\\)再相除， 这会造成数值溢出。 用prod()函数可以向量化内层循环： f2 &lt;- function(){ ny &lt;- 365 x &lt;- numeric(ny) for(n in 1:ny){ x[n] &lt;- 1 - prod((365:(365-n+1))/365) } x } 程序利用了向量与标量的除法， 以及内建函数prod()。 把程序用cumprod()函数改写， 可以完全避免循环： f3 &lt;- function(){ ny &lt;- 365 x &lt;- 1 - cumprod((ny:1)/ny) x } 用microbenchmark比较: microbenchmark::microbenchmark( f1(), f2(), f3() ) ## Unit: microseconds ## expr min lq mean median uq max neval ## f1() 2534.807 2577.730 2679.48244 2615.256 2712.9270 3408.187 100 ## f2() 323.855 333.365 414.81692 344.160 369.3485 5868.456 100 ## f3() 1.028 1.542 2.52415 2.056 2.5700 25.189 100 f2()比f1()快大约7倍， f3()比f2()又快了大约160倍， f3()比f1()快了一千倍以上！ 18.3 减少显式循环 显式循环是R运行速度较慢的部分， 有循环的程序也比较冗长， 与R的向量化简洁风格不太匹配。 另外， 在循环内修改数据子集，例如数据框子集， 可能会先制作副本再修改， 这当然会损失很多效率。 R 3.1.0版本以后列表元素在修改时不制作副本， 但数据框还会制作副本。 前面已经指出， 利用R的向量化运算可以减少很多循环程序。 R中的有些运算可以用内建函数完成， 如sum, prod, cumsum, cumprod, mean, var, sd等。 这些函数以编译程序的速度运行， 不存在效率损失。 R的sin, sqrt, log等函数都是向量化的， 可以直接对输入向量的每个元素进行变换。 对矩阵，用apply函数汇总矩阵每行或每列。 colMeans, rowMeans可以计算矩阵列平均和行平均， colSums, rowSums可以计算矩阵列和与行和。 apply类函数有多个， 包括apply, sapply, lapply, tapply, vapply, replicate等。 这些函数不一定能提高程序运行速度， 但是使用这些函数更符合R的程序设计风格， 使程序变得简洁， 当然， 程序更简洁并不等同于程序更容易理解， 要理解这样的程序， 需要更多学习与实践。 参见19.7。 18.3.1 replicate()函数 replicate()函数用来执行某段程序若干次， 类似于for()循环但是没有计数变量。 常用于随机模拟。 replicate()的缺省设置会把重复结果尽可能整齐排列成一个多维数组输出。 语法为 replicate(重复次数, 要重复的表达式) 其中的表达式可以是复合语句, 也可以是执行一次模拟的函数。 下面举一个简单模拟例子。 设总体\\(X\\)为\\(\\text{N}(0, 1)\\), 取样本量\\(n=5\\)， 重复地生成模拟样本共\\(B=6\\)组， 输出每组样本的样本均值和样本标准差。 模拟可以用如下的replicate()实现： set.seed(1) replicate(6, { x &lt;- rnorm(5, 0, 1); c(mean(x), sd(x)) }) ## [,1] [,2] [,3] [,4] [,5] [,6] ## [1,] 0.1292699 0.1351357 0.03812297 0.4595670 0.08123054 -0.3485770 ## [2,] 0.9610394 0.6688342 1.49887443 0.4648177 1.20109623 0.7046822 结果是一个矩阵，矩阵行数与每次模拟的结果（均值、标准差）个数相同， 这里第一行都是均值，第二行都是标准差； 矩阵每一列对应于一次模拟。此结果转置可能更合适。 18.4 避免制作副本 类似于x &lt;- c(x, y), x &lt;- rbind(x, y)这样的累积结果每次运行都会制作一个x的副本， 在x存储量较大或者重复修改次数很多时会减慢程序。 例如， 下面的程序执行10000次模拟， 每次模拟求10个U(0,1)均匀随机数的极差， 求平均极差： set.seed(101) system.time({ M &lt;- 1E5 x &lt;- c() for(i in seq(M)){ x &lt;- c(x, diff(range(runif(10)))) } mean(x) }) ## 用户 系统 流逝 ## 20.79 3.34 24.14 上面的程序不仅是低效率的做法， 也没有预先精心设计用来保存结果的数据结构。 数据建模或随机模拟的程序都应该事先分配好用来保存结果的数据结构， 在每次循环中填入相应结果。如： set.seed(101) system.time({ M &lt;- 1E5 x &lt;- numeric(M) for(i in seq(M)){ x[[i]] &lt;- diff(range(runif(10))) } mean(x) }) ## 用户 系统 流逝 ## 1.59 0.01 1.61 这样的程序结构更清晰， 效率更高， 而且循环次数越多， 比x &lt;- c(x, ...)这样的做法的优势越大。 在循环内修改数据框的值也会制作数据框副本， 当数据框很大或者循环次数很多时会使得程序很慢。如： set.seed(101) m &lt;- 2E4; n &lt;- 100 x &lt;- as.data.frame(matrix( runif(n*M), nrow=n, ncol=m)) system.time({ for(j in seq(m)){ x[[j]] &lt;- x[[j]] + 1 } }) ## 用户 系统 流逝 ## 14.92 0.02 14.94 在循环内修改列表元素就不会制作副本， 从而可以避免这样的效率问题，如： set.seed(101) m &lt;- 2E4; n &lt;- 100 x &lt;- replicate(m, runif(n), simplify=FALSE) system.time({ for(j in seq(m)){ x[[j]] &lt;- x[[j]] + 1 } }) ## 用户 系统 流逝 ## 0.01 0.01 0.03 x &lt;- as.data.frame(x) replicate()函数中用simplify=FALSE使结果总是返回列表。 要注意的是， 上面第二个程序中的as.data.frame(x)也是效率较差的。 将数据保存在列表中比保存在数据框中访问效率高， 数据框提供的功能更丰富。 18.5 R的计算函数 R中提供了大量的数学函数、统计函数和特殊函数， 可以打开R的HTML帮助页面， 进入“Search Enging &amp; Keywords”链接， 查看其中与算术、数学、优化、线性代数等有关的专题。 这里简单列出一部分常用函数， 对函数filter, fft, convolve进行说明。 18.5.1 数学函数 常用数学函数包括abs, sign, log, log10, sqrt, exp, sin, cos, tan, asin, acos, atan, atan2, sinh, cosh, tanh。 还有gamma, lgamma(伽玛函数的自然对数)。 用于取整的函数有ceiling, floor, round, trunc, signif, as.integer等。 这些函数是向量化的一元函数。 choose(n,k)返回从\\(n\\)中取\\(k\\)的组合数。 factorial(x)返回\\(x!\\)结果。 combn(x,m)返回从集合\\(x\\)中每次取出\\(m\\)个的所有不同取法， 结果为一个矩阵，矩阵每列为一种取法的\\(m\\)个元素值。 18.5.2 概括函数 sum对向量求和, prod求乘积。 cumsum和cumprod计算累计， 得到和输入等长的向量结果。 diff计算前后两项的差分（后一项减去前一项）。 mean计算均值，var计算样本方差或协方差矩阵， sd计算样本标准差, median计算中位数， quantile计算样本分位数。 cor计算相关系数。 colSums, colMeans, rowSums, rowMeans对矩阵的每列或每行计算总和或者平均值， 效率比用apply函数要高。 rle和inverse.rle用来计算数列中“连”长度及其逆向恢复， “连”经常用在统计学的随机性检验中。 18.5.3 最值 max和min求最大和最小， cummax和cummin累进计算。 range返回最小值和最大值两个元素。 对于max, min, range， 如果有多个自变量可以把这些自变量连接起来后计算。 pmax(x1,x2,...)对若干个等长向量计算对应元素的最大值， 不等长时短的被重复使用。 pmin类似。 比如，pmax(0, pmin(1,x))把x限制到\\([0,1]\\)内。 18.5.4 排序 sort返回排序结果。 可以用decreasing=TRUE选项进行降序排序。 sort可以有一个partial=选项， 这样只保证结果中partial=指定的下标位置是正确的。 比如: sort(c(3,1,4,2,5), partial=3) ## [1] 2 1 3 4 5 只保证结果的第三个元素正确。 可以用来计算样本分位数估计。 在sort()中用选项na.last指定缺失值的处理， 取NA则删去缺失值， 取TRUE则把缺失值排在最后面， 取FALSE则把缺失值排在最前面。 order返回排序用的下标序列, 它可以有多个自变量， 按这些自变量的字典序排序。 可以用decreasing=TRUE选项进行降序排序。 如果只有一个自变量，可以使用sort.list函数。 rank计算秩统计量，可以用ties.method指定同名次处理方法， 如ties.method=min取最小秩。 order, sort.list, rank也可以有 na.last选项，只能为TRUE或FALSE。 unique()返回去掉重复元素的结果， duplicated()对每个元素用一个逻辑值表示是否与前面某个元素重复。 如 unique(c(1,2,2,3,1)) ## [1] 1 2 3 duplicated(c(1,2,2,3,1)) ## [1] FALSE FALSE TRUE FALSE TRUE rev反转序列。 18.5.5 一元定积分integrate integrate(f, lower, upper)对一元函数f计算从lower到upper的定积分。 使用自适应算法保证精度。 如： integrate(sin, 0, pi) ## 2 with absolute error &lt; 2.2e-14 函数的返回值不仅仅包含定积分数值， 还包含精度等信息。 18.5.6 一元函数求根uniroot uniroot(f, interval)对函数f在给定区间内求一个根， interval为区间的两个端点。 要求f在两个区间端点的值异号。 即使有多个根也只能给出一个。 如 uniroot(function(x) x*(x-1)*(x+1), c(-2, 2)) ## $root ## [1] 0 ## ## $f.root ## [1] 0 ## ## $iter ## [1] 1 ## ## $init.it ## [1] NA ## ## $estim.prec ## [1] 2 对于多项式， 可以用polyroot函数求出所有的复根。 18.5.7 离散傅立叶变换fft R中fft函数使用快速傅立叶变换算法计算离散傅立叶变换。 设x为长度n的向量， y=fft(x)，则 y[k] = sum(x * complex( argument = -2*pi * (0:(n-1)) * (k-1)/n)) 即 \\[ \\begin{aligned} y_{k+1} =&amp; \\sum_{j=0}^{n-1} x_{j+1} \\exp\\left(-i 2\\pi \\frac{k j}{n} \\right), \\ k=0,1,\\dots,n-1. \\end{aligned} \\] 注意没有除以\\(n\\)，结果是复数向量。 另外，若y=fft(x), z=fft(y, inverse=T), 则 x == z/length(x)。 快速傅立叶变换是数值计算中十分常用的工具， R软件包fftw可以进行优化的快速傅立叶变换。 18.5.8 用filter函数作迭代 R在遇到向量自身迭代时很难用向量化编程解决， filter函数可以解决其中部分问题。 filter函数可以进行卷积型或自回归型的迭代。 语法为 filter(x, filter, method = c(&quot;convolution&quot;, &quot;recursive&quot;), sides=2, circular =FALSE, init) 下面用例子演示此函数的用途。 18.5.8.1 示例1：双侧滤波 对输入序列\\(x_t, t=1,2,\\dots,n\\)， 希望进行如下滤波计算: \\[ \\begin{aligned} y_{t} = \\sum_{j=-k}^k a_j x_{t-j}, \\ k+1 \\leq t \\leq n-k-1, \\end{aligned} \\] 其中\\((a_{-k}, \\dots, a_0, \\dots, a_{k})\\)是长度为\\(2k+1\\)的向量。 注意公式中\\(a_j\\)与\\(x_{t-j}\\)对应。 假设\\(x\\)保存在向量x中， \\((a_{-k}, \\dots, a_0, \\dots, a_{k})\\)保存在向量f中， \\(y_{k+1}, \\dots, y_{n-k}\\)保存在向量y中, 无定义部分取NA, 程序可以写成 y &lt;- filter(x, f, method=&quot;convolution&quot;, sides=2) 比如，设\\(x = (1, 3, 7, 12, 17, 23)\\), \\((a_{-1}, a_0, a_{1}) = (0.1, 0.5, 0.4)\\), 则 \\[ \\begin{aligned} y_t = 0.1 \\times x_{t+1} + 0.5 \\times x_t + 0.4 \\times x_{t-1}, \\ t=2,3,\\dots,5 \\end{aligned} \\] 用filter()函数计算，程序为： y &lt;- filter(c(1,3,7,12,17,23), c(0.1, 0.5, 0.4), method=&quot;convolution&quot;, sides=2) y ## Time Series: ## Start = 1 ## End = 6 ## Frequency = 1 ## [1] NA 2.6 5.9 10.5 15.6 NA 18.5.8.2 示例2: 单侧滤波 对输入序列\\(x_t, t=1,2,\\dots,n\\)， 希望进行如下滤波计算: \\[ \\begin{aligned} y_{t} = \\sum_{j=0}^k a_j x_{t-j}, \\ k+1 \\leq t \\leq n, \\end{aligned} \\] 其中\\((a_0, \\dots, a_{k})\\)是长度为\\(k+1\\)的向量。 注意公式中\\(a_j\\)与\\(x_{t-j}\\)对应。 假设\\(x\\)保存在向量x中， \\((a_0, \\dots, a_{k})\\)保存在向量f中， \\(y_{k+1}, \\dots, y_{n}\\)保存在向量y中, 无定义部分取NA, 程序可以写成 y &lt;- filter(x, f, method=&quot;convolution&quot;, sides=1) 比如，设\\(x = (1, 3, 7, 12, 17, 23)\\), \\((a_{0}, a_1, a_{2}) = (0.1, 0.5, 0.4)\\), 则 \\[ \\begin{aligned} y_t = 0.1 \\times x_{t} + 0.5 \\times x_{t-1} + 0.4 \\times x_{t-2}, \\ t=3,4,\\dots,6 \\end{aligned} \\] 程序为 y &lt;- filter(c(1,3,7,12,17,23), c(0.1, 0.5, 0.4), method=&quot;convolution&quot;, sides=1) y ## Time Series: ## Start = 1 ## End = 6 ## Frequency = 1 ## [1] NA NA 2.6 5.9 10.5 15.6 18.5.8.3 示例3: 自回归迭代 设输入\\(e_t, t=1,2,\\dots, n\\)， 要计算 \\[ \\begin{aligned} y_t = \\sum_{j=1}^k a_j y_{t-j} + e_t, \\ t=1,2,\\dots,n, \\end{aligned} \\] 其中\\((a_1, \\dots, a_k)\\)是\\(k\\)个实数， \\((y_{-k+1}, \\dots, y_0)\\)已知。 设\\(x\\)保存在向量x中，\\((a_1, \\dots, a_k)\\)保存在向量a中， \\((y_1, \\dots, y_n)\\)保存在向量y中。 如果\\((y_{-k+1}, \\dots, y_0)\\)都等于零， 可以用如下程序计算\\(y_1, y_2, \\dots, y_n\\): filter(x, a, method=&quot;recursive&quot;) 如果\\((y_0, \\dots, y_{-k+1})\\)保存在向量b中(注意与时间顺序相反)， 可以用如下程序计算\\(y_1, y_2, \\dots, y_n\\): filter(x, a, method=&quot;recursive&quot;, init=b) 比如， 设\\(e = (0.1, -0.2, -0.1, 0.2, 0.3, -0.2)\\), \\((a_1, a_2) = (0.9, 0.1)\\), \\(y_{-1}=y_0=0\\), 则 \\[ \\begin{aligned} y_t = 0.9 \\times y_{t-1} + 0.1 \\times y_{t-2} + e_t, \\ t=1,2,\\dots,6 \\end{aligned} \\] 迭代程序和结果为 y &lt;- filter(c(0.1, -0.2, -0.1, 0.2, 0.3, -0.2), c(0.9, 0.1), method=&quot;recursive&quot;) print(y, digits=3) ## Time Series: ## Start = 1 ## End = 6 ## Frequency = 1 ## [1] 0.1000 -0.1100 -0.1890 0.0189 0.2981 0.0702 这个例子中， 如果已知\\(y_{0}=200, y_{-1}=100\\), 迭代程序和结果为： y &lt;- filter(c(0.1, -0.2, -0.1, 0.2, 0.3, -0.2), c(0.9, 0.1), init=c(200, 100), method=&quot;recursive&quot;) print(y, digits=6) ## Time Series: ## Start = 1 ## End = 6 ## Frequency = 1 ## [1] 190.100 190.890 190.711 190.929 191.207 190.979 18.6 并行计算 现代桌面电脑和笔记本电脑的CPU通常有多个核心或虚拟核心（线程）， 如2核心或4虚拟核心。 通常R运行并不能利用全部的CPU能力， 仅能利用其中的一个虚拟核心。 使用特制的BLAS库（非R原有）可以并发运行多个线程， 一些R扩展包也可以利用多个线程。 利用多台计算机、多个CPU、CPU中的多核心和多线程同时完成一个计算任务称为并行计算。 想要充分利用多个电脑、多个CPU和CPU内的虚拟核心， 技术上比较复杂， 涉及到计算机之间与进程之间的通讯问题， 在要交流的数据量比较大时会造成并行计算的瓶颈。 实际上， 有些问题可以很容易地进行简单地并行计算。 比如， 在一个统计研究中， 需要对100组参数组合进行模拟， 评估不同参数组合下模型的性能。 假设研究人员有两台安装了R软件的计算机， 就可以在两台计算机上进行各自50组参数组合的模拟， 最后汇总在一起就可以了。 R的parallel包提供了一种比较简单的利用CPU多核心的功能， 思路与上面的例子类似， 如果有多个任务互相之间没有互相依赖， 就可以分解到多个计算机、多个CPU、多个虚拟核心中并行计算。 最简单的情形是一台具有单个CPU、多个虚拟核心的台式电脑或者笔记本电脑。 但是， 统计计算中最常见耗时计算任务是随机模拟， 随机模拟要设法避免不同进程的随机数序列的重复可能， 以及同一进程中不同线程的随机数序列的重复可能。 parallel包提供了parLapply()、parSapply()、parApply()函数， 作为lapply()、sapply()、apply()函数的并行版本， 与非并行版本相比， 需要用一个临时集群对象作为第一自变量。 18.6.1 例1：完全不互相依赖的并行运算 考虑如下计算问题: \\[ S_{k,n} = \\sum_{i=1}^n \\frac{1}{i^k} \\] 下面的程序取n为一百万，k为2到21，循环地用单线程计算。 f10 &lt;- function(k=2, n=1000){ s &lt;- 0.0 for(i in seq(n)) s &lt;- s + 1/i^k s } f11 &lt;- function(n=1000000){ nk &lt;- 20 v &lt;- sapply(2:(nk+1), function(k) f10(k, n)) v } system.time(f11())[3] ## elapsed ## 2.87 因为对不同的k， f0(k)计算互相不依赖， 也不涉及到随机数序列， 所以可以简单地并行计算而没有任何风险。 先查看本计算机的虚拟核心（线程）数： library(parallel) detectCores() ## [1] 8 用makeCluster()建立临时的有8个节点的单机集群： nNodes &lt;- 8 cpucl &lt;- makeCluster(nNodes) 用parSapply()或者parLapply()关于\\(k\\)并行地循环： f12 &lt;- function(n=1000000){ f10 &lt;- function(k=2, n=1000){ s &lt;- 0.0 for(i in seq(n)) s &lt;- s + 1/i^k s } nk &lt;- 20 v &lt;- parSapply(cpucl, 2:(nk+1), function(k) f10(k, n)) v } system.time(f12())[3] ## elapsed ## 1.19 并行版本速度提高了140%左右。 并行执行结束后， 需要解散临时的集群， 否则可能会有内存泄漏： stopCluster(cpucl) 注意并行版本的程序还需要一些在每个计算节点上的初始化， 比如调入扩展包，定义函数， 初始化不同的随机数序列等。 parallel包的并行执行用的是不同的进程， 所以传送给每个节点的计算函数要包括所有的依赖内容。 比如，f2()中内嵌了f0()的定义， 如果不将f0()定义在f2()内部， 就需要预先将f0()的定义传递给每个节点。 parallel包的clusterExport()函数可以用来把计算所依赖的对象预先传送到每个节点。 比如， 上面的f2()可以不包含f0()的定义， 而是用clusterExport()预先传递： cpucl &lt;- makeCluster(nNodes) clusterExport(cpucl, c(&quot;f10&quot;)) f13 &lt;- function(n=1000000){ nk &lt;- 20 v &lt;- parSapply(cpucl, 2:(nk+1), function(k) f10(k, n)) v } system.time(f13())[3] ## elapsed ## 1.08 stopCluster(cpucl) 如果需要在每个节点预先执行一些语句， 可以用clusterEvalQ()函数执行，如 clusterEvalQ(cpucl, library(dplyr)) 18.6.2 例2：使用相同随机数序列的并行计算 为了估计总体中某个比例\\(p\\)的置信区间， 调查了一组样本， 在\\(n\\)个受访者中选“是”的比例为\\(\\hat p\\)。 令\\(\\lambda\\)为标准正态分布的双侧\\(\\alpha\\)分位数， 参数\\(p\\)的近似\\(1-\\alpha\\)置信区间为 \\[ \\frac{\\hat p + \\frac{\\lambda^2}{2n}}{1 + \\frac{\\lambda^2}{n}} \\pm \\frac{\\lambda}{\\sqrt{n}} \\frac{\\sqrt{\\hat p (1 - \\hat p) + \\frac{\\lambda^2}{4n}}} {1 + \\frac{\\lambda^2}{n}} \\] 称为Wilson置信区间。 假设要估计不同\\(1-\\alpha\\), \\(n\\), \\(p\\)情况下， 置信区间的覆盖率（即置信区间包含真实参数\\(p\\)的概率）。 可以将这些参数组合定义成一个列表， 列表中每一项是一种参数组合， 对每一组合分别进行随机模拟，估计覆盖率。 因为不同参数组合之间没有互相依赖的关系， 随机数序列完全可以使用同一个序列。 不并行计算的程序示例： wilson &lt;- function(n, x, conf){ hatp &lt;- x/n lam &lt;- qnorm((conf+1)/2) lam2 &lt;- lam^2 / n p1 &lt;- (hatp + lam2/2)/(1 + lam2) delta &lt;- lam / sqrt(n) * sqrt(hatp*(1-hatp) + lam2/4) / (1 + lam2) c(p1-delta, p1+delta) } f20 &lt;- function(cpar){ set.seed(101) conf &lt;- cpar[1] n &lt;- cpar[2] p0 &lt;- cpar[3] nsim &lt;- 100000 cover &lt;- 0 for(i in seq(nsim)){ x &lt;- rbinom(1, n, p0) cf &lt;- wilson(n, x, conf) if(p0 &gt;= cf[1] &amp;&amp; p0 &lt;= cf[2]) cover &lt;- cover+1 } cover/nsim } f21 &lt;- function(){ dp &lt;- rbind(rep(c(0.8, 0.9), each=4), rep(rep(c(30, 100), each=2), 2), rep(c(0.5, 0.1), 4)) lp &lt;- as.list(as.data.frame(dp)) res &lt;- sapply(lp, f20) res } system.time(f21())[3] ## elapsed ## 4.3 约运行4.3秒。 改为并行版本： library(parallel) nNodes &lt;- 8 cpucl &lt;- makeCluster(nNodes) clusterExport(cpucl, c(&quot;f20&quot;, &quot;wilson&quot;)) f22 &lt;- function(){ dp &lt;- rbind(rep(c(0.8, 0.9), each=4), rep(rep(c(30, 100), each=2), 2), rep(c(0.5, 0.1), 4)) lp &lt;- as.list(as.data.frame(dp)) res &lt;- parSapply(cpucl, lp, f20) res } system.time(f22())[3] ## elapsed ## 1.25 stopCluster(cpucl) 运行约1.25秒， 速度提高240%左右。 这里模拟了8种参数组合， 每种参数组合模拟了十万次， 每种参数组合模拟所用的随机数序列是相同的。 18.6.3 例3：使用独立随机数序列的并行计算 大量的耗时的统计计算是随机模拟， 有时需要并行计算的部分必须使用独立的随机数序列。 比如，需要进行一千万次重复模拟，每次使用不同的随机数序列， 可以将其分解为10组模拟，每组模拟一百万次， 这就要求这10组模拟使用的随机数序列不重复。 R中实现了L'Ecuyer的多步迭代复合随机数发生器， 此随机数发生器周期很长， 而且很容易将发生器的状态前进指定的步数。 parallel包的nextRNGStream()函数可以将该发生器前进到下一段的开始， 每一段都足够长， 可以用于一个节点。 以Wilson置信区间的模拟为例。 设\\(n=30\\), \\(p=0.01\\), \\(1-\\alpha=0.95\\)， 取重复模拟次数为1千万次，估计Wilson置信区间的覆盖率。 单线程版本为： f31 &lt;- function(nsim=1E7){ set.seed(101) n &lt;- 30; p0 &lt;- 0.01; conf &lt;- 0.95 cover &lt;- 0 for(i in seq(nsim)){ x &lt;- rbinom(1, n, p0) cf &lt;- wilson(n, x, conf) if(p0 &gt;= cf[1] &amp;&amp; p0 &lt;= cf[2]) cover &lt;- cover+1 } cover/nsim } system.time(cvg1 &lt;- f31())[3] ## elapsed ## 42.61 单线程版本运行了大约43秒。 改成并行版本。 比例2多出的部分是为每个节点分别计算一个随机数种子将不同的种子传给不同节点。 parallel包的clusterApply()函数为临时集群的每个节点分别执行同一函数， 但对每个节点分别使用列表的不同元素作为函数的自变量。 library(parallel) nNodes &lt;- 8 cpucl &lt;- makeCluster(nNodes) each.seed &lt;- function(s){ assign(&quot;.Random.seed&quot;, s, envir = .GlobalEnv) } RNGkind(&quot;L&#39;Ecuyer-CMRG&quot;) set.seed(101) seed0 &lt;- .Random.seed seeds &lt;- as.list(1:nNodes) for(i in 1:nNodes){ # 给每个节点制作不同的种子 seed0 &lt;- nextRNGStream(seed0) seeds[[i]] &lt;- seed0 } ## 给每个节点传送不同种子： junk &lt;- clusterApply(cpucl, seeds, each.seed) f32 &lt;- function(isim, nsimsub=10000){ n &lt;- 30; p0 &lt;- 0.01; conf &lt;- 0.95 cover &lt;- 0 for(i in seq(nsimsub)){ x &lt;- rbinom(1, n, p0) cf &lt;- wilson(n, x, conf) if(p0 &gt;= cf[1] &amp;&amp; p0 &lt;= cf[2]) cover &lt;- cover+1 } cover } clusterExport(cpucl, c(&quot;f32&quot;, &quot;wilson&quot;)) f33 &lt;- function(nsim=1E7){ nbatch &lt;- 40 nsimsub &lt;- nsim / nbatch cvs &lt;- parSapply(cpucl, 1:nbatch, f32, nsimsub=nsimsub) print(cvs) sum(cvs)/(nsim*nbatch) } system.time(cvg2 &lt;- f33())[3] ## [1] 963759 963660 963885 963739 963714 964171 963615 963822 963720 963939 ## elapsed ## 13.63 stopCluster(cpucl) 并行版本运行了大约14秒，速度提高约210%。 从两个版本各自一千万次重复模拟结果来看， 用随机模拟方法得到的覆盖率估计的精度大约为3位有效数字。 更大规模的随机模拟问题， 可以考虑使用多CPU的计算工作站或者服务器， 或用多台计算机通过高速局域网组成并行计算集群。 还有一种选择是租用云计算服务。 "],["p-advfunc.html", "19 函数进阶 19.1 函数调用的各种形式 19.2 嵌套定义与句法作用域(lexical scoping) 19.3 辅助嵌套函数 19.4 懒惰求值 19.5 程序调试 19.6 函数式编程介绍 19.7 泛函 19.8 函数工厂 19.9 环境", " 19 函数进阶 19.1 函数调用的各种形式 在R语言中，有两条简明的理解R程序的原则： 任何成分都是R的对象（变量、函数等等）； 任何活动都是调用函数（求子集、四则运算、比较、函数调用等）。 函数调用有四种方式： 一、前缀形式。 这也是一般的格式，如fsub(5, 2)。 二、中缀形式。 二元运算符实际上都是函数，5 - 2的写法是中缀形式， 等同于`-`(5, 2)。因为-不是合法的R变量名（函数名）， 所以在写成前缀形式时要用反向单撇号`保护。 这样，在lapply等泛函中可以使用`+`这样的四则运算作为输入的操作。 如 5 - 2 ## [1] 3 `-`(5, 2) ## [1] 3 为了给1:5每个元素减去2，可以写成 sapply(1:5, `-`, 2) ## [1] -1 0 1 2 3 用户也可以自己定义函数名如%x%这样的中缀函数， 可以用中缀格式调用。 如： `%+%` &lt;- function(x, y) paste0(x, y) &quot;xyz&quot; %+% &quot;123&quot; ## [1] &quot;xyz123&quot; 三、替换形式。 对属性的修改经常这样写， 如 x &lt;- 1:2 names(x) &lt;- c(&quot;a&quot;, &quot;b&quot;) x ## a b ## 1 2 看起来是在对一个函数的输出结果赋值， 这很不合理， 但实际相当于前缀形式的 x &lt;- 1:2 `*tmp*` &lt;- x x &lt;- `names&lt;-`(x, c(&quot;a&quot;, &quot;b&quot;)) rm(`*tmp*`) x 即制作了x的副本，调用names&lt;-函数， 将x重新绑定到names&lt;-函数的返回值。 四、特殊形式。 x[1], x[[1]]这些取子集或元素以及修改， (), {}，if结构、for循环等本质上也是函数调用， 只不过用了特殊的语法。 这些函数在R中都是初等函数(primitive functions)。 初等函数仅在基本R中定义， 是由C代码实现的， 用户无法访问其三个部分。 取子集的特殊函数例如： x &lt;- 1:5 x[1] ## [1] 1 `[`(x, 1) ## [1] 1 x[1] &lt;- 999 x ## [1] 999 2 3 4 5 x &lt;- 1:5 x &lt;- `[&lt;-`(x, 1, 999) x ## [1] 999 2 3 4 5 注意上面的x[1] &lt;- 999的替代写法中， 调用`[&lt;-`(x, 1, 999)是将其返回值（一个向量对象）重新绑定给变量x， 才达到了修改x的目的。 for循环也是函数调用， 如for(i in 1:3) print(i)可以等价地写成`for`(i, 1:3, print(i))。 19.2 嵌套定义与句法作用域(lexical scoping) R语言允许在函数体内定义函数。 比如， x &lt;- -1 f0 &lt;- function(x){ f1 &lt;- function(){ x + 100 } f1() } 其中内嵌的函数f1()称为一个closure(闭包)。 内嵌的函数体内在读取某个变量值时， 如果此变量在函数体内还没有被赋值， 它就不是局部的， 会向定义的外面一层查找， 外层一层找不到，就继续向外查找。 上面例子f1()定义中的变量x不是局部变量， 就向外一层查找， 找到的会是f0的自变量x，而不是全局空间中x。 如 f0(1) ## [1] 101 最后x+100中x取的是f0的实参值x=1， 而不是全局变量x=-1。 这样的变量查找规则叫做句法作用域(lexical scoping)， 即函数运行中需要使用某个变量时， 从其定义时的环境向外层逐层查找， 而不是在调用时的环境中查找。 例如， f0 &lt;- function(){ f1 &lt;- function(){ x &lt;- -1 f2 &lt;- function(){ x + 100 } f2() } x &lt;- 1000 f1() } f0() ## [1] 99 其中f2()运行时， 用到的x是f1()函数体内的局部变量x=-1， 而不是被调用时f0()函数体内的局部变量x=1000， 所以结果是-1 + 100 = 99。 “句法作用域”指的是函数调用时查找变量是查找其定义时的变量对应的存储空间， 而不是定义时变量所取的历史值。 函数运行时在找到某个变量对应的存储空间后， 会使用该变量的当前值，而不是函数定义的时候该变量的历史值。 这种规则称为动态查找(dynamic lookup)。 例如 f0 &lt;- function(){ x &lt;- -1 f1 &lt;- function(){ x + 100 } x &lt;- 1000 f1() } f0() ## [1] 1100 结果为什么不是-1 + 100 = 99而是1000 + 100 = 1100? 这是因为， f1()在调用时， 使用的x是f0函数体内局部变量x的值， 但是要注意的是程序运行时会访问该变量的当前值，即1000， 而不是函数定义的时候x的历史值-1。 句法作用域与动态查找一个说的是如何查找某个变量对应的存储空间， 一个说的是使用该存储空间何时的存储值， 程序运行时两个规则需要联合使用。 句法作用域不仅适用于查找变量， 也适用于函数体内调用别的函数时查找函数。 查找函数的规则与查找变量规则相同。 19.3 辅助嵌套函数 有时内嵌函数仅仅是函数内用来实现模块化的一种工具， 和正常的函数作用相同，没有任何特殊作用。 例如，如下的程序在自变量x中输入一元二次方程\\(a x^2 + b x + c = 0\\)的三个系数, 输出解： solve.sqe &lt;- function(x){ fd &lt;- function(a, b, c) b^2 - 4*a*c d &lt;- fd(x[1], x[2], x[3]) if(d &gt;= 0){ return( (-x[2] + c(1,-1)*sqrt(d))/(2*x[1]) ) } else { return( complex(real=-x[2], imag=c(1,-1)*sqrt(-d))/(2*x[1]) ) } } 在这个函数中内嵌的函数fd仅起到一个计算二次判别式的作用， 没有用到任何的闭包特性， 其中的形参变量a, b, c都是局部变量。 运行如 solve.sqe(c(1, -2, 1)) ## [1] 1 1 solve.sqe(c(1, -2, 0)) ## [1] 2 0 solve.sqe(c(1, -2, 2)) ## [1] 1+1i 1-1i 这样的内嵌函数与直接在全局空间中定义的函数区别不大， 只有一条区别： 只能在定义它的函数内运行， 不能被直接调用， 可以看成是函数内的私有函数， 可以避免名字冲突。 19.4 懒惰求值 R函数在调用执行时， 除非用到某个形式变量的值才求出其对应实参的值。 这一点在实参是常数时无所谓， 但是如果实参是表达式就不一样了。 形参缺省值也是只有在函数运行时用到该形参的值时才求值。 例如， f &lt;- function(x, y=ifelse(x&gt;0, TRUE, FALSE)){ x &lt;- -111 if(y) x*2 else x*10 } f(5) ## [1] -1110 可以看出，虽然形参x输入的实参值为5, 但是这时形参y并没按x=5被赋值为TRUE, 而是到函数体中第二个语句才被求值， 这时x的值已经变成了-111， 故y的值是FALSE。 另外要注意的是， 懒惰求值使得缺省值在初次访问时， 是在函数内的环境（局部变量作用域）内求值的， 不是在其调用处的环境内求值。 在函数内部， 用missing(x)对形参x判断用户是否没有提供对应的实参， 对位置形参和有缺省值的形参都适用。 19.5 程序调试 19.5.1 基本调试策略 自己编写的某些涉及到复杂的算法的程序可能一开始并不能给出期望的结果。 这包括如下的情况： 程序报错， 需要找到出错的地方加以纠正； 程序正常运行， 输出了结果， 但是结果明显有错； 最糟糕的是， 程序结果也看起来很正常， 但实际结果是错误的。 以上这三种情况是依次越来越糟糕的。 直接运行出错的情况一般是比较容易处理的。 为了尽可能保证程序结果正确， 在自己编写新算法时， 要运用模块化思想， 将问题分解为若干个小问题， 使得每一个小问题都比较容易验证结果是否正确， 将每一个小问题编写成一个单独的函数， 这样也可以避免一段很长的程序中许多变量混杂在一起。 在划分模块并编写好程序后， 应该编写一系列的测试函数， 对每个函数进行测试， 保证其在各种情况下的结果是正确的。 最好采纳R的规则化的测试策略进行自动化测试， 在编写R扩展包时就推荐同时提供测试代码。 如果程序还是有错误， 首先可以求助于搜索引擎、用户社区等。 如果这个问题是常见问题， 往往这样就可以解决问题。 如果问题没有解决， 需要将问题最小化： 减少引起错误的程序的复杂程度， 将不必要的代码尽可能用固定的输入数据代替， 使得出错程序很短， 而且错误可重复。 有时会有不可重复的错误， 这样的错误往往很难解决， 超出了一般R用户的能力。 在将问题程序简化并且错误可重复以后， 就要试图定位错误。 一般编程语言都有如下的一些一般性查错(debugging)方法： 在程序中适当位置加上输出命令（语句）， 输出怀疑有错的变量值。 某些变成语言提供了跟踪以及条件跟踪命令， 可以在程序运行到某个语句或者触发了某个条件时程序中止， 但允许用户控制逐行运行程序并随时查看变量值， 称为跟踪调试(tracing)。 跟踪调试可以是命令行工具， 也可以是集成在RStudio这样的集成编程环境中的图形界面工具。 在查错时， 科学研究思维照样起作用： 根据错误表现提出可能的原因假设， 制作测试输入数据验证假设， 记录相应输出并分析是否与假设的错误原因吻合。 如此反复直到找到出错原因并加以纠正。 查错并纠正就可能会破坏了成熟的代码， 造成新的错误， 所以最好能有自动化的测试策略， 在每次修改程序后都重新测试程序是否保持输出正确。 19.5.2 找到出错的函数 在较复杂的程序出错时， 需要首先将错误定位到某一函数调用。如： f1 &lt;- function(x) f2(x) f2 &lt;- function(x) 1/x f1(&quot;abc&quot;) ## Error in 1/x : 二进列运算符中有非数值参数 为了在多层次函数调用中找到出错的函数，可以用如下命令： traceback() ## 2: f2(x) at #1 ## 1: f1(&quot;abc&quot;) 结果是所谓的反向追踪(traceback)， 一般编程语言中称为调用栈(calling stack)。 这个输出是从下向上堆叠显示， 下层是调用方， 上层是被调用方。 在RStudio中运行时， 出错程序的右端可以显示“Show Traceback”以及“Rerun with Debug”快捷图标， 点击“Show Traceback”图标也可以显示反向追踪结果。 如果是一个源文件用source命名或图标运行时出错， 在显示反向追踪结果时还可以显示调用的各命令所在的程序行号。 点击“Rerun with Debug”可以进入跟踪调试状态， 显示出错时的运行环境中的变量值。 19.5.3 跟踪调试 R和RStudio提供了很好的跟踪运行程序的能力。 R的browser()命令可以用在程序中， 命令进入跟踪调试； RStudio的源文件显示界面可以用鼠标点击定义跟踪调试位置。 函数定义一般都包含多行，所以一般不在命令行定义函数， 而是把函数定义以及较长的程序写在源程序文件中， 用source命令运行。 用source命令调入运行的程序与在命令行运行的效果基本相同， 这样定义的变量也是全局变量。 考虑如下函数定义: f &lt;- function(x){ for(i in 1:n){ s &lt;- s + x[i] } } 这个函数定义有许多问题。 用一个测试输入调用f，发现有错误: print(f(1:5)) ## Error in 1:n : NA/NaN参数 简单的函数可以直接仔细检查发现错误， 用cat, print等输出中间结果查找错误。 R提供了一个browser()函数， 在程序中插入对browser()函数的调用， 可以进入跟踪调试状态， 可以实时地查看甚至修改运行时变量的值。 在RStudio的编辑窗口中打开.R源程序文件， 在某一程序行行号左端的空白处用鼠标单击， 就可以设定某一行为端点， 在用source命令运行到该处时就可以进入跟踪调试状态。 加入browser()命令后的程序如： f &lt;- function(x){ browser() for(i in 1:n){ s &lt;- s + x[i] } } 程序运行遇到browser()函数或设定的断点时程序进入跟踪调试状态， 命令行的提示符变成“Browse[1]&gt;”。 这个命令行的环境一般不再是全局环境， 而是断点所在的函数的运行环境， 可以看到函数的局部变量。 可以在调试环境中用命令去查看当前定义的变量值、逐个命令地运行， 但是用RStudio则可以更方便地执行这些操作。 在调试命令行，可以使用如下命令： 输入变量名查看变量值； 用n命令或者换行键逐句运行； 用s命令跟踪进调用的函数内部逐句运行； 用f命令快速执行到循环末尾或者函数末尾； 用c命令恢复正常运行，不再跟踪； 用Q命令强行终止程序运行。 进入调试状态后， RStudio界面提供了相应的支持。 这时RStudio的命令行窗格(Console)将会显示用于控制运行的图标， 包括执行下一语句（Next）、跟踪进入要调用的函数运行(Step into)、执行到函数末尾或者循环末尾(Finish)、不再跟踪继续正常运行（Continue）、终止运行（Stop）。 同时， 在RStudio的Environment窗格中会显示当前执行的命令所在的运行环境的内容， 包括函数内的局部变量； 如果点击其中的下拉菜单还可以显示函数的各层父环境。 在同一窗格中还会显示向后追踪(Traceback)， 即函数是如何被调用的。 为调试如上函数f的程序， 在定义中插入对browser()的调用如: f &lt;- function(x){ browser() for(i in 1:n){ s &lt;- s + x[i] } } 当在RStudio中调试运行时， 程序编辑窗口将显示当前要运行的程序行， 用命令行窗口(Console)的Next快捷图标可以运行到下一行。 命令行的显示如： &gt; print(f(1:5)) Called from: eval(expr, p) Browse[1]&gt; n debug在D:/disk/projects/Rbookweb/tmp2.R#2: for (i in 1:n) { s &lt;- s + x[i] } Browse[2]&gt; 继续用“Next”图标运行，命令行结果如： Browse[2]&gt; n Error in 1:n : NA/NaN参数 发现是在for(i in 1:n)行遇到未定义的变量n。 在源文件中把出错行改为for(i in 1:length(x))， 再次运行, 发现在运行s &lt;- s + x[i]行时， 遇到“错误: 找不到对象’s’”。 这是忘记初始化引起的。 在for语句前添加s &lt;- 0语句，函数定义变成： f &lt;- function(x){ browser() s &lt;- 0 for(i in 1:length(x)){ s &lt;- s + x[i] } } 再次运行， 在跟踪到循环时， 为了避免繁琐的跟踪过程， 可以用“执行到函数末尾或者循环末尾”快捷图标或命令行的f命令， 或者“Continue”快捷图标或命令行的c命令。 程序不显示错误但是也没有显示结果为NULL而不是我们期望得输入元素之和。 检查可以看出错误是忘记把函数返回值写在函数定义最后。 在函数定义最后添加s一行， 再次运行，程序结果与手工验算结果一致。 函数变成 f &lt;- function(x){ browser() n &lt;- length(x) s &lt;- 0 for(i in 1:n){ s &lt;- s + x[i] } s } 自定义函数应该用各种不同输入测试其正确性和稳定性。 比如，上面的函数当自变量x为零长度向量时应该返回0才合适， 但是上面的写法会返回一个numeric(0)结果， 这个结果表示长度为零的向量： f(numeric(0)) ## Called from: f(numeric(0)) ## Browse[1]&gt; c ## numeric(0) 程序输入了零长度自变量， 我们期望其输出为零而不是numeric(0)。 在自变量x为零长度时， 函数中for(i in 1:length(x)应该一次都不进入循环， 跟踪运行可以发现实际对i=1和i=0共运行了两轮循环。 把这里的1:length(x)改成seq_along(x)解决了问题， seq_along(x)生成x的下标序列， 如果x是零长度的则下标序列为零长度向量。 函数不需要修改后， 可以把对browser()的调用删除或注释掉， 在RStudio中关闭断点。 函数最终修改为： f &lt;- function(x){ s &lt;- 0 for(i in seq_along(x)){ s &lt;- s + x[i] } s } 这里只是用这个简单函数演示如何调试程序， 求向量元素和这个问题本身是不需要我们去定义新函数的， sum函数本来就是完成这样的功能。 实际上，许多我们认为需要自己编写程序做的事情， 在R网站都能找到别人已经完成的扩展包。 19.5.4 条件断点 用browser()函数与R的if结构配合可以制作条件断点。 比如， 在调试带有循环的程序时， 发现错误发生在循环内， 如果从循环开始就跟踪运行， 会浪费许多时间。 设已知错误发生在循环变量i等于501的时候， 就可以在循环内插入： if(i == 501) browser() 这样就可以在更接近出错的位置进入跟踪运行。 19.5.5 开启对一个函数的调试 可以用debug(f)命令对函数f开启跟踪运行， 这时每次调用f()时都会自动进入跟踪运行状态。 用undebug(f)取消对f的这种操作。 19.5.6 出错调试选项 比较长的程序在调试时如果从开头就跟踪， 比较耗时。可以设置成出错后自动进入跟踪模式， 检查出错时的变量值。只要进行如下设置： options(error=recover) 则在出错后可以选择进入出错的某一层函数内部, 在browser环境中跟踪运行。 在RStudio中调试某一源程序文件时， 可以选择“Debug–On Error”菜单， 并选择“Break in Code”， 就可以在出错时自动在出错处进入跟踪状态。 例如，用options()函数进行设置后， 前面那个求向量元素和的例子程序按最初的定义， 运行时出现如下的选择： ## Error in f(1:5) : object &#39;n&#39; not found ## ## Enter a frame number, or 0 to exit ## ## 1: f(1:5) ## ## Selection: f(1:5) ## ## Selection: 1 ## Called from: top level ## Browse[1]&gt; 在Selection后面输入了1，就进入了函数内部跟踪。 用Q终止运行并退出整个browser跟踪。 当函数调用函数时可以选择进入哪一个函数进行跟踪。 如果在RStudio中设置了“Break in Code”， 会自动在出错处进入跟踪运行状态。 19.5.7 stop()、warning()、message() 编写程序时应尽可能提前发现不合法的输入和错误的状态。 发现错误时， 可以用stop(s)使程序运行出错停止， 其中s是一个字符型对象， 用来作为显示的出错信息。 发现某些问题后如果不严重， 可以不停止程序运行， 但用warning(s)提交一个警告信息， 其中s是字符型的警告信息。 警告信息的显示可能比实际运行要延迟一些。 有些警告信息实际是错误， 用options()的warn参数可以设置警告级别， 如设置warn=2则所有警告当作错误处理。 设置如 options(warn=2) 其中warn=0是默认做法， warn=1表示不延迟显示。 函数message()与stop()、warning()类似， 不算是错误或者警告， 是提示性的信息输出。 message()不会像warning()那样延迟显示。 比如， 长时间的等待之前给出一个提示， 正在读写文件或者网络时给出提示， 等等。 与cat()等相比较， cat()是用户要求的输出， 而message()是程序员对用户的提示。 19.5.8 预防性设计 在编写自定义函数时， 可以检查自变量输入以确保输入符合要求。 函数stopifnot可以指定自变量的若干个条件， 当自变量不符合条件时自动出错停止。 例如，函数f()需要输入两个数值型向量x, y, 需要长度相等， 可以用如下的程序 f &lt;- function(x, y){ stopifnot(is.numeric(x), is.numeric(y), length(x)==length(y)) ## 函数体程序语句... } 19.5.9 出错处理机制 R运行可以用stop()产生错误状态， 停止运行； 用warning()产生警告， 用message()产生提示。 基本R提供了tryCatch()函数， 用来保护可能出错的代码， 并可以指定出错时用的恢复或诊断代码。 try()函数也可以保护可能出错的代码， 使得出错时错误信息照样显示但不中断运行。 扩展包rlang提供了一些对出错处理机制的增强功能。 详见(Wickham 2019)第8章：Conditions。 19.6 函数式编程介绍 R支持类(class)和方法(method)， 实际提供了适用于多种自变量的通用函数(generic function)， 不同自变量类型调用该类特有的方法， 但函数名可以保持不变。 这可以支持一定的面向对象编程方式。 R也支持函数式编程， 但不是专门的函数式编程语言。 R语言的设计主要用函数求值来进行运算； R的用户主要使用函数调用来访问R的功能。 按照函数式编程的要求， 函数应该是“第一级对象”， 可以将函数对象绑定到变量名上面， 可以在列表等结构中保存多个函数， 可以在函数内定义函数， 可以用函数作为函数的自变量， R函数满足这样的要求。 函数式编程的目的是提供可理解、可证明正确的软件。 R虽然带有函数式编程语言特点， 但并不强求使用函数式编程规范。 典型的函数式编程语言如Haskel, Lisp的运行与R的显式的、顺序的执行方式相差很大。 19.6.1 纯函数 函数式编程要求每个函数必须功能清晰、定义确切， 最好是所谓“纯函数”。 R并不是专门的函数式编程语言， 专门的函数式编程语言提供了定义纯函数的功能。 纯函数需要满足如下条件： 没有副作用。调用一个函数对后续运算没有影响， 不管是再次调用此函数还是调用其它函数。 这样，用全局变量在函数之间传递信息就是不允许的。 其它副作用包括写文件、打印、绘图等， 这样的副作用对函数式要求破坏不大。 函数返回值包含了函数执行的所有效果。 不受外部影响。函数返回值只依赖于其自变量及函数的定义。 函数定义仅由对所有可能的自变量值确定返回值来确定， 不依赖于任何外部信息（也就不能依赖于全局变量与系统设置值）。 在专用的函数时变成语言中， 函数定义返回值的方式是隐含地遍历所有可能的参数值给出返回值， 而不是用过程式的计算来修改对象的值。 不受赋值影响。 函数定义不需要反复对内部对象（所谓“状态变量”）赋值或修改。 R的函数一般不能修改实参的值， 这有助于实现纯函数的要求。 但是，如果多个函数之间用全局变量传递信息， 就不能算是纯函数。 像options()函数这样修改全局运行环境的功能会破坏函数式要求。 尽可能让自己的函数不依赖于options()中的参数。 如果函数对相同的输入可以有不同的输出当然不是纯函数， 例如R中的随机数函数(sample(), runif(), rnorm等)。 与具体硬件、软件环境有关的一些因素也破坏纯函数要求， 如不同的硬件常数、精度等。 调用操作系统的功能对函数式要求破坏较大。 减少赋值主要需要减少循环，可以用R的向量化方法解决。 一个R函数是否满足纯函数要求不仅要看函数本身， 还要看函数内部调用的其它函数是否纯函数。 R不是专用的函数式编程语言， 但可以采用函数式编程的范式， 将大多数函数写成纯函数， 将有副作用的单独写在少数的函数中。 19.6.2 副作用和运行环境恢复 如果函数除了输出之外还在其它方面影响了运行环境， 这样的函数就不是纯函数。 所有画图函数(plot等)、输出函数(cat, print, save等)都是这样的函数。 这些对运行环境的改变叫做副作用（side effects）。 又比如，library()函数会引入新的函数和变量， setwd(), Sys.setenv(), Sys.setlocale()会改变R运行环境， options(), par()会改变R全局设置。 自定义R函数中如果调用了非纯函数也就变成了非纯函数。 编程中要尽量控制副作用而且要意识到副作用的影响， 尤其是全局设置与全局变量的影响。 有些函数不可避免地要修改运行环境， 比如当前工作目录(用setwd())、R运行选项(用options())、绘图参数(用par())等， 如果可能的话， 在函数结束运行前， 应该恢复对运行环境的修改。 为此，可以在函数体的前面部分调用on.exit()函数， 此函数的参数是在函数退出前要执行的表达式或复合表达式。 例如， 绘图的函数中经常需要用par()修改绘图参数， 这会使得后续程序出错。 为此，可以在函数开头保存原始的绘图参数， 函数结束时恢复到原始的绘图参数。 如 f &lt;- function(){ opar &lt;- par(mfrow=c(1,2)) on.exit(par(opar)) plot((-10):10) plot((-10):10, ((-10):10)^2) } f() 如果函数中需要多次调用on.exit()指定多个恢复动作， 除第一个调用的on.exit()以外都应该加上add=TRUE选项。 如果需要指定越晚添加的恢复动作越先执行， 在on.exit()中还要加上after=FALSE选项。 19.6.3 R的函数式编程功能 R语言不是专用的函数式编程语言， 但支持使用函数式编程的一些常见做法。 R函数时第一级对象， 支持内嵌函数， 并可以输入函数作为函数的自变量， 称这样的函数为泛函(functionals)， 如lapply类函数； 可以输出函数作为函数结果， 称这样的函数为函数工厂； 可以输入函数， 进行一定修改后输出函数， 称这样的函数为函数算子(function operators)。 这些功能都为函数式编程风格提供了有力的支持。 利用R的purrr扩展包， 可以用统一的风格使用函数式编程， 比基本R的lapply类函数、Map、Reduce等更容易使用。 下面讲解泛函、函数工厂和函数算子。 19.7 泛函 许多函数需要用函数作为参数，称这样的函数为泛函(functionals)。 典型的泛函是lapply类函数。 这样的函数具有很好的通用性， 因为需要进行的操作可以输入一个函数来规定， 用输入的函数规定要进行什么样的操作。 19.7.1 purrr::map函数 设我们要对列表或向量x的每个元素x[[i]]调用函数f()， 将结果保存成一个列表。 这样做的一个程序框架是： y &lt;- vector(list, length(x)) for(i in seq_along(x)){ y[[i]] &lt;- f(x[[i]]) } names(y) &lt;- names(x) 其中的输入x是任意的， 函数f是任意的。 purrr包的map()函数可以用一条命令完成上述任务： y &lt;- map(x, f) 这个函数与基本R的lapply功能基本相同， 对数据框、列表的每一项进行计算或操作时最为适用。 19.7.1.1 map数据框处理示例 下面举例说明map函数对数据框处理的应用。 typeof()函数求变量的存储类型，如 d.class &lt;- readr::read_csv(&#39;class.csv&#39;) ## Parsed with column specification: ## cols( ## name = col_character(), ## sex = col_character(), ## age = col_double(), ## height = col_double(), ## weight = col_double() ## ) typeof(d.class[[&quot;age&quot;]]) ## [1] &quot;double&quot; 这里d.class是一个tibble数据框， tibble也是一个列表， 每个列表元素是数据框的一列。 如下程序使用purrr::map()求每一列的存储类型， map的结果总是列表，每个列表元素对应于输入的一个元素， 如: library(purrr) map(d.class, typeof) ## $name ## [1] &quot;character&quot; ## ## $sex ## [1] &quot;character&quot; ## ## $age ## [1] &quot;double&quot; ## ## $height ## [1] &quot;double&quot; ## ## $weight ## [1] &quot;double&quot; 当结果比较简单时， 保存为列表不够方便， 函数unlist()可以将比较简单的列表转换为基本类型的向量，如： unlist(map(d.class, typeof)) ## name sex age height weight ## &quot;character&quot; &quot;character&quot; &quot;double&quot; &quot;double&quot; &quot;double&quot; 关于一个数据框的结构， 用str()函数可以得到更为详细的信息： str(d.class) ## Classes &#39;spec_tbl_df&#39;, &#39;tbl_df&#39;, &#39;tbl&#39; and &#39;data.frame&#39;: 19 obs. of 5 variables: ## $ name : chr &quot;Alice&quot; &quot;Becka&quot; &quot;Gail&quot; &quot;Karen&quot; ... ## $ sex : chr &quot;F&quot; &quot;F&quot; &quot;F&quot; &quot;F&quot; ... ## $ age : num 13 13 14 12 12 15 11 15 14 14 ... ## $ height: num 56.5 65.3 64.3 56.3 59.8 66.5 51.3 62.5 62.8 69 ... ## $ weight: num 84 98 90 77 84.5 ... ## - attr(*, &quot;spec&quot;)= ## .. cols( ## .. name = col_character(), ## .. sex = col_character(), ## .. age = col_double(), ## .. height = col_double(), ## .. weight = col_double() ## .. ) 19.7.1.2 map返回基本类型向量 purrr::map()总是返回列表。 如果确知其调用的函数总是返回某种类型的标量值， 可以用map的变种： map_lgl()：返回逻辑向量； map_int()：返回整型向量； map_dbl(): 返回双精度浮点型向量(double类型)； map_chr(): 返回字符型向量。 比如， 求d.class各列类型， 因为确知typeof()函数对每列返回一个标量字符串，所以可以写成： map_chr(d.class, typeof) ## name sex age height weight ## &quot;character&quot; &quot;character&quot; &quot;double&quot; &quot;double&quot; &quot;double&quot; 对d.class， 可以对每一列用is.numeric判断是否数值型， 结果为逻辑型向量， 如： map_lgl(d.class, is.numeric) ## name sex age height weight ## FALSE FALSE TRUE TRUE TRUE 19.7.1.3 ...形参 在R函数的形参中， 允许有一个特殊的...形参（三个小数点）， 这在调用泛函类型的函数时起到重要作用。 在调用泛函时， 所有没有形参与之匹配的实参， 不论是带有名字还是不带有名字的， 都自动归入这个参数， 将会由泛函传递给作为其自变量的函数。 ...参数的类型相当于一个列表， 列表元素可以部分有名部分无名， 用list(...)可以将其转换成列表再访问。 例如，函数mean()可以计算去掉部分最低、最高值之后的平均值， 用选项trim=指定一个两边分别舍弃的值的个数比例。 为了将d.class的三列数值型列计算上下各自扣除10%的平均值， 需要利用map_dbl()函数的...参数输入trim选项值，如： map_dbl(d.class[,3:5], mean, trim=0.10) ## age height weight ## 13.29412 62.41765 100.00000 上面的数值型列是直接在程序中固定列号选出的， 也可以用map_lgl()选出： dsub &lt;- d.class[, map_lgl(d.class, is.numeric)] map_dbl(dsub, mean, trim=0.10) ## age height weight ## 13.29412 62.41765 100.00000 purrr包提供了一个keep函数， 可以专门用来选择数据框各列或列表元素中满足某种条件的子集， 这个条件用一个返回逻辑值的函数来给出。如： dsub &lt;- keep(d.class, is.numeric) map_dbl(dsub, mean, trim=0.10) ## age height weight ## 13.29412 62.41765 100.00000 利用magrittr包的管道运算符%&gt;%可以将对一个数据框的删选、计算过程更清晰地表达出来， 不需要dsub这样存储中间结果的变量： d.class %&gt;% keep(is.numeric) %&gt;% map_dbl(mean, trim=0.10) ## age height weight ## 13.29412 62.41765 100.00000 需要注意的是， 在map类泛函中...仅用来将额外的选项传递给要调用的函数， 不支持向量化， 如果需要对两个或多个自变量的对应元素作变换， 需用用purrr包的map2等函数。 如果泛函中调用的是无名函数， 则...参数会造成变量作用域理解困难。 19.7.1.4 用map处理strsplit函数结果示例 假设有4个学生的3次小测验成绩， 每个学生的成绩记录到了一个以逗号分隔的字符串中，如： s &lt;- c(&#39;10, 8, 7&#39;, &#39;5, 2, 2&#39;, &#39;3, 7, 8&#39;, &#39;8, 8, 9&#39;) 对单个学生，可以用strsplit()函数把三个成绩拆分，如： strsplit(s[1], &#39;,&#39;, fixed=TRUE)[[1]] ## [1] &quot;10&quot; &quot; 8&quot; &quot; 7&quot; 注意这里strspil()的结果是仅有一个元素的列表， 用了“[[...]]”格式取出列表元素。 拆分的结果可以用as.numeric()转换为有三个元素的数值型向量： as.numeric(strsplit(s[1], &#39;,&#39;, fixed=TRUE)[[1]]) ## [1] 10 8 7 还可以求三次小测验的总分： sum(as.numeric(strsplit(s[1], &#39;,&#39;, fixed=TRUE)[[1]])) ## [1] 25 用strsplit()处理有4个字符串的字符型向量s, 结果是长度为4的列表： tmpr &lt;- strsplit(s, &#39;,&#39;, fixed=TRUE); tmpr ## [[1]] ## [1] &quot;10&quot; &quot; 8&quot; &quot; 7&quot; ## ## [[2]] ## [1] &quot;5&quot; &quot; 2&quot; &quot; 2&quot; ## ## [[3]] ## [1] &quot;3&quot; &quot; 7&quot; &quot; 8&quot; ## ## [[4]] ## [1] &quot;8&quot; &quot; 8&quot; &quot; 9&quot; 用map()和as.numeric()可以把列表中所有字符型转为数值型， 输出为一个列表， 然后再对各个列表元素中的向量求和。 使用管道运算符表达逐步的操作： s %&gt;% strsplit(split=&quot;,&quot;, fixed=TRUE) %&gt;% map(as.numeric) %&gt;% map_dbl(sum) ## [1] 25 9 18 25 19.7.1.5 在map中使用无名函数以及简写方法 map()中调用的函数可以是在map()中直接现场定义的无名函数。 仍考虑上面的问题，有4个学生， 每个学生有三门成绩，成绩之间用逗号分隔。 将每个学生的成绩拆分为三个字符串后， 就可以对每个学生调用一个统一的无名函数， 将字符型转换为数值型以后求和： map_dbl(strsplit(s, split=&quot;,&quot;, fixed=TRUE), function(x) sum(as.numeric(x))) ## [1] 25 9 18 25 或用管道运算符： s %&gt;% strsplit(split=&quot;,&quot;, fixed=TRUE) %&gt;% map_dbl(function(x) sum(as.numeric(x))) ## [1] 25 9 18 25 使用无名函数格式比较复杂， purrr包为在map()等泛函中使用无名函数提供了简化的写法， 将无名函数写成“~ 表达式”格式， 表达式就是无名函数定义， 用.表示只有一个自变量时的自变量名， 用.x和.y表示只有两个自变量时的自变量名， 用..1、..2、..3这样的名字表示有多个自变量时的自变量名。 如： map_dbl(strsplit(s, split=&quot;,&quot;, fixed=TRUE), ~ sum(as.numeric(.))) ## [1] 25 9 18 25 需要注意的是， 如果map()等泛函中的无名函数需要访问其它变量的话， 需要理解其变量作用域或访问环境（参见19.9）。 另外， 无名函数中的其它变量在每次被map()应用到输入列表的元素时都会重新计算求值。 建议这样的情况改用有名函数， 这样其中访问其它变量时作用域规则比较容易掌控， 也不会重复求值。 19.7.1.6 在map中提取列表元素成员的简写 较为复杂的数据， 有时表现为列表的列表， 每个列表元素都是列表或者向量。 JSON、YAML等格式转换为R对象就经常具有这种嵌套结构。 例如， 有如下的嵌套格式数据， 这样的数据不利于用数据框格式保存： od &lt;- list( list( 101, name=&quot;李明&quot;, age=15, hobbies=c(&quot;绘画&quot;, &quot;音乐&quot;)), list( 102, name=&quot;张聪&quot;, age=17, hobbies=c(&quot;足球&quot;), birth=&quot;2002-10-01&quot;) ) 为了取出每个列表元素的第一项，本来应该写成： map_dbl(od, function(x) x[[1]]) ## [1] 101 102 或： map_dbl(od, ~ .[[1]]) ## [1] 101 102 purrr包提供了进一步的简化写法， 在需要一个函数或者一个“~ 表达式”的地方， 可以用整数下标值表示对每个列表元素提取其中的指定成分，如： map_dbl(od, 1) ## [1] 101 102 类似地，可以在需要函数的地方写一个成员名， 提取每个列表元素中该成员，如： map_chr(od, &quot;name&quot;) ## [1] &quot;李明&quot; &quot;张聪&quot; 在应该用函数的地方还可以提供一个列表， 列表元素为成员序号或者成员名， 进行逐层挖掘，如： map_chr(od, list(&quot;hobbies&quot;, 1)) ## [1] &quot;绘画&quot; &quot;足球&quot; 表示取出每个列表元素的hobbies成员的第一个元素（每人的第一个业余爱好）。 取出不存在的成员会出错， 但可以用一个.default选项指定查找不到成员时的选项， 如： map_chr(od, &quot;birth&quot;, .default=NA) ## [1] NA &quot;2002-10-01&quot; 19.7.1.7 数据框分组处理示例 对d.class数据框， 希望分成男女生两个组， 每组内建立用身高预测体重的一元线性回归模型， 提取各模型的斜率项。 基本R的split函数可以按数据框的某列将数据框分成若干个子数据框， 结果为子数据框的列表。 借助于purrr包的map类函数和管道运算符， 可以将分组建模过程写成： d.class %&gt;% split(d.class[[&quot;sex&quot;]]) %&gt;% map(~ lm(weight ~ height, data=.)) %&gt;% # 这里的“.”是map需要输入的无名函数的自变量 map(coef) %&gt;% map_dbl(2) ## F M ## 3.424405 3.912549 这些步骤用基本R的lapply或者for循环也能够完成， 但会更难读懂， 或者需要生成许多中间临时变量， 不如上面例子这样步骤清晰而且不需要产生中间结果。 dplyr包和plyr包与这个例子的思想类似， 只不过更有针对性。 19.7.2 purrr包中map函数的变种 purrr包的map函数输入一个数据自变量和一个函数， 输出为列表； map_dbl()等将输出转化为基础类型的向量。 purrr包还提供了与map目的类似， 但输入输出类型有变化的一些函数， 包括： modify()，输入一个数据自变量和一个函数， 输出与输入数据同类型的结果； map2()可以输入两个数据自变量和一个函数， 将两个自变量相同下标的元素用函数进行变换， 输出列表； imap()根据一个下标遍历； walk()输入一个数据自变量和一个函数， 不返回任何结果，仅利用输入的函数的副作用； 输入若干个数据自变量和一个函数， 对数据自变量相同下标的元素用函数进行变换； 将这些map变种输入类型分为： 一个数据自变量，代表为map()； 两个自变量，代表为map2()； 一个自变量和一个下标变量，代表为imap()； 多个自变量，代表为pmap()。 将输入结果分为： 列表，代表为map(); 基础类型的向量，如map_dbl(), map_chr()等； 与输入数据类型相同的输出，代表为modify()； 不输出结果，代表为walk()。 输入类型和输出类型两两搭配， purrr包提供了27种map类函数。 19.7.2.1 输入输出类型相同的modify函数 purrr的modify函数与map函数作用类似， 并不会原地修改输入数据， 而是制作修改后的副本， 输出的结果类型与输入数据的结果类型相同， 所以可以用来修改数据框各列生成一个副本数据框。 比如， 对d.class中的三个数值型列， 都减去列中位数，其它列保持不变： d1 &lt;- modify(d.class, ~ if(is.numeric(.x)) .x - median(.x) else .x) purrr包还提供了一个modify_if()函数， 可以对满足条件的列进行修改，如： d2 &lt;- modify_if(d.class, is.numeric, ~ .x - median(.x)) 19.7.2.2 对两个自变量的相同下标元素调用函数 map()函数仅支持一个输入数据的列表或向量。 map2()函数支持两个输入数据的列表或向量， map2(x, y, f, ...)对每个下标i调用f(x[[i]], y[[i]], ...)， 结果返回一个列表。 如果知道函数f()会返回类型确定的标量值， 可以用map2_dbl()等变种。 例如， d1是某市2001年四个季度的若干项经济指标， d2是2002年的对应指标， 计算每项指标年度总和的同比增幅： d1 &lt;- tibble( x1 = c(106, 108, 103, 110), x2 = c(101, 112, 107, 105) ) d2 &lt;- tibble( x1 = c(104, 111, 112, 109), x2 = c(102, 114, 105, 107) ) map2_dbl(d1, d2, ~ (sum(.y) - sum(.x)) / sum(.x)) ## x1 x2 ## 0.021077283 0.007058824 如果计算结果与两个输入数据类型相同， 可以用modify2()。 比如， 上面的例子数据计算每个指标的同比增幅： modify2(d1, d2, ~ (.y - .x) / .x) ## # A tibble: 4 x 2 ## x1 x2 ## &lt;dbl&gt; &lt;dbl&gt; ## 1 -0.0189 0.00990 ## 2 0.0278 0.0179 ## 3 0.0874 -0.0187 ## 4 -0.00909 0.0190 map2()允许输入的x和y两个列表其中一个长度为1， 这时长度为1的列表的一个元素被重复利用。如： d1b &lt;- d1[,1,drop=FALSE] map2_dbl(d1b, d2, ~ (sum(.y) - sum(.x)) / sum(.x)) ## [1] 0.02107728 0.00234192 基本R的Map()函数起到与map2()和pmap()类似的作用。 19.7.2.3 不产生输出的walk类函数 有时仅需要遍历一个数据结构调用函数进行一些显示、绘图， 这称为函数的副作用， 不需要返回结果。 purrr的walk函数针对这种情形。 例如， 显示数据框中每个变量的类别： walk(d.class, ~ cat(typeof(.x), &quot;\\n&quot;)) ## character ## character ## double ## double ## double 上面这个例子缺点是没有显示对应的变量名。 walk2()函数可以接受两个数据自变量， 类似于map2()。 例如， 需要对一组数据分别保存到文件中， 就可以将数据列表与保存文件名的字符型向量作为walk2()的两个数据自变量。 下面的程序将d.class分成男女生两个子集， 保存到两个csv文件中： dl &lt;- split(d.class, d.class[[&quot;sex&quot;]]) walk2(dl, paste0(&quot;class-&quot;, names(dl), &quot;.csv&quot;), ~ write.csv(.x, file=.y)) 改用管道运算符： d.class %&gt;% split(d.class[[&quot;sex&quot;]]) %&gt;% walk2(paste0(&quot;class-&quot;, names(.), &quot;.csv&quot;), ~ write.csv(.x, file=.y)) 事实上， walk、walk2并不是没有输出， 它们返回不显示的第一个自变量， 所以也适合用在管道运算的中间使得管道不至于中断。 基本R没有提供类似walk的功能。 19.7.2.4 可同时访问下标或元素名与元素值的imap类函数 在前面用walk函数显示数据框各列类型的例子中， 没有能够同时显示变量名。 如果x有元素名， imap(x, f)相当于imap2(x, names(x), f)； 如果x没有元素名， imap(x, f)相当于imap2(x, seq_along(x), f)。 iwalk()与imap()类似但不返回信息。 调用的函数的第二个自变量， 或者无名函数的.y自变量是元素名或者元素下标。 imap_chr()等是固定返回类型的变种。 例如， 显示数据框各列的变量名： iwalk(d.class, ~ cat(.y, &quot;: &quot;, typeof(.x), &quot;\\n&quot;)) ## name : character ## sex : character ## age : double ## height : double ## weight : double 返回字符型向量的写法： imap_chr(d.class, ~ paste0(.y, &quot; ==&gt; &quot;, typeof(.x))) %&gt;% unname() ## [1] &quot;name ==&gt; character&quot; &quot;sex ==&gt; character&quot; &quot;age ==&gt; double&quot; ## [4] &quot;height ==&gt; double&quot; &quot;weight ==&gt; double&quot; 输入数据没有元素名的演示： dl &lt;- list(1:5, 101:103) iwalk(dl, ~ cat(&quot;NO. &quot;, .y, &quot;: &quot;, .x[[1]], &quot;\\n&quot;)) ## NO. 1 : 1 ## NO. 2 : 101 显示了每个列表元素的第一项。 基本R没有提供类似imap的功能。 19.7.2.5 多个数据自变量的pmap类函数 R的向量化可以很好地处理各个自变量是向量的情形， 但是对于列表、数据框等多个自变量则不能自动进行向量化处理。 purrr包的pmap类函数支持对多个列表、数据框、向量等进行向量化处理。 pmap不是将多个列表等作为多个自变量， 而是将它们打包为一个列表。 所以， map2(x, y, f)用pmap()表示为pmap(list(x, y), f)。 在确知输出类型时可以用pmap_chr(), pmap_dbl()等变种， 在不需要输出结果时可以用pwalk()。 比如， 将三个列表中的对应项用c()函数连接： x &lt;- list(101, name=&quot;李明&quot;) y &lt;- list(102, name=&quot;张聪&quot;) z &lt;- list(103, name=&quot;王国&quot;) pmap(list(x, y, z), c) ## [[1]] ## [1] 101 102 103 ## ## $name ## [1] &quot;李明&quot; &quot;张聪&quot; &quot;王国&quot; pmap()除了输入一个列表和要并行执行的函数以外， 也可以输入一个数据框， 对数据框的每一行执行函数。 例如： d &lt;- tibble::tibble( x = 101:103, y=c(&quot;李明&quot;, &quot;张聪&quot;, &quot;王国&quot;)) pmap_chr(d, function(...) paste(..., sep=&quot;:&quot;)) ## [1] &quot;101:李明&quot; &quot;102:张聪&quot; &quot;103:王国&quot; pmap()和其它的map()类函数有一个区别是， 因为将输入数据打包在一个列表中， 而列表元素是有变量名的， 这样就可以将列表变量名取为要调用的函数的自变量名， 使得对输入列表中各元素的每个成员调用函数时， 可以带有对应的形参名调用。 例如，mean()函数可以计算去掉最小、最大一部分后的平均值， mean(x, trim)用trim选项控制两端分别去掉的比例， 但是trim选项必须是标量。 用map_dbl()解决方法如下： set.seed(101) x &lt;- rcauchy(1000) trims &lt;- c(0.05, 0.1, 0.2, 0.3, 0.4) map_dbl(trims, ~ mean(x=x, trims=.)) ## [1] 0.7271278 0.7271278 0.7271278 0.7271278 0.7271278 可以用pmap()的列表元素名自动对应到调用函数形参名的方法： pmap_dbl(list(trims = trims), mean, x=x) ## [1] 0.7271278 0.7271278 0.7271278 0.7271278 0.7271278 或： pmap_dbl(list(trims = trims), ~ mean(x)) ## [1] 0.7271278 0.7271278 0.7271278 0.7271278 0.7271278 pmap()的变种有ivoke_map(.f, .x, ...)， 其中.f是一个元素为函数名的字符型向量， .x是列表， .x的每个元素是.f列表中对应的函数的参数。 如： sim &lt;- tribble( ~f, ~params, &quot;runif&quot;, list(min = -1, max = 1), &quot;rnorm&quot;, list(sd = 5), &quot;rpois&quot;, list(lambda = 10) ) sim %&gt;% mutate(sim = invoke_map(f, params, n = 10)) ## # A tibble: 3 x 3 ## f params sim ## &lt;chr&gt; &lt;list&gt; &lt;list&gt; ## 1 runif &lt;named list [2]&gt; &lt;dbl [10]&gt; ## 2 rnorm &lt;named list [1]&gt; &lt;dbl [10]&gt; ## 3 rpois &lt;named list [1]&gt; &lt;int [10]&gt; 这里利用了tibble类型的高级功能： 某一列可以是列表类型， 然后列表元素有可以是列表、向量等复合类型。 基本R的Map()函数提供了类似的功能， 但是不允许多个自变量中有长度为1的； 基本R的mapply()函数与Map()类似， 但是会像sapply()函数那样试图自动找到最简化的输出数据结构， 这在通用程序中会使得结果不可控。 19.7.3 purrr包中reduce类函数 19.7.3.1 reduce函数 许多二元运算符如加法、乘法， 可以很自然地推广到多个运算元之间的运算， 变成连加、连乘积等等。 某些常用的操作已经变成了R函数， 比如sum()、prod()， 但是其它一些运算， 包括用函数表示的运算， 也需要推广到对多个进行， 比如intersect(x, y)求两个变量的交集， 希望能推广到求多个变量的交集。 purrr包的reduce函数把输入列表（或向量）的元素逐次地用给定的函数进行合并计算。 比如，设f(x,y)是一个二元函数， 设z是有4个元素的列表， 则reduce(z, f)表示 f(f(f(z[[1]], z[[2]]), z[[3]]), z[[4]]) 例如， reduce(1:4, `+`) ## [1] 10 实际执行的是\\((((1 + 2) + 3) + 4)\\)。 当然，求\\(1:4\\)的和只需要sum(1:4)， 但是reduce可以对元素为复杂类型的列表进行逐项合并计算。 考虑多个集合的交集的问题。 下面的例子产生了4个集合， 然后反复调用intersect()求出了交集： set.seed(5) x &lt;- replicate(4, sample( 1:5, size=5, replace=TRUE), simplify=FALSE); x ## [[1]] ## [1] 2 3 1 3 1 ## ## [[2]] ## [1] 1 5 3 3 2 ## ## [[3]] ## [1] 5 4 2 5 3 ## ## [[4]] ## [1] 1 4 3 2 5 intersect(intersect(intersect(x[[1]], x[[2]]), x[[3]]), x[[4]]) ## [1] 2 3 也可以用magrittr包的%&gt;%符号写成: x[[1]] %&gt;% intersect(x[[2]]) %&gt;% intersect(x[[3]]) %&gt;% intersect(x[[4]]) ## [1] 2 3 还可以写成循环: y &lt;- x[[1]] for(i in 2:4) y &lt;- intersect(y, x[[i]]) y ## [1] 2 3 都比较繁琐。 利用purrr包的reduce函数，只要写成 reduce(x, intersect) ## [1] 2 3 泛函的好处是需要进行的变换或计算是作为参数输入的， 只要输入其它函数就可以改变要做的计算， 比如， 变成求各个集合的并集： reduce(x, union) ## [1] 2 3 1 5 4 reduce()支持...参数， 所以可以给要调用的函数额外的自变量或选项。 reduce函数对多个输入默认从左向右计算， 可以用.dir = \"backward\"选项东球从右向左合并。 可以用选项.init给出合并初值， 在通用程序中使用reduce()时应该提供此选项， 这样如果输入了零长度数据， 可以有一个默认的返回值； 输入非零长度数据时， 此初值作为第一个元素之前的值参与计算， 所以一定要取为与要进行的运算一致的值， 比如连加的初始值自然为0， 连乘积的初始值自然为1， 多个集合交集的初始值为全集（所有参与运算的各个集合应为此初值的子集）， 等等。 基本R的Reduce()函数提供了类似purrr:reduce()的功能， 不支持...参数。 19.7.3.2 reduce2函数 reduce2(x, y, f)中的x是要进行连续运算的数据列表或向量， 而y是给这些运算提供不同的参数。 如果没有.init初始值， f仅需调用length(x)-1次， 所以y仅需要有length(x)-1个元素； 如果有.init初始值， f需要调用length(x)次， y也需要与x等长。 19.7.3.3 accumulate函数 对于加法， R的sum()函数可以计算连加， 而cumsum()函数可以计算逐步的连加。如： sum(1:4) ## [1] 10 cumsum(1:4) ## [1] 1 3 6 10 purrr::reduce()将连加推广到了其它的二元运算， purrr::accumulate()则类似cumsum()的推广。 例如，对前面例子中的4个集合， 计算逐步的并集， 结果的第一项保持原来的第一项不变： accumulate(x, union) ## [[1]] ## [1] 2 3 1 3 1 ## ## [[2]] ## [1] 2 3 1 5 ## ## [[3]] ## [1] 2 3 1 5 4 ## ## [[4]] ## [1] 2 3 1 5 4 将上述结果简化显示： accumulate(x, union) %&gt;% map(~sort(unique(.))) ## [[1]] ## [1] 1 2 3 ## ## [[2]] ## [1] 1 2 3 5 ## ## [[3]] ## [1] 1 2 3 4 5 ## ## [[4]] ## [1] 1 2 3 4 5 19.7.3.4 Map-reduce算法 Map-reduce是大数据技术中的重要算法， 在Hadoop分布式数据库中主要使用此算法思想。 将数据分散存储在不同计算节点中， 将需要的操作先映射到每台计算节点， 进行信息提取压缩， 最后用reduce的思想将不同节点的信息整合在一起。 19.7.4 purrr包中使用示性函数的泛函 返回逻辑向量的函数称为示性函数， R中有许多is.xxx函数都是示性函数(predicate functions)。 示性函数本身不是泛函， 但是它们可以作为泛函的输入。 purrr包提供了如下的以示性函数函数为输入的泛函： some(.x, .p)，对数据列表或向量.x的每一个元素用.p判断， 只要至少有一个为真，结果就为真； every(.x, .p)与some类似，但需要所有元素的结果都为真结果才为真。 这些函数与any(map_lgl(.x, .p))和all(map_lgl(.x, .p))类似， 但是只要在遍历过程中能提前确定返回值就提前结束计算， 比如some只要遇到一个真值就不再继续判断， every只要遇到一个价值就不再继续判断。 detect(.x, .p)返回数据.x的元素中第一个用.p判断为真的元素值， 而detect_index(.x, .p)返回第一个为真的下标值。 keep(.x, .p)选取数据.x的元素中用.p判断为真的元素的子集； discard(.x, .p)返回不满足条件的元素子集。 例如，判断数据框中有无因子类型的列： some(d.class, is.factor) ## [1] FALSE 判断数据框是否完全由数值型列组成： every(d.class, is.numeric) ## [1] FALSE 返回向量中的第一个超过100的元素的值： detect(c(1, 5, 77, 105, 99, 123), ~ . &gt;= 100) ## [1] 105 返回向量中的第一个超过100的元素的下标： detect_index(c(1, 5, 77, 105, 99, 123), ~ . &gt;= 100) ## [1] 4 对于上一个例子，which(x &gt;= 100)可以返回所有满足条件的元素的下标。 下面的例子筛选出数据框的数值型列， 并用map_dbl求每列的平方和： d.class %&gt;% keep(is.numeric) %&gt;% map_dbl(~ sum(. ^ 2)) ## age height weight ## 3409.00 74304.92 199435.75 从数据框（或列表）中选一部分满足某种条件的子集进行变换是常用的做法， 所以map提供了map_if()和modify_if()变种， 允许输入一个示性函数， 对满足条件的子集才应用输入的变换函数进行处理， 输入数据中其它元素原样返回。 map_if返回列表， modify_if返回与输入数据相同类型的输出。 例如， 将数据框中数值型列除以100， 其它列保持不变： modify_if(d.class, is.numeric, `/`, 100) ## # A tibble: 19 x 5 ## name sex age height weight ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Alice F 0.13 0.565 0.84 ## 2 Becka F 0.13 0.653 0.98 ## 3 Gail F 0.14 0.643 0.9 ## 4 Karen F 0.12 0.563 0.77 ## 5 Kathy F 0.12 0.598 0.845 ## 6 Mary F 0.15 0.665 1.12 ## 7 Sandy F 0.11 0.513 0.505 ## 8 Sharon F 0.15 0.625 1.12 ## 9 Tammy F 0.14 0.628 1.02 ## 10 Alfred M 0.14 0.69 1.12 ## 11 Duke M 0.14 0.635 1.02 ## 12 Guido M 0.15 0.67 1.33 ## 13 James M 0.12 0.573 0.83 ## 14 Jeffrey M 0.13 0.625 0.84 ## 15 John M 0.12 0.59 0.995 ## 16 Philip M 0.16 0.72 1.5 ## 17 Robert M 0.12 0.648 1.28 ## 18 Thomas M 0.11 0.575 0.85 ## 19 William M 0.15 0.665 1.12 基本R的Find函数与detect作用类似， Position与detect_index作用类似， Filter函数与keep作用类似。 19.7.5 基本R的函数式编程支持 使用purrr包的泛函的好处是用法风格一致， 有许多方便功能。 对于少量的使用泛函的需求， 在不想使用purrr包的情况下， 可以使用基本R中的类似功能。 基本R的apply函数可以对矩阵的每行或每列进行计算， 或对多维向量的某个维度进行计算。 参见12.6。 基本R中的integrate、uniroot、optim、omptimize等函数也需要输入函数， 但主要用于数学计算， 与一般的函数式编程关系不大。 基本Rlapply函数用输入的函数对数据的每个元素进行变换，格式为 lapply(X, FUN, ...) 其中X是一个列表或向量， FUN是一个函数（可以是有名或无名函数）， 结果也总是一个列表， 结果列表的第\\(i\\)个元素是将X的第\\(i\\)个元素输入到FUN中的返回结果。 ...参数会输入到FUN中。 这与purrr::map()功能类似。 sapply与lapply函数类似， 但是sapply试图简化输出结果为向量或矩阵， 在不可行时才和lapply返回列表结果。 如果X长度为零，结果是长度为零的列表； 如果FUN(X[i])都是长度为1的结果， sapply()结果是一个向量； 如果FUN(X[i])都是长度相同且长度大于1的向量， sapply()结果是一个矩阵， 矩阵的第\\(i\\)列保存FUN(X[i])的结果。 因为sapply()的结果类型的不确定性， 在自定义函数中应慎用。 vapply()函数与sapply()函数类似， 但是它需要第三个参数即函数返回值类型的例子，格式为 vapply(X, FUN, FUN.VALUE, ...) 其中FUN.VALUE是每个FUN(X[i])的返回值的例子， 要求所有FUN(X[i])结果类型和长度相同。 例如，求d.class每一列类型的问题，用lapply，写成： lapply(d.class, typeof) ## $name ## [1] &quot;character&quot; ## ## $sex ## [1] &quot;character&quot; ## ## $age ## [1] &quot;double&quot; ## ## $height ## [1] &quot;double&quot; ## ## $weight ## [1] &quot;double&quot; lapply的结果总是列表。 sapply会尽可能将结果简化为向量或矩阵，如： sapply(d.class, typeof) ## name sex age height weight ## &quot;character&quot; &quot;character&quot; &quot;double&quot; &quot;double&quot; &quot;double&quot; 或使用vapply(): vapply(d.class, typeof, &quot;&quot;) ## name sex age height weight ## &quot;character&quot; &quot;character&quot; &quot;double&quot; &quot;double&quot; &quot;double&quot; vapply可以处理遍历时每次调用的函数返回值不是标量的情形， 结果为矩阵， purrr包的map_dbl等只能处理调用的函数返回值是标量的情形。 R提供了 Map, Reduce, Filter, Find, Negate, Position等支持函数式编程的泛函。 Map()与purrr::map、purrr::pmap功能类似， 以一个函数作为参数， 可以对其它参数的每一对应元素进行变换， 结果为列表。 例如， 对数据框d， 如下的程序可以计算每列的平方和： d &lt;- data.frame( x = c(1, 7, 2), y = c(3, 5, 9)) Map(function(x) sum(x^2), d) ## $x ## [1] 54 ## ## $y ## [1] 115 实际上，这个例子也可以用lapply()改写成 lapply(d, function(x) sum(x^2)) ## $x ## [1] 54 ## ## $y ## [1] 115 Map()比lapply()增强的地方在于它允许对多个列表的对应元素逐一处理。 例如，为了求出d中每一行的最大值，可以用 Map(max, d$x, d$y) ## [[1]] ## [1] 3 ## ## [[2]] ## [1] 7 ## ## [[3]] ## [1] 9 可以用unlist()函数将列表结果转换为向量，如 unlist(Map(max, d$x, d$y)) ## [1] 3 7 9 mapply()函数与Map()类似， 但是可以自动简化结果类型， 可以看成是sapply()推广到了可以对多个输入的对应元素逐项处理。 mapply()可以用参数MoreArgs指定逐项处理时一些共同的参数。 如 mapply(max, d$x, d$y) ## [1] 3 7 9 当d数据框有多列时为了求每行的最大值， 可以用Reduce函数将两两求最大值的运算推广到多个之间的运算。 Reduce函数功能与purrr::reduce类似， 把输入列表（或向量）的元素逐次地用给定的函数进行合并计算。 例如，求四个集合的交集： set.seed(5) x &lt;- replicate(4, sample( 1:5, size=5, replace=TRUE), simplify=FALSE); x ## [[1]] ## [1] 2 3 1 3 1 ## ## [[2]] ## [1] 1 5 3 3 2 ## ## [[3]] ## [1] 5 4 2 5 3 ## ## [[4]] ## [1] 1 4 3 2 5 Reduce(intersect, x) ## [1] 2 3 Reduce函数对多个输入默认从左向右计算， 可以用right参数选择是否从右向左合并。 参数init给出合并初值， 参数accumulate要求保留每一步合并的结果（累计）。 这个函数可以把很多仅适用于两个运算元的运算推广到多个参数的情形。 Filter(f, x)与purrr::keep作用类似， 用一个示性函数f作为筛选规则， 从列表或向量x中筛选出用f作用后为真值的元素子集。 例如 f &lt;- function(x) x &gt; 0 &amp; x &lt; 1 Filter(f, c(-0.5, 0.5, 0.8, 1)) ## [1] 0.5 0.8 当然，这样的简单例子完全可以改写成： x &lt;- c(-0.5, 0.5, 0.8, 1) x[x&gt;0 &amp; x &lt; 1] ## [1] 0.5 0.8 但是，对于比较复杂类型的判断， 比如当x是列表且其元素本身也是复合类型的时候， 就需要把判断写成一个函数， 然后可以用Filter比较简单地表达按照判断规则取子集的操作。 Find()功能与purrr::detect类似， 返回满足条件的第一个元素， 也可以用参数right=TRUE要求返回满足条件的最后一个。 Position()功能与purrr::detect_index类似， 返回第一个满足条件的元素所在的下标位置。 19.7.6 自定义泛函 用户也可以自定义泛函。 比如，希望对一个数据框中所有的数值型变量计算某些统计量， 要计算的统计量由用户决定而不是由此自定义函数决定， 输入的函数的结果总是数值型向量， 编写自定义的泛函为： summary.df.numeric &lt;- function(df, FUN, ...){ sapply(Filter(is.numeric, df), FUN, ...) } 这里参数FUN是用来计算统计量的函数。 例如对d.class中每个数值型变量计算最小值： d.class &lt;- readr::read_csv(&quot;class.csv&quot;) ## Parsed with column specification: ## cols( ## name = col_character(), ## sex = col_character(), ## age = col_double(), ## height = col_double(), ## weight = col_double() ## ) summary.df.numeric(d.class, summary, na.rm=TRUE) ## age height weight ## Min. 11.00000 51.30000 50.5000 ## 1st Qu. 12.00000 58.25000 84.2500 ## Median 13.00000 62.80000 99.5000 ## Mean 13.31579 62.33684 100.0263 ## 3rd Qu. 14.50000 65.90000 112.2500 ## Max. 16.00000 72.00000 150.0000 为了说明上面定义的泛函是如何对数据框进行处理的， 我们对其进行如下的改写： summary.df.numeric2 &lt;- function(df, FUN, ...){ res &lt;- c() nd &lt;- c() for(j in seq_along(df)){ if(is.numeric(df[[j]])){ resj &lt;- FUN(df[[j]], ...) # 这里！ res &lt;- cbind(res, resj) nd &lt;- cbind(nd, names(df)[j]) } } if(ncol(res)&gt;0) { colnames(res) &lt;- nd if(nrow(res) == 1) { res &lt;- c(res) names(res) &lt;- nd } } res } summary.df.numeric2(d.class, min, na.rm=TRUE) ## age height weight ## 11.0 51.3 50.5 summary.df.numeric2(d.class, summary, na.rm=TRUE) ## age height weight ## Min. 11.00000 51.30000 50.5000 ## 1st Qu. 12.00000 58.25000 84.2500 ## Median 13.00000 62.80000 99.5000 ## Mean 13.31579 62.33684 100.0263 ## 3rd Qu. 14.50000 65.90000 112.2500 ## Max. 16.00000 72.00000 150.0000 19.8 函数工厂 函数的返回值可以是函数， 为此只要在函数内部定义嵌套函数并以嵌套函数为返回值。 返回函数的函数称为函数工厂， 函数工厂的输出结果称为一个闭包(closer)。 因为函数由形参表、函数体和定义环境三个部分组成， 函数工厂输出的闭包的定义环境是函数工厂的内部环境， 即函数工厂运行时产生的运行环境， 所以闭包包含了生产它的函数工厂的运行环境， 可以将闭包的一些状态信息保存在该环境中， 实现带有状态的函数。 基本R函数approxfun和splinefun就是以函数为输出的函数工厂。 19.8.1 闭包例子 利用函数工厂和闭包可以解决前面提出的记录函数已运行次数的问题。如 f.gen &lt;- function(){ runTimes &lt;- 0 function(){ runTimes &lt;&lt;- runTimes + 1 print(runTimes) } } f &lt;- f.gen() f() ## [1] 1 f() ## [1] 2 函数f.gen中定义了内嵌函数并以内嵌函数为输出， f.gen是一个函数工厂, 其返回值是一个闭包， 闭包也是一个R函数， 这个返回值“绑定”(bind)到变量名f上， 所以f是一个函数。 调用函数f时用到变量runTimes， 用了&lt;&lt;-这种格式给这个变量赋值， 这样赋值的含义是在定义时的环境中逐层向上(向外，向父环境方向)查找变量是否存在， 在哪一层找到变量就给那里的变量赋值。 这样查找的结果是变量runTimes在f.gen的运行环境中。 调用f的时候f.gen已经结束运行了， 一般说来f.gen的运行环境应该已经不存在了； 但是， 函数的定义环境是随函数本身一同保存的， 因为函数工厂f.gen输出了函数f， f的定义环境是f.gen的运行环境， 所以起到了把f.gen的运行环境保存在f中的效果， 而f.gen运行环境中的变量值runTimes也就保存在了函数f中， 可以持续被f访问， 不像f的局部变量那样每次运行结束就会被清除掉。 注意， 如果函数工厂生产出了两个闭包， 这两个闭包的定义环境是不同的， 因为生产时的运行环境是不同的。 例如， 生产两个计数器， 这两个计数器是分别计数的： c1 &lt;- f.gen() c2 &lt;- f.gen() c1() ## [1] 1 c1() ## [1] 2 c2() ## [1] 1 下面是一个类似的函数工厂例子, 产生的闭包可以显示从上次调用到下次调用之间经过的时间： make_stop_watch &lt;- function(){ saved.time &lt;- proc.time()[3] function(){ t1 &lt;- proc.time()[3] td &lt;- t1 - saved.time saved.time &lt;&lt;- t1 cat(&quot;流逝时间（秒）：&quot;, td, &quot;\\n&quot;) invisible(td) } } ticker &lt;- make_stop_watch() ticker() ## 流逝时间（秒）： 0 for(i in 1:1000) sort(runif(10000)) ticker() ## 流逝时间（秒）： 1.53 其中proc.time()返回当前的R会话已运行的时间， 结果在MS Windows系统中有三个值，分别是用户时间、系统时间、流逝时间， 其中流逝时间比较客观。 19.8.2 动态查找和懒惰求值引起的问题 上面的两个函数工厂都没有使用任何选项。 如果函数工厂有选项， 其中的选项值会被保存到生产出的闭包函数中， 但是因为懒惰求值规则的影响， 有可能调用闭包函数时才对选项求值， 如果保存选项的变量在生产和调用之间改变了值， 就会发生错误。 比如， 下面的函数工厂可以生产出进行幂变换的函数： make.pf &lt;- function(power){ function(x) x^power } p &lt;- 2 square &lt;- make.pf(p) p &lt;- 3 square(4) ## [1] 64 在生产出square函数时， 选项p的值是2， 所以函数square应该是做平方变换的函数， 虽然在调用之前p的值被改成了3， 但是按理说不应该修改已经生产出来的square定义。 程序结果说明调用square时用的是p=3的值， 这是怎么回事？ R函数有懒惰求值规则， 在生产出square的哪一步， 因为并不需要实际计算x^power， 所以实参p的值并没有被计算， 而是将square的定义环境中的power指向了全局空间的变量p， 调用square(4)的时候才实际需要power的值， 这时power才求值， 其值为p的当前值。 避免这样的问题的办法是在函数工厂内用force()函数命令输入的参数当场求值而不是懒惰求值。 如： make.pf &lt;- function(power){ force(power) function(x) x^power } p &lt;- 2 square &lt;- make.pf(p) p &lt;- 3 square(4) ## [1] 16 这个版本的程序结果正确。 19.8.3 函数工厂的内存负担 因为函数工厂生产出的闭包函数保存了函数工厂的运行环境， 如果这个运行环境很大， 就会造成较大的不必要的内存占用。 所以， 函数工厂内应尽量不要有占用大量内存的变量。 可以在函数工厂内用rm()删除不再使用的变量。 19.8.4 函数算子 函数算子输入函数，输出函数， 通常用来对输入函数的行为进行改进或做细微的修改。 基本R的Vectorize函数输入一个函数， 将其改造成支持向量化的版本。 下面的dot_every函数输入一个函数， 将其改造为被循环调用时可以每调用一定次数就显示一个小数点， 这样可以用来显示循环的进度， 也适用于在lapply或purrr::map等函数调用时显示仅需。 dot_every &lt;- function(f, n) { force(f) force(n) i &lt;- 0 function(...) { i &lt;&lt;- i + 1 if (i %% n == 0) cat(&quot;.&quot;) f(...) } } sim &lt;- function(i){ x &lt;- runif(1E6) invisible(sort(x)) } walk(1:100, dot_every(sim, 10)) 19.9 环境 环境是R语言比较困难的概念， 一般用户也不需要了解环境就能很好地使用R， 也不影响自定义函数。 环境是支持变量作用域、命名空间、R6类型等功能的数据结构， 了解环境有助于更好地理解作用域等概念。 这部分内容主要来自(Wickham 2019)相应章节。 19.9.1 基本概念 19.9.1.1 基本认识 环境作为一个数据结构与有名的列表相似， 但是其中的名字必须都互不相同， 且没有次序（类似集合）， 环境都有一个父环境， 修改环境内容时都不制作副本。 rlang扩展包可以比较方便地操作R的语法内容。 可以用rlang::env()生成新的环境， 这类似于list()函数的用法， 如： e1 &lt;- rlang::env( a = FALSE, b = &quot;a&quot;, c = 2.3, d = 1:3) 环境的作用是将一系列的名字（变量名、函数名等）与R对象绑定起来， 即建立从名字到对象的对应关系， 不计次序。 对环境的修改是直接进行而不制作副本的。 如： e1$e &lt;- list(x=1, y=&quot;abcd&quot;) 显示环境， 只会显示一个地址信息， 对用户没有什么用处： e1 ## &lt;environment: 0x000001d185e88860&gt; rlang包的env_print()函数可以给出较多的信息： rlang::env_print(e1) ## &lt;environment: 000001D185E88860&gt; ## parent: &lt;environment: global&gt; ## bindings: ## * a: &lt;lgl&gt; ## * b: &lt;chr&gt; ## * c: &lt;dbl&gt; ## * d: &lt;int&gt; ## * e: &lt;list&gt; rlang::env_names()可以获得环境中绑定的名字组成的字符型向量： rlang::env_names(e1) ## [1] &quot;a&quot; &quot;b&quot; &quot;c&quot; &quot;d&quot; &quot;e&quot; 19.9.1.2 重要环境 rlang::current_env()或基本R的environment()返回调用代码时所在的环境， 比如， 在命令行调用时，返回&lt;environment: R_GlobalEnv&gt;。 rlang::global_env()和基本R的globalenv()返回全局环境， 这是另一个重要环境， 也称为“工作空间”， 是在命令行运行时所处的环境。 为了比较两个环境是否同一个， 需要用indentical(e1, e2)， 而不能用==比较。 19.9.1.3 父环境 每个环境都有一个父环境， 这样在按句法规则查找变量的绑定对象时， 就依次查找环境本身、其父环境、父环境的父环境， 等等。内嵌函数的父环境是定义它的函数的内部环境。 rlang的env()在生成环境时， 可以用第一个无名的参数输入父环境， 如： e1 &lt;- rlang::env(a=1, b=2) e2 &lt;- rlang::env(e1, c=3, d=4) 当rlang::env()没有输入父环境时， 父环境就设为调用时的环境。 用rlang::env_parent()获得父环境， 用rlang::env_parents()获得各层父环境，如： rlang::env_print(e1) ## &lt;environment: 000001D185DDE7D0&gt; ## parent: &lt;environment: global&gt; ## bindings: ## * a: &lt;dbl&gt; ## * b: &lt;dbl&gt; rlang::env_parent(e2) ## &lt;environment: 0x000001d185dde7d0&gt; rlang::env_parents(e2) ## [[1]] &lt;env: 000001D185DDE7D0&gt; ## [[2]] $ &lt;env: global&gt; 对于以全局环境为父环境的环境， env_parents()的输出截止到全局环境为止； 但是， 全局环境的上层还有加载的各个扩展包的环境， 这也是查找变量的较后面的搜索路径。 为了制造一个上层不包含全局环境的环境， 可以用rlang::empty_env()作为父环境， 这个环境称为空环境，记为R_EmptyEnv。 19.9.1.4 在上层环境中赋值 用“&lt;&lt;-”在各级父环境中赋值， 最先在那一层父环境中找到变量就在那一层中赋值， 如果直到全局环境都没有找到变量， 就在全局环境中新建一个变量。 全局变量应谨慎使用， 它使得程序之间的数据输入输出变得不明晰。 在使用闭包时常常需要使用这种赋值方式保存并修改一个闭包的状态。 如： f0 &lt;- function(){ x &lt;- 0 f1 &lt;- function(){ f2 &lt;- function(){ x &lt;&lt;- x+1 x } f2() } f1 } f01 &lt;- f0() f01() ## [1] 1 f01() ## [1] 2 在上面的例子中， &lt;&lt;-首先在f1环境内查找x， 没有找到就继续向上在f0的环境内查找x。 19.9.1.5 环境中名字的访问 类似于列表元素访问，用“环境$名字”格式或者“环境[[\"名字\"]]”读取环境的元素， 不存在时返回NULL。如： e1 &lt;- rlang::env(rlang::empty_env(), x=1, y=2) e2 &lt;- rlang::env(e1, a=3, b=4) e2$a ## [1] 3 e2[[&quot;b&quot;]] ## [1] 4 e2$x ## NULL 从上例也可以看出不能直接读取父环境中的变量。 如果希望在找不到变量时出错， 可以用rlang::env_get(环境名, \"名字\")，如： rlang::env_get(e2, &quot;x&quot;) ## Error in rlang::env_get(e2, &quot;x&quot;) : 找不到对象&#39;x&#39; 可以设置env_get()在查找不到时的缺省值，如： rlang::env_get(e2, &quot;x&quot;, default=NA) ## [1] NA 为了在环境中增加绑定或重新绑定， 可以用$或[[格式直接赋值， 可以用rlang::env_poke()或rlang::env_bind()， rlang::env_bind()运行同时进行多个绑定，如： e1 &lt;- rlang::env(x=1, y=2) e1$z &lt;- 3 rlang::env_poke(e1, &quot;a&quot;, 11) rlang::env_bind(e1, b=12, c=13) rlang::env_names(e1) ## [1] &quot;x&quot; &quot;y&quot; &quot;z&quot; &quot;a&quot; &quot;b&quot; &quot;c&quot; 用rlang::env_has()检查某个环境中是否绑定了指定的名字，如： rlang::env_has(e1, c(&quot;x&quot;, &quot;c&quot;, &quot;f&quot;)) ## x c f ## TRUE TRUE FALSE 为了在环境中删除一个名字的绑定， 需要用rlang::env_unbind()，如： rlang::env_unbind(e1, c(&quot;z&quot;, &quot;c&quot;)) rlang::env_names(e1) ## [1] &quot;x&quot; &quot;y&quot; &quot;a&quot; &quot;b&quot; 注意env_unbind()只是解除了绑定， 原来的对象并不会马上被删除， 如果没有其它名字引用该对象， R的垃圾收集器会随后删除该对象。 基本R的get()，assign(), exists()，rm()等函数起到与rlang包中的env_get()， env_poke(), env_has(), env_unbind()类似的功能， 但是这些函数通常都针对调用时的当前环境， 不容易处理其他环境， 另外它们都有一个inherits选项默认为TRUE， 可以自动搜索父环境， 所以不如rlang包的函数功能明确。 19.9.1.6 两种较少使用的特殊环境 rlang::env_bind_lazy()可以创造延迟的绑定， 就是类似于R函数形参缺省值的懒惰求值那样， 第一次使用其值的时候才进行绑定。 利用这种技术， 可以实现类似autoload()的功能， autoload()可以使得用到某个扩展包中指定的名字时才自动载入该扩展包， 利用延迟绑定， 可以使得数据框看起来像是已经在内存中， 但实际是用到该数据框时才中硬盘中读入。 基本R中提供了类似的delayedAssign()函数。 rlang::env_bind_acitive()可以制造一个环境， 每次访问环境中的名字都重新求值并绑定一次。 基本R中提供了类似的makeActiveBinding()函数。 19.9.2 逐层向上访问环境 要逐层向上访问环境， 可以利用R的递归函数。 下面写一个逐层向上查找指定的名字所在的环境的自定义函数。 （来自Advanced R）。 where &lt;- function(name, env = rlang::caller_env()) { if (identical(env, empty_env())) { # 找到了顶层都没有找到 stop(&quot;找不到 &quot;, name, call. = FALSE) } else if (rlang::env_has(env, name)) { # 在当前的env环境中找到了，返回找到时的环境 env } else { # 利用递归向上层查找 Recall(name, rlang::env_parent(env)) } } 自变量name是要查找的名字， env是从那个环境开始逐层向上查找， env的缺省值是调用where()函数时的环境。 定义中分了三种情况： 到顶层（空环境）都没有找到， 出错停止； 在向上逐层查找中在某个环境中找到了， 返回找到时的环境； 否则就利用递归向上层查找。 这个例子可以用作环境逐层向上遍历的模板。 19.9.3 特殊环境 实际上， 一般用户都不会用到rlang::env()生成的环境； 但是用户都会接触到使用R语言时自然产生的各种环境， 只不过许多用户可能没有认识到自己是在使用环境。 R语言使用中涉及到环境的情景有： 扩展包的环境和搜索路径； 函数环境； 命名空间； 运行环境。 19.9.3.1 扩展包环境 每次用library()或require()命令载入一个扩展包， 它定义的变量和函数就构成一个环境， 这个环境变成全局环境的父环境。 这样， 全局环境的各层父环境包括用户载入的扩展包和启动R会话时会自动载入的扩展包（如stats等）， 载入最晚的一个扩展包的环境是全局环境的父环境， 载入越早的扩展包的环境距离全局环境的层次越远。 实际上， 在查找某个名字时， 在当前环境没有找到时会逐层向父环境查找， 这些父环境一般就包括全局环境和全局环境上层的各个加载了的扩展包形成的环境， 这种搜索次序称为当前搜索路径， search()返回当前搜索路径，如： search() ## [1] &quot;.GlobalEnv&quot; &quot;tools:rstudio&quot; &quot;package:stats&quot; ## [4] &quot;package:graphics&quot; &quot;package:grDevices&quot; &quot;package:utils&quot; ## [7] &quot;package:datasets&quot; &quot;package:methods&quot; &quot;Autoloads&quot; ## [10]&quot;package:base&quot; rlang::search_envs()返回以环境为元素的搜索路径。 搜索路径中除了全局环境之外， 最后两个比较特殊： Autoloads用类似于函数缺省值懒惰求值的方法在需要用到某个变量时才从磁盘将其载入到内存中， 适用于占用存储空间很大的数据框之类的对象。 package:base是基本R的环境，必须先载入这一环境才能加载其它环境。 可以直接用rlang::base_env()返回这一环境。 19.9.3.2 函数内部的环境 自定义函数包括形参表、函数体和定义时绑定的环境三个部分， 非内嵌的也不在扩展包中定义的函数一般都与全局环境绑定， 这样的函数的绑定环境没有什么用处， 即使不了解环境部分也能够很好地使用这样的函数。 内嵌在函数内定义的函数称为闭包， 闭包的绑定的环境是定义它的函数的内部环境， 如果这个闭包作为定义它的函数的输出， 闭包对象带有一个私有环境， 即定义它的函数的内部环境， 可以用来保存闭包函数的状态。 在前面的讲到函数工厂时给出了闭包的例子。 用rlang::fn_env(f)可以求函数f的绑定环境。 如： f1 &lt;- function(x) 2*x rlang::fn_env(f1) ## &lt;environment: R_GlobalEnv&gt; 又如闭包： f1 &lt;- function(){ times &lt;- 0 f2 &lt;- function(){ times &lt;&lt;- times + 1 cat(&quot;NO. &quot;, times, &quot;\\n&quot;, sep=&quot;&quot;) } print(rlang::fn_env(f2)) f2 } f2b &lt;- f1() ## &lt;environment: 0x00000201dc5096d8&gt; print(rlang::fn_env(f2b)) ## &lt;environment: 0x00000201dc5096d8&gt; f2b() ## NO. 1 f2b() ## NO. 2 这个例子显示的f2和f2b的环境都是f1内部的环境， 在现实f2b的环境时虽然f1()已经结束运行， 但是闭包可以保存其定义时的环境。 19.9.3.3 命名空间 变量名和函数名的搜索路径中包含了已载入的扩展包的环境， 这就造成一个问题： 后载入的扩展包中的函数会遮盖住先载入的扩展包中的同名函数， 变量也是如此。 所以， 应该仅载入必要的扩展包， 尽可能用“扩展包名::函数名”的格式调用。 这些问题是用户可控的， 还有一个本质性的问题： 假设扩展包A中的函数f1要用到扩展包B中的函数f11， 先载入了扩展包B， 然后载入了扩展包A， 这时调用A中的f1()没有问题。 现在假设随后又调入了一个扩展C， 扩展包C中也定义了一个f11函数， 那么， 现在调用A中的f1时， 会调用B中的f11还是C中的f11? 如果调用C中的f11就是会程序出错或给出错误结果。 为了避免这样的不可控的错误发生， R语言的扩展包开发进行了严格的规定。 R的扩展包与两个环境有关， 一个就是扩展包的环境， 这实际是用户能看到的R扩展包提供的变量和函数， 在载入扩展包时会插入到搜索路径中。 另一个环境是命名空间环境， 这是扩展包私有的一个环境， 其中的变量和函数有一些对包的用户不可见， 扩展包环境中那些用户可见的变量和函数也在命名空间环境中。 R扩展包在设计时都会利用命名空间严格限定包内部调用的其它包中的函数， 不至于引起歧义。 每个扩展包的命名空间环境都有如下的一套上层环境： imports环境，其中包含所有的用到的其它扩展包的函数， 这是由扩展包的开发者确定的，所以不会错误调用错误的包； imports环境的父环境是基本R环境对应的命名空间环境，但其父环境与基本R环境的父环境不同； 基本R命名空间环境的父环境是全局环境。注意基本R环境的父环境是空环境。 所以， 扩展包内调用其它扩展包的函数是需要开发者明确地加入到imports环境中的， 不受用户调用时载入了那些扩展包和载入次序影响。 扩展包环境（针对用户的）和扩展包命名空间环境（包开发者自用）这`两个环境不发生直接的引用联系， 可以通过函数环境逐层向上变量发生联系。 19.9.3.4 运行环境 函数在调用执行时自动生成一个运行环境， 其父环境为函数定义时的环境， 比如， 设f是在命令行定义的函数， 调用f()时自动生成一个f的运行环境， 相当于f的局部变量和形参的环境， 其父环境为f定义时的环境， 即全局环境。 设函数f2在函数工厂f1中定义并被f1输出为一个闭包f2b， 则调用f2b时自动生成一个f2b的运行环境， 相当于f2b的局部变量和形参组成的环境， 此运行环境的父环境是定义时的环境， 即f2函数内部的环境。 函数执行结束则运行环境消失。 为了能够保留下来运行环境， 一种办法是将运行环境在运行时用rlang::current_env()获取并作为函数的返回值保存到变量中， 另一种办法是像函数工厂那样输出一个闭包， 闭包的环境就是函数工厂的运行环境。 19.9.4 调用栈 函数在被调用时， 还涉及到调用它的环境， 可以用rlang::caller_env()获得。 调用环境与调用时的实参计算有关， 需要了解调用栈(call stack)概念， 调用栈由若干个分层的框架(frames)组成。 R运行出错时会显示一个traceback()结果， 就是调用栈的各个框架。 如： f1 &lt;- function(x) { f2(x = 2) } f2 &lt;- function(x) { f3(x = 3) } f3 &lt;- function(x) { stop() } f1() ## Error in f3(x = 3) : ## 4. stop() ## 3. f3(x = 3) ## 2. f2(x = 2) ## 1. f1() 上面例子在用stop()产生出错信号时显示调用栈， 下面的函数调用了上面的函数。 可以用lobstr::cst()显示函数的调用栈。 当调用时有懒惰求值时， 调用栈就可能有多个分支。 调用栈中的每一次调用称为一个框架， 或求值上下文(evaluation context)。 框架是支持R语言的重要成分， R程序仅能对框架数据结构作很少的操作。 每个框架有三个构成部分： 一个表示调用函数的表达式expr。 一个环境，通常是调用的函数的运行环境。 但是，全局框架的环境还是全局环境， 使用eval()会造出一个框架， 其环境则是可以由用户干预的。 父框架，即调用它的框架。 框架还会保存函数的一些非正常执行路径， 如on.exit()指定的操作， 出错时的处理。 R采用句法作用域， 即由定义决定变量作用域， 有少数语言如Lisp采用动态作用域(dynamic scoping)， 即在调用栈上查找变量值。 19.9.5 将环境用作一般数据结构 环境中的变量都是引用， 或者绑定， 不需要制作环境副本， 这使得环境可以当作一种高级的数据类型使用。 将环境作为一般数据结构使用， 可以用在如下一些方面： 因为不需要制作副本， 所以可以节省内存空间。 但是直接使用环境不够友好， 可以使用R6类型的数据， R6类型是建立在环境的基础上的。 在自己建立的扩展包中， 用环境保存包的状态。 这样一个包中的函数多次调用时， 可以在多次调用之间传递一些状态信息。 可以在包中用get.xxx()函数和set.xxx()函数提供包用户访问状态的接口函数。 环境可以当作一个杂凑表用， 杂凑表可以在常数时间将名字对应到值。 References "],["knitr.html", "20 用R制作研究报告", " 20 用R制作研究报告 一个统计或数据分析的科研项目， 都会产生一个或多个研究报告。 因为使用统计与数据分析不可避免地有很多计算涉及在内， 这里假设使用R软件做了计算。 科研是一个不断改进的过程， 所以每一次重新做了计算， 研究报告中的汇总表格、图形都要更新。 这样的任务比较繁琐， 也容易出错。 “文学式编程”(literate programming, (Knuth 1984))是这样一种思想， 把撰写报告与计算程序有机地结合在一起， 用一个源文件文件既包含报告内容， 又包含计算程序。 每次产生研究报告时， 先运行源文件中的计算程序得到计算结果， 这些结果包括文字性内容与图形， 然后利用适当软件自动地把这些原始文字、计算结果组合成最终的报告。 利用这样的思想， 可以自动生成重复的例行报告， 还可以作为“可重复科学研究”的载体。 上述的源文件一般是文本文件， 格式可以是Markdown格式， 也可以是LaTeX格式等许多格式。 R的knitr软件包就是用来支持这样的编程思想的一个扩展包。 Markdown是一种很简单的文本文件格式， 通常保存为.md扩展名， 利用R程序进行扩展的版本保存为.Rmd扩展名。 Markdown文件里面有一些简单的格式标注方法， 比如两个星号之间的文字会转化为斜体， 缩进四个空格或一个制表符的内容会看成代码。 Markdown仅适用于比较简单的文章、源程序说明等， 不太适用于复杂的含有大量数学公式、图表的文章， 从markdown格式比较适合转换为html(网页)格式， 也可以转换为MS Word的docx格式， 通过LaTeX编译器可以转换为PDF格式， 也可以将docx转存为PDF格式， 或者用输出到PDF文件的打印机将网页格式转换为PDF格式。 LaTeX是一个文档排版系统， 功能强大，结果美观， 设计合理。 缺点是需要学习类似于HTML的另一种语言。 LaTeX源文件主要是编译为PDF。 R扩展包knitr包支持在Markdown格式、LaTeX格式等类型的文件中插入R代码， 经过转换， 文中的R代码可以变成代码的结果文字、表格、图形， 与原有报告文字有机地结合在一起。 插入了R代码的markdowng格式的文件一般以.Rmd为扩展名， R的rmarkdown扩展包和knitr包一起为Rmd格式提供了支持。 R的bookdown包进一步增强了R Markdown格式的功能， 支持生成PDF、多文件互相链接的HTML、Word等输出， 其中的表格、图形可以变成浮动表， 公式、定理可以自动编号并支持文献、公式、定理、图表、章节的引用和链接， 所以比较适用于编写一本书或论文、研究报告。 knitr包也支持在LaTeX源文件中插入R代码， 通过编译使得R代码运行结果、图形自动插入生成的研究报告中。 原来有一个Sweave扩展包是支持在LaTeX中插入R代码的， 现在knitr的功能已经涵盖并增强了此包功能。 下面几章分别介绍markdown格式、R markdown格式、bookdown扩展包、简易网站制作和幻灯片制作。 参考： (Xie, Allaire, and Grolemund 2019) (Xie 2017) 利用R Markdown格式可以执行如下的任务： 将单一的R Markdown文件编译为不同的格式，如： HTML; PDF; MS Word。 在RStudio软件内制作笔记本文档，可以在其中包含说明文字与R代码， 可以在笔记本文档内交互地运行R代码并能将结果交互地显示在笔记本内。 生成演示幻灯片，可以是基于HTML5的，也可以是基于LaTeX beamer扩展包的， 或者MS Powerpoint。 编写多章节组成的书籍。 编写期刊论文。 制作网站或者博客。 制作商业智能仪表盘(dashboards)，即数据可视化展示。 References "],["markdown.html", "21 Markdown格式 21.1 介绍 21.2 Markdown格式文件的应用 21.3 markdown格式说明 21.4 附录：pandoc软件介绍", " 21 Markdown格式 21.1 介绍 Markdown是一种很简单的文本文件格式， 通常保存为.md扩展名。 Mardown中文内容应该使用UTF-8编码。 Markdown文件里面有一些简单的格式标注方法， 比如两个星号之间的文字会转化为斜体， 缩进四个空格或一个制表符的内容会看成代码。 Markdown适用于比较简单的文章、源程序说明等， 不太适用于复杂的含有大量数学公式、图表的文章， 从markdown格式比较适合转换为html(网页)格式， 也可以转换为MS Word的docx格式， 通过docx格式可以转存为PDF格式。 R扩展包knitr、rmarkdown和bookdown与pandoc软件一起大大扩展了markdown格式的适用范围。 如果需要作为一本书发布在网站上或者出版， 可考虑使用R的bookdown扩展包。 如果需要对出版格式进行精确控制， 可考虑用LaTeX格式， LaTeX格式很复杂， 学习比较困难， 但是表达能力强。 21.2 Markdown格式文件的应用 Markdown格式用在一些微博、论坛中作为缺省格式， 用户在网络浏览器软件的输入框中按照markdown格式输入， 网站自动将其转换为html富文本内容显示出来。 因为markdown格式就是纯文本， 而且其格式十分简单， 所以可以仅仅用普通文本编辑器编写markdown格式的文件， 不需要转换为其它格式。 有一些独立运行的编辑软件， 在其中输入了markdown格式文件后， 可以并列地显示转化为html富文本后的结果， 很多还支持自动备份到云服务中。 但是，这些独立运行的编辑器大都有商业因素。 比如，国内的印象笔记软件是提供了云存储的笔记软件， 在其PC端就支持创建markdown格式的笔记， 可以在输入时即时显示html效果。 RStudio软件不是专用的Markdown编辑器， 它是一个R程序的集成编辑、运行环境， 对个人用户免费， 在R Studio中可以编辑Markdown文件和含有R代码的Markdown文件， 可以一键将其转化成HTML、MS Word docx文件， 在单独安装的LaTeX编译软件支持下还可以直接编译成PDF。 RStudio支持下的增强的Mardown格式， 称为RMarkdown格式， 以.Rmd为扩展名， 支持大多数的LaTeX公式， 在bookdown扩展包支持下还支持公式、定理、图表等自动编号和引用、链接。 21.3 markdown格式说明 这部分内容参考了markdown手册和Rstudio的文档， 以及(Xie, Allaire, and Grolemund 2019)。 21.3.1 概述 Markdown格式是John Gruber于2004年创造的， Markdown 的目标是实现“易读易写”。 Markdown定义了一种简单好用的文本文件格式， 作为单独的文本文件， 此格式没有什么多余的标签， 又可以转化为很多其它的格式。 Markdown 的语法全由一些符号所组成， 这些符号经过精挑细选，其作用一目了然。 比如：在文字两旁加上星号，看起来就像强调。 Markdown 的列表看起来就像我们平常在邮件中写一个列表的方法。 Markdown 的区块引用看起来就真的像是引用一段文字， 就像你曾在电子邮件中见过的那样。 需要时， 可以直接在markdown中写HTML标记内容。 markdown能实现的功能是HTML的一部分， 但是比HTML内容更干净， 没有掺杂过多的与要表达的意思无关的标签。 Markdown的理念是，能让文档更容易读、写和随意改。 21.3.2 段落 一个段落由一行或连续的多行组成。 段落之间以空行分隔。 同一段落内的不同行在转换成HTML或docx等格式后会重新排列， 原来的段内换行被当成了空格，这样的规定与LaTeX类似。 普通段落不该用空格或制表符来缩进， 不应在行尾留有空格。 为了在段内换行并且转化后仍保持段内换行， 输入时在前面行的末尾输入两个或两个以上空格。例如： 白日依山尽，黄河入海流。 欲穷千里目，更上一层楼。 显示结果为： 白日依山尽，黄河入海流。 欲穷千里目，更上一层楼。 这样做的缺点是末尾的空格时不可见的。 可以使用HTML的&lt;br&gt;标签在段内换行，如： 白日依山尽，黄河入海流。&lt;br&gt; 欲穷千里目，更上一层楼。 结果为 白日依山尽，黄河入海流。 欲穷千里目，更上一层楼。 21.3.3 段内文字格式 在一段内，用星号或下划线包围的内容如*强调*是强调格式。 用双星号或双下划线包围的内容如**加重**是加重格式。 星号、下划线与要强调或加重的内容之间不要空开， 否则会当作普通星号或下划线解释， 在行首还会当作列表。 为了插入普通的星号或下划线，可以使用反斜杠保护， 或者写成段内代码格式。 可以用一对~作为界定符给出下标， 如HO~2~会变成HO2。 可以用一对^作为界定符给出上标， 如Cu^2+^会变成Cu2+。 但是，数学公式一般还是应该使用LaTeX数学公式形式（见22.8）。 在普通段落内一部分内容希望显示成代码， 对其中的特殊字符不进行解释， 只要包在两个反向单撇号内。 如`if(_x_ &gt; 0) y=1;`会变成if(_x_ &gt; 0) y=1;。 如果内容本身就包含反向单撇号， 可以在两边使用更多个数的反向单撇号， 如`` `x` ``会变成`x`。 在Markdown文件中， 为了使得某些有特殊意义的字符不作特殊解释， 可以在该字符前面加上反斜杠\\， 取消其特殊含义。 在Rmarkdown文件中， 为了原样显示反向单撇号， 可以在两边用双写的反向单撇号界定字符串。 21.3.4 标题和分隔线 以一个井号#开始的行是一级标题， 以两个井号#开始的行是二级标题， …………， 以六个井号#开始的行是六级标题。 标题行前面应该空一行， 否则可能把某些偶然出现在行首的#号误认为标题行的标志。 对一级标题， 也可以用标题内容下面输入一行等于号=表示上一行内容是一级标题。 对二级标题， 可以用标题内容下面输入一行减号-表示上一行内容是二级标题。 等于号和减号的个数不限。 用三个或三个以上连续的星号组成的行， 可以转换成分隔线。下面是一个分隔线： 21.3.5 引用段落 可以用类似Email的回复包含原始邮件内容的办法输入引用段落， 即，在段落的每行前面加一个大于号。 比如下面的诗： &gt; 白日依山尽，黄河入海流。 &gt; 欲穷千里目，更上一层楼。 转换成 白日依山尽，黄河入海流。 欲穷千里目，更上一层楼。 注意引用也是段落模式，内容中的换行不起作用，空行导致分段。 引用段落也可以仅在段落第一行写大于号， 其它行顶格写，例如下面的两段引用： &gt; 远上寒山石径斜， 白云生处有人家。 &gt; &gt; 停车坐爱枫林晚， 霜叶红于二月花。 转换成 远上寒山石径斜， 白云生处有人家。 停车坐爱枫林晚， 霜叶红于二月花。 引用也可以嵌套，如： &gt; 张三说：李四这样说过 &gt; &gt;&gt; 不想当将军的木匠不是好厨子。 &gt; 转换成 张三说：李四这样说过 不想当将军的木匠不是好厨子。 注意嵌套内容前后都有空的引用行，否则不能实现嵌套引用。 引用内也可以嵌套其它的Markdown格式如标题、列表等。 引用前后应该有空行把引用内容与其他内容分隔开。 为了在引用中换行， 就需要加引用空行。 为了排版诗、词之类的内容， 希望人为控制换行和引导空格， 可以将引用中的&gt;替换成|，如： | 白日依山尽， | 黄河入海流。 | 欲穷千里目， | 更上一层楼。 转换成 白日依山尽， 黄河入海流。 欲穷千里目， 更上一层楼。 | 枯藤老树昏鸦， | 小桥流水人家， | 古道西风瘦马。 | 夕阳西下， | 断肠人在天涯。 转换成： 枯藤老树昏鸦， 小桥流水人家， 古道西风瘦马。 夕阳西下， 断肠人在天涯。 其中不用|开头的行仍会当作上一行的续行， 不会强行换行。 21.3.6 列表 列表分为不编号的列表和编号的列表。 不编号的列表转化后通常显示圆点开头的列表项。 在Markdown中， 用星号表示一个不编号的列表项。 星号也可以替换成加号或减号， 后面必须有一个或多个空格。 每个列表项可以输入多行， 各行的内容最好左对齐， 左对齐在使用文本格式时较易阅读， 但不是必须的。 两个列表项之间不要空行。 例如： * 白日依山尽， 黄河入海流。 * 欲穷千里目， 更上一层楼。 转换为 白日依山尽， 黄河入海流。 欲穷千里目， 更上一层楼。 段落顶头的数字加句点和空格表示编号列表， 两个列表项之间尽量不要空行。 例如： 1. 第一种解决方法， 收买敌人的高官。 2. 第二种解决方法， 尽可能拖延。 转换为 第一种解决方法， 收买敌人的高官。 第二种解决方法， 尽可能拖延。 标准的markdown编号列表不能自己定义数字的显示格式， 不允许开始值不等于1。 pandoc支持更自由的列表， 允许输入时有括号或右括号，允许使用字母和罗马数字，但是括号会被去掉。如 (1) 顶层一； a) 内层二； b) 内层三； (2) 顶层二。 转换为 顶层一； 内层二； 内层三； 顶层二。 为了避免错误地产生非本意的编号列表， 在行首写数字加句点和空格时，可以在句点前加反斜杠， 或者在句点前加空格。例如，下面是一个年号： 2016\\. 如上输入将不会错误地解释为有序列表。 如果列表项目中有多个段落， 这时两个列表项之间应该以空行分隔， 每个项目除了第一行外，输入的每行内容都应该缩进4个空格或者一个制表符。 例如： * R语言第一个版本开发于1976-1980，基于Fortran； 于1980年移植到Unix, 并对外发布源代码。 1984年出版的“棕皮书” 总结了1984年为止的版本, 并开始发布授权的源代码。 这个版本叫做旧S。与我们现在用的S语言有较大差别。 1989--1988对S进行了较大更新， 变成了我们现在使用的S语言，称为第二版。 1988年出版的“蓝皮书”做了总结。 * 1992年出版的“白皮书”描述了在S语言中实现的统计建模功能， 增强了面向对象的特性。软件称为第三版，这是我们现在用的多数版本。 1998年出版的“绿皮书”描述了第四版S语言，主要是编程功能的深层次改进。 现行的S系统并没有都采用第四版，S-PLUS的第5版才采用了S语言第四版。 转换为 R语言第一个版本开发于1976-1980，基于Fortran； 于1980年移植到Unix, 并对外发布源代码。 1984年出版的“棕皮书” 总结了1984年为止的版本, 并开始发布授权的源代码。 这个版本叫做旧S。与我们现在用的S语言有较大差别。 1989–1988对S进行了较大更新， 变成了我们现在使用的S语言，称为第二版。 1988年出版的“蓝皮书”做了总结。 1992年出版的“白皮书”描述了在S语言中实现的统计建模功能， 增强了面向对象的特性。软件称为第三版，这是我们现在用的多数版本。 1998年出版的“绿皮书”描述了第四版S语言，主要是编程功能的深层次改进。 现行的S系统并没有都采用第四版，S-PLUS的第5版才采用了S语言第四版。 列表项目内如果有引用段落， 需要都缩进4个空格。 如果有程序代码， 需要缩进4个空格后用三个反单撇号表示开始与结束。 列表可以嵌套， 嵌套的列表需要缩进4个空格， 中间不需要空行。 例如： 1. 第一类工作包括： + 技术服务； + 咨询服务。 2. 其它工作略。 转换为 第一类工作包括： 技术服务； 咨询服务。 其它工作略。 如果需要把每个列表项当作段落排版，可以在每个列表项后空行。 21.3.7 源程序 为了让源程序能够自动显示成源程序的样式， 而不至于自动分行、特殊字符解释， 用空行把源程序与其它内容隔开， 并把源程序行都缩进4个空格（或以上）或者一个制表符。 源程序格式持续到不缩进4个空格的地方为止。 例如，下面的输入： f &lt;- function(x){ n &lt;- length(x) y &lt;- numeric(n) y[x &gt;= 0] &lt;- 1 ##y[x &lt; 0] &lt;- 0 y } 转换为 f &lt;- function(x){ n &lt;- length(x) y &lt;- numeric(n) y[x &gt;= 0] &lt;- 1 ##y[x &lt; 0] &lt;- 0 y } 更适当的做法是用三个连续的反向单撇号表示代码开头与代码结束， 中间就会当作源程序代码处理。 例如下面的输入 ``` &gt; x &lt;- rnorm(100) &gt; hist(x) ``` 转换为 &gt; x &lt;- rnorm(100) &gt; hist(x) R的knitr包在Markdown格式的文件中插入R可执行代码时， 就用了这样的方法。 而且，R Markdown格式的代码块不需要用空行与前后分隔开。 在pandoc程序的支持下， 代码段还可以采用栅栏式代码段， 在代码段开头前面一行加上至少三个连续~符号， 在结尾后面一行加同样数目的~符号。 这样的代码段前后也必须空行以与其它内容分开。 另外，如果代码内本身含有~行， 只要使得开头与结尾标志中的~个数更多就可以了。 例如下面的输入 ~~~ #include &lt;math.h&gt; double sqr(double x){ return(x*x); } ~~~ 转换为 #include &lt;math.h&gt; double sqr(double x){ return(x*x); } 使用栅栏式代码段时可以在开始行尾写大括号， 在大括号内写选项。 其中一种选项是要求按照某种编程语言对结果进行彩色语法显示， 如.cpp表示C++，.c表示C，.r表示R，.python表示python等。 选项.numberLines要求该代码行编号， 选项startFrom=指定开始行号。如 如: ~~~{.cpp .numberLines startFrom=101} #include &lt;math.h&gt; double sqr(double x){ return(x*x); } ~~~ 转换为 #include &lt;math.h&gt; double sqr(double x){ return(x*x); } 21.3.8 链接 最简单的链接是原样显示的可点击的链接， 只要把链接地址用小于号和大于号包在中间， 两边用空格和其它内容隔开。 如果是网页，需要加http://， 如果是邮箱，需要加mailto:。 例如，如下代码: 北京大学的网页地址是： &lt;http://www.pku.edu.cn/&gt; 。 显示为 北京大学的网页地址是： http://www.pku.edu.cn/ 。 除此之外， Markdown 还支持两种形式的链接语法： 行内式和引用式两种形式。 不管是哪一种，链接的显示文字都是用方括号[...]来标记。 要建立一个行内式的链接， 只要在方括号内写链接的显示文字， 右方括号后面紧接着圆括号， 并在圆括号中间插入网址链接即可。 方括号部分与圆括号部分之间不能断开。 例如： 请参考：[李东风的教学主页](http://www.math.pku.edu.cn/teachers/lidf/course/index.htm) 变成了 请参考：李东风的教学主页 在圆括号中，链接后面还可以包含用双撇号包围的标题文字， 与链接之间用空格分开。 引用式的链接， 需要在某处（比如文章结尾）定义一些链接的标识符， 然后用方括号包围链接的显示文字， 后面紧接着方括号包围着链接的标识符。 为了定义链接标识符， 用方括号包围链接标识符， 前面可以有至多3个空格缩进， 右方括号后面紧接着冒号和一个空格， 空格后写链接地址， 然后空格，在两个双撇号中间写一个链接地址的标题。 例如 [baidu]: http://baidu.com/ &quot;百度&quot; [pku]: http://www.pku.edu.cn/ &quot;北大&quot; 这时，在文章中就可以用标识符调用链接， 如[北京大学主页][pku]将变成链接北京大学主页。 使用引用式的链接， 有些像论文中把所有参考文献排列在文章末尾， 文中用到某一篇文献只要提及其序号。 还有一种链接是内部链接，用于文内跳转。 在各级标题行的末尾， 可以添加{#自定义标签}这样的内容， 其中“自定义标签”是自己写的一个标识符， 标识符仅使用英文字母、数字、下划线、减号， 用来区分不同的位置。 比如，本文第一节“介绍”添加了markdown-intro为标签， 就可以用“[回到介绍](#markdown-intro)”产生链接 回到介绍。 21.3.9 插入图形 图形只能用链接形式， 不可能保存到一个纯文本文件内。 图形文件可以存在于远程服务器上， 也可以是与生成的HTML文件在同一目录结构中的文件。 语法仍使用行内式和参考式两种形式。 转化成HTML、PDF、Word格式后可以把图形内嵌在输出文件内部。 行内式的图片链接， 是普通行内链接格式前面添加了一个叹号， 惊叹后面紧接着方括号， 方括号内写图片的标题，标题可以空缺， 在右方括号后面紧接着圆括号， 圆括号内写图片的链接。 例如，下面的代码可以插入百度的一个logo，使用的是网上的资源: ![](http://www.baidu.com/img/baidu_jgylogo3.gif) 结果为 为了插入保存在本地的与Markdown源文件在同一子目录或下级子目录的图形， 只要在圆括号中写图片文件名（如果与Markdown源文件在同一子目录）或相对路径。 例如，在D:\\work\\figs下的图形文件baidu_logo.gif在本Markdown源文件所在目录的figs子目录中, 可以用代码 ![](figs/bd_logo.png) 结果为 这样含有网上图片和本地图片的Markdown源文件转化为HTML和docx格式， 都可以正常显示插入的图片。 与链接类似， 也可以在文章某处（比如末尾）定义图片的标识符， 然后把行内图片引用中图片地址替换成图片标识符即可。 21.3.10 表格 Markdown文本格式的表格就像是用减号、等号、竖线画的文本格式表格一样， 转化为HTML、docx等格式后就变成了富文本的表格。 有如下几种表格： 管道表 简单表 换行表 有格表 21.3.10.1 管道表 管道表在两列之间用竖线分开， 在列标题下面用减号画横线， 用如下方法指定各对齐方式： 在列标题下的横线开始加冒号，表示左对齐； 在列标题下的横线末尾加冒号，表示右对齐； 在列标题下的横线两端加冒号，表示居中对齐； 列标题下面仅有横线没有冒号，表示缺省对齐方式，一般是左对齐。 在表格内容后面空一行后写用Table:开头的表格说明。 这种方法不需要输入内容上下对齐，适用于中文内容。 后面所讲的简单表、换行表、有格表需要能够输入内容对齐， 对于中英文混合内容很难做到对齐， 所以仅管道表比较适合中文内容。 例如: | 姓名 | 收入 | 职业 | 颜色偏好 | |:------|-----------:|:---------------:|-----------| | 赵四海 | 123456 | 业务经理 | 红 | | 刘英 | 50 | 无 | 蓝 | | 钱德里 | 3200 | 保洁 | 灰 | Table: 管道表示例 结果为 管道表示例 姓名 收入 职业 颜色偏好 赵四海 123456 业务经理 红 刘英 50 无 蓝 钱德里 3200 保洁 灰 管道表不允许输入单元格换行， 单元格内容太宽时转换结果可能自动换行， 自动换行时列宽度与输入的列标题下横线宽度成比例。 21.3.10.2 简单表 简单表的格式是， 第一行是各列标题， 第二行是各标题下面用减号组成的表格线， 同一行的不同列要用空格分开， 从第三行开始是内容。 在表格前或表格后用空行隔开的以Table:开头的行是表格说明或标题。 为了确定表格每列单元格内容如何对齐， 用列标题下的表格线给出提示： 表格线与列标题右对齐，表示该列右对齐； 表格线与列标题左对齐，表示该列左对齐； 列标题在表格线中间，表示该列居中对齐； 列标题左右都与表格线对齐，表示该列为缺省对齐方式，一般是左对齐。 一定要使用一个等宽字体来编辑这样的表格，否则对齐与否无法准确分辨。 单元格内容不能超出表格线左端。 经过试验发现， 中文内容很难按这种方法对齐。 例如： Name Income Job Color ------ -------- ------------------ ----- Jane 123456 Research Assistant red John 50 N/A blue William 3200 Cleaner blue Table: 一个简单表的例子 结果为： 一个简单表的例子 Name Income Job Color Jane 123456 Research Assistant red John 50 N/A blue William 3200 Cleaner blue 21.3.10.3 换行表 换行表在输入列标题和单元格内容时， 允许输入内容拆分行，但是转化后并不拆分行。 这样的表以一行减号开始，以一行减号结束， 中间的表格用空行分开实际的不同行。 例如： ---------------------------------------------------- Name of Subject Income Job color ------ -------- ------------------ ----- Jane 123456 Research red Ayer Assistant John 50 N/A blue Tukey William 3200 Cleaner blue Tale ---------------------------------------------------- Table: 一个换行表的例子 结果为： 一个换行表的例子 Name of Subject Income Job color Jane Ayer 123456 Research Assistant red John Tukey 50 N/A blue William Tale 3200 Cleaner blue 换行表输入时各列的输入宽度是有作用的， 输入较宽的列结果也较宽。 21.3.10.4 有格表 完全用减号、竖线、等于号、加号画出表格线。 这样的表在文本格式下呈现出很好的表格形状。 转化后不能指定对齐方式。 例如： Table: 有格表示例 +---------------+---------------+--------------------+ | Fruit | Price | Advantages | +===============+===============+====================+ | Bananas | $1.34 | - built-in wrapper | | | | - bright color | +---------------+---------------+--------------------+ | Oranges | $2.10 | - cures scurvy | | | | - tasty | +---------------+---------------+--------------------+ 结果为 有格表示例 Fruit Price Advantages Bananas $1.34 built-in wrapper bright color Oranges $2.10 cures scurvy tasty 21.4 附录：pandoc软件介绍 pandoc是一个杰出的开源软件， 作者为John MacFarlane。 RStudio软件中已经包含了这个软件。 软件在命令行运行， 可以用来在多种不同的文件格式之间进行转换， 输入格式一般是文本格式， 比如markdown、LaTeX、MediaWiki、reStructured Text、 HTML、DocBook， 但是也可以输入MS Word docx、Open Office ODT、EPUB格式。 输出可以是这些文本格式， 也可以是MS Word docx、Open Office ODT、EPUB、LaTeX等格式， 在安装了LaTeX编译系统如MikTeX时可以输出为PDF。 RStudio软件中包括了一份pandoc软件程序。 可以用普通文本编辑器编写markdown格式的文件， 用pandoc转换为HTML或MS Word docx等格式。 因为pandoc需要UTF8编码的输入文件， 所以应该把markdown文件保存为UTF格式， MS Windows下的Notepad++软件可以很容易地编辑文本文件 并在各种编码之间转换。 实际上，MS Windows下有一个markdown编辑程序Smarks就是基于pandoc软件的。 首先， 从pandoc网站下载并安装pandoc。 安装程序很奇怪地安装到了 C:\\Users\\登录用户名\\AppData\\Local\\Pandoc中， 请将此子目录复制到一个合适的位置， 比如C:\\Pandoc。 如果把此路径加入到Windows系统的可执行文件搜索路径中 （在“控制面板-系统和安全-系统-高级系统设置-环境变量”中， 为系统变量的Path添加一个分号分开的路径C:\\Pandoc即可以不用全路径访问 pandoc.exe可执行文件。 为了用pandoc转化某个markdown文件， 首先在该文件所在子目录打开一个Windows命令行窗口， 在MS Win10系统中只要在文件管理器的“文件”菜单选择 “打开命令提示符”即可。 比如，文件名是test.md, 用如下pandoc命令可以转换为.docx文件(MS Word文件的新版本): C:\\Pandoc\\pandoc -o test.docx test.md 用如下pandoc命令可以转换为.html文件: C:\\Pandoc\\pandoc -s -o --mathjax test.html test.md 如果把pandoc.exe加入了Windows操作系统的Path环境变量中， 上面的 C:\\Pandoc\\pandoc 可以简写为 pandoc。 pandoc在其它操作系统中也有相应的版本。 软件下载与文档见Pandoc的网站http://pandoc.org。 如果使用RStudio编辑markdown文件或者R Markdown文件， 它会自动调用内置的pandoc程序。 References "],["rmarkdown.html", "22 R Markdown文件格式 22.1 R Markdown文件 22.2 R Markdown文件的编译 22.3 在R Markdown文件中插入R代码 22.4 输出表格 22.5 利用R程序插图 22.6 代码段选项 22.7 章节目录链接问题 22.8 数学公式 22.9 其它编程语言引擎 22.10 交互内容 22.11 属性设置 22.12 LaTeX和PDF输出 22.13 生成期刊文章 22.14 附录：经验与问题", " 22 R Markdown文件格式 22.1 R Markdown文件 借助于R的knitr和rmarkdown扩展包的帮助， 可以在Markdown格式的源文件中插入R代码， 使得R代码的结果能够自动插入到最后生成的研究报告中。 这种格式称为R Markdown格式，简称为Rmd格式， 相应的源文件扩展名为.Rmd。 输出格式可以是HTML、docx、pdf、beamer等。 R Markdown的基础格式是markdown格式， 严格说来是Pandoc软件支持的增强版的markdown格式， 比如， 支持LaTex格式的数学公式， 支持各种编程语言语法彩色加亮显示，等等。 knitr的详细文档参见网站knitr文档。 关于R Markdown可参考专著(Xie, Allaire, and Grolemund 2019)和(Xie, Dervieux, and Riederer 2020)。 RStudio网站提供了一个R Markdown使用摘要下载： (rmarkdown-2.0.pdf)[rmarkdown-2.0.pdf]。 Pandoc的文档见pandoc网站。 一个Rmd文件中包含元数据(metadata)、正文内容和R代码三种成分， 比如，下面是一个简单的Rmd文件样例： --- title: &quot;R语言简介&quot; author: &quot;李东风&quot; date: &quot;2020-12-28&quot; output: html_document --- 这里是正文段落。 段落中仍可以利用一般的Markdown语法， 比如在两边用双星号表示**粗体加重**， 在用两边反单撇号表示代码，如`y &lt;- sin(x)`。 下面是一个R代码段，有文字输出： ```{r} set.seed(1) x &lt;- round(rnorm(10), 2) print(x) ``` 下面是一个R代码段，有图形输出： ```{r} plot(x) ``` 下面是一个R代码段， 有富文本表格输出： ```{r} knitr::kable(as.data.frame(x)) ``` 在文字段落内部也可以有代码， 比如，x的第一个元素值为`r x[1]`。 ``` 在文件开头用三个减号组成的行包围的内容称为元数据， 可以用来规定文章标题、作者、日期、输出格式、输出设置等属性。 见22.11。 因为中文需要一些特殊的设置， 以及在网络条件不好的条件下支持数学公式显示， 本书作者提供了一个Rmarkdown模板， 下载链接为: Bookdown-template-v0-4.zip。 其中的Rmarkdown子目录包含了所需模板， 其它子目录有一些别的模板， 为了在本地支持网页中的数学公式显示还有一个MathJax目录。 22.2 R Markdown文件的编译 RStudio是一个集成的R软件环境， 可以用来编辑和执行R程序， 这个软件也可以用来编辑和编译R Markdown格式的文件， 使得R Markdown格式的文件变得容易使用。 在RStudio中可以直接用一个快捷图标一次性地把R代码结果插入内容中并编译为HTML或MS Word docx格式， 还支持Markdown中LaTeX格式的数学公式。 建议使用RStudio软件作为R Markdown文件的编辑器。 在RStudio软件中，用菜单“File–New File–R Markdown”新建一个R Markdown文件，扩展名为.Rmd。 用快捷图标Knit可以将文件转换成HTML格式、PDF格式（需要安装LaTeX编译软件）、MS Word格式。 从HTML格式可以转换成PDF格式。 为此， 安装Google的Chrome浏览器， 在Chrome中打开HTML文件后， 然后选择菜单“打印”， 选打印机为“另存为PDF”， 然后选“更多设置”， 将其中的“缩放”改为自定义， 比例改为“90%”， 就可以将HTML网页转换成PDF， 其中的数学公式、表格、图形都可以比较好地转换。 注意，如果不缩小打印， 数学公式的编号以及较长的数学公式可能会被裁剪掉。 从Word文件也可以转换成PDF格式， 用MS Word软件的“文件-导出”或者“文件-另存为”功能即可。 如果想将R Markdown文件借助于LaTeX格式转换为PDF， 需要在系统中安装一个TeX编译器。 rmarkdown包从第1.9版本开始要求使用tinytex扩展包以及配套的TinyTeX软件包， 没有提供用本机原有的LaTex编译系统的选择， 如果不安装tinytex，编译为PDF格式时会出错。 关于TinyTeX的安装和使用参见22.12。 如果不借助于RStudio软件， 可以用R软件、knitr包、rmarkdown包、pandoc软件来完成R Markdown源文件的编译。 比如，假设test.Rmd是一个这样的R Markdown格式的文件， 注意一定要使用UTF-8编码保存， 可以在R或RStudio中运行如下命令以生成含有运行结果的html文件: rmarkdown::render(&quot;myfile.Rmd&quot;, output_format = &quot;html_document&quot;, encoding=&quot;UTF-8&quot;) 其中myfile.Rmd是源文件， 产生的HTML文件带有图形、支持数学公式。 在R或RStudio中可以用如下命令把.Rmd文件转化为MS Word docx格式: rmarkdown::render(&quot;myfile.Rmd&quot;, output_format = &quot;word_document&quot;, encoding=&quot;UTF-8&quot;) 使用RStudio软件使得这些任务可以一键完成， 而且有很好的数学公式支持， 所以建议编辑R Markdown文件还是使用RStudio软件。 用RStudio的Knit图标一键编译与用rmarkdown::render()命令编译有重要差别： 用Knit图标编译，Rmd文件中的程序会在一个崭新的会话中执行， 当前会话中已经定义的函数、变量、导入的扩展包不会影响到编译结果； 用rmarkdown::render()编译， Rmd文件中的程序是在当前会话中执行的， 会带来一定的兼容性问题， 有可能在别人的环境下就不能正确执行或者会给出不同结果。 但是，rmarkdown::render()可以通过程序调用， 比如，循环地从同一个Rmd生成一系列不同的报告。 为了不让当前会话环境干扰结果， 可以人为地打开一个新会话。 22.2.1 编译的实际过程 编译Rmd文件， 一般是调用rmarkdown::render()函数执行任务。 编译的第一步， 会调用knitr包的knit()函数将代码段中的程序依次运行， 结果保存为一个临时.md文件中， 图形结果暂存在单独的图形文件中， 文字结果会直接保存在临时.md文件中。 编译的第二步， 调用外部程序Pandoc将临时的.md文件转换为要求的Word、HTML等输出格式； 如果要求的输出是pdf_document， 则会调用Pandoc先将临时的.md文件转换为一个中间的.tex文件， 然后利用tinytex包调用外部的TinyTex软件将.tex文件编译为PDF结果。 Pandoc是一个功能强大的文件转换程序， 可以在多种不同的文件格式之间转换， 具有丰富的选项。 对于markdown格式， Pandoc也提供了丰富的扩充功能， 最重要的是支持LaTeX格式的数学公式。 见21.4。 22.3 在R Markdown文件中插入R代码 插入的R代码分为行内代码与代码块。 行内代码的结果插入到一个段落中间， 代码以`r开头，以`结尾， 如`r sin(pi/2)`在结果中会显示为1。 为了原样显示一个反向单撇号， 可以在两边用双反向单撇号界定并用空格隔开内部的内容。 代码块则把结果当作单独的段落， 按照Markdown格式的规定， 代码块的前后需要有空行， 但是R Markdown实际上放松了这个要求， 允许前后不空行。 R代码段以单独的一行开头， 此行以三个反单撇号开始， 然后是{r}，如```{r}。 代码段以占据单独一行的三个反单撇号```结尾。 如 ```{r} set.seed(1) x &lt;- round(rnorm(10), 2) print(x) ``` 结果将变成 set.seed(1) x &lt;- round(rnorm(10), 2) print(x) ## [1] -0.63 0.18 -0.84 1.60 0.33 -0.82 0.49 0.74 0.58 -0.31 可以看出，代码段程序会被插入到最终结果中， 代码段的文本型输出会插入到程序的后面。 代码块也可以嵌入到引用、列表等环境中。 代码块中作的图将自动插入到当前位置。 下面的程序： ```{r} plot(x) ``` 结果将显示为: plot(x) 在RStudio中， 可以用Insert快捷图标插入代码段， 还可以用Ctrl+Alt+I快捷键插入代码段。 22.4 输出表格 knitr包提供了一个 kable() 函数可以用来把数据框或矩阵转化成有格式的表格， 支持HTML、docx、LaTeX等格式。 例如，计算线性回归后， summary()函数的输出中有coefficients一项，是一个矩阵， 如果直接文本显示比较难看： x &lt;- 1:10; y &lt;- x^2; lmr &lt;- lm(y ~ x) co &lt;- summary(lmr)$coefficients print(co) ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -22 5.5497748 -3.964125 4.152962e-03 ## x 11 0.8944272 12.298374 1.777539e-06 可以用knitr包的kable函数来显示: knitr::kable(co) Estimate Std. Error t value Pr(&gt;|t|) (Intercept) -22 5.5497748 -3.964125 0.0041530 x 11 0.8944272 12.298374 0.0000018 kable()函数的digits=选项可以控制小数点后数字位数， caption=选项可以指定表的标题内容。 R扩展包xtable提供了一个xtable()函数， 也可以用来生成HTML格式和LaTeX格式的表格， 但是需要指定要输出的格式。 xtable对比较多的R数据类型和输出类型提供了表格式显示功能， 包括矩阵、数据框、回归分析结果、方差分析结果、主成分分析结果、 若干分析结果的summary结果等。 例如，上面的回归结果用xtable()函数显示如: print(xtable::xtable(lmr), type=&#39;html&#39;) Estimate Std. Error t value Pr(&gt;|t|) (Intercept) -22.0000 5.5498 -3.96 0.0042 x 11.0000 0.8944 12.30 0.0000 这个代码段用了选项results='asis'， 因为xtable生成的是直接用来插入到结果中的html代码。 注意这里指定了输出为HTML类型。 如果将本文件转化为docx, xtable的结果不可用。 R扩展包pander提供了更好的表格能力， 也能与knitr包很好的合作输出。 其pander()函数可以将多种R输出格式转换成knitr需要的表格形式。 如 pander::pander(lmr) Fitting linear model: y ~ x Estimate Std. Error t value Pr(&gt;|t|) (Intercept) -22 5.55 -3.964 0.004153 x 11 0.8944 12.3 1.778e-06 但是，经过试验发现， 表中中有中文时pander包会出错。 22.5 利用R程序插图 Rmd文件的插图有两种， 一种是已经保存为图形文件的， 主要是png和pdf图片； 另一种是文中的R代码生成的图形。 已经有图形文件的， 可以用markdown格式原来的插图方法， 见markdown格式介绍。 但是，这样做不能给图形自动编号， 另外因为制作图书是有网页和PDF书两种主要输出格式的， 原有的插图方式在这两种输出格式上有细微的不一致。 所以，最好是统一使用Rmd的插图方法。 Rmd的插图方法就是写一段R代码段来插图， 如果是用程序作图，则代码中写作图的代码； 如果是已有的图形文件， 可以在一个单独的R代码段中用类似下面的命令插图： ```{r, echo=FALSE} knitr::include_graphics(&quot;figs/myfig01.png&quot;) ``` 其中figs是存放图形文件的子目录名， myfig01.png是要插入的图形文件名。 这样， 如果同时还有myfig01.pdf的话， 则HTML输出使用png图片而PDF输出自动选用pdf文件。 另外， 插图的选项在代码段的选项中规定： 用代码段的fig.with和fig.height选项指定作图的宽和高（英寸）， 用out.width和out.height选项指定在输出中实际显示的宽和高， 实际显示的宽和高如果使用如\"90%\"这样的百分数单位则可以自动适应输出的大小。 由于PDF中的中文编码不能自动识别， 所以在每个Rmd源文件的开头应该加上如下的设置， 使得生成PDF图时中文能够正确显示： ```{r setup-pdf, include=FALSE} pdf.options(family=&quot;GB1&quot;) ``` 其中include=FALSE表示要不显示代码段的代码， 有运行结果也不插入到输出结果中， 是否运行视缺省的eval=的值而定。 22.6 代码段选项 独立代码段以```{r}开头， 在大括号内还可以写一些选项， 选项之间以及与开始的r之间用逗号分隔， 所有选项写在同一行内不要换行。 选项都使用“选项名=选项值”的格式， 选项值除了使用常量外也可以使用全局变量名或表达式。 在大括号内开头的 r空格后写一个由英文大小写字母、数字、减号组成的标识符， 作为代码段的标签。 标签中不要用其它类型的字符， 下划线也不要用。 如 ```{r firstCode} cat(&#39;This is 第一段, 有标签.\\n&#39;) ``` 关于代码段选项， 详见https://yihui.name/knitr/options。 22.6.1 代码和文本输出结果格式 R代码块和R代码块的运行结果通常是代码块原样输出， 运行结果用井号保护起来， 这样有利于从文章中复制粘贴代码。 如： ```{r} s &lt;- 0 for(x in 1:5) s &lt;- s + x^x s ``` 结果为: s &lt;- 0 for(x in 1:5) s &lt;- s + x^x s ## [1] 3413 22.6.1.1 highlight选项 转化后的R代码块缺省显示为彩色加亮形式。 用选项highlight=FALSE关闭彩色加亮功能。 22.6.1.2 prompt和comment选项 如果希望代码用R的大于号提示符开始， 用选项prompt=TRUE。 如果希望结果不用井号保护， 使用选项comment=''。 例如： ```{r prompt=TRUE, comment=&#39;&#39;} sum(1:5) ``` 结果为: &gt; sum(1:5) [1] 15 22.6.1.3 echo选项 如果希望不显示代码， 加选项echo=FALSE。 如 ```{r echo=FALSE} print(1:5) ``` 结果为: ## [1] 1 2 3 4 5 22.6.1.4 tidy选项 加选项tidy=TRUE可以自动重新排列代码段， 使得代码段格式更符合规范。例如： ```{r tidy=TRUE} s &lt;- 0 for(x in 1:5) {s &lt;- s + x^x; print(s)} ``` 结果为: s &lt;- 0 for (x in 1:5) { s &lt;- s + x^x print(s) } ## [1] 1 ## [1] 5 ## [1] 32 ## [1] 288 ## [1] 3413 22.6.1.5 eval选项和include选项 加选项eval=FALSE, 可以使得代码仅显示而不实际运行。 这样的代码段如果有标签， 可以在后续代码段中被引用。 加选项include=FALSE， 则本代码段仅运行， 但是代码和结果都不写入到生成的文档中。 22.6.1.6 child选项 加选项child='文件名.Rmd'可以调入另一个.Rmd文件的内容。 如果有多个.Rmd文件依赖于相同的代码，可以用这样的方法。 22.6.1.7 collapse选项 一个代码块的代码、输出通常被分解为多个原样文本块中， 如果一个代码块希望所有的代码、输出都写到同一个原样文本块中， 加选项collapse=TRUE。 例如， 没有这个选项时： ```{r} sin(pi/2) cos(pi/2) ``` 结果为： sin(pi/2) ## [1] 1 cos(pi/2) ## [1] 6.123032e-17 代码和结果被分成了4个原样文本块。 加上collapse=TRUE后，结果为： sin(pi/2) ## [1] 1 cos(pi/2) ## [1] 6.123032e-17 代码和结果都在一个原样文本块中。 22.6.1.8 results选项 用选项results=选择文本型结果的类型。 取值有： markup, 这是缺省选项， 会把文本型结果变成HTML的原样文本格式。 hide, 运行了代码后不显示运行结果。 hold, 一个代码块所有的代码都显示完， 才显示所有的结果。 asis, 文本型输出直接进入到HTML文件中， 这需要R代码直接生成HTML标签， knitr包的kable()函数可以把数据框转换为HTML代码的表格。 例如：results='hold'的示例: ```{r collapse=TRUE, results=&#39;hold&#39;} sin(pi/2) cos(pi/2) ``` 结果为: sin(pi/2) cos(pi/2) ## [1] 1 ## [1] 6.123032e-17 22.6.1.9 错误信息选项 选项warning=FALSE使得代码段的警告信息不进入编译结果， 而是在控制台(console)中显示。 有一些扩展包的载入警告可以用这种办法屏蔽。 选项error=FALSE可以使得错误信息不进入编译结果， 而是出错停止并将错误信息在控制台中显示。 选项message=FALSE可以使得message级别的信息不进入编译结果， 而是在控制台中显示。 22.6.1.10 控制普通文字结果宽度 Rmd代码段选项中没有直接提供控制输出的普通文字结果行宽的功能， 但可以用代码行options(width=80)控制， 这里80可以替换成自己选择的每行字符个数。 如： options(width=80) print(123456789001:123456789020) ## [1] 123456789001 123456789002 123456789003 123456789004 123456789005 ## [6] 123456789006 123456789007 123456789008 123456789009 123456789010 ## [11] 123456789011 123456789012 123456789013 123456789014 123456789015 ## [16] 123456789016 123456789017 123456789018 123456789019 123456789020 用options()可以设置行宽， PDF输出的编码， 这样的调用一般放在Rmd文件的开头， YAML的后面， 用setup作代码段标签， 加include=FALSE选项表示仅运行但不使用运行得到的文字和图形输出结果。 22.6.2 图形选项 22.6.2.1 图形大小 用fig.width=指定生成的图形的宽度， 用fig.height=指定生成的图形的高度， 单位是英寸（1英寸等于2.54厘米）。 下面给出一个长宽都是10厘米的图例。 ```{r fig.width=10/2.54, fig.height=10/2.54} curve(exp(-0.1*x)*sin(x), 0, 4*pi) abline(h=0, lty=3) ``` 结果为: curve(exp(-0.1*x)*sin(x), 0, 4*pi) abline(h=0, lty=3) fig.width=和fig.height=规定的是生成的图形大小， 实际生成图形的显示大小会受到dpi（分辨率）影响， 默认dpi是72（每英寸72个点）， 也可以用dpi=选择分辨率。 转化后的HTML文件显示时不一定按原始大小显示。 用out.width=和out.height=可以指定显示大小， 但是必须是最终文件格式承认的单位， 比如HTML的图形大小单位是点（平常说屏幕分辨率的单位）。 或者写成如90%这样的百分比格式。 例如在上面的例子中加上输出度为页面宽度80%的选项： ```{r fig.width=10/2.54, fig.height=10/2.54, out.width=&quot;80%&quot;} curve(exp(-0.1*x)*sin(x), 0, 4*pi) abline(h=0, lty=3) ``` 注意所有选项都要写在一行中，不能换行。 结果为: curve(exp(-0.1*x)*sin(x), 0, 4*pi) abline(h=0, lty=3) 当输出结果为HTML结果或者LaTeX转换的PDF时， 只要两个图形的总宽度小于页面宽度， 两个连续的图形就可以左右并列放置。 Word不支持这种功能。 例如： ```{r, echo=FALSE, fig.width=10/2.54, fig.height=10/2.54, out.width=&quot;45%&quot;} curve(exp(-0.1*x)*sin(x), 0, 2*pi) abline(h=0, lty=3) curve(exp(-0.1*x)*cos(x), 0, 2*pi) abline(h=0, lty=3) ``` 结果为 22.6.2.2 图形结果选择 用fig.keep=选项可以选择保留哪些R代码生成的图。 缺省是fig.keep='high', 即保留每个高级图形函数的结果图形， 低级图形函数对高级图形函数的更改不单独保存而汇总到高级图形函数结果中。 如 par(mar = c(3, 3, 0.1, 0.1)) plot(1:10, ann = FALSE, las = 1) text(5, 9, &quot;Testing low level graphics&quot;) 其中text()函数的结果与高级图形函数plot()的结果一起显示。 fig.keep还可以取：all, 会把低级图形函数修改后的结果单独保存； last, 仅保留最后一个图形；first, 仅保留第一个图； none, 所有图都不显示出来。 22.6.2.3 图形中的中文编码 如果编译输出目标是HTML， 程序产生的图形是PNG格式， 属于点阵图， 图中的任何中文内容不会有乱码问题。 但是， 如果输出目标是PDF， 程序将产生PDF格式的图形， 这种图形属于矢量图， 需要正确设置文字编码才能保证图中的中文不会乱码。 设置的办法是用pdf.options()函数作如下指定： pdf.options(height=10/2.54, width=10/2.54, family=&quot;GB1&quot;) 其中的family选项指定了支持中文， 而height和width则是指定生成的每个图片的物理大小， 以英寸为单位。 这样的设定一般都放在Rmd文件开头， YAML后面的位置， 用setup作代码段标签， 加include=FALSE选项表示仅运行但不使用运行得到的文字和图形输出结果。 22.6.3 缓存(cache)选项 当R Markdown文章比较长，包含的R代码比较多， 或者代码段运行需要比较长时间时， 反复编译整篇文章会造成不必要的计算， 因为有些代码段并没有修改， 依赖的数据也没有改变。 knitr提供了缓存功能， 代码段选项cache=TRUE对代码段打开缓存， 允许暂存上次运行的结果（包括产生的变量、函数、文本结果和图形） 而不需要重复运行代码段。 当代码段被修改时， 缓存被放弃， 编译时重新运行代码段。 缓存这种功能需要慎重使用， 免得错误地使用了旧的结果。 当后面的代码段需要使用前面代码段结果时， 如果前面结果改了， 后面的代码段就不能使用缓存的结果而必须重新计算。 为此， 在后面的代码段中应该加上dependson=选项， 比如dependson=c('codeA', 'codeB')， 其中codeA和codeB是前面的缓存了的代码段的标签， 其结果会用在本代码段中。 也可以使用代码段选项autodep=TRUE， knitr试图自动确定前后代码段之间的依赖关系， 每当前面的代码段改变时， 后面的用到其结果代码段也自动重新计算而不使用缓存的旧结果。 建议仅对计算一次需要较长时间的代码段使用缓存功能， 后面依赖于其结果的代码一定要加上dependson=选项。 建议代码段尽可能有标签，这样在编译失败时能马上看出失败的地点。 对于用options()、par()等改变全局设置的代码段， 应不缓存， 缓存功能不能缓存这些全局设置的修改。 为了保险起见， 可以尽量不使用缓存功能， 而是用save()功能将需要长时间结算的结果保存下来， 用load()载入然后输出到结果文档中。 22.7 章节目录链接问题 对于英文文件， R Markdown基于的pandoc软件可以自动从标题生成适当的链接标签， 将HTML输出或者PDF输出设置属性toc: true后可以生成可点击的章节目录。 但是，目前Pandoc对于中文文件的支持差一些， 所以中文文件要自动生成可点击的目录， 需要在每个标题行的末尾，空格后添加{#label}， 其中label是自己指定的标签内容， 但是建议仅使用英文字母、数字、减号。 如 ### 第三章第一节标题 {#c3-s1-int} 如果希望某个标题不参与自动编号， 可以在标题末尾空格之后加上{-}标记。 但是，这种办法使得该标题没有合适的链接， 所以另一种做法是在大括号内写.unnumbered属性和标签，如： ## 摘要 {.unnumbered #abstract} 还可以用.unlisted属性表示不要将标题加入到目录中。 bookdown包支持的部分（PART）、附录（APPENDIX）也使用{-}来标记， 也存在没有合适的链接的问题， 也可以试验用.unnumbered属性。 22.8 数学公式 22.8.1 在Markdown中输入数学公式 原始的Markdown格式并不支持数学公式。 Pandoc扩展的markdown格式提供了对数学公式的支持， 可以在Markdown文件中插入LaTeX格式的数学公式。 虽然不能提供所有的LaTeX公式能力， 但是常用的数学公式还是能做得很好， 转换到HTML、docx都可以得到正常显示的公式。 用RStudio软件编译Markdown文件，可以在其中插入LaTeX格式的数学公式， 编译成HTML或者docx格式后都可以正常显示数学公式, 在另外安装的LaTeX编译器的支持下也可以将.Rmd格式编译LaTeX格式然后再转换为PDF格式， 这种方法对数学公式的支持会更完善。 关于数学公式的软件设置参见下面设置部分的内容。 22.8.2 数学公式类别 数学公式公式分为行内公式和独立公式。 行内公式和段落的文字混排， 写在两个美元符号$中间，或者\\(和\\)之间。 例如$f(x)=\\frac{1}{2} \\int_0^1 \\sin^2 (t x) dt$变成 \\(f(x)=\\frac{1}{2} \\int_0^1 \\sin^2 (t x) dt\\)。 开头的$后面不能紧跟着空格， 结尾的$不能紧跟在空格后面。 独立公式写在成对的美元符号中间，或者\\[和\\]之间。 例如： $$ f(x) = \\frac{1}{2} \\sum_{j=1}^\\infty \\int_0^1 \\sin^2(j t x) dt . $$ 显示为 \\[ f(x) = \\frac{1}{2} \\sum_{j=1}^\\infty \\int_0^1 \\sin^2(j t x) dt . \\] 22.8.3 基本功能 在数学公式中， 用下划线表示下标， 比如$x_1$结果为\\(x_1\\)。 用^表示上标， 如$x^2$结果为\\(x^2\\)。 上下标都有，如$x_1^2$结果为\\(x_1^2\\)。 公式中用大括号表示一个整体， 比如$x^(1)$不能得到\\(x^{(1)}\\)， 需要用$x^{(1)}$。 公式中用反斜杠开始一个命令， 命令仅包含字母而不能包含数字， 数字只能作为参数。 如$\\frac{1}{2}$和$\\frac12$都可以生成\\(\\frac{1}{2}\\)。 类似的命令如$\\sqrt{2}$为\\(\\sqrt{2}\\)。 希腊字母都有对应的命令， 如$\\alpha$为\\(\\alpha\\)， $\\Sigma$为\\(\\Sigma\\)。 常用数学函数有自己的命令， 如$\\sin x$变成\\(\\sin x\\)， $\\exp (x)$为\\(\\exp (x)\\)。 圆括号与方括号可以直接使用， 绝对值符号用|， 如$|x|$变成\\(|x|\\)。 但是，大括号必须写成\\{和\\}的形式， 如$\\exp\\{-\\frac12 x^2\\}$变成\\(\\exp\\{-\\frac12 x^2\\}\\)。 为了使得括号能够与括号内部的内容等高， 可以用\\left和\\right命令进行修饰， 如 $$ \\phi(x) = \\frac{1}{\\sqrt{2\\pi}} \\exp\\left\\{ \\frac{1}{2} x^2 \\right\\} $$ 变成 \\[ \\phi(x) = \\frac{1}{\\sqrt{2\\pi}} \\exp\\left\\{ \\frac{1}{2} x^2 \\right\\} \\] 注意\\left与\\right必须成对使用，否则出错。 求和如$\\sum_{i=1}^n x_i$变成\\(\\sum_{i=1}^n x_i\\)。 乘积如$\\prod_{i=1}^n x_i$变成\\(\\prod_{i=1}^n x_i\\)。 积分如$\\int_0^1 f(x) dx$变成\\(\\int_0^1 f(x) dx\\)。 22.8.4 修饰符 $f'(x)$显示为\\(f&#39;(x)\\)， 表示导数； $f''(x)$显示为\\(f&#39;&#39;(x)\\)， 表示二阶导数。 顺便说一句， 偏导数写法如$\\frac{\\partial f(x,t)}{\\partial x}$， 显示为\\(\\frac{\\partial f(x,t)}{\\partial x}\\)。 \\(\\bar{x}\\)的写法是$\\bar{x}$。 \\(\\overline{\\text{span}}\\)的写法是$\\overline{\\text{span}}$。 \\(\\hat{x}\\)的写法是$\\hat{x}$。 \\(\\tilde{x}\\)的写法是$\\tilde{x}$。 \\(\\vec{x}\\)的写法是$\\vec{x}$。 22.8.5 对齐与矩阵 为了产生对齐的公式， 在独立公式中使用aligned环境。 公式中的环境以\\begin{环境名}开始， 以\\end{环境名}结束， 用\\\\表示换行，用&amp;表示一个上下对齐位置。 如 $$ \\begin{aligned} f(x) =&amp; \\sum_{k=0}^\\infty \\frac{1}{k!} x^k \\\\ =&amp; e^x \\end{aligned} $$ 转化成 \\[ \\begin{aligned} f(x) =&amp; \\sum_{k=0}^\\infty \\frac{1}{k!} x^k \\\\ =&amp; e^x \\end{aligned} \\] 可以用pmatrix环境制作写在圆括号中的矩阵， 用bmatrix环境制作写在方括号中的矩阵， 用vmatrix制作写在绝对值号中的矩阵，如 \\[ \\begin{pmatrix} x_{11} &amp; x_{12} \\\\ x_{21} &amp; x_{22} \\end{pmatrix} \\] 列向量、行向量也可以用这种办法制作。 22.8.6 特殊字体 数学公式中的单词、文字必须用\\text{...}保护，比如 $$ \\text{CV} = \\frac{S}{\\bar x} \\times 100 \\% $$ 变成 \\[ \\text{CV} = \\frac{S}{\\bar x} \\times 100 \\% \\] 上例中如果不用\\text{}保护，就会显示为 \\[ CV = \\frac{S}{\\bar x} \\times 100 \\% \\] 这里的\\(CV\\)通常理解为\\(C\\)乘以\\(V\\)。 有时用粗体表示向量或者矩阵， 用\\boldsymbol{...}说明。如 $$ \\boldsymbol{v} = (v_1, v_2)^T $$ 变成 \\[ \\boldsymbol{v} = (v_1, v_2)^T \\] 美术体英文字母用\\mathcal{...}， 如\\(\\mathcal{A, B, C}\\)写法为$\\mathcal{A, B, C}$。 手写花体字母用\\mathscr{...}， 如\\(\\mathscr{B, C, F, G}\\)写法为$\\mathscr{B, C, F, G}$。 22.9 其它编程语言引擎 Rmd文件中除了R代码段以外， 还可以插入Rcpp、Python、Julia、SQL等许多编程语言的代码段， 常用编程语言还可以与R代码段进行信息交换。 22.10 交互内容 在Rmd生成HTML结果时， 可以在结果中包含允许读者交互操作的内容， 比如， 用户修改模型参数， 使得模型报表、图形交互地改变。 有两种方法可以实现交互： HTML小程序(widgets)， 由R扩展包htmlwidgets实现， 利用JavaScript函数库进行交互。 在这一功能基础上有一些派生的扩展包， 如DT，leaflet, dygraph。 利用shiny框架，这也是一个R扩展包， 交互功能由R的一个会话驱动。 Rmd文件的YAML元数据中需要设置runtime: shiny。 22.11 属性设置 22.11.1 YAML元数据 可以在RStudio软件中编辑markdown文件与Rmarkdown文件， RStudio的markdown支持来自knitr、rmarkdown、bookdown扩展包和pandoc软件， .Rmd文件支持一些特殊的文件设置， 这些设置写在markdown文件和.Rmd文件的开头位置， 用三个减号组成的行作为开始标记与结束标记， 称为YAML元数据块(YAML meta data block)， 块后面必须用空行分隔。 元数据块中可以用“设置属性名: 设置属性值”的办法设置属性， 用缩进表示属性内容，用上下对齐的行表示多项列表。 常用属性有title(标题)、author(作者)、date(日期)、output_format(输出格式)等，如 --- title: &quot;临时测试&quot; author: &quot;李东风&quot; date: &quot;2016年7月6日&quot; --- 这三个设置会出现在转换后结果的标题部分。 RStudio的中文支持还是有时出现问题， 如果出现涉及到YAML的错误， 先将中文内容替换为英文试一试。 因为冒号:在属性设置中有特殊意义， 属性设置值如果含有冒号， 需要把整个属性值两边用单撇号界定。 属性值可以是列表或多项，例如： --- title: &#39;This is the title: it contains a colon&#39; author: - name: Author One affiliation: University of Somewhere - name: Author Two affiliation: University of Nowhere tags: [nothing, nothingness] abstract: | This is the abstract. It consists of two paragraphs. --- 此例中有title、author、tags、abstract四个属性。 author属性包含两个作者， 每个作者又有name和affiliation两个属性。 tags属性是一个两项的列表。 abstract属性用管道符号|表示开头，不需要结束标志，内容缩进。 22.11.2 输出格式 .Rmd文件开头的YAML元数据中， 属性output选择输出的格式， 如 html_document是HTML输出; pdf_document是PDF输出，通过系统中另外安装LaTeX编译系统转换； word_document是docx格式的Word文件输出，等等。 输出格式指定如： output: html_document: default word_document: default pdf_document: default 其中default表示该输出格式完全使用默认设置。 在输出格式没有定制设置时必须有default指定。 除了上述三种常见格式以外， 在RStudio中使用时， 还支持一种html_notebook输出格式， 这种输出格式完全在当前的R会话中运行代码块， 其Knit按钮会变成Preview按钮， 可以显示当前已有的结果到HTML窗口， 不显示未运行部分的结果。 这可以交互地人为控制代码块的运行， 因为不需要重新运行代码块，预览的速度也比较快。 其它输出格式在用Knit编译时都要在一个新的R会话中逐一运行文中的代码块。 有时需要根据编译输出目标采用不同的设置， 比如， 输出为html时可以使用HTML插件(widgets)， 而输出到PDF则不可以。 函数knitr::is_html_output()可以判断当前编译的源文件是否正在被编译为HTML， knitr::is_latex_output()可以判断是否正在编译为LaTeX然后再转换为PDF。 另外，也可以用 knitr::opts_knit$get(\"rmarkdown.pandoc.to\") 感知当前编译过程的目标， 对HTML类，结果为\"html\"， 对PDF，结果为\"latex\"。 22.11.3 输出格式设置 在每种输出格式后面还可以继续添加该输出特有属性。 如： output: html_document: toc: true number_sections: true word_document: toc: true pdf_document: toc: true 22.11.4 目录设置 输出格式的toc: true选项指定自动生成目录， HTML输出、PDF输出、Word输出都支持此功能。 见上例。 output: html_document: toc: true toc_depth: 2 上例中，html_document是output的属性， 隶属关系用缩进表示； html_document又有自己的属性toc和toc_depth， 隶属关系用缩进表示。 属性toc: true表示要自动生成可点击的目录。 输出格式的属性toc_depth是目录包含的章节层级数。 对html_document输出， 属性toc_float: true使得生成的文档在左侧显示一个目录导览窗格。 而toc_float属性又可以指定一些属性，隶属关系用缩进表示。 toc_float的属性collapse: true表示仅展开章节第一层级， smooth_scroll: true使得通过导览窗格跳跃时页面有平滑滚动过程显示。 用如： output: html_document: toc: true toc_float: collapse: true smooth_scroll: true 22.11.5 章节自动编号 输出格式的属性number_sections为true可以自动对章节编号。 HTML输出与PDF输出都支持此功能。 在章节自动编号时， 如果不是利用bookdown包而是基于基本的R Markdown， 文中的分节最高层级最好用一个井号， 对应于节， 如果用两个井号， 编号会变成0.1，0.2这样。 22.11.6 Word输出章节自动编号及模板功能 Word文件不能自动编号， 解决办法是生成适当的模板文件， 如wordstyle.docx, 然后在Rmd文件的元数据部分为word_document输出增加reference_docx选项，如: output: html_document: toc: true number_sections: true word_document: toc: true reference_docx: wordstyle.docx 这样，新编译的Rmd文件就可以采用wordstyle.docx的格式设置， 比如章节自动编号等。 目前目录标题还是英文， 需要在结果中人为地修改为中文。 一个样例模板下载如下： wordstyle.docx 22.11.7 HTML特有输出格式设置 对于html_document输出类型， 可以用theme属性设置一个主题， 取值如default, cerulean, journal, flatly, darkly, readable, spacelab, united, cosmo, lumen, paper, sandstone, simplex, yeti。 用highlight属性设置程序语言语法高亮样式， 可取值有default, tango, pygments, kate, monochrome, espresso, zenburn, haddock, and textmate。 用null表示取消语法高亮。 可以用css属性指定一个自定义的CSS样式表文件。 如果希望完全用自己的样式代替原有样式， 可以设置theme: null。 code_folding属性设置HTML结果中代码折叠选项， 取值hide可以隐藏代码， 但读者通过选项可见。 取值show可以显示代码， 但读者通过选项可隐藏代码显示。 22.11.8 关于数学公式支持的设置 Rmd格式支持数学公式， 在生成的HTML、Word、PDF中都可以正常显示数学公式。 以HTML为输出时， 会使用MathJax库显示数学公式。 这是一个用于在浏览器中显示数学公式的Javascript程序库， 显示效果很好， 还支持多种显示实现方式， 支持包括LaTeX在内的多种数学公式输入方法。 R Markdown原来使用MathJax版本2， 现在MathJax已经发布了版本3， 有很大的改动， 我们这里应仍使用版本2。 MathJax库很大， 所以一般是从其网站按需远程调用的， 但是远程调用MathJax库在网络不畅通时会使得公式显示极为缓慢甚至无法显示， 所以Rmd允许将MathJax本地化。 在.Rmd文件头部YAML元数据的某种HTML输出格式的属性中， 设置属性mathjax: local和就可以使得MathJax库被放在生成的HTML的一个下层目录中。 设置如 output: html_document: toc: true self_contained: false mathjax: local 注意设置mathjax: local同时必须设置self_contained: false。 在不使用本地MathJax副本时， 可以设置self_contained: true， 这使得图形文件、JavaScript代码等依赖项也打包在生成的单一HTML文件中， 如果设为false， 这些依赖文件会存放在单独文件中。 可以用lib_dir属性指定一个子目录用来存放这些依赖文件， 多个Rmd文件可以共用同一个lib_dir值。 将MathJax用mathjax: local属性本地化有明显的缺点。 这时，每个Rmd项目都需要一个MathJax库副本， 使得文件备份变得很麻烦。 下面的设置方法可以令多个Rmd项目共享一个共同的本地MathJax库。 22.11.9 输出设置文件 如果一个项目包含多个.Rmd文件， 每个文件单独用YAML元数据进行设置比较繁琐， 修改时也很麻烦。 可以在项目目录中增加一个_output.yml文件， 其中包含所有.Rmd文件共用的output属性的设置， 各个.Rmd文件还可以有自己单独的output属性， .Rmd文件YAML元数据中的属性优先级高于共同设置的属性。 例如，_output.yml文件内容如下： html_document: toc: yes number_sections: yes mathjax: &quot;../../MathJax/MathJax.js&quot; includes: in_header: &quot;_header.html&quot; word_document: toc: yes reference_docx: wordstyle.docx pdf_document: includes: in_header: preamble.tex latex_engine: xelatex 上面设置了使用本地硬盘的MathJax库， 位于项目目录的上两层目录中的MathJax子目录中。 这样可以使得多个项目共享一个MathJax库。 将生成的结果当作网站发布时， 只要将MathJax库也安装到项目在网站的目录的上两层的MathJax子目录中就可以。 其中_header.html内容如下，是关于MathJax具体的一些设置： &lt;script type=&quot;text/x-mathjax-config&quot;&gt; MathJax.Hub.Config({ jax: [&quot;input/TeX&quot;,&quot;output/SVG&quot;], extensions: [&quot;tex2jax.js&quot;,&quot;MathMenu.js&quot;,&quot;MathZoom.js&quot;], TeX: { extensions: [&quot;AMSmath.js&quot;,&quot;AMSsymbols.js&quot;,&quot;noErrors.js&quot;,&quot;noUndefined.js&quot;] } }); &lt;/script&gt; 注意， _output.yml文件都是输出设置， 所以这个文件中不能再写output属性，下面的_output.yml写法是不正确的： output: html_document: toc: yes 22.12 LaTeX和PDF输出 Rmd文件的pdf_document输出类型是先转换为LaTeX文件， 再借助tinytex扩展包和LaTeX编译程序包TinyTeX转换为PDF。 rmarkdown从第1.9版本开始不再支持使用本机系统中已有的LaTeX编译系统， 只允许使用TinyTeX。 TinyTeX优点是直接用R命令就可以安装， 更新也由R自动进行，不需要用户干预。 22.12.1 TinyTex的安装使用 为了安装R的tinytex扩展包和单独的TinyTeX编译软件， 如果已经安装了其它的LaTeX编译系统需要先卸载， 否则可能有冲突，然后在R中运行： install.packages(&#39;tinytex&#39;) tinytex::tlmgr_repo(&#39;http://mirrors.tuna.tsinghua.edu.cn/CTAN/&#39;) tinytex::install_tinytex() 其中上面第一行命令安装R的tinytex扩展包， 第二行将下载LaTeX编译程序的服务器设置为清华大学tuna镜像站， 第三行安装LaTeX编译程序。 如果安装成功， TinyTeX软件包在MS Windows系统中一般会安装在 C:\\Users\\用户名\\AppData\\Roaming\\TinyTeX目录中， 其中“用户名”应替换成系统当前用户名。 如果需要删除TinyTeX软件包， 只要直接删除那个子目录就可以。 为了判断TinyTeX是否安装成功， 在RStudio中运行 tinytex::is_tinytex() 结果应为TRUE, 出错或者结果为FALSE都说明安装不成功。 当用户使用RMarkdown和tinytex包转换latex并编译为PDF时， 如果缺少某些latex宏包， tinytex会自动安装缺少的宏包。 因为TinyTex与已有的其它Latex编译软件会发生冲突， 所以安装了TinyTex后用户不在Rmd中使用Latex也需要使用TinyTex这个软件。 在安装TinyTex时已经设置好了程序运行路径(PATH)， 所以在Texworks等软件中可以直接调用xelatex等编译程序， 但是可能会遇到某些latex宏包找不到的问题， 并且不能自动安装下载这些宏包， 需要用户用命令查找并下载安装。 一种安装缺失文件的方式是在R中用tinytex包搜索编译产生的.log文件， 自动安装缺少的宏包。 比如， 编译文件为C:\\user\\rep.log中， 可以用如下命令查找并安装缺失的宏包： library(tinytex) parse_install(&quot;C:/user/rep.log&quot;) 另一种办法是在R中用tinytex扩展包直接搜索所需的扩展包然后安装。 比如， latex编译错误信息提示缺少了一个dsfont.sty宏包， 可以在R中运行如下命令搜索： library(tinytex) tlmgr_search(&quot;dsfont.sty&quot;) ## tlmgr.pl: package repository ## http://mirrors.tuna.tsinghua.edu.cn/CTAN/systems/texlive/tlnet (verified) ## doublestroke: ## texmf-dist/tex/latex/doublestroke/dsfont.stytlmgr search --file --global &quot;dsfont.sty&quot; 结果中显示了当前使用的下载镜像网站的网址， 以及要安装dsfont.sty，需要安装的是doublestroke包。 所以： tlmgr_install(&quot;doublestroke&quot;) ## tlmgr install doublestroke ## tlmgr.pl: package repository ## http://mirrors.tuna.tsinghua.edu.cn/CTAN/systems/texlive/tlnet (verified) ## [1/1, ??:??/??:??] install: doublestroke [66k] ## running mktexlsr ... ## done running mktexlsr. ## running updmap-sys ... ## done running updmap-sys. ## tlmgr.pl: package log updated: ## C:/Users/user/AppData/Roaming/TinyTeX/texmf-var/web2c/tlmgr.log 这样就安装了dsfont.sty宏包。 如下的R命令可以更新已安装的latex宏包： tlmgr_update() 如果latex系统有大幅改版， 可能会导致已安装的tinytex出错而且不能通过更新安装包纠正， 这时可以删除已安装的tinytex软件， 重新安装。 在MS Windows系统中tinytex一般安装在 C:\\Users\\用户名\\AppData\\Roaming\\TinyTeX目录中， 其中“用户名”应替换成系统当前用户名。 如果需要删除TinyTeX软件包， 只要直接删除那个子目录就可以。 tinytex包的tlmgr_search()、tlmgr_install()、tlmgr_update()都是TexLive软件包中的tlmgr命令在R中的方便调用方法， 可以在命令行直接调用tlmgr命令， 参考https://www.tug.org/texlive/doc/tlmgr.html。 22.12.2 Rmd中Latex设置 许多LaTeX相关的YAML元数据不是设置在输出属性中， 而是设置为文件的顶级元数据。 如 --- title: &quot;R语言简介&quot; author: &quot;李东风&quot; date: &quot;2020-12-28&quot; output: pdf_document fontsize: &quot;12pt&quot; papersize: &quot;a5&quot; geometry: &quot;margin=1in&quot; --- 其中属性fontsize, papersize和geometry都是LaTeX选项， 但是没有作为output--pdf_document的属性， 而是作为Rmd文件的顶级元数据属性。 使用较小的纸张大小(如a5)和较大的字体(12pt)， 可以使得制作的PDF结果容易放大显示， 这对于将PDF文件传送到屏幕较小的电子书阅读器上或者手机上阅读时比较有用。 用属性documentclass指定LaTeX文档类型， 比如article是论文格式， book是图书格式。 ctexart和ctexbook是适用于中文的格式， 但兼容性不好。 fontsize是正文字体大小， 可取10pt, 11pt, 12pt， 其中10pt是缺省大小。 geometry用来指定geometry包的参数。 默认的LaTeX编译引擎是pdfLaTeX。 可以在pdf_document输出的属性中设置latex_engine: xelatex将引擎替换成xeLaTeX。 xeLaTeX的优点是支持UTF8编码，可以使用系统中现有字体， 而我们在写中文的R Markdown文档时必须使用UTF-8编码。 Rmd文件中的文献引用可以由pandoc软件执行， 但是在用LaTeX转换PDF时， 可以指定用一个LaTeX引用包， 如： --- output: pdf_document: latex_engine: xelatex citation_package: natbib --- 为了自动生成目录并自动为章节编号， 仍在pdf_document的属性中指定toc: true和number_section: true。 在使用bookdown管理Rmd文件时， 文献引用、目录、章节编号方式有另外的指定办法以及默认规则。 为了能够检查转换过程中的错误， 可以用pdf_document的属性keep_tex: true， 保留作为中间结果的.tex文件， 人工检查其中的错误。 可以在pdf_document输出的属性中指定若干个.tex文件插入到LaTeX文档的导言、正文最前面、正文最后面，如 --- output: pdf_document: latex_engine: xelatex keep_tex: true citation_package: natbib toc: true number_sections: true includes: in_header: preamble.tex before_body: doc-prefix.tex after_body: doc-suffix.tex --- preamble.tex主要用来载入额外的LaTeX包以及定义新的命令， 一个preamble.tex的例子如下 \\usepackage{ctex} % 支持中文的标点和章节模式 %\\usepackage{xltxtra} % XeLaTeX的一些额外符号 \\usepackage{amsthm,mathrsfs} % 基本的ams数学公式 \\usepackage{booktabs} % 增强的表格功能 \\usepackage{longtable} % 支持超过一页的表格 % 下面是自定义的定理环境排版方法 \\makeatletter \\def\\thm@space@setup{% \\thm@preskip=8pt plus 2pt minus 4pt \\thm@postskip=\\thm@preskip } \\makeatother 22.13 生成期刊文章 节22.12的办法可以用来生成LaTeX然后转换为PDF， 可以用来撰写学位论文和期刊论文。 但是学位论文和期刊论文都有比较严格的格式要求， 用节22.12的一般方法需要对LaTeX比较熟悉才能达到格式要求。 用R扩展包rticles可以比较容易地将Rmd文件转换成期刊可接受的LaTeX和PDF格式。 见https://bookdown.org/yihui/rmarkdown/journals.html。 扩展包中对一些常见期刊提供了模板。 首先要安装rticles扩展包，命令为 install.packages(&quot;rticles&quot;) 为了生成新的论文源文件， 在RStudio中， 用“File – New File – R Markdown – from Template”菜单， 从列出的文章模板中选一个。 杂志投稿的Rmd模板是用许多元数据来规定格式的。 用户可以修改其中的标题、作者、作者单位等信息。 因为rticlels的输出只有PDF， 所以必要时可以在Rmd源文件中直接使用LaTeX命令， 但如果Rmd本身可以完成时尽可能用Rmd的功能。 因为定理、图表自动标号和索引功能是由bookdown包提供的， 而rticles的输出类型实际是rmarkdown::pdf_docment， 所以可以联合使用bookdown与rticles，如 output: bookdown::pdf_book base_format: rticles::peerj_article 其中peerj_article可以替换成rticles提供的其它格式。 如果自己需要的模板rticles没有提供， 可以自己设法定义模板， 参见https://bookdown.org/yihui/rmarkdown/document-templates.html。 22.14 附录：经验与问题 22.14.1 Word模板制作 如果有合适的Word格式样例， 可以在YAML元数据的word_document的属性中， 设置reference_docs属性指向该模板文件。 为了制作Word模板， 不应该从头开始， 而是在没有模板的情况下从Rmd文件转换生成一个Word文件， 将其作为模板文件的基础进行修改。 在修改过程中， 应该制作过程的备份，以便修改错误时能退回上一个版本。 如果文章的大标题样式不是“标题”， 将样式改为“标题”以免在后续的自动编号过程中参与编号。 修改的方法是选中大标题， 然后在Word软件主菜单的“开始–样式”选择框中选中“标题”， 就可以设置其样式。 Word的目录是与“标题1”同级的， 这样会在自动编号时参与编号； 为此， 选中“Contents”， 然后在主菜单的“开始–样式”选择框中， 找到突出显示的“TOC标题”， 右键单击“修改”， 在弹出的对话框中将“样式基准”从“标题1”改为“标题”， 并在同一对话框中将适当调整样式， 如字体类型、大小、颜色、是否居中。 改完后保存并保存一个副本。 如果需要修改“标题”，“作者”，“日期”，“标题1”等等的字体、大小、颜色、对齐方式， 可以选中该部分，并在“样式”中邮件单击相应的样式，选择“修改”进行修改， 保存样式文件并试验Rmd文件是否正确地利用了修改的样式。 为了实现自动编号， 先在正文中选中一个一级标题（不能是目录标题）， 从Word的主菜单栏找到“开始——段落——多级列表——定义新的多级列表”， 在打开的对话框中点击“更多”选项， 逐一地选择“单击要修改的级别”， 将级别1、2、3等分别修改， 主要是修改“将级别链接到样式”使得”级别1“与“标题1”对应， “级别2”与“标题2”对应，等等。 注意这个修改要一次性完成， 不能保存了文件后再次定义新的多级列表。 修改模板文件的页边距也会使得利用其为模板的Rmd文件转换结果被修改。 为了修改模板文件的页边距， 在主菜单“布局——页边距——自定义页边距”弹出的对话框中修改。 生成的目录的标题内容是“Table of Contents”， 目前只能对Rmd输出的docx文件直接修改， 修改模板文件的标题内容并不能使得Rmd输出被修改。 参考：Richard Layton的网站文章 https://rmarkdown.rstudio.com/articles_docx.html。 22.14.2 数学公式设置补充 如果不使用RStudio, R扩展包rmarkdown的markdownToHTML()函数可以把含有数学公式的内容转换成可显示公式的HTML文件， R扩展包knitr的knit2html()也可以实现此功能。 用rmarkdown扩展包的markdownToHTML()函数生成的含有数学公式的内容。 单独使用pandoc软件时， 也可以用普通文本编辑器在Markdown文件中输入LaTeX格式的数学公式， 然后用pandoc软件转化为带有数学公式的docx文件， 不需要额外选项。 但是，为了能够在转换的HTML文件中正常显示数学公式， 需要在运行Pandoc时增加运行选项--maxjax，如 pandoc --mathjax -s -o test.html test.md 经试验，这样转化的HTML文件可以在Firefox以及Microsoft的 Edge浏览器和Internet Explorer浏览器中正常显示数学公式。 如果公式中的中文显示不正常， 对显示的公式右键单击弹出选项菜单， 选择“Math Settings–Math Renderer–SVG”或者“HTML-CSS”。 References "],["bookdown.html", "23 用bookdown制作图书 23.1 介绍 23.2 一本书的设置 23.3 章节结构 23.4 书的编译 23.5 交叉引用 23.6 数学公式和公式编号 23.7 定理类编号 23.8 文献引用 23.9 插图 23.10 表格 23.11 数学公式的设置 23.12 使用经验 23.13 bookdown的一些使用问题", " 23 用bookdown制作图书 23.1 介绍 R的bookdown扩展包(https://github.com/rstudio/bookdown) 是继knitr和rmarkdown扩展包之后， 另一个增强markdown格式的扩展， 使得Rmd格式可以支持公式、定理、图表自动编号和引用、链接， 文献引用和链接等适用于编写书籍的功能。 在bookdown的管理下一本书的内容可以分解成多个Rmd文件， 其中可以有可执行的R代码， R代码生成的文字结果、表格、图形可以自动插入到生成的内容中， 表格和图形可以是浮动排版的。 输出格式主要支持gitbook格式的网页图书， 这种图书在左侧显示目录， 右侧显示内容， 并可以自动链接到上一章和下一章； 通过单独安装的LaTeX编译器支持将书籍转换为一个PDF文件， 支持中文； 可以生成ePub等格式的电子书。 主要用于编写有多个章节的书籍， 也可以用来生成单一文件的研究报告。 建议使用RStudio集成环境制作这样的图书， 该软件内建了一键编译整本书的功能。 需要安装bookdown扩展包的最新版本。 bookdown扩展包现在还比较新， 还有一些BUG， 所以尽可能使用最新版的bookdown扩展包并且及时更新RStudio软件。 查看编译的网站建议使用Google Chrome浏览器， 此浏览器对gitbook的支持较好。 为了新写一本书或者从已有的书转换， 最简单的做法是从bookdown的网站下载bookdown配套的例书的zip文件 (见https://github.com/rstudio/bookdown-demo)， 将其解压到本地硬盘某个子目录， 然后修改其中的内容适应自己的书的需要。 因为中文需要一些特殊的设置， 以及在网络条件不好的条件下支持数学公式显示， 本书作者提供了一个粗浅的中文书bookdown模板， 下载链接为: bookdown-template-v0-5.zip。 其中的CBook子目录包含了所需的中文书模板， CArticle子目录包含了论文格式模板， 其它子目录有一些别的模板， 为了在本地支持网页中的数学公式显示还有一个MathJax目录。 参见其中的readme.txt说明文件。 23.2 一本书的设置 一本用bookdown管理的书， 一般放置在某个子目录下， 并作为一个RStudio项目(project)用RStudio管理。 也可以自己新建一个目录， 然后编辑生成必要的文件。 注意，所有的文本文件都要使用UTF-8编码。 一本bookdown书， 一般都需要有一个index.Rmd文件， 这是最后生成的网站的主页的原始文件， 可以在这个文件中写一些书的说明， 并在开头的YAML元数据部分进行有关设置， 如标题、作者、日期等。 index.Rmd的一个例子如下： --- title: &quot;统计计算&quot; author: &quot;李东风&quot; date: &quot;2020-12-28&quot; site: bookdown::bookdown_site output: bookdown::gitbook documentclass: book bibliography: [myrefs.bib] biblio-style: apa link-citations: yes description: &quot;本科生《统计计算》教材。采用R的bookdown制作，输出格式为bookdown::gitbook.&quot; --- # 前言 {-} 统计计算研究如何将统计学的问题用计算机正确、高效地实现。 其中在三个减号组成的两行之间的内容叫做YAML元数据， 是一本书的设置， 上例中有书的标题、作者名、日期（用R程序自动生成）、描述。 其中的site选项很重要， 一定要有这个选项， site: bookdown::bookdown_site使得RStudio软件能辨认这是一个bookdown图书项目， 从而为其提供一键编译快捷方式。 元数据中output项指定默认的输出格式。 documentclass项为借助LaTeX编译PDF格式指定LaTeX的模板， 现在还不能支持ctexbook模板所以使用了book模板。 bibliography项指定一个或者几个.bib格式的文献数据库。 一个bookdown图书项目除了index.Rmd文件之外， 一般还应该有一个_bookdown.yml文件存放与整本书有关的YAML元数据。 例如 new_session: true book_filename: &#39;statcompc&#39; language: label: thm: &#39;定理&#39; def: &#39;定义&#39; exm: &#39;例&#39; proof: &#39;证明: &#39; solution: &#39;解: &#39; fig: &#39;图&#39; tab: &#39;表&#39; ui: chapter_name: &#39;&#39; delete_merged_file: true 其中new_session: true设置很重要， 这使得每一个Rmd文件中的R程序都在一个单独的R会话中独立地运行， 避免了不同Rmd文件之间同名变量和同名标签的互相干扰。 book_filename是最终生成的LaTeX PDF图书或者ePub电子书的主文件名。 language下可以定制一些与章节名、定理名等有关的名称。 另外一个需要的设置文件是_output.yml文件， 用于输出格式的设置。 这部分内容也可以包含在index.Rmd的元数据部分。 内容如 bookdown::gitbook: includes: in_header: mathjax-local.html config: toc: before: | &lt;li&gt;&lt;a href=&quot;http://www.math.pku.edu.cn/teachers/lidf/course/statcomp/_book/index.html&quot;&gt;统计计算&lt;/a&gt;&lt;/li&gt; after: | &lt;li&gt;&lt;a href=&quot;http://www.math.pku.edu.cn/teachers/lidf/&quot; target=&quot;blank&quot;&gt;编著：李东风&lt;/a&gt;&lt;/li&gt; download: [&quot;pdf&quot;] bookdown::pdf_book: includes: in_header: preamble.tex latex_engine: xelatex citation_package: biblatex keep_tex: yes bookdown::epub_book: default 其中的style.css是自定义的CSS显示格式， 可以去掉这一行，使用默认的CSS格式。 这个例子文件分为三部分， gitbook、pdf_book和epub_book三种输出格式分别设置了一些输出选项。 在gitbook部分， 设置了目录上方显示的书的主页的链接（before项）和目录下方显示的作者信息。 在in_header部分插入了一部分个性化的HTML代码， 这部分代码是使用本地的数学公式显示支持以免外网不同时数学公式不能显示， 插入的内容将出现在每个生成的HTML文件的head部分。 在pdf_book部分，设置了通过LaTeX编译整本书为PDF的一些选项。 指定了latex_engine为xelatex， 这对中文支持很重要。 in_header选项要求在LaTeX文件导言部分插入一个preamble.tex文件， 内容如： \\usepackage{ctex} \\usepackage{amsthm,mathrsfs} \\usepackage{booktabs} \\usepackage{longtable} \\makeatletter \\def\\thm@space@setup{% \\thm@preskip=8pt plus 2pt minus 4pt \\thm@postskip=\\thm@preskip } \\makeatother 其中很重要的是使用ctex包来支持中文。 在index.Rmd的元数据中也可以指定一些LaTeX选项， 比如指定页边距等（这些设置有些是非标准的，一般不需要）： classoption: twoside fontsize: 12pt linestretch: 1.5 geometry: &quot;left=4cm, right=3cm, top=2.5cm, bottom=2.5cm&quot; fontsize: 12pt linestretch: 1.5 toc-depth: 1 lof: True lot: True 在bookdown项目中与index.Rmd同级的所有.Rmd文件都自动作为书的一章， 除非文件名以下划线开头。 这样做的好处是作者可以任意地增删章节， 编译整本书时章节编号会自动调整。 但是， 章节的顺序将按照文件名的字典序排列， 所以， 所有的包含一章内容的.Rmd文件， 最好命名为类似0201-rng.Rmd这样的名字， 文件名前面人为地加上排序用的序号， 使得章节按照自己的次序排列。 实际上， 也可以设置不自动将每个.Rmd文件都作为一章， 而是在_output.yml中设置一项rmd_files， 列出所有需要作为一章的文件，并以列出次序编译，如 rmd_files: [&quot;index.Rmd&quot;, &quot;rng.Rmd&quot;, &quot;simulation.Rmd&quot;, &quot;refs.Rmd&quot;] 这时，应该添加一个_site.yml文件，内容如： site: &quot;bookdown::bookdown_site&quot; output: bookdown::gitbook 23.3 章节结构 除了index.Rmd文件， 项目中每个.Rmd文件都作为一章。 每个.Rmd文件第一行， 应该是以一个井号和空格开头的一级标题， 后面再加空格然后有大括号内以井号开头的章标签， 如 # 随机数 {#rng} 这些章标签去掉井号后会作为生成的HTML文件的名字， 所以一定要有章标签， 而且章节标签在全书中都不要重复以免冲突。 文件内可以用两个井号和一个空格开始的行表示节标题， 最后也应该有大括号内以井号开头的节标签，如 # 随机数 {#rng} ## 均匀随机数发生器 {#rng-unif} 使用bookdown写书， 一般每章不要太长， 否则编译预览很慢， 读者浏览网页格式也慢。 内容相近的章节可以作为一个“部分”。 为此， 在一个部分的第一个章节文件的章标题前面增加一行， 以# (PART)开头， 以{-}结尾， 中间是部分的名称，如 # (PART) 随机数和随机模拟 {-} # 随机数 {#rng} 书的最后可以有附录， 附录的章节将显示为A.1, B.1这样的格式。 为此， 在附录章节的第一个文件开头加如下的第一行标题行： # (APPENDIX) 附录 {-} # 一些定理的证明 {#formula} 23.4 书的编译 建议使用RStudio软件编辑内容， 管理和编译整本书。 在index.Rmd或者_bookdown.yml中设置site: bookdown::bookdown_site后， RStudio就能识别这个项目是一个bookdown项目， 这时RStudio会有一个Build窗格，其中有“Build book”快捷图标， 从下拉菜单中选择一个输出格式（包括gitbook、pdf_book、epub_book）， 就可以编译整本书。 对gitbook格式， 即HTML网页格式， 编译完成后会弹出一个预览窗口， 其中的“Open in Browser”按钮可以将内容在操作系统默认的网络浏览器中打开。 另一种办法是在命令窗口用如下命令编译（以输出gitbook为例）， 我个人认为这种办法更好用： bookdown::render_book(&quot;index.Rmd&quot;, output_format=&quot;bookdown::gitbook&quot;, encoding=&quot;UTF-8&quot;) 编译结果默认保存在_book子目录中， 可以在_bookdown.yml中设置output_dir项改为其它子目录。 编译整本书为pdf_book格式时，如果成功编译， 也会弹出一个PDF预览窗口。 可以在_book子目录中找到这个PDF文件。 将书编译为PDF需要利用LaTeX编译器， 这需要单独安装LaTeX编译软件， 如Windows下的CTEX套装软件。 LaTeX编译器对输入要求十分严格， 一丁点儿错误都会造成整本书的编译失败， 所以对于不熟悉LaTeX的用户， 不建议使用bookdown的pdf_book输出格式。 如果仅在R Markdown中使用LaTeX编译器， 可以安装谢益辉的TinyTeX。 对于较短的书， 做了一定修改后都可以重新编译gitbook结果和pdf_book结果。 在书比较长了以后， 每次编译都花费很长时间， 所以可以仅编译gitbook格式的一章， 修改满意后再编译整本书。 仅编译一章也需要所有的.Rmd文件都是已经编译过一遍的， 新增的Rmd文件和图形文件会使得编译单章出错， 每次新增了Rmd文件和图形文件都应该重新编译整本书， 但是内容修改后不必要重新编译整本书， 可以仅编译单章。 编译单章现在没有快捷图标， 只能在RStudio控制台（命令行）运行如下命令： bookdown::preview_chapter(&quot;chap-name.Rmd&quot;, output_format=&quot;bookdown::gitbook&quot;, encoding=&quot;UTF-8&quot;) 其中chap-name.Rmd是要编译的单章的文件名。 编译完成后在结果目录（默认是_book）中找到相应的HTML文件打开查看， 再次编译后仅需在浏览器中重新载入文件。 建议使用Google chrome浏览器， 用MS IE或者Edge浏览器对gitbook的Javascrpt支持不够好， 使得目录的层级管理、自动滚动、单章编译后的目录更新不正常， 而chrome则没有问题。 编译单章也不能解决所有的问题， 有些问题还是需要编译整本书， 而章节很多时整本书编译又太慢。 为此， 可以在项目中增加一个临时的部分内容子目录， 如testing子目录， 在子目录中存放相同的设置文件index.Rmd、_bookdown.yml、_output.yml， 以及图形文件、文献数据库文件， 并将要检查的若干章节复制到testing子目录中， 在testing中新建一个bookdown项目， 然后编译其中的整本书。 这在调试部分章节的HTML和PDf输出时很有效。 解决问题后主要将修改过的章节复制回原始的书的目录中。 有时仅仅想验证某个长数学公式或者表格， 用上述的编译单章或者单独一个小规模测试项目的办法也不经济。 这时，单独开一个备用的普通RStudio项目， 不能是bookdown项目， 在其中的Rmd文件中验证数学公式和表格的编排， 这样效率最快了。 有时需要根据编译输出目标采用不同的设置， 比如， 输出为html时可以使用HTML插件(widgets)， 而输出到PDF则不可以。 可以用 knitr::opts_knit$get(\"rmarkdown.pandoc.to\") 感知当前编译过程的目标， 对HTML类，输出为\"html\"， 对PDF，输出为\"latex\"。 23.5 交叉引用 在写作时，每个一级到三级标题都应该有自定义的标签， 格式是在标题行末尾空格后添加{#label}， 其中label是自己指定的标签， 使用英文、数字、减号， 不要使用中文， 而且整本书不要有重复的标签。 为避免不同章节使用了重复标签， 可以取label的前一部分为所在章节的文件名。 如果要引用某一章节， 有如下的做法： §\\@ref(label)，label是某个标题对应的标签。 结果显示为如§3.1.1这样的章节号，并可点击， 点击时跳跃到相应的章节。 [链接文本](#label) 其中label是某个标题对应的标签。 结果产生一个链接，显示为链接文本，点击时跳到label对应的章节。 23.6 数学公式和公式编号 通过R的knitr和rmarkdown扩展包， .Rmd格式文件已经支持数学公式， 见R Markdown说明。 在用$$符号在两端界定的公式后面， 可以用\\tag{标号}命令增加人为的公式编号，如 $$ y = f(x) \\tag{*} $$ 结果显示为 \\[ y = f(x) \\tag{*} \\] 要注意的是， 在$$界定的数学公式内用了aligned环境后， 仅能在\\end{aligned}之后加\\tag{标号}命令， 而不能写在aligned环境内。 这样， 多行的公式将不能为每行编号。 用\\tag命令人为编号比较简单易用， 但是在有大量公式需要编号时就很不方便， 只要增加了一个公式就需要人为地重新编号并修改相应的引用。 bookdown包支持对公式自动编号， 并可以按公式标签引用公式， 引用带有超链接。 bookdown的自动编号对LaTeX的equation环境、align环境都可以使用， 而且不需要在两端用$$界定。 在公式的末尾或者一行公式的\\\\换行符之前， 写(\\#eq:mylabel)， 其中mylabel是自己给公式的文字标签， 文字标签可以使用英文字母、数字、减号、下划线。 如 \\begin{align} f(x) =&amp; \\sum_{k=0}^\\infty \\frac{1}{k!} x^k (\\#eq:efunc-sum) \\\\ = e^x (\\#eq:efunc-ex) \\end{align} 将会对两行公式自动编号。 引用公式时， 用如\\@ref(eq:mylabel)，其中mylabel是公式的自定义标签， 编译后这样的引用会变成带有链接的圆括号内的编号。 公式编号在全书中都不要有冲突（不同的公式定义了相同的编号）。 一种办法是，自定义的公式标签的开头以章节文件名开头。 23.7 定理类编号 定理、引理、命题、例题等， 使用特殊的markdown代码格式， 以三个反单撇号开头， 以三个反单撇号结尾， 在开头的三个反单撇号后面写{theorem}表示定理。 在theorem后面，用空格或逗号分隔后写一个定理的自定义标签， 因为现在bookdown的功能还不完善， 所以所有的定理类都应该自定义一个标签。 可以用name=\"定理名称\"指定一个显示的定理名。 标签也可以写成label=\"mythlabel\"，其中mythlabel是自定义的标签。 设某个定理的自定义标签是mythlabel， 则可以用如\\@ref(thm:mythlabel)引用此定理的编号， 编号是在每一章内从头编号的。 编号有自动生成的链接。 例如： ``{theorem norlim-weakconv, name=&quot;弱收敛&quot;} $\\xi_n$依分布收敛到$\\xi$， 当且仅当对任意$\\mathbb R$上的一元实值连续函数$f(\\cdot)$都有 $$ E f(\\xi_n) \\to E f(\\xi), \\ n \\to \\infty $$ ``` 当定理或例子内有列表时， 一定注意列表前后要空行， 否则会导致嵌套错误。 这种错误在编译HTML时无法发现， 但是会造成结果莫名其妙地出错。 bookdown提供了证明环境， 但是不太实用。 对例题， 将theorem替换成example， 在引用时将thm替换成exm。 如： ``{example noralim-aspr-ce, name=&quot;依概率收敛不a.s.收敛反例&quot;} a.s.收敛推出依概率收敛， 但是反之不然。给出反例。 ``` 定理类的段落包括如下的种类： 表23.1: 定理类段落 环境名 默认显示名 标签前缀 theorem Theorem thm lemma Lemma lem corollary Corollary cor proposition Proposition prp conjecture Conjecture cnj definition Definition def example Example exm exercise Exercise exr 其中的显示名可以在_bookdown.yml的language的label属性中修改， 见23.2。 23.8 文献引用 bookdown使用.bib格式的文献数据库， 关于.bib格式的文献数据库请参考LaTeX的有关说明。 在index.Rmd的YAML元数据部分或者_bookdown.yml中用bibliography可以设置使用的一个或者多个.bib格式的文献数据库文件。 设某篇文章的.bib索引键是Qin2007:comp， 用 @Qin2007:comp 可以引用此文献， 用[@Qin2007:comp] 可以生成带有括号的引用， 引用都有超链接。 指定.bib文件时可以用相对路径， 如“../docs/mybib.bib”。 下面是一个样例.bib文件的内容（主要要用UTF-8编码保存）： % Encoding: UTF-8 @Book{MWP06-HighStat, author = {茆诗松 and 王静龙 and 濮晓龙}, title = {高等数理统计}, year = {2006}, edition = {第二版}, publisher = {高等教育出版社} } @BOOK{Unwin-Visualize06, title = {Graphics of Large Datasets Visualizing a Million}, publisher = {Springer}, year = {2006}, author = {Antony Unwin and Martin Theus and Heike Hofmann} } @Article{Wichmann1982:RNG, author = {Wichmann, B. A. and Hill, I. D.}, title = {Algorithm as 183: An efficient and portable pseudo-random number generator}, journal = {Applied Statistics}, year = {1982}, volume = {31}, pages = {188–190. Remarks: 34, 198 and 35, 89}, } @Book{QGCZ2011:StochProc, author = {钱敏平 and 龚光鲁 and 陈大岳 and 章复熹}, title = {应用随机过程}, year = {2011}, publisher = {高等教育出版社}, } 23.9 插图 bookdown图书的插图有两种， 一种是已经保存为图形文件的， 主要是png、jpg和pdf图片； 另一种是文中的R代码生成的图形。 已经有图形文件的， 可以用markdown格式原来的插图方法， 见markdown格式介绍。 但是，这样做不能给图形自动编号， 另外因为制作图书是有网页和PDF书两种主要输出格式的， 原有的插图方式在这两种输出格式上有细微的不一致。 所以，最好是统一使用Rmd的插图方法。 Rmd的插图方法就是写一段R代码段来插图， 如果是用程序作图，则代码中写作图的代码； 如果是已有的图形文件， 可以在一个单独的R代码段中用类似下面的命令插图： knitr::include_graphics(&quot;figs/myfig01.png&quot;) 其中figs是存放图形文件的子目录名， myfig01.png是要插入的图形文件名。 这样， 如果同时还有myfig01.pdf的话， 则HTML输出使用png图片而PDF输出自动选用pdf文件。 另外， 插图的选项在代码段的选项中规定： 用代码段的fig.with和fig.height选项指定作图的宽和高（英寸）， 用out.width和out.height选项指定在输出中实际显示的宽和高， 实际显示的宽和高如果使用如\"90%\"这样的百分数单位则可以自动适应输出的大小。 为了使得插图可以自动编号并可以被引用， 为代码段指定标签并增加一个fig.cap=\"...\"选项指定图形标题。 代码段的标签变成浮动图形的标签，如myfiglabel， 则为了引用这个图只要用\\@ref(fig:myfiglabel)。 注意，在整本书中这些标签都不能重复， 否则编译LaTeX支持的PDF输出会失败。 有些插图会伴随很长的说明文字， 这可以用代码段的fig.cap=选项指定， 但是其中的Markdown特有的格式在转换LaTeX时不一定支持， 而且在代码段选项中写太长的文字说明也是的程序难以辨认。 所以， 可以使用文字引用的方式： 在单独的一段中， 用如下格式定义一段可引用的文字内容： (ref:mylabel) 这里用实际的文字内容代替， 可以有多行，不能分段。 其中mylabel是自己定义的仅由英文大小写字母、数字和减号组成的引用标志符。在需要使用这段文字的位置，用(ref:mylabel)这种格式引用。 注意定义和引用都是用的(ref:mylabel)语法。 用R生成PDF格式的图形时， 需要指定中文作为family选项， 所以在每个源文件的开头应该加上如下的设置， 使得生成PDF图时中文能够正确显示： ```{r setup-pdf, include=FALSE} pdf.options(family=&quot;GB1&quot;) ``` 其中include=FALSE表示要不显示代码段的代码， 有运行结果也不插入到输出结果中， 是否允许运行视缺省的eval=的值而定。 23.10 表格 23.10.1 Markdown表格 bookdown书的表格也有两种， 一种是原来markdown格式的表格， 最好仅使用管道表， 管道表对中文内容支持最好。 为了对这样的表格自动编号， 需要在表格的前面或者后面空开一行的位置， 写 Table: (\\#tab:mylabel) 表的说明 其中mylabel是自定义的表格标签。 在引用这个表时用如 \\@ref(tab:mylabel)。 23.10.2 用kable()函数制作表格 另一种表格是R代码生成的表格， 主要使用knitr::kable()函数。 在knitr::kable()函数中用选项caption=指定表格的说明文字（标题）， 这时生成表格的R代码段的标签，如myfiglab， 就自动构成了表格的引用标签主干， 实际引用如 \\@ref(tab:myfiglab)。 加选项digits， 可以指定小数点后的数字位数。 不同列使用不同位数时， 可以指定一个位数的向量。 为了适应较长的表， 可以在LaTeX的preamble.tex中引入longtable包， 并在knitr::kable()中加选项longtable=TRUE。 可以设置kable()显示缺失值的方式， 如； options(knitr.kable.NA = &quot;&quot;) 则缺失值显示成空单元。 默认显示是NA。 23.10.3 R中其它制作表格的包 如果要对表格进行更丰富的定制， 可以使用kableExtra包。 flextable和fluxtable支持较多的输出格式和常见表格功能。 还有许多扩展包，不一一列举。 23.11 数学公式的设置 bookdown在生成PDF时使用LaTeX软件， 所以PDF输出的数学公式的支持很好， 但是LaTeX编译器也很挑剔， 稍微一点错误也造成编译失败。 比如，在行内公式内部如果紧邻$符号有多余的空格， 如$ y $，编译PDF时会出错。 bookdown生成的gitbook格式的网页书籍， 在有数学公式时， 使用MathJax库在浏览器中显示数学公式。 MathJax是用于网络浏览器中显示数学公式的优秀的Javascript程序库， 可免费使用。 但是， 当数学公式中含有中文（用\\text{}或\\mbox{}命令）时， 数学公式可能会显示不正常。 另外，数学公式默认使用远程服务器上的MathJax程序库处理， 在网络不通畅时显示很慢或者无法显示。 bookdown中使用MathJax的版本2， 但MathJax已经升级到版本3， 版本3有很大改动， 暂时还应该使用版本2以避免冲突。 为了避免远程调用MathJax程序库的麻烦， 改为本地使用。 将MathJax安装在了书生成的网站主目录的上三层，用../../../MathJax/mathjax.js路径访问。 假设下载整个MathJax库后解压放在了书的网页文件所在子目录的上三层的位置。 增加设置文件_header.html： &lt;script type=&quot;text/x-mathjax-config&quot;&gt; MathJax.Hub.Config({ jax: [&quot;input/TeX&quot;,&quot;output/SVG&quot;], extensions: [&quot;tex2jax.js&quot;,&quot;MathMenu.js&quot;,&quot;MathZoom.js&quot;], TeX: { extensions: [&quot;AMSmath.js&quot;,&quot;AMSsymbols.js&quot;,&quot;noErrors.js&quot;,&quot;noUndefined.js&quot;] } }); &lt;/script&gt; &lt;script type=&quot;text/javascript&quot; src=&quot;../../../MathJax/MathJax.js&quot;&gt; &lt;/script&gt; 如果希望用远程服务器上的MathJax，可以使用如下的mathjax-cdnjs.html设置文件： &lt;script type=&quot;text/x-mathjax-config&quot;&gt; MathJax.Hub.Config({ jax: [&quot;input/TeX&quot;,&quot;output/HTML-CSS&quot;], extensions: [&quot;tex2jax.js&quot;,&quot;MathMenu.js&quot;,&quot;MathZoom.js&quot;], TeX: { extensions: [&quot;AMSmath.js&quot;,&quot;AMSsymbols.js&quot;,&quot;noErrors.js&quot;,&quot;noUndefined.js&quot;] } }); &lt;/script&gt; &lt;script type=&quot;text/javascript&quot; src=&quot;https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/MathJax.js&quot;&gt; &lt;/script&gt; 为了调用这样的设置文件，在_output.yml设置文件中如下设置： bookdown::gitbook: css: style.css includes: in_header: _header.html 注意，MathJax要求先设置再调入。 由于浏览器对MathJax输出方式有记忆， 所以如果不能正常显示中文公式， 需要右键单击公式，选择“Math Settings—Math Renderer”中的“SVG”或者“HTML-CSS”。 23.12 使用经验 Ed Berry在网上分享了用bookdown生成PDF学位论文的经验： https://eddjberry.netlify.com/post/writing-your-thesis-with-bookdown/ 。 Chester Ismay提供了一个R扩展包thesisdown， 见 https://github.com/ismayc/thesisdown， 例子见https://thesisdown.netlify.com/。 有数学公式时， 对行内公式边缘处多余的空格十分敏感， 所以行内公式边缘不要有空格。 如果已经有用LaTeX写的书， 要转换为bookdown的Rmd格式， 可以用RStudio的支持RegEx的替换模式，如 \\\\keyword{([^}]+?)}替换成**\\1**。 \\\\textbf{([^}]+?)}替换成**\\1**。 \\\\texttt{([^}]+?)}替换成\\1。 可以写一个函数对LaTeX文件进行转换生成Rmd文件， 再手工修改。函数如 latex2rmd &lt;- function(fname=&quot;_tmp/tomd.tex&quot;, encoding=&quot;UTF-8&quot;){ lines &lt;- readLines(fname, encoding=encoding) if(encoding != &quot;UTF-8&quot;) lines &lt;- iconv(lines, from=encoding, to=&quot;UTF-8&quot;) print(head(lines, 10)) lines &lt;- gsub(&quot;\\\\\\\\keyword[{]([^}]+?)[}]&quot;, &quot;**\\\\1**&quot;, lines, perl=TRUE) lines &lt;- gsub(&quot;\\\\\\\\textbf[{]([^}]+?)[}]&quot;, &quot;**\\\\1**&quot;, lines, perl=TRUE) lines &lt;- gsub(&quot;\\\\\\\\texttt[{]([^}]+?)[}]&quot;, &quot;`\\\\1`&quot;, lines, perl=TRUE) lines &lt;- gsub(&quot;\\\\\\\\label[{](eq:[^}]+?)[}]&quot;, &quot;(\\\\\\\\#\\\\1)&quot;, lines, perl=TRUE) lines &lt;- gsub(&quot;\\\\\\\\eqref[{]([^}]+?)[}]&quot;, &quot;\\\\\\\\@ref(\\\\1)&quot;, lines, perl=TRUE) lines &lt;- gsub(&quot;\\\\\\\\bs\\\\\\\\&quot;, &quot;\\\\\\\\boldsymbol\\\\\\\\&quot;, lines, perl=TRUE) lines &lt;- gsub(&quot;\\\\\\\\bs &quot;, &quot;\\\\\\\\boldsymbol &quot;, lines, perl=TRUE) lines &lt;- gsub(&quot;\\\\\\\\Rbb&quot;, &quot;\\\\\\\\mathbb R&quot;, lines, perl=TRUE) lines &lt;- gsub(&quot;\\\\\\\\Zbb&quot;, &quot;\\\\\\\\mathbb Z&quot;, lines, perl=TRUE) lines &lt;- gsub(&quot;\\\\\\\\Var[(]&quot;, &quot;\\\\\\\\text\\\\{Var\\\\}(&quot;, lines, perl=TRUE) lines &lt;- gsub(&quot;\\\\\\\\Cov[(]&quot;, &quot;\\\\\\\\text\\\\{Cov\\\\}(&quot;, lines, perl=TRUE) lines &lt;- gsub(&quot;(\\\\\\\\S)(\\\\d)&quot;, &quot;§\\\\2&quot;, lines, perl=TRUE) lines &lt;- gsub(&quot;(\\\\\\\\S) &quot;, &quot;§ &quot;, lines, perl=TRUE) lines &lt;- gsub(&quot;(\\\\\\\\defeq)&quot;, &quot;\\\\\\\\stackrel{\\\\\\\\triangle}{=}&quot;, lines, perl=TRUE) lines &lt;- gsub(&quot;\\\\\\\\argmin_&quot;, &quot;\\\\\\\\mathop{\\\\\\\\text{argmin}}_&quot;, lines, perl=TRUE) lines &lt;- gsub(&quot;^\\\\s*\\\\\\\\item&quot;, &quot;*&quot;, lines, perl=TRUE) lines &lt;- gsub(&quot;\\\\\\\\begin[{]frame[}]&quot;, &quot;&quot;, lines, perl=TRUE) lines &lt;- gsub(&quot;\\\\\\\\end[{]frame[}]&quot;, &quot;&quot;, lines, perl=TRUE) lines &lt;- gsub(&quot;\\\\\\\\begin[{]itemize[}]\\\\[&lt;\\\\+-&gt;\\\\]&quot;, &quot;&quot;, lines, perl=TRUE) lines &lt;- gsub(&quot;\\\\\\\\end[{]itemize[}]&quot;, &quot;&quot;, lines, perl=TRUE) lines &lt;- gsub(&quot;\\\\\\\\begin[{]itemize[}]&quot;, &quot;&quot;, lines, perl=TRUE) lines &lt;- gsub(&quot;\\\\\\\\bm &quot;, &quot;\\\\\\\\boldsymbol &quot;, lines, perl=TRUE) lines &lt;- gsub(&quot;\\\\\\\\bm\\\\\\\\&quot;, &quot;\\\\\\\\boldsymbol\\\\\\\\&quot;, lines, perl=TRUE) lines &lt;- gsub(&quot;\\\\\\\\tr[(]&quot;, &quot;\\\\\\\\text{tr}(&quot;, lines, perl=TRUE) lines &lt;- gsub(&quot;\\\\begin{align*}&quot;, &quot;$$\\\\begin{aligned}&quot;, lines, fixed=TRUE) lines &lt;- gsub(&quot;\\\\end{align*}&quot;, &quot;\\\\end{aligned}$$&quot;, lines, fixed=TRUE) print(head(lines, 20)) ##writeLines(lines, &quot;_tmp/fromtex-clean.Rmd&quot;) con1 &lt;- file(&quot;_tmp/fromtex-clean.Rmd&quot;, &quot;wt&quot;, encoding=&quot;UTF-8&quot;) writeLines(lines, con=con1) close(con1) } Rmd格式对算法编排的支持不够好。 编排算法可以用表格来换行， 仍用\\qquad和\\qquad缩进， 不要用空格缩进，因为在LaTeX转PDF时空格会损失。 但是算法内容中有公式含有竖线时还是无法与表格线区分开来。 编排算法也可以用数学公式， 写在$$界定范围内， 用aligned环境分行， 缩进使用\\quad和\\qquad。 只是无法对if这样的关键字用重体排印。 为了能够生成中文的PDF，不要指定doclass为ctexbook， 而是指定为book，然后在preamble.tex中引入ctex包。 为了PDF输出，不要引入太多的数学包， 因为从markdown到HTML不支持复杂的数学。 用R作图时如果图形中有汉字， 在代码块选项中加上dev=\"png\", dpi=300。 否则生成PDF时会有中文编码问题。 另一办法是在每个.Rmd文件开头的setup源代码段插入 pdf.options(family=&quot;GB1&quot;) 这样可以生成支持中文字的PDF图形。 在编译出错时，会在主目录留下编译的tex源文件及相关文件。 但是，此tex源文件中使用的R生成的图片路径不对， 需要将tex源文件复制到bookdown_files目录， 将直接插入的图片也复制到这个目录， 然后编译tex文件发现问题，逐个修复。 建议建立小的测试项目专门调试有问题的文件。 连分数的加号是\\genfrac{}{}{0pt}{}{}{+}。 23.13 bookdown的一些使用问题 在数学公式中用\\text{\\@ref(eq:label)}引用公式，HTML成功， LaTeX版本会有BUG，重复了\\。 如果使用文内的链接，则LaTeX成功， HTML不成功。 YAML部分有的中文文字（如作者名）会出错， 代以ASCII则不出错。 2020-06-05发现此问题已消失。 example的自动编号有问题，不加label的example， 其HTML结果在不同章之间会编号混淆， 避免问题的临时办法是example都加上label。 用本地文件格式提供的下载文件不能用中文文件名。 # 参考文献 {-}这种在一本书末尾生成参考文献列表的办法， 可能造成“file name too long”错误。 2020-06-05发现此问题已消失。 BUG: 编译时出现“file name too long”错误，可能原因： 章节名称必须有英文、数字、减号的标签。 用行尾标记{-}的方法取消章节进入目录时，中文标题会出错，改用英文标题。# (PART) 部分名 {-}也是如此，需要用英文名。 2020-06-05发现此问题已消失。 "],["rmdsite.html", "24 用R Markdown制作简易网站 24.1 介绍 24.2 简易网站制作 24.3 用blogdown制作网站", " 24 用R Markdown制作简易网站 24.1 介绍 为了从多个.Rmd源文件制作网站， 可以使用blogdown扩展包或者bookdown扩展包。 bookdown扩展包可以生成gitbook格式的网站， 带有左侧的章节目录和前后页面的导航链接， 很适用于一本书的网站。 但是， bookdown使用时需要重新编译整个网站才能产生正确的链接。 也可以仅利用rmarkdown包的render.site()功能制作简易的网站。 24.2 简易网站制作 一种简易的制作网站的办法是仅仅利用rmarkdown包的render.site()功能。 为了使得rmarkdown和RStudio将一个子目录（项目）看成一个网站项目， 只要此项目中含有index.Rmd和_site.yml文件。 所有网页.Rmd源文件都必须在项目的顶级目录中。 只要将编译所得的网站目录上传到任意的网站服务器就可以发布到网上。 24.2.1 网站结构 index.Rmd是主页内容， 可以在此处人工加入其它页面链接（参见markdown格式说明中链接写法）， 也可以制作单独的目录页面。 内容如 --- title: &quot;概率论&quot; --- * [概率分布](dist.html) * [期望](expect.html) _site.yml是一个YAML文件， 其中包含站点的设定和输出设定。 内容如 name: &quot;概率论&quot; output_dir: &quot;_probbook&quot; output: html_document: toc: true mathjax: &quot;../../../MathJax/MathJax.js&quot; self_contained: false includes: in_header: &quot;_header.html&quot; navbar: title: &quot;概率论&quot; left: - text: &quot;Home&quot; href: index.html - text: &quot;About&quot; href: about.html 这里name设置站点名称， output_dir给出生成的html及其他辅助文件的存放目录，缺省时用_site子目录。 navbar域设置了网站的菜单，这里包括Home(主页), Contents(目录), About(关于)三个页面的导航菜单。 output域设定输出的选项， 其中html_document就是用rmarkdown::render_site()生成的网站的输出文件格式， 其中toc: true说明每个页面都有自身内容的目录, 关于mathjax, self_contained, includes都与数学公式设置有关， 这里设置数学公式使用与本网站在同一目录系统或同一网站地址存放的MathJax数学公式显示库， 该库放在生成的HTML文件所在目录向上两层的MathJax子目录中。 in_header指定一个要插入到生成的每个HTML的head部分的内容文件， 这里内容文件_header.html的内容是 &lt;script type=&quot;text/x-mathjax-config&quot;&gt; MathJax.Hub.Config({ jax: [&quot;input/TeX&quot;,&quot;output/SVG&quot;], extensions: [&quot;tex2jax.js&quot;,&quot;MathMenu.js&quot;,&quot;MathZoom.js&quot;], TeX: { extensions: [&quot;AMSmath.js&quot;,&quot;AMSsymbols.js&quot;,&quot;noErrors.js&quot;,&quot;noUndefined.js&quot;] } }); &lt;/script&gt; 是对MathJax的一些设置，主要使用LaTeX作为输入格式。 24.2.2 编译 具有index.Rmd和_site.yml文件的项目， 在RStudio软件中会显示一个Build窗格， 点击其中的Build Website可以自动调用rmarkdown::render_site()生成整个站点， 存放在output_dir指定的输出目录中，默认目录名为_site。 为了将生成的站点发布到网站， 只要将输出目录的所有内容全部复制到服务器的某个子目录中就可以了。 rmarkdown::render_site()生成整个站点时会自动逐个编译.Rmd文件， 并将项目目录中其它的文件和子目录复制到输出目录中， 以句点或者下划线开头的文件和子目录不复制， .R, .r, .Rmd文件不复制。 因为是自动依次编译所有的.Rmd文件， 所以中间某个源文件编译错误就会使得整个编译失败， 修正错误后还是需要再次编译所有文件， 这一点不太方便。 但是，rmarkdown::render_site()提供了这样一种操作模式： 将有错的文件先移动到其它目录中， 编译整个站点，这时生成的站点仅包含确认无误的各个页面； 然后， 再将可能有错的文件移动回到项目目录， 逐个地打开每个未成功编译的文件， 用Knit按钮单独编译， 编译成功后结果文件也自动进入输出目录。 RStudio的Knit按钮或者rmarkdown::render_site()命令可以人工控制一个一个地编译.Rmd文件， 编译成功一个就存放到输出目录中一个， 这是用rmarkdown::render_site()制作网站比用bookdown扩展包制作网站的一个优点。 因为网站的目录是自己编写的链接， 所以这样逐个编译不会破坏网站的链接。 编译单个文件的命令如 rmarkdown::render_site(&quot;sec1.Rmd&quot;, output_format = &quot;html_document&quot;, encoding=&quot;UTF-8&quot;) 其中sec1.Rmd是某个网页内容源文件。 可以用rmarkdown::clean_site()删除生成的文件， 包括程序结果缓存。 如果用bookdown包， 只有编译所有文件才能生成正确的网站目录， bookdown也能编译单个文件， 但是仅能作为调试， 调试成功后还是需要编译所有文件才能使得网站目录正确。 bookdown站点的优势在于自动生成网站目录而不需要人工管理目录， 而且bookdown支持图书的公式、定理、图标自动编号和链接， 文献列表和文献引用， 所以bookdown是比rmarkdown::render_site()编译调试速度比较慢但是功能更强大的一种制作网站的工具， 而且还可以生成PDF版图书。 所以，一本书如果不需要很多的公式自动编号、图表编号、文献， 在编写阶段可以使用rmarkdown::render_site()制作， 定稿后再改成bookdown图书格式， 实际上每个源文件内容部分不需要改变， 只需要修改一下头部就可以了。 站点的设置需要将_site.yml中的site域的值改为bookdown::bookdown_site， 并增加_bookdown.yml和_output.yml两个设置文件。 详见23。 24.2.3 内容文件 内容文件只要用普通的Rmd文件即可，如某一网页的源文件如 --- title: &quot;期望&quot; --- 随机变量**数学期望**可以看成是对随机变量取值的加权平均， 某个值的取值概率越大，加权越大。 对离散随机变量， 期望是加权和； 对连续型随机变量， 期望是用密度函数加权对`x`积分。 24.2.4 网站设置 在_site.yml文件中进行网站设置， 样例见24.2.1。 顶级设置有： name: 网站名称； output_dir: 保存编译结果的子目录名，默认为_site， 如果设置为.，则表示编译结果放在项目的顶级目录中而不是子目录中； includes: 指定输出的网站中要包含的文件， 输出时默认不包含.R，.r, .Rmd，.RData, .rds文件和文件名以小数点或者下划线开头的文件， 所以例外要写在这里， 如includes: [\"data1.R\", \"data2.R\"]; excludes: 指定项目中不希望输出的结果网站的文件， 可以有通配符，如 excludes: [\"backup.txt\", \"*.xlsx\"]; output: 其中的html_document属性的设置是所有Rmd网页源文件的共同设置， 参见22.11.3， 每一个Rmd文件本身也可以有自己的属性设置； navbar: 用来设置导航菜单，属性left指定主菜单栏， 根据所用的网站主题，可能显示在左侧或者顶部。 属性right指定一个右侧导航栏。 includes和excludes设置主要是为了改变默认的文件发布规则， 所有的.Rmd文件只要不是文件名以下划线开头就都会被编译并且复制到结果子目录中。 24.3 用blogdown制作网站 R扩展包blogdown可以与Hugo软件配合制作简单的静态网站。 网站的所有文件都存在于一个目录中， 只要上传到任意的网站服务器就可以发布， 没有任何限制。 网站内容用R Markdown格式编写， 在R或者RStudio中编译为网站。 这样的做法使得网站内容容易再现， 而且也可以将内容转换为PDF、Word等格式。 blogdown包的R Markdown格式支持bookdown包的扩充， 如公式、图表编号与引用。 blogdown包的名称虽然包含了blog， 但是其建站并不限于博客类型， 任何类型的静态网站都可以构建， 比较适合的是个人网站。 参考： (Yihui Xie 2017) (Xie, Allaire, and Grolemund 2019) 24.3.1 生成新网站的框架 在RStudio中， 菜单“File – New Project – blogdown site”可以生成一个网站框架， 注意一定要新建目录而不是用已有目录， 而且第一次新建网站时还会自动下载Hugo静态网站生成程序。 生成的网站框架包括如下文件与子目录： index.Rmd：主页面的源文件。 config.toml: 网站设置文件。 ./content/: 存放作为网站内容的md或者Rmd文件。可以在下面再建立子目录。 ./content/post/用来保存博客类型的网页，但是不做要求。 ./resources: ./static: 保存图片、CSS等文件，在发布网站时会被复制到./public子目录中。 ./themes: 存放多个网站主题。 ./public: 发布网站时所用到的所有文件。 生成的内容被复制到这个目录中。 只要将这个目录的内容全部复制到任何一个支持静态内容的网站服务器， 就可以发布网站。 这样建站， 建成的网站应该在RStudio的Viewer窗格自动显示， 如果没有自动显示网站或者再次打开网站项目， 点击图标栏的Addins -- Serve site可以启动网站服务器发布该网站。 或者用用命令 blogdown::serve_site() 启动网站服务器。 每次在RStudio或者R中打开一个网站项目， 都只需要启动一次服务器。 blogdown的服务器会在后台运行， 侦测到文件修改时会自动重建， 这称为在线重建(Live Reload)。 在线重建功能基于R扩展包servr。 所以用户只要发布新的消息或者修改已有消息， 不用关心后台的转换问题。 blogdown提供了一些RStudio的addin程序， 可以为网站功能提供方便， 比如New Post可以生成新消息， Update Metadata可以修改消息的YAML元数据， Insert Image可以在消息中插入图片。 使用在线重建功能时， 应关闭一些其他功能。 在RStudio的“Tools – Project Options – Build Tools”对话框中， 取消选定“Preview site after building”和“Re-knit current preview when supporting files change”。 如果不使用在线重建功能， 即不使用Serve site， 可以在RStudio的Build窗格中用“Build Book”功能手工控制网站的重建。 24.3.2 网页内容文件及其设置 网页内容文件可以用Rmd文件也可以用md文件， 但是Rmd文件使用Pandoc和bookdown包支持的文件格式， 功能更强， 比如支持LaTeX数学公式， 公式、图表自动标号与交叉索引，等等， 所以最好是用Rmd文件。 如果有某个Rmd源文件暂时不想编译输出， 可以将其扩展名临时改为一个不被编译的扩展名如.txt。 blogdown编译结果的网页是HTML格式， 其Rmd元数据输出类型为blogdown::html_page， 此类型基于bookdown::html_document2， 又基于rmarkdown::html_document。 这样，可以在Rmd源文件的元数据部分对该输出类型设置相应的属性， 如toc: true等。 例子： --- title: &quot;一个试验网页&quot; author: &quot;李东风&quot; date: &quot;2019-07-08&quot; output: blogdown::html_page: toc: true fig_width: 6 dev: svg --- 为了给所有输出设置统一的属性， 可以在项目目录中添加_output.yml文件， 在其中设置输出文件的各种属性，如： blogdown::html_page: toc: true fig_width: 6 dev: svg 24.3.3 初学者的工作流程 Hugo建站程序比较复杂， 如果要挑选自己喜爱的网站主题(theme)， 移植网站也比较麻烦。 对于了解网站技术不多的建站者， 建议用如下的流程建立新站： 在https://themes.gohugo.io/仔细地挑选一个合适的网站主题(theme)； 在RStudio中通过生成一个在已有目录的新项目； 在新项目的控制台中提交命令blogdown::new_site(theme = 'user/repo')， 其中user/repo是前面所选的主题的用户名与资源(repository)名； 试验新网站看是否满意。 如果不满意可以重复以上步骤， 如果满意， 就可以修改config.toml中的设置。 如果某个选项不明白， 可以在该主题的文档中查找， 通常是资源的README文件。 只需要修改必须需改的选项。 为修改已有网站内容， 用如下的步骤： 点击RStudio的addin “Serve Site”， 可以在修改过程中动态地构建网站。 每次打开RStudio的网站项目仅需执行一次这个命令。 用“New Post” addin添加新的网页。 在修改某个网页时，用“Update Metadata” addin修改网页元数据， 主要是网页标签等。 为了发布网站， 只要将项目内的public目录上传到任一支持静态内容的网站服务器。 如果没有合适的服务提供商， 可以考虑https://www.netlify.com/， 可以用Github账户登录并有一定的免费建站服务。 如果熟悉Github， 还可以将自己的网站源文件作为一个Github 资源(repository)， 将Github资源发布到Netlify， 就不需将public的内容上传到网站， 而只要有源文件就可以了， Netlify支持Hugo。 24.3.4 网站设置文件 在项目根目录中有一个config.toml文件， 是Hugo软件的建站设置文件， 可以设置网站标题、描述、菜单等。 一个例子如下： baseurl = &quot;/&quot; languageCode = &quot;en-us&quot; title = &quot;试验Blogdown网站&quot; theme = &quot;hugo-lithium&quot; googleAnalytics = &quot;&quot; disqusShortname = &quot;&quot; ignoreFiles = [&quot;\\\\.Rmd$&quot;, &quot;\\\\.Rmarkdown$&quot;, &quot;_files$&quot;, &quot;_cache$&quot;] [permalinks] post = &quot;/:year/:month/:day/:slug/&quot; [[menu.main]] name = &quot;About&quot; url = &quot;/about/&quot; [[menu.main]] name = &quot;Li Dongfeng Homepage&quot; url = &quot;http://www.math.pku.edu.cn/teachers/lidf/&quot; [params] description = &quot;用Hugo和blogdown制作的网站&quot; # options for highlight.js (version, additional languages, and theme) highlightjsVersion = &quot;9.12.0&quot; highlightjsCDN = &quot;//cdnjs.cloudflare.com/ajax/libs&quot; highlightjsLang = [&quot;r&quot;, &quot;yaml&quot;] highlightjsTheme = &quot;github&quot; MathJaxCDN = &quot;//cdnjs.cloudflare.com/ajax/libs&quot; MathJaxVersion = &quot;2.7.5&quot; # path to the favicon, under &quot;static&quot; favicon = &quot;favicon.ico&quot; [params.logo] url = &quot;logo.png&quot; width = 50 height = 50 alt = &quot;Logo&quot; 在设置文件中， 字符串要写成用双撇号界定的形式， 布尔值要写成没有双撇号的true或者false。 用方括号包围的项（如[permalinks]）会定义一个列表类型的变量， 下面缩进后的内容是列表的元素。 用双方括号包围的项是列表数组， 即每一项都是列表， 但是合并在一起由组成一个元素为列表的数组。 如上面[[menu.main]]有若干项， 每一项是一个主菜单项， 其设置是一个列表。 主菜单位置、配色等在其它地方设置， 主设置文件中仅设置其文字和对应链接。 不同的网站主题需要不同的config.toml文件。 下面给出一些选项的解释。 baseURL：这是你的网页发布到网站上时， 该网站给你的主页面的地址。 一般是需要设置为自己发布以后的divide。 languageCode: 中文是zh-cn，英文是en-us， 可能会影响一些排版规则， 但是编码都是UTF-8。 permalinks: Hugo和blogdown在发布HTML与图片等内容时需要不变的链接， 默认是content中的每个Rmd文件变成public或public/post下的同名子目录中的index.html文件。可以用permalinks指定命名规则。 slug是网页元数据可以设置的一项类似于文章标识符的东西， 不设置则使用文章标题。 publishDir: 生成的网站存放的文件，默认为public目录。 theme：在themes/目录中保存所选主题的目录的名字。 ignoreFiles: 项目中那些文件不被复制到生成结果网站中。 hasCJKLanguage: 如果有大量中文、日文、韩文内容， 设置为true可以在网页统计和单词书统计时更准确。 [params]: 主题特有的设置放在这里。 24.3.5 静态文件 项目中在./static/下的文件称为静态文件， 可以保存自己的图片、Javascript库等， 发布时自动复制到./public/中。 比如， 文件.static/figs/mypic01.png， 在Rmd文件中可以用![](figs/mypic01.png)引用。 每个主题中一般也有一个static目录， 自己的static目录中的同名文件在发布时可以覆盖主题中的同名文件， 这样可以修改主题的一些资源或者设置。 从Rmd编译生成的文件也可能会被static中的同名文件覆盖。 还可以将网页编译为PDF等格式存放在static目录中。 rmarkdown::build_dir()命令可以将目录中所有Rmd文件按照其元数据的输出格式编译输出。 References "],["slides.html", "25 制作幻灯片 25.1 介绍 25.2 Slidy幻灯片 25.3 MS PowerPoint幻灯片 25.4 Bearmer幻灯片格式 25.5 R Presentation格式", " 25 制作幻灯片 25.1 介绍 R Markdown文件(.Rmd)文件支持多种输出， 如网页(html_document)、MS Word(word_document)、PDF(pdf_document, 需要LaTeX编译器支持)等， 还支持生成网页格式的幻灯片(slidy_presentation, ioslides_presentation)， 以及LaTeX beamer格式的PDF幻灯片(beamer_presentation)， 和Microsoft Office的PowerPoint幻灯片格式。 25.2 Slidy幻灯片 Rmd文件选用输出格式slidy_presentation可以生成网页格式的幻灯片， 并具有缩放字体大小、显示幻灯片目录等功能。 只要在.Rmd文件开头的YAML元数据部分指定output: slidy_presentation。 因为幻灯片的单位是帧(frame)， 与论文的结构有很大区别， 所以幻灯片Rmd文件很难同时作为论文的源文件。 25.2.1 文件格式 幻灯片分为多个帧，每帧用二级标题作为标志并以其为标题。 二级标题就是行首以两个井号和空格开始的行， 或者在标题下面画由减号组成的线的行。 用一级标题作为单独的分节帧， 将单独显示在一帧中。 一级标题是行首以一个井号和空格开始的行， 或者在标题下面画由等于号组成的线的行。 帧也可以没有标题，比如仅有照片的帧， 这时， 用三个或三个以上的减号连在一起标识新帧的开始。 一个简单的slidy_presentation幻灯片源文件example-slidy.Rmd， 内容如： --- title: &quot;R幻灯片演示样例&quot; author: &quot;李东风&quot; date: &quot;2017-11-16&quot; output: slidy_presentation --- # 用R Markdown的slidy输出作幻灯片 ## 幻灯片结构 - 用二级标题标志一个页面开始 - 用一级标题制作单独的分节页面 - 用三个或三个以上减号标志没有标题的页面开始 - 每个页面一般用markdown列表显示若干个项目 ## 幻灯片编译 - 用RStudio编辑 - 用RStudio的Knit按钮，选`slidy_presentation`作为输出格式 ----- [一个演示画面](figs/demoscreen.png) 25.2.2 幻灯片编译 幻灯片用RStudio的knit按钮编译， 选择输出格式为slidy_presentation， 结果在浏览器中播放， 最好使用外部浏览器而不使用RStudio自带的浏览器， 自带的浏览器在显示数学公式时对网络环境条件有要求而且不能完美地支持关于数学公式的本地设置。 除了使用knit按钮，还可以用类似如下命令： rmarkdown::render(&quot;mydemo.Rmd&quot;, output_format = &quot;slidy_presentation&quot;, encoding=&quot;UTF-8&quot;) 其中mydemo.Rmd是源文件。 为了制作幻灯片，最好单独设置一个RStudio项目， 并且此项目仅生成幻灯片， 而不生成普通网页、Word、PDF等输出， 否则可能造成结果混乱。 希望rmarkdown包的后续版本能取消这个限制。 25.2.3 播放控制 播放时，用如下方式控制： 鼠标左键单击、光标右移键、向下翻页键、空格键都可以翻到下一页； 光标左移键、向上翻页键回退一页； 单击下方的Contents或单击C键显示幻灯片目录列表，可单击转移到任意页面； Home键回到幻灯片开头； 用A键切换是否将所有页面合并显示成一个长的网页； 用S键缩写字体，用B键放大字体； 通过选择保存为PDF的打印机进行打印， 可以将幻灯片转换为PDF， 但是打印生成的PDF仍是每页仅有原来的一帧， 所以转换成一个单页的HTML再打印可能更合适。 25.2.4 生成单页HTML 对slidy幻灯片的Rmd源文件不加修改， 也可以通过命令直接转换为普通的单页HTML文件， 但是因为在slidy幻灯片源文件中二级标题用来分帧， 而普通Rmd文件中二级标题用来分小节， 所以生成的单页HTML文件会有许多小节。 这样的文件更适合打印以及转换为PDF文件。 命令如： rmarkdown::render(&quot;mydemo.Rmd&quot;, output_file=&quot;handout.html&quot;, output_format=&quot;html_document&quot;, encoding=&quot;UTF-8&quot;) 25.2.5 数学公式处理与输出设置文件 讲课用的幻灯片经常会有数学公式， 比较关键的问题是数学公式如何处理。 网页中的数学公式一般使用一个公开的自由Javascript库MathJax显示， 但是这个库很大， 如果使用远程的库， 在网络不畅通时显示公式就不正常。 更好的办法是使用局部的MathJax库或将MathJax库安装在临近的网站服务器上。 为了使用局部的MathJax库， 简单的办法是在YAML的ioslides_presentation项目下面指定mathjax: local， 如： --- title: &quot;R幻灯片演示样例&quot; output: slidy_presentation: mathjax: local --- 上述办法容易使用， 缺点是多个不同的演示项目无法共用一个局部的MathJax库， 生成的结果包含了许多小的支持文件。 为此， 可以将MathJax库装在演示项目所在目录的上层（比如上两层的MathJax目录内）， 将设置MathJax的代码放在_header.html文件中， _header.html中的内容如： &lt;script type=&quot;text/x-mathjax-config&quot;&gt; MathJax.Hub.Config({ jax: [&quot;input/TeX&quot;,&quot;output/SVG&quot;], extensions: [&quot;tex2jax.js&quot;,&quot;MathMenu.js&quot;,&quot;MathZoom.js&quot;], TeX: { extensions: [&quot;AMSmath.js&quot;,&quot;AMSsymbols.js&quot;,&quot;noErrors.js&quot;,&quot;noUndefined.js&quot;] } }); &lt;/script&gt; 在演示项目所在目录中增加一个_output.yml文件， 这使得该项目所有输出的共用的输出设置，内容如： slidy_presentation: toc: false mathjax: &quot;../../MathJax/MathJax.js&quot; self_contained: false includes: in_header: &quot;_header.html&quot; html_document: toc: true number_sections: false mathjax: &quot;../../MathJax/MathJax.js&quot; self_contained: false includes: in_header: &quot;_header.html&quot; 这里关闭了self_contained选项， 设置了MathJax库在本地目录，具体是演示项目所在目录上面两层的MathJax目录中。 公式中如果有中文， 开始时可能显示不正常， 这时右键点击公式弹出菜单选择“Math Settings–Math Renderer”， 取为“HTML-CSS”或“SVG”应可解决问题。 上面的输出设置文件中也设置了输出html_document， 这是单页的HTML格式， 取消了自动章节编号， 因为源文件中每帧都是一个小节。 25.2.6 其它选项 用slidy_presentation的font_adjustment: -1可以缩小字体一号， 类似可以设为+1，-2等。 在播放时也可以用S和B键缩小或放大显示。 可以在播放时在浏览器状态栏显示倒数计时器， 用slidy_presentation的duration: 5表示每帧显示5分钟。 这是总的预计时间， 适用于演讲有时间限制的情况。 可以用footer属性指定每帧都显示的状态栏脚注，如： --- output: slidy_presentation: font_adjustment: -1 duration: 5 footer: &quot;北京大学&quot; --- slidy_presentation输出属性incremental: true可以使得列表显示需要每点击一次才显示下一项。 25.2.7 slidy幻灯片激光笔失效问题的修改 slidy幻灯片翻页是用空格、左右光标、上下翻页键， 而一般激光笔翻页是模拟上下光标键。 为此， 在安装的R软件目录的 library/rmarkdown/rmd/slidy/Slidy2/scripts子目录中， 找到slidy.js文件， 用编辑器打开， 用编辑器的搜索功能搜索key == 37， 将其替换成key == 37 || key == 38， 这里37是向左光标的编码， 替换后就是向左或者向上光标。 用编辑器的搜索功能搜索key == 39, 将其替换成key == 39 || key == 40， 这里39是向右光标的编码， 替换后就是向右或者向上光标。 修改完毕后保存， 然后将slidy.js用文件压缩程序（如7zip）压缩为slidy.js.gz。 这样就可以在用rmarkdown制作的slidy_presentation结果中支持激光笔翻页了。 这样修改后， 如果某帧超高， 需要滚动显示， 就只能通过鼠标滚轮滚动了。 25.3 MS PowerPoint幻灯片 powerpoint_presentation输出格式可以生成MS PowerPoint文件。 设置如： --- output: powerpoint_presentation: slide_level: 2 --- 可以用powerpoint_presentation的reference_doc属性指向一个.pptx的文件， 作为模板， 模板中的样式将被输出结果采用。 可以用Rstudio的Knit快捷图标实现转换（选其中的knit to PowerPoint）， 或者用如下命令： rmarkdown::render(&quot;slides.Rmd&quot;, output_format=&quot;powerpoint_presentation&quot;, encoding=&quot;UTF-8&quot;) 如果从bookdown内容转化成演示幻灯片， 需要大量修改原始文件内容， 设置成幻灯片常用的逐条播放格式。 如果不希望进行这样的修改， 可以直接在MS PowerPoint软件中直接输入或者复制粘贴已经编译好的网页格式输出的内容。 这样复制粘贴有一个缺点， 就是基于MathJax显示在网页中的公式， 无法通过复制粘贴转换到PowerPoint中。 一种办法是用rmarkdown将需要转换的带有公式的Rmd文件编译为Word格式或者PowerPoint格式， 再复制进入PowerPoint软件的新页面中。 编译为Word格式的命令如： rmarkdown::render(&quot;slides.Rmd&quot;, output_format=&quot;word_document&quot;, encoding=&quot;UTF-8&quot;) 25.4 Bearmer幻灯片格式 上述Slidy格式的幻灯片， 也可以通过LaTeX编译器转换成LaTeX beamer格式的幻灯片， 设置如： --- output: beamer_presentation: latex_engine: xelatex slide_level: 2 theme: CambridgeUS colortheme: dolphin includes: in_heaer: &quot;preamble.tex&quot; --- 其中slide_level用来规定几级标题开始新的一帧。 theme指定一种主题， colortheme指定一种配色方案， in_header在LaTeX导言部分插入preamble.tex， 内容见22.12。 编译命令如： rmarkdown::render(&quot;mydemo.Rmd&quot;, output_format = &quot;beamer_presentation&quot;, encoding=&quot;UTF-8&quot;) 结果是一个PDF文件。 截止到2019年7月时，编译不成功。 原因在于Rmd到Beamer幻灯片的转换是预期使用pdflatex引擎的， 而中文更适合用xelatex引擎， 但目前的rmarkdown包中beamer幻灯片功能对xelatex引擎支持不足。 如果是纯英文内容的幻灯片， 可以在上面的设置中去掉关于latex_engine的设置并在preamble.tex中去掉与中文有关的内容，则可以编译成功。 25.5 R Presentation格式 R Studio软件单独提供了对一种R Presentation格式的源文件的支持， 以.Rpres扩展名结尾， 是一种特殊的R Markdown文件， 与slidy的源文件也类似。 Rpres文件编译为HTML格式的幻灯片， 使用reveal.js控制显示。 reveal.js中也有对激光笔支持不好的问题， 这是因为reveal.js中用向右光标键翻页， 对向下光标另有定义， 激光笔一般是模拟向下和向上光标键来翻页的。 为了支持激光笔， 找到RStudio的安装目录， 在resources/presentation/revealjs/js中找到reveal.js文件， 在文件编辑器中打开， 通过搜索找到case 38:, 将其剪切到case 33:后面， 变成case 33: case 38:。 找到case 40:, 将其剪切到case 34:后面， 变成case 34: case 40:。 同一目录还有一个reveal.min.js文件， 也进行上述修改。 "],["summary-manip.html", "26 数据整理 26.1 tidyverse系统 26.2 用filter()选择行子集 26.3 按行序号选择行子集 26.4 用sample_n()对观测随机抽样 26.5 用distinct()去除重复行 26.6 用drop_na()去除指定的变量有缺失值的行 26.7 用select()选择列子集 26.8 取出单个变量为向量 26.9 用arrange()排序 26.10 用rename()修改变量名 26.11 用mutate()计算新变量 26.12 用tranmute()生成新变量的数据框 26.13 用管道连接多次操作 26.14 宽表转换为长表 26.15 长表转换为宽表 26.16 拆分数据列 26.17 合并数据列 26.18 数据框纵向合并 26.19 横向合并 26.20 利用第二个数据集筛选 26.21 数据集的集合操作 26.22 标准化", " 26 数据整理 26.1 tidyverse系统 假设数据以tibble格式保存。 数据集如果用于统计与绘图， 需要满足一定的格式要求， (Wickham 2014)称之为整洁数据(tidy data)， 基本要求是每行一个观测， 每列一个变量， 每个单元格恰好有一个数据值。 这些变量应该是真正的属性， 而不是同一属性在不同年、月等时间的值分别放到单独的列。 数据集经常需要选行子集、选列子集、排序、定义新变量、横向合并、长宽转换等操作， 而且经常会用若干个连续的操作分步处理， magrittr包的管道运算符%&gt;%特别适用于这种分步处理。 dplyr包和tidyr包定义了一系列“动词”， 可以用比较自然的方式进行数据整理。 较复杂的分组操作还可以利用purrr包的map类函数。 为了使用这些功能，可以载入tidyverse包， 则magrittr包，readr包，dplyr包和tidyr包都会被自动载入: library(tidyverse) 下面的例子中用如下的一个班的学生数据作为例子， 保存在如下class.csv文件中： name,sex,age,height,weight Alice,F,13,56.5,84 Becka,F,13,65.3,98 Gail,F,14,64.3,90 Karen,F,12,56.3,77 Kathy,F,12,59.8,84.5 Mary,F,15,66.5,112 Sandy,F,11,51.3,50.5 Sharon,F,15,62.5,112.5 Tammy,F,14,62.8,102.5 Alfred,M,14,69,112.5 Duke,M,14,63.5,102.5 Guido,M,15,67,133 James,M,12,57.3,83 Jeffrey,M,13,62.5,84 John,M,12,59,99.5 Philip,M,16,72,150 Robert,M,12,64.8,128 Thomas,M,11,57.5,85 William,M,15,66.5,112 读入为tibble: d.class &lt;- read_csv( &quot;class.csv&quot;, col_types=cols( .default = col_double(), name=col_character(), sex=col_factor(levels=c(&quot;M&quot;, &quot;F&quot;)) )) 这个数据框有19个观测， 有如下5个变量： name sex age height weight R的NHANES扩展包提供了一个规模更大的示例数据框NHANES， 可以看作是美国扣除住院病人以外的人群的一个随机样本， 有10000个观测，有76个变量， 主题是个人的健康与营养方面的信息。 仅作为教学使用而不足以作为严谨的科研用数据。 原始数据的情况详见http://www.cdc.gov/nchs/nhanes.htm。 载入NHANES数据框： library(NHANES) data(NHANES) print(dim(NHANES)) ## [1] 10000 76 print(names(NHANES)) ## [1] &quot;ID&quot; &quot;SurveyYr&quot; &quot;Gender&quot; &quot;Age&quot; ## [5] &quot;AgeDecade&quot; &quot;AgeMonths&quot; &quot;Race1&quot; &quot;Race3&quot; ## [9] &quot;Education&quot; &quot;MaritalStatus&quot; &quot;HHIncome&quot; &quot;HHIncomeMid&quot; ## [13] &quot;Poverty&quot; &quot;HomeRooms&quot; &quot;HomeOwn&quot; &quot;Work&quot; ## [17] &quot;Weight&quot; &quot;Length&quot; &quot;HeadCirc&quot; &quot;Height&quot; ## [21] &quot;BMI&quot; &quot;BMICatUnder20yrs&quot; &quot;BMI_WHO&quot; &quot;Pulse&quot; ## [25] &quot;BPSysAve&quot; &quot;BPDiaAve&quot; &quot;BPSys1&quot; &quot;BPDia1&quot; ## [29] &quot;BPSys2&quot; &quot;BPDia2&quot; &quot;BPSys3&quot; &quot;BPDia3&quot; ## [33] &quot;Testosterone&quot; &quot;DirectChol&quot; &quot;TotChol&quot; &quot;UrineVol1&quot; ## [37] &quot;UrineFlow1&quot; &quot;UrineVol2&quot; &quot;UrineFlow2&quot; &quot;Diabetes&quot; ## [41] &quot;DiabetesAge&quot; &quot;HealthGen&quot; &quot;DaysPhysHlthBad&quot; &quot;DaysMentHlthBad&quot; ## [45] &quot;LittleInterest&quot; &quot;Depressed&quot; &quot;nPregnancies&quot; &quot;nBabies&quot; ## [49] &quot;Age1stBaby&quot; &quot;SleepHrsNight&quot; &quot;SleepTrouble&quot; &quot;PhysActive&quot; ## [53] &quot;PhysActiveDays&quot; &quot;TVHrsDay&quot; &quot;CompHrsDay&quot; &quot;TVHrsDayChild&quot; ## [57] &quot;CompHrsDayChild&quot; &quot;Alcohol12PlusYr&quot; &quot;AlcoholDay&quot; &quot;AlcoholYear&quot; ## [61] &quot;SmokeNow&quot; &quot;Smoke100&quot; &quot;Smoke100n&quot; &quot;SmokeAge&quot; ## [65] &quot;Marijuana&quot; &quot;AgeFirstMarij&quot; &quot;RegularMarij&quot; &quot;AgeRegMarij&quot; ## [69] &quot;HardDrugs&quot; &quot;SexEver&quot; &quot;SexAge&quot; &quot;SexNumPartnLife&quot; ## [73] &quot;SexNumPartYear&quot; &quot;SameSex&quot; &quot;SexOrientation&quot; &quot;PregnantNow&quot; 变量ID是受试者编号， SurveyYr是调查年份， 同一受试者可能在多个调查年份中有数据。 变量中包括性别、年龄、种族、收入等人口学数据， 包括体重、身高、脉搏、血压等基本体检数据， 以及是否糖尿病、是否抑郁、是否怀孕、已生产子女数等更详细的健康数据， 运动习惯、饮酒、性生活等行为方面的数据。 这个教学用数据集最初的使用者是Cashmere高中的Michelle Dalrymple 和新西兰奥克兰大学的Chris Wild。 26.2 用filter()选择行子集 数据框的任何行子集仍为数据框，即使只有一行而且都是数值也是如此。 行子集可以用行下标选取， 如d.class[8:12,]。 函数head()取出数据框的前面若干行， tail()取出数据框的最后若干行。 dplyr包的filter()函数可以按条件选出符合条件的行组成的子集。 下例从d.class中选出年龄在13岁和13岁以下的女生： d.class %&gt;% filter(sex==&quot;F&quot;, age&lt;=13) %&gt;% knitr::kable() name sex age height weight Alice F 13 56.5 84.0 Becka F 13 65.3 98.0 Karen F 12 56.3 77.0 Kathy F 12 59.8 84.5 Sandy F 11 51.3 50.5 filter()函数第一个参数是要选择的数据框， 后续的参数是条件， 这些条件是需要同时满足的， 另外， 条件中取缺失值的观测自动放弃， 这一点与直接在数据框的行下标中用逻辑下标有所不同， 逻辑下标中有缺失值会在结果中产生缺失值。 filter()会自动舍弃行名， 如果需要行名只能将其转换成数据框的一列。 filter()的结果为行子集数据框。 用在管道操作当中的时候第一自变量省略（是管道传递下来的）。 26.3 按行序号选择行子集 基本R的utils包的函数head(x, n)可以用来选择数据框x前面n行， tail(x, n)可以用来选择数据框x后面n行，如： d.class %&gt;% head(n=5) %&gt;% knitr::kable() name sex age height weight Alice F 13 56.5 84.0 Becka F 13 65.3 98.0 Gail F 14 64.3 90.0 Karen F 12 56.3 77.0 Kathy F 12 59.8 84.5 dplyr包的函数slice(.data, ...)可以用来选择指定序号的行子集， 正的序号表示保留，负的序号表示排除。如： d.class %&gt;% slice(3:5) %&gt;% knitr::kable() name sex age height weight Gail F 14 64.3 90.0 Karen F 12 56.3 77.0 Kathy F 12 59.8 84.5 26.4 用sample_n()对观测随机抽样 dplyr包的sample_n(tbl, size)函数可以从数据集tbl中随机无放回抽取size行，如： d.class %&gt;% sample_n(size = 3) %&gt;% knitr::kable() name sex age height weight Alfred M 14 69.0 112.5 Gail F 14 64.3 90.0 Karen F 12 56.3 77.0 sample_n()中加选项replace=TRUE可以变成有放回抽样。 可以用weight选项指定数据框中的一列作为抽样权重， 进行不等概抽样。 26.5 用distinct()去除重复行 有时我们希望得到一个或若干个变量组合的所有不同值。 dplyr包的distinct()函数可以对数据框指定若干变量， 然后筛选出所有不同值， 每组不同值仅保留一行。 指定变量名时不是写成字符串形式而是直接写变量名， 这是dplyr和tidyr包的特点。 例如，筛选出性别与年龄的所有不同组合： d.class %&gt;% distinct(sex, age) %&gt;% knitr::kable() sex age F 13 F 14 F 12 F 15 F 11 M 14 M 15 M 12 M 13 M 16 M 11 如果希望保留数据框中其它变量， 可以加选项.keep_all=TRUE。 下面的程序查看NHANES数据框中ID与SurveyYr的组合的不同值的个数： NHANES %&gt;% distinct(ID, SurveyYr) %&gt;% nrow() ## [1] 6779 这个结果提示有些人在某一调查年中有多个观测。 26.6 用drop_na()去除指定的变量有缺失值的行 在进行统计建模时， 通常需要用到的因变量和自变量都不包含缺失值。 tidyr包的drop_na()函数可以对数据框指定一到多个变量， 删去指定的变量有缺失值的行。 不指定变量时有任何变量缺失的行都会被删去。 例如，将NHANES中所有存在缺失值的行删去后数出保留的行数， 原来有10000行： NHANES %&gt;% drop_na() %&gt;% nrow() ## [1] 0 可见所有行都有缺失值。下面仅剔除AlcoholDay缺失的观测并计数： NHANES %&gt;% drop_na(AlcoholDay) %&gt;% nrow() ## [1] 4914 基本stats包的complete.cases函数返回是否无缺失值的逻辑向量， na.omit函数则返回无缺失值的观测的子集。 26.7 用select()选择列子集 dplyr包的select()选择列子集，并返回列子集结果。 可以指定变量名，如 d.class %&gt;% select(name, age) %&gt;% head(n=3) %&gt;% knitr::kable() name age Alice 13 Becka 13 Gail 14 可以用冒号表示列范围，如 d.class %&gt;% select(age:weight) %&gt;% head(n=3) %&gt;% knitr::kable() age height weight 13 56.5 84 13 65.3 98 14 64.3 90 可以用数字序号表示列范围，如 d.class %&gt;% select(3:5) %&gt;% head(n=3) %&gt;% knitr::kable() age height weight 13 56.5 84 13 65.3 98 14 64.3 90 参数中前面写负号表示扣除，如 d.class %&gt;% select(-name, -age) %&gt;% head(n=3) %&gt;% knitr::kable() sex height weight F 56.5 84 F 65.3 98 F 64.3 90 如果要选择的变量名已经保存为一个字符型向量， 可以用one_of()函数引入，如 vars &lt;- c(&quot;name&quot;, &quot;sex&quot;) d.class %&gt;% select(one_of(vars)) %&gt;% head(n=3) %&gt;% knitr::kable() name sex Alice F Becka F Gail F R的字符串函数（如paste()）和正则表达式函数可以用来生成变量名子集， 然后在select中配合one_of使用。 select()有若干个配套函数可以按名字的模式选择变量列， 如 starts_with(\"se\"): 选择名字以“se”`开头的变量列； ends_with(\"ght\"): 选择名字以“ght”`结尾的变量列； contains(\"no\"): 选择名字中含有子串“no”`的变量列； matches(\"^[[:alpha:]]+[[:digit:]]+$\")， 选择列名匹配某个正则表达式模式的变量列， 这里匹配前一部分是字母，后一部分是数字的变量名，如abc12。 num_range(\"x\", 1:3)，选择x1, x2, x3。 everything(): 代指所有选中的变量， 这可以用来将指定的变量次序提前， 其它变量排在后面。 R函数subset也能对数据框选取列子集和行子集。 26.8 取出单个变量为向量 如果需要选择单个变量并使得结果为普通向量， 可以用dplyr包的pull()函数，如： d.class %&gt;% head(n=3) %&gt;% pull(name) %&gt;% paste(collapse=&quot;:&quot;) ## [1] &quot;Alice:Becka:Gail&quot; pull()可以指定单个变量名， 也可以指定变量序号， 负的变量序号从最后一个变量数起。 缺省变量名和序号时取出最后一个变量。 如果要取出的变量名保存在一个字符型变量varname中， 可以用pull(.data, !!sym(varname))这种格式； 如果varname是函数的自变量， 可以用pull(.data, {{ varname }})这种格式。 或者， 先选择仅有一个变量的子数据框再用pull()，如： varname &lt;- &quot;name&quot; d.class %&gt;% head(n=3) %&gt;% select(one_of(varname)) %&gt;% pull() %&gt;% paste(collapse=&quot;:&quot;) ## [1] &quot;Alice:Becka:Gail&quot; 基于基本R， 也可以用d.class[[\"name\"]]这种格式取出一列为普通变量， 如果varname保存了变量名， 可以用d.class[[varname]]这种格式。 不能用d.class[,\"name\"]这种方法， 对于tibble类型， 其结果仍是一个子数据框； 用d.class[\"name\"]这种格式， 结果也是一个子数据框。 26.9 用arrange()排序 dplyr包的arrange()按照数据框的某一列或某几列排序， 返回排序后的结果，如 d.class %&gt;% arrange(sex, age) %&gt;% knitr::kable() name sex age height weight Thomas M 11 57.5 85.0 James M 12 57.3 83.0 John M 12 59.0 99.5 Robert M 12 64.8 128.0 Jeffrey M 13 62.5 84.0 Alfred M 14 69.0 112.5 Duke M 14 63.5 102.5 Guido M 15 67.0 133.0 William M 15 66.5 112.0 Philip M 16 72.0 150.0 Sandy F 11 51.3 50.5 Karen F 12 56.3 77.0 Kathy F 12 59.8 84.5 Alice F 13 56.5 84.0 Becka F 13 65.3 98.0 Gail F 14 64.3 90.0 Tammy F 14 62.8 102.5 Mary F 15 66.5 112.0 Sharon F 15 62.5 112.5 用desc()包裹想要降序排列的变量，如 d.class %&gt;% arrange(sex, desc(age)) %&gt;% knitr::kable() name sex age height weight Philip M 16 72.0 150.0 Guido M 15 67.0 133.0 William M 15 66.5 112.0 Alfred M 14 69.0 112.5 Duke M 14 63.5 102.5 Jeffrey M 13 62.5 84.0 James M 12 57.3 83.0 John M 12 59.0 99.5 Robert M 12 64.8 128.0 Thomas M 11 57.5 85.0 Mary F 15 66.5 112.0 Sharon F 15 62.5 112.5 Gail F 14 64.3 90.0 Tammy F 14 62.8 102.5 Alice F 13 56.5 84.0 Becka F 13 65.3 98.0 Karen F 12 56.3 77.0 Kathy F 12 59.8 84.5 Sandy F 11 51.3 50.5 排序时不论升序还是降序， 所有的缺失值都自动排到末尾。 R函数order()可以用来给出数据框的排序次序， 然后以其输出为数据框行下标， 可以将数据框排序。 26.10 用rename()修改变量名 在dplyr包的rename()中用“新名字=旧名字”格式修改变量名， 如 d2.class &lt;- d.class %&gt;% dplyr::rename(h=height, w=weight) 注意这样改名字不是对原始数据框修改而是返回改了名字后的新数据框。 rename()这个函数可能出现在其它包中， 保险起见写成dplyr::rename()。 26.11 用mutate()计算新变量 dplyr包的mutate()可以为数据框计算新变量， 返回含有新变量以及原变量的新数据框。 如 d.class %&gt;% mutate( rwh=weight/height, sexc=ifelse(sex==&quot;F&quot;, &quot;女&quot;, &quot;男&quot;)) %&gt;% head(n=3) %&gt;% knitr::kable() name sex age height weight rwh sexc Alice F 13 56.5 84 1.486726 女 Becka F 13 65.3 98 1.500766 女 Gail F 14 64.3 90 1.399689 女 用mutate()计算新变量时如果计算比较复杂， 也可以用多个语句组成复合语句，如： d.class %&gt;% mutate( sexc = { x &lt;- rep(&quot;男&quot;, length(sex)) x[sex == &quot;F&quot;] &lt;- &quot;女&quot; x } ) %&gt;% head(n=3) %&gt;% knitr::kable() name sex age height weight sexc Alice F 13 56.5 84 女 Becka F 13 65.3 98 女 Gail F 14 64.3 90 女 注意这样生成新变量不是在原来的数据框中添加， 原来的数据框没有被修改， 而是返回添加了新变量的新数据框。 R软件的巧妙设计保证了这样虽然是生成了新数据框， 但是与原来数据框重复的列并不会重复保存。 计算公式中可以包含对数据框中变量的统计函数结果，如 d.class %&gt;% mutate( cheight = height - mean(height)) %&gt;% knitr::kable() 新变量可以与老变量名相同， 这样就在输出中修改了老变量。 26.12 用tranmute()生成新变量的数据框 函数transmute()用法与mutate()类似， 但是仅保留新定义的变量， 不保留原来的所有变量。 如： d.class %&gt;% transmute( height_cm = round(height*2.54), weight_kg = round(weight*0.4535924), bmi = weight_kg / (height_cm / 100)^2) %&gt;% head(n=3) %&gt;% knitr::kable() height_cm weight_kg bmi 144 38 18.32562 166 44 15.96748 163 41 15.43152 可见结果中仅保留了新定义的变量。 定义新变量也可以直接为数据框的新变量赋值： d.class[[&quot;rwh&quot;]] &lt;- d.class[[&quot;weight&quot;]] / d.class[[&quot;height&quot;]] 这样的做法与mutate()的区别是这样不会生成新数据框， 新变量是在原数据框中增加的。 给数据框中某个变量赋值为NULL可以修改数据框， 从数据框中删去该变量。 26.13 用管道连接多次操作 管道运算符特别适用于对同一数据集进行多次操作。 例如，对d.class数据，先选出所有女生， 再去掉性别和age变量： d.class %&gt;% filter(sex==&quot;F&quot;) %&gt;% select(-sex, -age) %&gt;% knitr::kable() name height weight rwh Alice 56.5 84.0 1.4867257 Becka 65.3 98.0 1.5007657 Gail 64.3 90.0 1.3996890 Karen 56.3 77.0 1.3676732 Kathy 59.8 84.5 1.4130435 Mary 66.5 112.0 1.6842105 Sandy 51.3 50.5 0.9844055 Sharon 62.5 112.5 1.8000000 Tammy 62.8 102.5 1.6321656 管道操作的结果可以保存为新的tibble，如: class_F &lt;- d.class %&gt;% filter(sex==&quot;F&quot;) %&gt;% select(-sex, -age) 也可以将赋值用-&gt;写在最后，如： d.class %&gt;% filter(sex==&quot;F&quot;) %&gt;% select(-sex, -age) -&gt; class_F 如果管道传递的变量在下一层调用中不是第一自变量， 可以用.代表，如： d.class %&gt;% lm(weight ~ height, data=.) %&gt;% coef() ## (Intercept) height ## -143.02692 3.89903 为了明确表示不使用管道输入作为第一自变量， 可以将管道操作的那一层加上大括号，如： d.class %&gt;% { lm(weight ~ height, data=.) } %&gt;% coef() ## (Intercept) height ## -143.02692 3.89903 26.14 宽表转换为长表 26.14.1 pivot_longer函数 tidyr的pivot_longer()函数可以将横向的多次观测堆叠在一列中。 例如， 下面的数据： knitr::kable(dwide1) subject 1 2 3 4 1 1 NA NA NA 2 NA 7 NA 4 3 5 10 NA NA 4 NA NA 9 NA subject是受试者编号， 每个受试者有4次随访， NA表示缺失。 数据分析和绘图用的函数一般不能直接使用这样的数据， 一般需要将测量值作为变量名， 将4次测量合并在一列中， 将随访序号单独放在另外一列中。 用pivot_longer()函数实现： dwide1 %&gt;% pivot_longer(`1`:`4`, names_to = &quot;time&quot;, values_to = &quot;response&quot;) %&gt;% knitr::kable() subject time response 1 1 1 1 2 NA 1 3 NA 1 4 NA 2 1 NA 2 2 7 2 3 NA 2 4 4 3 1 5 3 2 10 3 3 NA 3 4 NA 4 1 NA 4 2 NA 4 3 9 4 4 NA 选项names_to指定一个新变量名， 将原来的列标题转换为该变量的值； 选项values_to指定一个新变量名， 将原来的各个列对应的测量值保存在该变量名的列中。 注意原来的变量名不是合法R变量名， 所以在pivot_longer()中用反单撇号保护， 并用了冒号来表示变量范围， 也可以仿照select函数中指定变量名的方法将`1`:`4`写成: c(\"1\", \"2\", \"3\", \"4\") -subject cols = one_of(vars), 其中vars是保存了1到4的字符串的字符型向量。 如果转换结果中不希望保留那些NA， 可以加values_drop_na=TRUE: dwide1 %&gt;% pivot_longer(`1`:`4`, names_to = &quot;time&quot;, values_to = &quot;response&quot;, values_drop_na = TRUE) %&gt;% knitr::kable() subject time response 1 1 1 2 2 7 2 4 4 3 1 5 3 2 10 4 3 9 26.14.2 从列名中提取数值 有时要合并的列名中带有数值， 需要将这些数值部分提取出来， 这时可以用names_prefix指定要去掉的非数值前缀， 用names_transform指定将列名转换为值时， 转换的类型， names_transform是一个列表， 实现列表元素名到转换函数的映射。 例如，上述的dwide1数据框变成这样： subject FU1 FU2 FU3 FU4 1 1 NA NA NA 2 NA 7 NA 4 3 5 10 NA NA 4 NA NA 9 NA 可以用如下程序将随访编号变成整数值存入一列： dwide2 %&gt;% pivot_longer(cols = paste0(&quot;FU&quot;, 1:4), names_to = &quot;time&quot;, values_to = &quot;response&quot;, names_prefix = &quot;FU&quot;, names_transform = list(time = as.integer), values_drop_na = TRUE) %&gt;% knitr::kable() subject time response 1 1 1 2 2 7 2 4 4 3 1 5 3 2 10 4 3 9 其中的cols = paste0(\"FU\", 1:4)也可以写成cols = starts_with(\"FU\")。 26.14.3 从列名中提取多个分类变量值 上面的dwide2数据集的FU1到FU4变量中包含了随访次数这一个变量的值。 有些数据集在列名中用编码形式保存了不止一个变量的信息， 假设那些列保存的数值仍属于同一属性。 例如，下面的数据： unit F_1 F_2 M_1 M_2 1 55 52 64 60 2 98 93 120 116 3 40 38 44 40 假设这是对某个问题的赞成或反对意见的某个抽样调查的频数表， unit是不同的抽样子集， 其它四列都是频数， F_1代表女性中赞成人数， F_2代表女性中反对人数， M_1代表男性中赞成人数， M_2代表男性中反对人数。 为了利用这样的数据， 需要将不同性别和两种意见的人数都合并到一列中， 增加性别和意见列。 对于这种用一定规则将多个变量值编码进入列名的情形， 需要使用正则表达式的方式将有变量值的部分用正则表达式的捕获子集标记出来， 关于正则表达式详见36.3。 程序为： dwide3 %&gt;% pivot_longer( cols = F_1:M_2, names_to = c(&quot;gender&quot;, &quot;response&quot;), values_to = &quot;freq&quot;, names_pattern = &quot;(F|M)_(1|2)&quot;, names_ptypes = list( gender = factor( levels = c(&quot;F&quot;, &quot;M&quot;)), response = factor( levels = c(&quot;1&quot;, &quot;2&quot;)) ) ) %&gt;% knitr::kable() unit gender response freq 1 F 1 55 1 F 2 52 1 M 1 64 1 M 2 60 2 F 1 98 2 F 2 93 2 M 1 120 2 M 2 116 3 F 1 40 3 F 2 38 3 M 1 44 3 M 2 40 在列名的各个部分之间有分隔符如_时， 可以用names_sep选项代替names_pattern选项，如： dwide3 %&gt;% pivot_longer( cols = F_1:M_2, names_to = c(&quot;gender&quot;, &quot;response&quot;), values_to = &quot;freq&quot;, names_sep = &quot;_&quot;, names_ptypes = list( gender = factor( levels = c(&quot;F&quot;, &quot;M&quot;)), response = factor( levels = c(&quot;1&quot;, &quot;2&quot;)) ) ) %&gt;% knitr::kable() unit gender response freq 1 F 1 55 1 F 2 52 1 M 1 64 1 M 2 60 2 F 1 98 2 F 2 93 2 M 1 120 2 M 2 116 3 F 1 40 3 F 2 38 3 M 1 44 3 M 2 40 26.14.4 一行中有多个属性的多次观测的情形 设有多个属性的多次测量用编号的列名保存在了同一观测中， 例如， 基本R软件中的anscombe数据集的一部分行： dwide4 &lt;- anscombe[1:3,] dwide4[[&quot;id&quot;]] &lt;- seq(3) dwide4 &lt;- dwide4 %&gt;% select(id, everything()) knitr::kable(dwide4) id x1 x2 x3 x4 y1 y2 y3 y4 1 10 10 10 8 8.04 9.14 7.46 6.58 2 8 8 8 8 6.95 8.14 6.77 5.76 3 13 13 13 8 7.58 8.74 12.74 7.71 这可以看成是每个受试者的x, y两个变量的4次随访的值保存在了一个观测中。 用names_pattern指定切分变量名和随访号的模式， 在对应的names_to中用特殊的\".value\"名字表示切分出来的那一部分实际是变量名， 这时不需要values_to选项。 程序如下： dwide4 %&gt;% pivot_longer( -id, names_pattern = &quot;(x|y)([[:digit:]])&quot;, names_to = c(&quot;.value&quot;, &quot;time&quot;) ) %&gt;% knitr::kable() id time x y 1 1 10 8.04 1 2 10 9.14 1 3 10 7.46 1 4 8 6.58 2 1 8 6.95 2 2 8 8.14 2 3 8 6.77 2 4 8 5.76 3 1 13 7.58 3 2 13 8.74 3 3 13 12.74 3 4 8 7.71 26.15 长表转换为宽表 26.15.1 将多个混在一起的变量拆开 tidyr包的pivot_wider函数可以将长表变成宽表。 这适用于将多个变量保存到了一列的情况。 例如，下面的长表将变量x和y放在了同一列中： id variable value 1 x 11 1 y 23 2 x 10 2 y 20 3 x 15 3 y 28 这样的数据也不利于进行统计分析， 我们用pivot_wider函数将两个变量放到各自的列中， 用names_from选项指定区分不同变量的列， 用values_from指定保存实际变量值的列： dlong1 %&gt;% pivot_wider( names_from = &quot;variable&quot;, values_from = &quot;value&quot; ) %&gt;% knitr::kable() id x y 1 11 23 2 10 20 3 15 28 其中的变量名也可以不用双撇号保护。 在这样拆分列时， 有可能某些变量值不存在，例如： id variable value 1 x 11 1 y 23 2 x 10 3 y 28 这里2号id缺少y，3号id缺少x。 直接转换为宽表： dlong2 %&gt;% pivot_wider( names_from = variable, values_from = value ) %&gt;% knitr::kable() id x y 1 11 23 2 10 NA 3 NA 28 产生了缺失值。 如果知道缺失值实际等于0， 可以用选项values_fill=选项指定，如： dlong2 %&gt;% pivot_wider( names_from = variable, values_from = value, values_fill = list( value = 0) ) %&gt;% knitr::kable() id x y 1 11 23 2 10 0 3 0 28 26.15.2 将多个类别合并到一个观测 设3个受试者的2次测量值放在变量x中， 用time区分2次测量值： id time x 1 1 11 1 2 10 2 1 15 2 2 13 3 1 18 3 2 16 下面的程序将x的两次测量变成变量x1和x2： dlong3 %&gt;% pivot_wider( names_from = time, values_from = x, names_prefix = &quot;x&quot;) %&gt;% knitr::kable() id x1 x2 1 11 10 2 15 13 3 18 16 26.15.3 将交叉类别合并到一个观测 考虑如下的频数表数据： year sex type count 2018 F Benign 4 2018 F Malignant 9 2018 M Benign 18 2018 M Malignant 3 2019 F Benign 6 2019 F Malignant 10 2019 M Benign 20 2019 M Malignant 5 下面的程序将每年的数据合并到一行中： dlong4 %&gt;% pivot_wider( names_from = c(&quot;sex&quot;, &quot;type&quot;), values_from = &quot;count&quot; ) %&gt;% knitr::kable() year F_Benign F_Malignant M_Benign M_Malignant 2018 4 9 18 3 2019 6 10 20 5 26.15.4 多个变量的多种值 设有如下的x变量和y变量的分组汇总统计数据： group variable avg sd 1 x 1.2 0.5 1 y -5.1 0.4 2 x 1.4 0.5 2 y -4.9 0.8 3 x 1.3 0.7 3 y -4.3 0.9 下面将x和y的两种统计量都放到同一行中： dlong5 %&gt;% pivot_wider( names_from = &quot;variable&quot;, values_from = c(&quot;avg&quot;, &quot;sd&quot;) ) %&gt;% knitr::kable() group avg_x avg_y sd_x sd_y 1 1.2 -5.1 0.5 0.4 2 1.4 -4.9 0.5 0.8 3 1.3 -4.3 0.7 0.9 26.15.5 长宽转换混合使用 有时数据需要使用两个方向的转换才能达到可用的程度， 比如下面的数据： knitr::kable(dlong6) id variable 2018 2019 1 x 1.2 1.3 1 y -5.1 -5.4 2 x 1.4 1.6 2 y -4.9 -4.2 3 x 1.3 1.5 3 y -4.3 -4.1 这个数据的问题是x, y应该放在两列中却合并成一个了， 2018和2019应该放在一列中却分成了两列。 先合并2018和2019这两列， 然后再拆分x和y： dlong6 %&gt;% pivot_longer( `2018`:`2019`, names_to = &quot;year&quot;, values_to = &quot;value&quot; ) %&gt;% pivot_wider( names_from = &quot;variable&quot;, values_from = &quot;value&quot; ) %&gt;% knitr::kable() id year x y 1 2018 1.2 -5.1 1 2019 1.3 -5.4 2 2018 1.4 -4.9 2 2019 1.6 -4.2 3 2018 1.3 -4.3 3 2019 1.5 -4.1 26.16 拆分数据列 有时应该放在不同列的数据用分隔符分隔后放在同一列中了。 比如，下面数据集中“succ/total”列存放了用“/”分隔开的成功数与试验数： d.sep &lt;- read_csv( &quot;testid, succ/total 1, 1/10 2, 3/5 3, 2/8 &quot;) knitr::kable(d.sep) testid succ/total 1 1/10 2 3/5 3 2/8 用tidyr::separate()可以将这样的列拆分为各自的变量列，如 d.sep %&gt;% separate(`succ/total`, into=c(&quot;succ&quot;, &quot;total&quot;), sep=&quot;/&quot;, convert=TRUE) %&gt;% knitr::kable() testid succ total 1 1 10 2 3 5 3 2 8 其中into指定拆分后新变量名， sep指定分隔符， convert=TRUE要求自动将分割后的值转换为适当的类型。 sep还可以指定取子串的字符位置， 按位置拆分各个子串。 选项extra指出拆分时有多余内容的处理方法， 选项fill指出有不足内容的处理方法。 拆分的也可以是变量名和因子， 比如， 变量包括血压的高压和低压， 分男女计算了平均值， 结果表格可能为如下格式： knitr::kable(dbpa) var avg male:systolicbp 118 male:diastolicbp 85 female:systolicbp 115 female:diastolicbp 83 用separate()函数将变量名和性别值分开： dbpa2 &lt;- dbpa %&gt;% separate(var, into = c(&quot;sex&quot;, &quot;var&quot;), sep=&quot;:&quot;) knitr::kable(dbpa2) sex var avg male systolicbp 118 male diastolicbp 85 female systolicbp 115 female diastolicbp 83 实际上，这个数据集可能还需要将高压和低压变成两列， 用pivot_wider()函数： dbpa3 &lt;- dbpa2 %&gt;% pivot_wider( names_from = &quot;var&quot;, values_from = &quot;avg&quot;) knitr::kable(dbpa3) sex systolicbp diastolicbp male 118 85 female 115 83 函数extract()可以按照某种正则表达式表示的模式从指定列拆分出对应于正则表达式中捕获组的一列或多列内容。 例如，下面的数据中factors水平AA, AB, BA, BB实际是两个因子的组合， 将其拆分出来： dexp &lt;- tibble( design = c(&quot;AA&quot;, &quot;AB&quot;, &quot;BA&quot;, &quot;BB&quot;), response = c(120, 110, 105, 95)) knitr::kable(dexp) design response AA 120 AB 110 BA 105 BB 95 dexp %&gt;% extract( design, into = c(&quot;fac1&quot;, &quot;fac2&quot;), regex = &quot;(.)(.)&quot; ) %&gt;% knitr::kable() fac1 fac2 response A A 120 A B 110 B A 105 B B 95 26.17 合并数据列 tidyr::unite()函数可以将同一行的两列或多列的内容合并成一列。 这是separate()的反向操作， 如： d.sep %&gt;% separate(`succ/total`, into=c(&quot;succ&quot;, &quot;total&quot;), sep=&quot;/&quot;, convert=TRUE) %&gt;% unite(ratio, succ, total, sep=&quot;:&quot;) %&gt;% knitr::kable() testid ratio 1 1:10 2 3:5 3 2:8 unite()的第一个参数是要修改的数据框， 这里用管道%&gt;%传递进来， 第二个参数是合并后的变量名（ratio变量）， 其它参数是要合并的变量名，sep指定分隔符。 实际上用mutate()、paste()或者sprintf()也能完成合并。 26.18 数据框纵向合并 矩阵或数据框要纵向合并，使用rbind函数即可。 dplyr包的bind_rows()函数也可以对两个或多个数据框纵向合并。 要求变量集合是相同的，变量次序可以不同。 比如，有如下两个分开男生、女生的数据框： d3.class &lt;- d.class %&gt;% select(name, sex, age) %&gt;% filter(sex==&quot;M&quot;) d4.class &lt;- d.class %&gt;% select(name, sex, age) %&gt;% filter(sex==&quot;F&quot;) 合并行如下: d3.class %&gt;% bind_rows(d4.class) %&gt;% knitr::kable() name sex age Alfred M 14 Duke M 14 Guido M 15 James M 12 Jeffrey M 13 John M 12 Philip M 16 Robert M 12 Thomas M 11 William M 15 Alice F 13 Becka F 13 Gail F 14 Karen F 12 Kathy F 12 Mary F 15 Sandy F 11 Sharon F 15 Tammy F 14 将下面的数据框的变量列次序打乱， 合并不受影响： d3.class %&gt;% select(age, name, sex) %&gt;% bind_rows(d4.class) %&gt;% knitr::kable() age name sex 14 Alfred M 14 Duke M 15 Guido M 12 James M 13 Jeffrey M 12 John M 16 Philip M 12 Robert M 11 Thomas M 15 William M 13 Alice F 13 Becka F 14 Gail F 12 Karen F 12 Kathy F 15 Mary F 11 Sandy F 15 Sharon F 14 Tammy F 26.19 横向合并 为了将两个行数相同的数据框按行号对齐合并， 可以用基本R的cbind()函数或者dplyr包的bind_cols()函数。 实际数据往往没有存放在单一的表中， 需要从多个表查找数据。 多个表之间的连接， 一般靠关键列（key）对准来连接。 连接可以是一对一的， 一对多的。 多对多连接应用较少， 因为多对多连接是所有两两组合。 在规范的数据库中，每个表都应该有主键， 这可以是一列，也可以是多列的组合。 为了确定某列是主键， 可以用count()和filter()，如 d.class %&gt;% count(name) %&gt;% filter(n&gt;1) ## # A tibble: 0 x 2 ## # ... with 2 variables: name &lt;chr&gt;, n &lt;int&gt; 没有发现重复出现的name， 说明d.class中name可以作为主键。 为了演示一对一的横向连接， 我们将d.class拆分为两个数据集d1.class和d2.class, 两个数据集都有主键name， d1.class包含变量name, sex, d2.class包含变量name, age, height, weight, 并删去某些观测： d1.class &lt;- d.class %&gt;% select(name, sex) %&gt;% filter(!(name %in% &quot;Becka&quot;)) d2.class &lt;- d.class %&gt;% select(name, age, height, weight) 用dplyr包的inner_join()函数将两个数据框按键值横向合并， 仅保留能匹配的观测。因为d1.class中丢失了Becka的观测， 所以合并后的数据框中也没有Becka的观测： d1.class %&gt;% inner_join(d2.class) %&gt;% knitr::kable() ## Joining, by = &quot;name&quot; name sex age height weight Alice F 13 56.5 84.0 Gail F 14 64.3 90.0 Karen F 12 56.3 77.0 Kathy F 12 59.8 84.5 Mary F 15 66.5 112.0 Sandy F 11 51.3 50.5 Sharon F 15 62.5 112.5 Tammy F 14 62.8 102.5 Alfred M 14 69.0 112.5 Duke M 14 63.5 102.5 Guido M 15 67.0 133.0 James M 12 57.3 83.0 Jeffrey M 13 62.5 84.0 John M 12 59.0 99.5 Philip M 16 72.0 150.0 Robert M 12 64.8 128.0 Thomas M 11 57.5 85.0 William M 15 66.5 112.0 横向连接自动找到了共同的变量name作为连接的键值， 可以在inner_join()中用by=指定键值变量名， 如果有不同的变量名， 可以用by = c(\"a\"=\"b\")的格式指定左数据框的键值a与右数据框的键值b匹配进行连接。 两个表的横向连接， 经常是多对一连接。 例如， d.stu中有学生学号、班级号、姓名、性别， d.cl中有班级号、班主任名、年级， 可以通过班级号将两个表连接起来： d.stu &lt;- tibble( sid=c(1,2,3,4,5,6), cid=c(1,2,1,2,1,2), sname=c(&quot;John&quot;, &quot;Mary&quot;, &quot;James&quot;, &quot;Kitty&quot;, &quot;Jasmine&quot;, &quot;Kim&quot;), sex=c(&quot;M&quot;, &quot;F&quot;, &quot;M&quot;, &quot;F&quot;, &quot;F&quot;, &quot;M&quot;)) knitr::kable(d.stu) sid cid sname sex 1 1 John M 2 2 Mary F 3 1 James M 4 2 Kitty F 5 1 Jasmine F 6 2 Kim M d.cl &lt;- tibble( cid=c(1,2), tname=c(&quot;Philip&quot;, &quot;Joane&quot;), grade=c(&quot;2017&quot;, &quot;2016&quot;) ) knitr::kable(d.cl) cid tname grade 1 Philip 2017 2 Joane 2016 d.stu %&gt;% left_join(d.cl, by=&quot;cid&quot;) %&gt;% knitr::kable() sid cid sname sex tname grade 1 1 John M Philip 2017 2 2 Mary F Joane 2016 3 1 James M Philip 2017 4 2 Kitty F Joane 2016 5 1 Jasmine F Philip 2017 6 2 Kim M Joane 2016 left_join()按照by变量指定的关键列匹配观测， 左数据集所有观测不论匹配与否全部保留， 右数据集仅使用与左数据集能匹配的观测。 不指定by变量时， 使用左、右数据集的共同列作为关键列。 如果左右数据集关键列变量名不同， 可以用by=c(\"左名\"=\"右名\")的格式。 类似地， right_join()保留右数据集的所有观测， 而仅保留左数据集中能匹配的观测。 full_join()保留所有观测。 inner_join()仅保留能匹配的观测。 26.20 利用第二个数据集筛选 left_join()将右表中与左表匹配的观测的额外的列添加到左表中。 如果希望按照右表筛选左表的观测， 可以用semi_join()， 函数anti_join()则是要求保留与右表不匹配的观测。 26.21 数据集的集合操作 R的intersect()，union(), setdiff()本来是以向量作为集合进行集合操作。 dplyr包也提供了这些函数， 但是将两个tibble的各行作为元素进行集合操作。 26.22 标准化 设x是各列都为数值的列表(包括数据框和tibble)或数值型矩阵， 用scale(x)可以把每一列都标准化， 即每一列都减去该列的平均值，然后除以该列的样本标准差。 用scale(x, center=TRUE, scale=FALSE)仅中心化而不标准化。 如 d.class %&gt;% select(height, weight) %&gt;% scale() ## height weight ## [1,] -1.13843504 -0.70371312 ## [2,] 0.57794313 -0.08897522 ## [3,] 0.38290015 -0.44025402 ## [4,] -1.17744363 -1.01108207 ## [5,] -0.49479323 -0.68175819 ## [6,] 0.81199469 0.52576268 ## [7,] -2.15265850 -2.17469309 ## [8,] 0.03182280 0.54771760 ## [9,] 0.09033569 0.10861910 ## [10,] 1.29960213 0.54771760 ## [11,] 0.22686577 0.10861910 ## [12,] 0.90951618 1.44786952 ## [13,] -0.98240066 -0.74762297 ## [14,] 0.03182280 -0.70371312 ## [15,] -0.65082761 -0.02311045 ## [16,] 1.88473105 2.19433697 ## [17,] 0.48042164 1.22832027 ## [18,] -0.94339207 -0.65980327 ## [19,] 0.81199469 0.52576268 ## attr(,&quot;scaled:center&quot;) ## height weight ## 62.33684 100.02632 ## attr(,&quot;scaled:scale&quot;) ## height weight ## 5.127075 22.773933 为了把x的每列变到\\([0,1]\\)内，可以用如下的方法： d.class %&gt;% select(height, weight) %&gt;% scale(center=apply(., 2, min), scale=apply(., 2, max) - apply(., 2, min)) 其中的.在管道操作中表示被传递处理的变量（一般是数据框）。 也可以写一个自定义的进行零一标准化的函数： scale01 &lt;- function(x){ mind &lt;- apply(x, 2, min) maxd &lt;- apply(x, 2, max) scale(x, center=mind, scale=maxd-mind) } d.class %&gt;% select(height, weight) %&gt;% scale01 ## height weight ## [1,] 0.2512077 0.3366834 ## [2,] 0.6763285 0.4773869 ## [3,] 0.6280193 0.3969849 ## [4,] 0.2415459 0.2663317 ## [5,] 0.4106280 0.3417085 ## [6,] 0.7342995 0.6180905 ## [7,] 0.0000000 0.0000000 ## [8,] 0.5410628 0.6231156 ## [9,] 0.5555556 0.5226131 ## [10,] 0.8550725 0.6231156 ## [11,] 0.5893720 0.5226131 ## [12,] 0.7584541 0.8291457 ## [13,] 0.2898551 0.3266332 ## [14,] 0.5410628 0.3366834 ## [15,] 0.3719807 0.4924623 ## [16,] 1.0000000 1.0000000 ## [17,] 0.6521739 0.7788945 ## [18,] 0.2995169 0.3467337 ## [19,] 0.7342995 0.6180905 ## attr(,&quot;scaled:center&quot;) ## height weight ## 51.3 50.5 ## attr(,&quot;scaled:scale&quot;) ## height weight ## 20.7 99.5 注意在管道操作中某个操作除了被传递的第一自变量外没有其它自变量时， 可以不写函数调用的空括号()。 函数sweep()可以执行对每列更一般的变换。 References "],["summary-summ.html", "27 数据汇总 27.1 用dplyr作数据汇总 27.2 多个变量的汇总 27.3 用dplyr作数据分组汇总 27.4 交叉分类的汇总 27.5 tibble中的列表列 27.6 基本R的汇总功能 27.7 用基本R作分类概括 27.8 用plyr包进行分类概括 27.9 练习", " 27 数据汇总 27.1 用dplyr作数据汇总 dplyr包的summarise()函数可以对数据框计算统计量。 以肺癌病人化疗数据cancer.csv为例， 有34个肺癌病人的数据： d.cancer &lt;- read_csv( &quot;cancer.csv&quot;, locale=locale(encoding=&quot;GBK&quot;)) ## Parsed with column specification: ## cols( ## id = col_double(), ## age = col_double(), ## sex = col_character(), ## type = col_character(), ## v0 = col_double(), ## v1 = col_double() ## ) knitr::kable(d.cancer) id age sex type v0 v1 1 70 F 腺癌 26.51 2.91 2 70 F 腺癌 135.48 35.08 3 69 F 腺癌 209.74 74.44 4 68 M 腺癌 61.00 34.97 5 67 M 鳞癌 237.75 128.34 6 75 F 腺癌 330.24 112.34 7 52 M 鳞癌 104.90 32.10 8 71 M 鳞癌 85.15 29.15 9 68 M 鳞癌 101.65 22.15 10 79 M 鳞癌 65.54 21.94 11 55 M 腺癌 125.31 12.33 12 54 M 鳞癌 224.36 99.44 13 55 F 腺癌 12.93 2.30 14 75 M 腺癌 40.21 23.96 15 61 F 腺癌 12.58 7.39 16 76 M 鳞癌 231.04 112.58 17 65 M 鳞癌 172.13 91.62 18 66 M 鳞癌 39.26 13.95 19 NA F 腺癌 32.91 9.45 20 63 F 腺癌 161.00 122.45 21 67 M 鳞癌 105.26 68.35 22 51 M 鳞癌 13.25 5.25 23 49 M 鳞癌 18.70 3.34 24 49 M 鳞癌 60.23 50.36 25 NA F 鳞癌 223.00 25.59 26 NA M 鳞癌 145.70 35.36 27 NA M 鳞癌 138.44 11.30 28 NA M 鳞癌 83.71 76.45 29 NA M 鳞癌 74.48 23.66 30 NA F 腺癌 42.70 5.97 31 NA M 鳞癌 142.48 68.46 32 NA F 鳞癌 46.97 27.32 33 NA F 鳞癌 170.63 74.76 34 NA F 鳞癌 67.37 54.52 求年龄(age)的观测个数、非缺失观测个数、平均值、标准差： d.cancer %&gt;% summarise( nobs = n(), n = sum(!is.na(age)), mean.age=mean(age, na.rm=TRUE), sd.age=sd(age, na.rm=TRUE)) %&gt;% knitr::kable() nobs n mean.age sd.age 34 23 64.13043 9.161701 其中n()计算观测数（行数）。 为了计算某列的非缺失值个数，用sum(!is.na(x))。 summarise中常用的汇总函数有： 位置度量：mean(), median()。 分散程度（变异性）度量：sd(), IQR(), mad()。 分位数：min(), max(), quantile()。 按下标查询，如first(x)取出x[1]， last(x)取出x的最后一个元素， nth(x,2)取出x[2]。 可以提供一个缺省值以防某个下标位置不存在。 计数：n()给出某个组的观测数， sum(!is.na(x))统计x的非缺失值个数， n_distinct(x)统计x的不同值个数(缺失值也算一个值)。 count(x)给出x的每个不同值的个数（类似于table()函数）。 这里有些函数是dplyr包提供的， 仅适用于tibble类型。 27.2 多个变量的汇总 在有多个变量需要汇总时， summarise的格式就会比较罗嗦。 比如， 需要对cancer数据集中v0和v1两个变量同时计算平均值和标准差： d.cancer %&gt;% summarise( mean.v0=mean(v0, na.rm=TRUE), sd.v0 = sd(v0, na.rm=TRUE), mean.v1=mean(v1, na.rm=TRUE), sd.v1 = sd(v1, na.rm=TRUE)) %&gt;% knitr::kable() mean.v0 sd.v0 mean.v1 sd.v1 110.0768 79.52338 44.69353 38.44172 显然，如果有许多变量要计算不止一个统计量， 就需要人为地将每一个变量的每一个统计量单独命名。 dplyr包的summarse_at()函数可以指定一批变量名与一批统计函数， 自动命名结果变量，如： d.cancer %&gt;% summarise_at( c(&quot;v0&quot;, &quot;v1&quot;), list(avg = ~mean(.), std = ~sd(.)), na.rm=TRUE) %&gt;% knitr::kable() v0_avg v1_avg v0_std v1_std 110.0768 44.69353 79.52338 38.44172 其中的选项na.rm将作为...格式的参数传递给统计函数mean和sd。 summarise_at的第三自变量（在管道中的第二自变量位置）可以取： 一个函数，如mean； 一个如~ f(.)这样的自定义无名函数，其中.表示自变量； 函数或者自定义无名函数的列表。 结果统计量自动命名为“变量名_统计量名”的格式。 其中的变量子集也可以用序号范围表示， 或者用vars()函数写成不加撇号的格式，如： d.cancer %&gt;% summarise_at( 5:6, list(avg = ~mean(.), std = ~sd(.)), na.rm=TRUE) %&gt;% knitr::kable() v0_avg v1_avg v0_std v1_std 110.0768 44.69353 79.52338 38.44172 或 d.cancer %&gt;% summarise_at( vars(v0, v1), list(avg = ~mean(.), std = ~sd(.)), na.rm=TRUE) %&gt;% knitr::kable() v0_avg v1_avg v0_std v1_std 110.0768 44.69353 79.52338 38.44172 如果要对所有数值型变量计算某些统计量， 可以用summarize_if(is.numeric, list(变量后缀=~统计函数名&lt;, ...&gt;))， 如： d.cancer %&gt;% summarise_if( is.numeric, list(avg = ~mean(.), std = ~sd(.)), na.rm=TRUE) %&gt;% knitr::kable() id_avg age_avg v0_avg v1_avg id_std age_std v0_std v1_std 17.5 NA 110.0768 44.69353 9.958246 NaN 79.52338 38.44172 其中的is_numeric用来筛选需要进行统计的变量子集， 可以替换成其它的示性函数（对每列返回一个逻辑值的函数）。 summarise_all可以对所有变量计算统计量，如： d.cancer %&gt;% select(v0, v1) %&gt;% summarise_all( list(avg = ~mean(.), std = ~sd(.)), na.rm=TRUE) %&gt;% knitr::kable() v0_avg v1_avg v0_std v1_std 110.0768 44.69353 79.52338 38.44172 可以用tidyr包将上面的变量与统计量拆开， 将变量放到不同的观测中，如： d.cancer %&gt;% select(v0, v1) %&gt;% summarise_all( list(avg = ~mean(.), std = ~sd(.)), na.rm=TRUE) %&gt;% pivot_longer( everything(), names_sep =&quot;_&quot;, names_to = c(&quot;variable&quot;, &quot;.value&quot;) ) %&gt;% knitr::kable() variable avg std v0 110.07676 79.52338 v1 44.69353 38.44172 27.3 用dplyr作数据分组汇总 数据汇总问题更常见的是作分组汇总。 dplyr包的group_by()函数对数据框（或tibble）分组， 随后的summarise()将按照分组汇总。 比如， 按不同性别分组计算人数与年龄平均值： d.cancer %&gt;% group_by(sex) %&gt;% summarise( count=n(), mean.age=mean(age, na.rm=TRUE)) %&gt;% knitr::kable() sex count mean.age F 13 66.14286 M 21 63.25000 按不同性别分组计算v0和v1的人数、平均值、标准差： d.cancer %&gt;% group_by(sex) %&gt;% summarise_at( c(&quot;v0&quot;, &quot;v1&quot;), list(count = ~n(), avg = ~mean(.), std = ~sd(.)), na.rm=TRUE) %&gt;% knitr::kable() sex v0_count v1_count v0_avg v1_avg v0_std v1_std F 13 13 113.2354 42.65538 100.06621 41.72226 M 21 21 108.1214 45.95524 66.45374 37.27592 上面的程序应该将v0_count和v1_count合并， 但是summarise_at在有多个变量和多个统计量时总会将变量两两搭配， 确实需要时可以分别统计再合并，结果程序会略繁琐一些： bind_cols( d.cancer %&gt;% group_by(sex) %&gt;% summarise(count = n() ), d.cancer %&gt;% group_by(sex) %&gt;% summarise_at( c(&quot;v0&quot;, &quot;v1&quot;), list(avg = ~mean(.), std = ~sd(.)), na.rm=TRUE) %&gt;% select(-sex) ) ## # A tibble: 2 x 6 ## sex count v0_avg v1_avg v0_std v1_std ## &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 F 13 113. 42.7 100. 41.7 ## 2 M 21 108. 46.0 66.5 37.3 为了查询数值型变量取值满足某种条件的个数和比例， 可以将该条件用sum()和mean()函数统计， 比如， 对男女两组分别计算年龄在60岁以上的人数和比例： d.cancer %&gt;% group_by(sex) %&gt;% summarise( nold = sum(age &gt;= 60, na.rm=TRUE), pold = nold / n()) %&gt;% knitr::kable() sex nold pold F 6 0.4615385 M 10 0.4761905 用group_by()分组后除了可以分组汇总， 还可以分组筛选： d.cancer %&gt;% group_by(sex) %&gt;% filter(rank(desc(v0)) &lt;= 2) %&gt;% arrange(sex, desc(v0)) %&gt;% knitr::kable() id age sex type v0 v1 6 75 F 腺癌 330.24 112.34 25 NA F 鳞癌 223.00 25.59 5 67 M 鳞癌 237.75 128.34 16 76 M 鳞癌 231.04 112.58 以上程序按性别分组后， 在每组中找出疗前体积排名在前两名的。 在分组后也可以根据每组的统计量用mutate()定义新变量。 比如，每组的v0, v1除以本组的最大值（结果略）： d.cancer %&gt;% group_by(sex) %&gt;% mutate( v0s = v0 / max(v0), v1s = v1 / max(v1)) 27.4 交叉分类的汇总 下面的程序对d.cancer数据框分性别与病理类型分别统计人数： d.cancer %&gt;% group_by(sex, type) %&gt;% summarise(freq=n()) %&gt;% knitr::kable() sex type freq F 鳞癌 4 F 腺癌 9 M 鳞癌 18 M 腺癌 3 如果仅需要计算交叉分类频数， 不需要用group_by()， 可以用dplyr的count()函数，如： d.cancer %&gt;% count(sex, type) %&gt;% knitr::kable() sex type n F 鳞癌 4 F 腺癌 9 M 鳞癌 18 M 腺癌 3 下面的程序数出NHANES数据框中ID(受访者编码)与SurveyYr(考察年份)每一对组合的出现次数, 筛选出二次及以上者，并降序排列，仅显示前10行结果： NHANES %&gt;% count(ID, SurveyYr) %&gt;% filter(n &gt;=2 ) %&gt;% arrange(desc(n)) %&gt;% head(10) %&gt;% knitr::kable() ID SurveyYr n 70324 2011_12 8 62927 2011_12 7 63297 2011_12 7 69626 2011_12 7 60566 2009_10 6 61442 2009_10 6 63163 2011_12 6 63330 2011_12 6 63390 2011_12 6 63744 2011_12 6 用group_by()交叉分组汇总后的结果不是普通的tibble， 总是带有外层分组信息， 最内层的分组信息不再有效。 不注意这种规定在后续的使用中可能会产生问题， 为此， 可以用ungroup()函数取消分组。 例如， 希望在用group_by()按照性别和病理类别交叉分类计算频数后求所有病人的总人数， 用了如下程序： d.cancer %&gt;% group_by(sex, type) %&gt;% summarise(freq=n()) %&gt;% summarise(ntotal=sum(freq)) %&gt;% knitr::kable() sex ntotal F 13 M 21 可以看出并没有能够计算总人数， 而是按原来交叉分类的外层分类即性别分组计算了总人数。 这是因为交叉分组计算频数后的结果仍按照外层分类变量sex分组， 所以summarise(ntotal=sum(freq))也是分两组进行的。 在中间加入ungroup()就可以不分组计算总人数： d.cancer %&gt;% group_by(sex, type) %&gt;% summarise(freq=n()) %&gt;% ungroup() %&gt;% summarise(ntotal=sum(freq)) %&gt;% knitr::kable() ntotal 34 得到了需要的结果。 27.5 tibble中的列表列 27.5.1 nest和unnest dplyr包的group_by与summarise、summarise_at等函数配合， 可以对数据框分组计算各种概括统计量。 但是，如果分组以后希望进行更复杂的统计分析， 比如分组回归建模， summarise就不够用了。 这时， 可以用基本R的split函数将数据框按某个分类变量拆分为子数据框的列表， 然后用purrr包的map类函数分类建模， 最终将各个模型的结果合并为一个数据框。 上面的办法虽然可行， 但是管理不够方便。 tidyr包（属于tidyverse系列，载入tidyverse时会自动载入）提供了nest和unnest函数， 可以将子数据框保存在tibble中， 可以将保存在tibble中的子数据框合并为一个大数据框。 实际上， tibble允许存在数据类型是列表(list)的列， 子数据框就是以列表数据类型保存在tibble的一列中的。 27.5.2 group_by与nest配合 对数据框用group_by分组后调用nest函数就可以生成每个组的子数据框。 例如， 将d.cancer数据框按type分类拆分为2个子数据框， 存入tibble的data列中： d.cancer %&gt;% group_by(type) %&gt;% nest() ## # A tibble: 2 x 2 ## # Groups: type [2] ## type data ## &lt;chr&gt; &lt;list&gt; ## 1 腺癌 &lt;tibble [12 x 5]&gt; ## 2 鳞癌 &lt;tibble [22 x 5]&gt; 现在data列是列表类型的， 有2个元素， 每个元素是一个子数据框。 group_by()中也可以用两个或多个分类变量构成交叉分组。 可以用purrr包的map()等函数对每个子数据框进行处理， 结果可以用mutate保存为新的列表类型的列， 如果结果是数值型标量也可以保存为普通的数据框列。 例如，下面先定义对子数据框回归建模的函数， 然后用purrr包的map函数将回归建模的函数作用到data列的每个元素， 用mutate保存到列表类型的lmr列中： fmod &lt;- function(subdf) lm(v1 ~ v0, data = subdf) mod.cancer &lt;- d.cancer %&gt;% group_by(type) %&gt;% nest() %&gt;% mutate(lmr = map(data, fmod)) mod.cancer ## # A tibble: 2 x 3 ## # Groups: type [2] ## type data lmr ## &lt;chr&gt; &lt;list&gt; &lt;list&gt; ## 1 腺癌 &lt;tibble [12 x 5]&gt; &lt;lm&gt; ## 2 鳞癌 &lt;tibble [22 x 5]&gt; &lt;lm&gt; 写一个函数从一个回归模型及相应子数据框中， 提取R方， 将提取的结果保存为普通数值型列r.squared： frsqr &lt;- function(mod){ summary(mod)$r.squared } mod.cancer %&gt;% mutate( r.squared = map_dbl(lmr, frsqr)) %&gt;% select(-data, -lmr) ## # A tibble: 2 x 2 ## # Groups: type [2] ## type r.squared ## &lt;chr&gt; &lt;dbl&gt; ## 1 腺癌 0.710 ## 2 鳞癌 0.520 map()和map_dbl()中输入函数时可以用purrr包的无名函数写法，如： d.cancer %&gt;% group_by(type) %&gt;% nest() %&gt;% mutate( lmr = map(data, ~ lm(v1 ~ v0, data = .x)), r.squared = map_dbl(lmr, ~ summary(.x)$r.squared)) %&gt;% select(-data, -lmr) ## # A tibble: 2 x 2 ## # Groups: type [2] ## type r.squared ## &lt;chr&gt; &lt;dbl&gt; ## 1 腺癌 0.710 ## 2 鳞癌 0.520 也可以从每个模型提取多个值， 这时， 为了使得多个值在展开时能保存在同一行中， 需要将每个子数据框的提取结果保存为一个一行的子数据框： fextract &lt;- function(mod){ x1 &lt;- coef(mod) tibble( intercept = x1[1], v0 = x1[2], r.squared = summary(mod)$r.squared ) } mod.cancer %&gt;% mutate( outlist = map(lmr, fextract)) ## # A tibble: 2 x 4 ## # Groups: type [2] ## type data lmr outlist ## &lt;chr&gt; &lt;list&gt; &lt;list&gt; &lt;list&gt; ## 1 腺癌 &lt;tibble [12 x 5]&gt; &lt;lm&gt; &lt;tibble [1 x 3]&gt; ## 2 鳞癌 &lt;tibble [22 x 5]&gt; &lt;lm&gt; &lt;tibble [1 x 3]&gt; 结果的outlist列是列表类型的， 每个元素是一个\\(1 \\times 3\\)的tibble。 下面，就可以用unnest将每个组提取的回归结果转换为普通的数据框列： mod.cancer %&gt;% mutate( outlist = map(lmr, fextract)) %&gt;% select(-data, -lmr) %&gt;% unnest(outlist) ## # A tibble: 2 x 4 ## # Groups: type [2] ## type intercept v0 r.squared ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 腺癌 0.225 0.370 0.710 ## 2 鳞癌 5.51 0.374 0.520 提取的结果也可以是一个不止一行的子数据框，例如， 提取回归结果中的系数估计、标准误差、t统计量和检验p值组成的矩阵： fcoefmat &lt;- function(mod){ as_tibble(summary(mod)$coefficients, rownames=&quot;term&quot;) } mod.cancer %&gt;% mutate( outlist = map(lmr, fcoefmat)) %&gt;% unnest(outlist) %&gt;% select(-data, - lmr) ## # A tibble: 4 x 6 ## # Groups: type [2] ## type term Estimate `Std. Error` `t value` `Pr(&gt;|t|)` ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 腺癌 (Intercept) 0.225 10.2 0.0221 0.983 ## 2 腺癌 v0 0.370 0.0749 4.94 0.000585 ## 3 鳞癌 (Intercept) 5.51 10.8 0.510 0.616 ## 4 鳞癌 v0 0.374 0.0803 4.66 0.000151 为了更好地提取统计模型的信息为规整的数据框格式， broom扩展包提供了tidy函数， 可以将统计模型的输出转换为数据框； 这些功能与tidyr的nest, unnest配合， 可以很好地提取统计模型的信息，如： mod.cancer %&gt;% mutate( outlist = map(lmr, broom::tidy)) %&gt;% select(-data, -lmr) %&gt;% unnest(outlist) ## # A tibble: 4 x 6 ## # Groups: type [2] ## type term estimate std.error statistic p.value ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 腺癌 (Intercept) 0.225 10.2 0.0221 0.983 ## 2 腺癌 v0 0.370 0.0749 4.94 0.000585 ## 3 鳞癌 (Intercept) 5.51 10.8 0.510 0.616 ## 4 鳞癌 v0 0.374 0.0803 4.66 0.000151 unnest提取出的信息也可以是一个向量， 在展开时会展开到同一列中。 例如， 对每个组提取回归的拟合值： mod.cancer %&gt;% mutate( v1hat = map(lmr, ~ fitted(.))) %&gt;% select(-lmr) %&gt;% unnest(c(data, v1hat)) ## # A tibble: 34 x 7 ## # Groups: type [2] ## type id age sex v0 v1 v1hat ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 腺癌 1 70 F 26.5 2.91 10.0 ## 2 腺癌 2 70 F 135. 35.1 50.4 ## 3 腺癌 3 69 F 210. 74.4 77.9 ## 4 腺癌 4 68 M 61 35.0 22.8 ## 5 腺癌 6 75 F 330. 112. 123. ## 6 腺癌 11 55 M 125. 12.3 46.6 ## 7 腺癌 13 55 F 12.9 2.3 5.01 ## 8 腺癌 14 75 M 40.2 24.0 15.1 ## 9 腺癌 15 61 F 12.6 7.39 4.88 ## 10 腺癌 19 NA F 32.9 9.45 12.4 ## # ... with 24 more rows 程序中的unnest将data列和v1hat列都释放为普通的数据框列了， data列中释放出了多列原始数据， fitted列中释放出了v1回归拟合值。 27.5.3 summarise统计量用列表表示 实际上， summarise等函数如果将结果用list()声明， 汇总结果就可以保存为列表类型的列， 结果可以包含多个值， unnest可以将结果恢复成正常的数据框， 如： vnames &lt;- expand_grid( var = c(&quot;v0&quot;, &quot;v1&quot;), stat = c(&quot;min&quot;, &quot;max&quot;)) %&gt;% pmap_chr(paste, sep=&quot;_&quot;) d.cancer %&gt;% group_by(type) %&gt;% summarise( stat = list(vnames), value = list(c(range(v0), range(v1))) ) %&gt;% unnest(c(stat, value)) ## # A tibble: 8 x 3 ## type stat value ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 鳞癌 v0_min 13.2 ## 2 鳞癌 v0_max 238. ## 3 鳞癌 v1_min 3.34 ## 4 鳞癌 v1_max 128. ## 5 腺癌 v0_min 12.6 ## 6 腺癌 v0_max 330. ## 7 腺癌 v1_min 2.3 ## 8 腺癌 v1_max 122. 这个例子可以用长宽表转换方法变成每个统计量占一列： d.cancer %&gt;% group_by(type) %&gt;% summarise( stat = list(vnames), value = list(c(range(v0), range(v1))) ) %&gt;% unnest(c(stat, value)) %&gt;% separate(stat, into = c(&quot;variable&quot;, &quot;stat&quot;), sep=&quot;_&quot;) %&gt;% pivot_wider( names_from = &quot;stat&quot;, values_from = &quot;value&quot; ) ## # A tibble: 4 x 4 ## type variable min max ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 鳞癌 v0 13.2 238. ## 2 鳞癌 v1 3.34 128. ## 3 腺癌 v0 12.6 330. ## 4 腺癌 v1 2.3 122. 27.5.4 unnest的语法格式 unnest()第一自变量为管道输入的数据框， 第二自变量cols可以用如下格式： 单个变量名，不需要写成字符串形式； 多个变量名，写成c(x, y, z)这样的格式，不需要写成字符型向量； 保存在字符型向量中的变量名，用one_of(vnames)格式， 其中vnames是保存了要释放的列名的字符型向量的变量名; 也可以写成one_of(c(\"x\", \"y\", \"z\"))这样的格式。 27.5.5 直接生成列表类型的列 也可以直接生成列表类型的列， 符合条件时可以用unnest()合并为大数据框。 如： d1 &lt;- tibble( id = 1:2, df = vector(&quot;list&quot;, length=2)) d1[[&quot;df&quot;]][1] &lt;- list( tibble(x=1, y=2) ) d1[[&quot;df&quot;]][2] &lt;- list( tibble(x=11:12, y=21:22) ) d1 %&gt;% unnest(cols = c(df)) ## # A tibble: 3 x 3 ## id x y ## &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 1 2 ## 2 2 11 21 ## 3 2 12 22 27.6 基本R的汇总功能 27.6.1 summary()函数 对数值型向量x，用summary(x)可以获得变量的平均值、中位数、 最小值、最大值、四分之一和四分之三分位数。 如 summary(d.cancer[[&quot;v0&quot;]]) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 12.58 43.77 93.40 110.08 157.18 330.24 summary(d.cancer[[&quot;v1&quot;]]) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 2.30 12.73 30.62 44.69 72.94 128.34 v0是放疗前的肿瘤体积， v1是放疗后的体积， 可以看出放疗后体积减小了很多。 可以用盒形图表现类似的信息，如 boxplot(d.cancer[,c(&quot;v0&quot;, &quot;v1&quot;)], main=&quot;肿瘤体积&quot;) 对一个数据框d， 用summary(d)可以获得每个连续型变量的基本统计量， 和每个离散取值变量的频率。如 summary(d.cancer) ## id age sex type ## Min. : 1.00 Min. :49.00 Length:34 Length:34 ## 1st Qu.: 9.25 1st Qu.:55.00 Class :character Class :character ## Median :17.50 Median :67.00 Mode :character Mode :character ## Mean :17.50 Mean :64.13 ## 3rd Qu.:25.75 3rd Qu.:70.00 ## Max. :34.00 Max. :79.00 ## NA&#39;s :11 ## v0 v1 ## Min. : 12.58 Min. : 2.30 ## 1st Qu.: 43.77 1st Qu.: 12.73 ## Median : 93.40 Median : 30.62 ## Mean :110.08 Mean : 44.69 ## 3rd Qu.:157.18 3rd Qu.: 72.94 ## Max. :330.24 Max. :128.34 ## 对数据框d，用str(d)可以获得各个变量的类型和取值样例。 如 str(d.cancer) ## Classes &#39;spec_tbl_df&#39;, &#39;tbl_df&#39;, &#39;tbl&#39; and &#39;data.frame&#39;: 34 obs. of 6 variables: ## $ id : num 1 2 3 4 5 6 7 8 9 10 ... ## $ age : num 70 70 69 68 67 75 52 71 68 79 ... ## $ sex : chr &quot;F&quot; &quot;F&quot; &quot;F&quot; &quot;M&quot; ... ## $ type: chr &quot;腺癌&quot; &quot;腺癌&quot; &quot;腺癌&quot; &quot;腺癌&quot; ... ## $ v0 : num 26.5 135.5 209.7 61 237.8 ... ## $ v1 : num 2.91 35.08 74.44 34.97 128.34 ... ## - attr(*, &quot;spec&quot;)= ## .. cols( ## .. id = col_double(), ## .. age = col_double(), ## .. sex = col_character(), ## .. type = col_character(), ## .. v0 = col_double(), ## .. v1 = col_double() ## .. ) 用head(d)可以返回数据框（或向量、矩阵）的前几行， 用tail(d)可以返回数据框的后几行。 27.6.2 连续型变量概括函数 对连续取值的变量x， 可以用mean, std, var, sum, prod, min, max等函数获取基本统计量。 加na.rm=TRUE选项可以仅对非缺失值计算。 sort(x)返回排序后的结果。 rev(x)把x所有元素次序颠倒后返回。 quantile(x, c(0.05, 0.95))可以求x的样本分位数。 rank(x)对x求秩得分（即名次，但从最小到最大排列）。 27.6.3 分类变量概括 分类变量一般输入为因子。 对因子或其它向量x， table(x)返回x的每个不同值的频率（出现次数）， 结果为一个类（class）为table的一维数组。 每个元素有对应的元素名，为x的各水平值。 如 res &lt;- table(d.cancer[[&quot;sex&quot;]]); res ## ## F M ## 13 21 res[&quot;F&quot;] ## F ## 13 对单个分类变量, table结果是一个有元素名的向量。 用as.data.frame()函数把table的结果转为数据框: as.data.frame(res) ## Var1 Freq ## 1 F 13 ## 2 M 21 用prop.table()将频数转换成百分比： prop.table(res) ## ## F M ## 0.3823529 0.6176471 table作的单变量频数表可以用barplot表现为图形，如: barplot(res, main=&quot;性别分布&quot;) 对两个分类变量x1和x2， 其每个组合的出现次数可以用table(x1,x2)函数统计， 结果叫做列联表。 如 res2 &lt;- with(d.cancer, table(sex, type)); res2 ## type ## sex 鳞癌 腺癌 ## F 4 9 ## M 18 3 结果是一个类为table的二维数组（矩阵）， 每行以第一个变量x1的各水平值为行名， 每列以第二个变量x2的各水平值为列名。 这里用了with()函数引入一个数据框， 后续的参数中的表达式可以直接使用数据框的变量。 对两个分类变量, table结果是一个矩阵。 用as.data.frame函数把table的结果转为数据框: as.data.frame(res2) ## sex type Freq ## 1 F 鳞癌 4 ## 2 M 鳞癌 18 ## 3 F 腺癌 9 ## 4 M 腺癌 3 列联表的结果可以用条形图表示。如 barplot(res2, legend=TRUE) 或 barplot(res2, legend=TRUE, beside=TRUE) 对于table()的结果列联表， 可以用addmargins()函数增加行和与列和。 如 addmargins(res2) ## type ## sex 鳞癌 腺癌 Sum ## F 4 9 13 ## M 18 3 21 ## Sum 22 12 34 用margin.table()可以计算列联表行或列的和并返回，如 margin.table(res2, 1) ## sex ## F M ## 13 21 margin.table(res2, 2) ## type ## 鳞癌 腺癌 ## 22 12 用prop.table(r)把一个列联表r转换成百分比表。 如 prop.table(res2) ## type ## sex 鳞癌 腺癌 ## F 0.11764706 0.26470588 ## M 0.52941176 0.08823529 用prop.table(res,1)把列联表res转换成行百分比表。 用prop.table(res,2)把列联表res转换成列百分比表。 如 prop.table(res2, 1) ## type ## sex 鳞癌 腺癌 ## F 0.3076923 0.6923077 ## M 0.8571429 0.1428571 prop.table(res2, 2) ## type ## sex 鳞癌 腺癌 ## F 0.1818182 0.7500000 ## M 0.8181818 0.2500000 在有多个分类变量时， 用as.data.frame(table(x1, x2, x3)) 形成多个分类变量交叉分类的频数统计数据框。 dplyr包的count()功能与table()类似。 27.6.4 数据框概括 用colMeans()对数据框或矩阵的每列计算均值， 用colSums()对数据框或矩阵的每列计算总和。 用rowMeans()和rowSums()对矩阵的每行计算均值或总和。 数据框与矩阵有区别， 某些适用于矩阵的计算对数据框不适用， 例如矩阵乘法。 用as.matrix()把数据框的数值子集转换成矩阵。 对矩阵，用apply(x, 1, FUN)对矩阵x的每一行使用函数FUN计算结果， 用apply(x, 2, FUN)对矩阵x的每一列使用函数FUN计算结果。 如果apply(x,1,FUN)中的FUN对每个行变量得到多个\\(m\\)结果， 结果将是一个矩阵，行数为\\(m\\)，列数等于nrow(x)。 如果apply(x,2,FUN)中的FUN对每个列变量得到多个\\(m\\)结果， 结果将是一个矩阵，行数为\\(m\\)，列数等于ncol(x)。 例如： apply(as.matrix(iris[,1:4]), 2, function(x) c(n=sum(!is.na(x)), mean=mean(x, na.rm=TRUE), sd=sd(x, na.rm=TRUE))) ## Sepal.Length Sepal.Width Petal.Length Petal.Width ## n 150.0000000 150.0000000 150.000000 150.0000000 ## mean 5.8433333 3.0573333 3.758000 1.1993333 ## sd 0.8280661 0.4358663 1.765298 0.7622377 27.7 用基本R作分类概括 27.7.1 用tapply()分组概括向量 用tapply()函数进行分组概括, 格式为： tapply(X, INDEX, FUN) 其中X是一个向量， INDEX是一个分类变量， FUN是概括统计函数。 比如，下面的程序分性别组计算疗前体积的均值： with( d.cancer, tapply(v0, sex, mean)) ## F M ## 113.2354 108.1214 27.7.2 用aggregate()分组概括数据框 aggregate函数对输入的数据框用指定的分组变量（或交叉分组） 分组进行概括统计。 例如，下面的程序按性别分组计算年龄、疗前体积、疗后体积的平均值: aggregate( d.cancer[, c(&quot;age&quot;, &quot;v0&quot;, &quot;v1&quot;)], list(sex=d.cancer[[&quot;sex&quot;]]), mean, na.rm=TRUE) ## sex age v0 v1 ## 1 F 66.14286 113.2354 42.65538 ## 2 M 63.25000 108.1214 45.95524 aggregate()第一个参数是数据框， 第二个参数是列表，列表元素是用来分组或交叉分组的变量， 第三个参数是概括用的函数， 概括用的函数的选项可以在后面给出。 可以交叉分组后概括，如 with( d.cancer, aggregate( cbind(v0, v1), list(sex=sex, type=type), mean)) ## sex type v0 v1 ## 1 F 鳞癌 126.99250 45.54750 ## 2 M 鳞癌 113.55722 49.65556 ## 3 F 腺癌 107.12111 41.37000 ## 4 M 腺癌 75.50667 23.75333 27.7.3 用split()函数分组后概括 split函数可以把数据框的各行按照一个或几个分组变量分为子集的列表， 然后可以用sapply()或vapply()对每组进行概括。 如 sp &lt;- split(d.cancer[,c(&quot;v0&quot;,&quot;v1&quot;)], d.cancer[[&quot;sex&quot;]]) sapply(sp, colMeans) ## F M ## v0 113.23538 108.12143 ## v1 42.65538 45.95524 返回矩阵，行为变量v0, v1，列为不同性别， 值为相应的变量在各性别组的平均值。 当sapply()对列表每项的操作返回一个向量时， 总是列表每项的输出保存为结果的一列。 colMeans函数计算分组后数据框子集每列的平均值。 27.8 用plyr包进行分类概括 plyr是一个专注于分组后分别分析然后将分析结果尽可能合理地合并的扩展包, 功能强大， dplyr包仅针对数据框，使用更方便，但是对于复杂情况功能不如plyr包强。 plyr包已经被dplyr、purrr包代替，不再继续开发新版本。 这部分内容仅作为备忘， 读者可以跳过。 plyr的输入支持数组、数据框、列表， 输出支持数组、数据框、列表或无输出。 分组分析的函数输出格式需要与指定的输出格式一致。 这里主要介绍从数据框分组概括并将结果保存为数据框的方法， 使用plyr包的ddply()函数。 实际上，dplyr包的这种功能更方便。 plyr包的优点是可以自定义概括函数， 使得结果表格符合用户的预期， 处理多个变量时程序更简洁。 plyr包与dplyr包的函数名冲突比较大， 所以需要先卸载dplyr包再调用plyr包： if(&quot;dplyr&quot; %in% .packages()) detach(&quot;package:dplyr&quot;) library(plyr) ddply()函数第一自变量是要分组的数据框， 第二自变量是分组用的变量名， 第三自变量是一个概括函数， 此概括函数以一个数据框子集（数据类型是数据框）为输入， 输出是一个数值、一个数值型向量或者一个数据框, 但最好是数据框。 例如，按性别分组，计算v0的平均值： ddply(d.cancer, &quot;sex&quot;, function(d) c(mean.v0 = mean(d[[&quot;v0&quot;]], na.rm=TRUE))) 下面的程序按性别分组， 分别计算v0与v1的平均值： ddply(d.cancer, &quot;sex&quot;, function(d) colMeans(d[,c(&quot;v0&quot;, &quot;v1&quot;)])) 下面的程序按性别分组，计算v0和v1的平均值、标准差： f1 &lt;- function(dsub){ tab &lt;- tibble( &quot;变量&quot;=c(&quot;v0&quot;, &quot;v1&quot;), &quot;均值&quot;=c(mean(dsub[,&quot;v0&quot;], na.rm=TRUE), mean(dsub[,&quot;v1&quot;], na.rm=TRUE)), &quot;标准差&quot;=c(sd(dsub[,&quot;v0&quot;], na.rm=TRUE), sd(dsub[,&quot;v1&quot;], na.rm=TRUE))) tab } ddply(d.cancer, &quot;sex&quot;, f1) 注意f1()结果是一个数据框。 程序有些重复内容，对每个变量和每个统计量都需要分别写出， 如果这样用plyr包就不如直接用dplyr::summarise()了。 下面用vapply()简化程序。 按性别分组，然后v0、v1各自一行结果， 计算非缺失值个数、均值、标准差、中位数： f2 &lt;- function(d, variables){ d1 &lt;- d[,variables,drop=FALSE] nnotmiss &lt;- vapply(d1, function(x) sum(!is.na(x)), 1L) xm &lt;- vapply(d1, mean, 0.0, na.rm=TRUE) xsd &lt;- vapply(d1, sd, 1.0, na.rm=TRUE) xmed &lt;- vapply(d1, median, 0.0, na.rm=TRUE) data.frame(variable=variables, n=nnotmiss, mean=xm, sd=xsd, median=xmed) } ddply(d.cancer, &quot;sex&quot;, f2, variables = c(&quot;v0&quot;, &quot;v1&quot;)) f2()函数针对分组后的数据框子集， 这样的函数可以先在一个子集上试验。 在f2()函数中， 设输入的数据子集为d， 要分析的变量组成的数据框为d1， 用vapply()函数对d1的每一列计算一种统计量， 然后将每种统计量作为结果数据框的一列。 vapply()函数类似于lapply()和sapply()， 但是用第三个自变量表示要应用的变换函数的返回值类型和个数， 用举例的方法给出。 ddply()也可以对交叉分类后每个类分别汇总， 例如按照性别与病理类型交叉分组后汇总v0、v1： ddply(d.cancer, c(&quot;sex&quot;, &quot;type&quot;), f2, variables=c(&quot;v0&quot;, &quot;v1&quot;)) 上面的程序写法适用于已知要分析的变量名的情况。 如果想对每个数值型变量都分析， 而且想把要计算的统计量用统一的格式调用，可以写成： f3 &lt;- function(d){ ff &lt;- function(x){ c(n=sum(!is.na(x)), each(mean, sd, median)(x, na.rm=TRUE)) } ldply(Filter(is.numeric, d), ff) } ddply(d.cancer, &quot;sex&quot;, f3) ff()函数对输入的一个数值型向量计算4种统计量， 返回一个长度为4的数值型向量， 用来对分组后的数据子集中的一列计算4种统计量。 plyr包的each()函数接受多个函数， 返回一个函数可以同时得到这几个函数的结果， 结果中各元素用输入的函数名命名。 f3()函数中的Filter函数用于从列表或数据框中取出满足条件的项， 这里取出输入的数据子集d中所有的数值型列。 f3()函数中的ldply()函数接受一个列表或看成列表的一个数据框， 对数据框的每列应用ff()函数计算4种统计量， 然后合并所有各列的统计量为一个数据框， 结果数据框的每行对应于d中的一列。 程序中的ddply()函数接受一个数据框， 第二自变量指定用来将数据框分组的变量， 第三自变量f3()是对分组后的数据框子集进行分析的函数， 此函数接受一个数据框，输出一个数据框。 上面的程序也可以利用无名函数写成： f4 &lt;- function(x){ c(n=sum(!is.na(x)), each(mean, sd, median)(x, na.rm=TRUE)) } ddply(d.cancer, &quot;sex&quot;, function(d) ldply(Filter(is.numeric, d), f4)) 27.9 练习 把patients.csv读入“d.patients”中， 并计算发病年龄、发病年、发病月、 发病年月（格式如“200702”表示2007年2月份）。 把“现住地址国标”作为字符型，去掉最后两位，仅保留前6位数字， 保存到变量“地址编码”中。 按照地址编码和发病年月交叉分类汇总发病人数， 保存到数据框d.pas1中， 然后保存为CSV文件“分区分年月统计.csv”中。 要求结果有三列：“地址编码”、“发病年月”、“发病人数”。 按照地址编码和发病月分类汇总发病人数， 保存到数据框d.pas2中， 然后保存为CSV文件“分区分月统计.csv”中。 要求每个地址编码占一行， 各列为地址编码以及1、2、…………、12各月份， 每行为同一地址编码各月份的发病数。 按发病年月和性别汇总发病人数， 并计算同年月不分性别的发病总人数。 结果保存到数据框d.pas3中， 然后保存到CSV文件“分年月分性别统计.csv”中。 要求每个不同年月占一行， 变量包括年月、男性发病数、女性发病数、总计。 分析病人的职业分布，保存到数据框d.pas4中， 然后保存到CSV文件“职业构成.csv”中。 要求各列为职业、发病人数、百分比（结果乘以100并保留一位小数）。 把年龄分成0—9, 11—19, ……, 70以上各段， 保存为“年龄段”变量。 用年龄段和性别交叉汇总发病人数和百分比(结果乘以100并保留一位小数)， 保存到“年龄性别分布.csv”中。 要求将每个年龄段的男性发病人数、发病率、女性发病人数、发病率存为一行。 "],["graph.html", "28 基本R绘图 28.1 常用高级图形 28.2 低级图形函数 28.3 图形参数 28.4 图形输出 28.5 包含多种中文字体的图形 28.6 其它图形", " 28 基本R绘图 R语言的前身是S语言， S语言的设计目的就是交互式数据分析、绘图。 所以绘图是R的重要功能。 R有最初的基本绘图， 这是从S语言继承过来的， 还有一些功能更易用、更强大的绘图系统， 如lattice、ggplot2。 基本绘图使用简单， 灵活性强， 但是为了做出满意的图形需要比较多的调整。 这里先讲解R语言的基本绘图功能。 R的基本绘图功能有两类图形函数： 高级图形函数， 直接针对某一绘图任务作出完整图形； 低级图形函数，在已有图形上添加内容。 具备有限的与图形交互的能力（函数locator 和identify）。 28.1 常用高级图形 28.1.1 条形图 d.cancer数据框包含了肺癌病人放疗的一些数据， 从cancer.csv读入： d.cancer &lt;- readr::read_csv(&quot;cancer.csv&quot;, locale=locale(encoding=&quot;GBK&quot;)) ## Parsed with column specification: ## cols( ## id = col_double(), ## age = col_double(), ## sex = col_character(), ## type = col_character(), ## v0 = col_double(), ## v1 = col_double() ## ) 统计男女个数并用条形图表示： res1 &lt;- table(d.cancer[,&#39;sex&#39;]); print(res1) ## ## F M ## 13 21 barplot(res1) 可以增加标题，采用不同的颜色： barplot(res1, main=&quot;性别分布&quot;, col=c(&quot;brown2&quot;, &quot;aquamarine1&quot;)) R函数colors()可以返回R中定义的用字符串表示的六百多种颜色名字。 如 head(colors(), 6) ## [1] &quot;white&quot; &quot;aliceblue&quot; &quot;antiquewhite&quot; &quot;antiquewhite1&quot; ## [5] &quot;antiquewhite2&quot; &quot;antiquewhite3&quot; 下面的函数可以用来挑选颜色， 鼠标点击画出的颜色就可以挑选， 结果返回挑选出的颜色名： select.colors &lt;- function(){ nc &lt;- length(colors()) x &lt;- rep(seq(26), 26)[1:nc] y &lt;- rep(seq(26), each=26)[1:nc] cols &lt;- colors() plot(x, y, type=&quot;p&quot;, pch=16, cex=2, col=cols) res &lt;- cols[identify(x,y, labels=cols)] res } 用width选项与xlim选项配合可以调整条形宽度，如 barplot(res1, width=0.5, xlim=c(-3, 5), main=&quot;性别分布&quot;, col=c(&quot;brown2&quot;, &quot;aquamarine1&quot;)) 按性别与病理类型交叉分组后统计频数，结果称为列联表： res2 &lt;- with(d.cancer, table(sex, type)); res2 ## type ## sex 鳞癌 腺癌 ## F 4 9 ## M 18 3 用分段条形图表现交叉分组频数， 交叉频数表每列为一条： barplot(res2, legend=TRUE) 用并排条形图表现交叉分组频数， 交叉频数表每列为一组： barplot(res2, beside=TRUE, legend=TRUE) 增加标题，指定颜色，调整图例位置，调整条形宽度： barplot(res2, beside=TRUE, legend=TRUE, main=&#39;不同种类病人的性别&#39;, ylim=c(0, 20), xlim=c(-1, 6), width=0.6, col=c(&quot;brown2&quot;, &quot;aquamarine1&quot;)) 28.1.2 直方图和密度估计图 用hist作直方图以了解连续取值变量分布情况。 例如，下面的程序模拟正态分布数据并做直方图： x &lt;- rnorm(30, mean=100, sd=1) print(round(x,2)) ## [1] 99.97 100.08 99.80 101.57 102.29 98.88 101.85 98.54 98.70 97.87 ## [11] 99.17 99.54 100.25 100.22 101.47 101.93 98.63 100.37 99.64 99.71 ## [21] 101.54 101.23 100.12 98.98 100.83 102.25 98.98 100.57 99.39 99.98 hist(x) 可以用main=、xlab=、ylab=等选项， 可以用col=指定各个条形的颜色，如： hist(x, col=rainbow(15), main=&#39;正态随机数&#39;, xlab=&#39;&#39;, ylab=&#39;频数&#39;) 函数density()估计核密度。 下面的程序作直方图， 并添加核密度曲线： tmp.dens &lt;- density(x) hist(x, freq=FALSE, ylim=c(0,max(tmp.dens$y)), col=rainbow(15), main=&#39;正态随机数&#39;, xlab=&#39;&#39;, ylab=&#39;频数&#39;) lines(tmp.dens, lwd=2, col=&#39;blue&#39;) 28.1.3 盒形图 盒形图可以简洁地表现变量分布，如 with(d.cancer, boxplot(v0)) 其中中间粗线是中位数， 盒子上下边缘是\\(\\frac{3}{4}\\)和\\(\\frac{1}{4}\\)分位数， 两条触须线延伸到取值区域的边缘。 盒形图可以很容易地比较两组或多组，如 with(d.cancer, boxplot(v0 ~ sex)) 也可以画若干个变量的并排盒形图，如 with(d.cancer, boxplot(list(&#39;疗前&#39;=v0, &#39;疗后&#39;=v1))) 28.1.4 正态QQ图 用qqnorm和qqline作正态QQ图。 当变量样本来自正态分布总体时， 正态QQ图的散点近似在一条直线周围。 QQ图一般作法如下： 设有\\(n\\)个观测\\(y_1\\), \\(y_2\\), , \\(y_n\\), 并已从小到大排列, 则\\(y_i\\) 是总体的\\(i/n\\)分位数的估计, 设\\(x_i\\) 是标准正态分布的\\(i/n\\)分位数, 则在样本来自正态\\(N(\\mu, \\sigma^2)\\) 的情况下, 记\\(N(\\mu, \\sigma^2)\\) 的分布函数为\\(F(x)\\)， 有\\(y_i \\approx F^{-1}(\\frac{i}{n})\\), \\(F(y_i)=\\Phi(\\frac{y_i-\\mu}{\\sigma}) \\approx \\frac{i}{n}\\), \\(\\frac{y_i-\\mu}{\\sigma} \\approx \\Phi^{-1}(\\frac{i}{n}) = x_i\\), \\(y_i \\approx \\mu + \\sigma x_i\\)， 于是用\\((x_i, y_i)\\) (\\(i=1, 2, \\ldots, n\\))作为坐标画散点图应该近似呈现为截距\\(\\mu\\)、 斜率 \\(\\sigma\\) 的一条直线。 但是, 上述的近似有一个小缺点: \\(y_1\\) 是观测到的最小值, 对应于\\(1/n\\)分位数, \\(y_n\\)是观测到的最大值, 却对应于 \\(n / n = 100\\%\\) 分位数, 对最小和最大值的处理不对称, 相当于说总体分布不能超过\\(y_n\\), 这是不合理的。 所以在实际画正态QQ图时, \\(y_i\\)不是对应于标准正态的\\(i/n\\)分位数而是对应于略调整的如\\((i-0.375)/(n+0.25)\\)这样的分位数, 这种做法叫做连续性修正。 这时, \\(y_1\\)对应于\\(\\frac{0.625}{n+0.25}\\)分位数而 \\(y_n\\)对应于\\(1 - \\frac{0.625}{n+0.25}\\)分位数, 两边各留了\\(\\frac{0.625}{n+0.25}\\)。 下面的程序模拟正态分布随机数，并作正态QQ图: qqnorm(x) qqline(x, lwd=2, col=&#39;blue&#39;) 下面的程序模拟对数正态数据，并作正态QQ图: z &lt;- 10^rnorm(30, mean=0, sd=0.2) qqnorm(z) qqline(z, lwd=2, col=&#39;blue&#39;) 28.1.5 散点图 以d.class数据为例， 有name, sex, age, height, weight等变量。 从class.csv读入： d.class &lt;- read_csv(&quot;class.csv&quot;) ## Parsed with column specification: ## cols( ## name = col_character(), ## sex = col_character(), ## age = col_double(), ## height = col_double(), ## weight = col_double() ## ) 体重对身高的散点图： plot(d.class$height, d.class$weight) 用with()函数简化数据框变量访问格式: with(d.class, plot(height, weight)) 在plot()函数内用main参数增加标题， 用xlab参数指定横轴标注， 用ylab参数指定纵轴标注，如 with(d.class, plot(height, weight, main=&#39;体重与身高关系&#39;, xlab=&#39;身高&#39;, ylab=&#39;体重&#39;)) 用pch参数指定不同散点形状，用col参数指定颜色， 用cex参数指定大小，如： with(d.class, plot(height, weight, pch=16, col=&#39;blue&#39;, cex=2)) 用气泡大小表现第三维（年龄）： with(d.class, plot(height, weight, pch=16, col=&#39;blue&#39;, cex=1 + (age - min(age))/(max(age)-min(age)))) 用气泡大小表现年龄， 用颜色区分性别： with(d.class, plot(height, weight, main=&#39;体重与身高关系&#39;, xlab=&#39;身高&#39;, ylab=&#39;体重&#39;, pch=16, col=ifelse(sex==&#39;M&#39;, &#39;blue&#39;, &#39;red&#39;), cex=1 + (age - min(age)) /(max(age)-min(age)))) 用pairs()函数可以做散点图矩阵： pairs(d.class[, c(&#39;age&#39;, &#39;height&#39;, &#39;weight&#39;)]) 28.1.6 曲线图 curve()函数接受一个函数， 或者一个以x为变量的表达式， 以及曲线的自变量的左、右端点， 绘制函数或者表达式的曲线图，如： curve(1 - 3*x - x^2, -4, 2) 又如： curve(sin, -2*pi, 2*pi) 在plot函数中使用 type=’l’参数可以作曲线图， 如 x &lt;- seq(0, 2*pi, length=200) y &lt;- sin(x) plot(x,y, type=&#39;l&#39;) 除了仍可以用main, xlab, ylab, col等参数外， 还可以用lwd指定线宽度， lty指定虚线，如 plot(x,y, type=&#39;l&#39;, lwd=2, lty=3) 多条曲线， 可以用matplot()函数。例如 x &lt;- seq(0, 2*pi, length=200) y1 &lt;- sin(x) y2 &lt;- cos(x) matplot(x, cbind(y1, y2), type=&#39;l&#39;, lty=1, lwd=2, col=c(&quot;red&quot;, &quot;blue&quot;), xlab=&quot;x&quot;, ylab=&quot;&quot;) abline(h=0, col=&#39;gray&#39;) 28.1.7 三维图 用persp函数作三维曲面图, contour作等值线图， image作色块图。 坐标x和y构成一张平面网格， 数据z是包含z坐标的矩阵，每行对应一个横坐标， 每列对应一个纵坐标。 下面的程序生成二元正态分布密度曲面数据： x &lt;- seq(-3,3, length=100) y &lt;- x f &lt;- function(x,y,ssq1=1, ssq2=2, rho=0.5){ det1 &lt;- ssq1*ssq2*(1 - rho^2) s1 &lt;- sqrt(ssq1) s2 &lt;- sqrt(ssq2) 1/(2*pi*sqrt(det1)) * exp(-0.5 / det1 * ( ssq2*x^2 + ssq1*y^2 - 2*rho*s1*s2*x*y)) } z &lt;- outer(x, y, f) 作二元正态密度函数的三维曲面图、等高线图、色块图: persp(x, y, z) contour(x, y, z) image(x, y, z) 28.1.8 动态三维图 rgl包能制作动态的三维散点图与曲面图。 library(rgl) iris数据框包含了3种鸢尾花的各50个样品的测量值， 测量值包括花萼长、宽， 花瓣长、宽。 用rgl的plot3d()作动态三维散点图如下： with(iris, plot3d( Sepal.Length, Sepal.Width, Petal.Length, type=&quot;s&quot;, col=as.numeric(Species))) 这个图可以用鼠标拖动旋转。 其中type=\"s\"表示绘点符号是球体形状。 还可选\"p\"(点)、\"l\"(连线)、\"h\"(向z=0连线)。 可以用size=指定大小倍数（缺省值为3）。 用rgl的persp3d()函数作曲面图。 如 二元正态分布密度曲面： x &lt;- seq(-3,3, length=100) y &lt;- x f &lt;- function(x,y,ssq1=1, ssq2=2, rho=0.5){ det1 &lt;- ssq1*ssq2*(1 - rho^2) s1 &lt;- sqrt(ssq1) s2 &lt;- sqrt(ssq2) 1/(2*pi*sqrt(det1)) * exp(-0.5 / det1 * ( ssq2*x^2 + ssq1*y^2 - 2*rho*s1*s2*x*y)) } z &lt;- outer(x, y, f) persp3d(x=x, y=y, z=z, col=&#39;red&#39;) rgl也有低级图形函数支持向已有图形添加物体、文字等， 也支持并列多图。 适当设置可以在R Markdown生成的HTML结果中动态显示三维图。 28.2 低级图形函数 28.2.1 abline() 用abline函数在图中增加直线。 可以指定截距和斜率， 或为竖线指定横坐标(用参数v)， 为水平线指定纵坐标(用参数h)。 如 with(d.class, plot(height, weight)) abline(-143, 3.9, col=&quot;red&quot;, lwd=2) abline(v=c(55,60,65,70), col=&quot;gray&quot;) abline(h=c(60,80,100,120,140), col=&quot;gray&quot;) 28.2.2 points() 用points函数增加散点，如： x &lt;- seq(0, 2*pi, length=200) y &lt;- sin(x) special &lt;- list(x=(0:4)*pi/2, y=sin((0:4)*pi/2)) plot(x, y, type=&#39;l&#39;) points(special$x, special$y, col=&quot;red&quot;, pch=16, cex=2) points(special, col=&quot;red&quot;, pch=16, cex=2) 28.2.3 lines() 用lines函数增加曲线，如： x &lt;- seq(0, 2*pi, length=200) y1 &lt;- sin(x) y2 &lt;- cos(x) plot(x, y1, type=&#39;l&#39;, lwd=2, col=&quot;red&quot;) lines(x, y2, lwd=2, col=&quot;blue&quot;) abline(h=0, col=&#39;gray&#39;) 28.2.4 图例 可以用legend函数增加标注，如 x &lt;- seq(0, 2*pi, length=200) y1 &lt;- sin(x) y2 &lt;- cos(x) plot(x, y1, type=&#39;l&#39;, lwd=2, col=&quot;red&quot;) lines(x, y2, lwd=2, col=&quot;blue&quot;) abline(h=0, col=&#39;gray&#39;) legend(0, -0.5, col=c(&quot;red&quot;, &quot;blue&quot;), lty=c(1,1), lwd=c(2,2), legend=c(&quot;sin&quot;, &quot;cos&quot;)) x &lt;- seq(0, 2*pi, length=200) y1 &lt;- sin(x) y2 &lt;- cos(x) plot(x, y1, type=&#39;l&#39;, lwd=2, col=&quot;red&quot;) lines(x, y2, lwd=2, col=&quot;blue&quot;) abline(h=0, col=&#39;gray&#39;) legend(&#39;top&#39;, col=c(&quot;red&quot;, &quot;blue&quot;), lty=c(1,1), lwd=c(2,2), legend=c(&quot;sin&quot;, &quot;cos&quot;)) 28.2.5 axis() 在plot()函数中用 axes=FALSE可以取消自动的坐标轴。 用box()函数画坐标边框。 用axis函数单独绘制坐标轴。 axis的第一个参数取1，2，3，4， 分别表示横轴、纵轴、上方和右方。 axis的参数at为 刻度线位置，labels为标签。 如 x &lt;- c(&#39;一月&#39;=15, &#39;二月&#39;=20, &#39;三月&#39;=18, &#39;四月&#39;=22) plot(seq(along=x), x, axes=FALSE, type=&#39;b&#39;, lwd=3, main=&#39;前四个月销售额&#39;, xlab=&#39;&#39;, ylab=&#39;销售额&#39;) box(); axis(2) axis(1, at=seq(along=x), labels=names(x)) R基本绘图支持少量的数学公式显示功能，如不用数学符号时： x &lt;- seq(0, 2*pi, length=200) y1 &lt;- sin(x) plot(x, y1, type=&#39;l&#39;, lwd=2, axes=FALSE, xlab=&#39;x&#39;, ylab=&#39;&#39;) abline(h=0, col=&#39;gray&#39;) box() axis(2) axis(1, at=(0:4)/2*pi, labels=c(&#39;0&#39;, &#39;pi/2&#39;, &#39;pi&#39;, &#39;3pi/2&#39;, &#39;2pi&#39;)) 使用数学符号时： x &lt;- seq(0, 2*pi, length=200) y1 &lt;- sin(x) plot(x, y1, type=&#39;l&#39;, lwd=2, axes=FALSE, xlab=&#39;x&#39;, ylab=&#39;&#39;) abline(h=0, col=&#39;gray&#39;) box() axis(2) axis(1, at=(0:4)/2*pi, labels=c(0, expression(pi/2), expression(pi), expression(3*pi/2), expression(2*pi))) 绘图中使用数学符号的演示： demo(plotmath) 28.2.6 text() text()在坐标区域内添加文字。 mtext()在边空处添加文字。 如 with(d.class, plot(height, weight)) lm1 &lt;- lm(weight ~ height, data=d.class) abline(lm1, col=&#39;red&#39;, lwd=2) a &lt;- coef(lm1)[1] b &lt;- coef(lm1)[2] text(52, 145, adj=0, &#39;线性回归:&#39;) text(52, 140, adj=0, substitute(hat(y) == a + b*x, list(a=round(coef(lm1)[1], 2), b=round(coef(lm1)[2], 2)))) 28.2.7 locator()和identify() locator()函数在执行时等待用户在图形的坐标区域内点击并返回点击处的坐标。 可以用参数n指定要点击的点的个数。 不指定个数则需要用右键菜单退出。 这个函数也可以用来要求用户点击以进行到下一图形。 如 x &lt;- seq(0, 2*pi, length=200) y1 &lt;- sin(x); y2 &lt;- cos(x) plot(x, y1, type=&#39;l&#39;, col=&quot;red&quot;) lines(x, y2, col=&quot;blue&quot;) legend(locator(1), col=c(&quot;red&quot;, &quot;blue&quot;), lty=c(1,1), legend=c(&quot;sin&quot;, &quot;cos&quot;)) identify()可以识别点击处的点并标注标签， 格式为identify(x, y, labels)， 其中(x,y)给出可点击的点的坐标， labels是每个点对应的标签， 点击那个点就在那个点旁边标对应的标签。 28.3 图形参数 用图形参数可以选择点的形状、颜色、线型、粗细、坐标轴做法、边空、一页多图等。 有些参数直接用在绘图函数内，如plot函数可以用 pch、col、cex、lty、 lwd等参数。 有些图形参数必须使用par()函数指定。 par函数指定图形参数并返回原来的参数值， 所以在修改参数值作图后通常应该恢复原始参数值， 做法如 opar &lt;- par(mfrow=c(2,2)) with(d.class, {hist(height); boxplot(height); qqnorm(height); qqline(height); plot(height); rug(height,side=2)}) par(opar) 在函数内，可以在函数开头修改了图形参数后， 用on.exit()函数将恢复原始图形参数作为函数退出前必须完成的任务，如 f &lt;- function(){ opar &lt;- par(mfrow=c(2,2)); on.exit(par(opar)) with( d.class, {hist(height); boxplot(height); qqnorm(height); qqline(height); plot(height); rug(height,side=2) }) } f() 28.3.1 例子：用图形参数解决barplot图形横坐标值过宽 barplot的横坐标标注太宽时，自动将某些标注省略。 用las=2指定坐标轴刻度标签垂直于坐标轴， 这样x轴的刻度值就变成了纵向的。 注意使用mar参数增加横坐标边空大小。 例如 f &lt;- function(){ opar &lt;- par(mar=c(8, 4, 2, 0.5)); on.exit(par(opar)) x &lt;- 1:10 names(x) &lt;- paste(10000000000 + (1:10)) barplot(x, las=2) } f() 图形参数可以分为如下四类 图形元素控制； 坐标轴与坐标刻度； 图形边空； 一页多图。 28.3.2 图形元素控制 pch=16参数。散点符号，取\\(0\\sim 18\\)的数。 lty=2参数。线型，1为实线，从2开始为各种虚线。 lwd=2参数，线的粗细，标准粗细为1。 col=\"red\"参数，颜色，可以是数字\\(1\\sim 8\\)， 或颜色名字符串如\"red\"，\"blue\"等。 用colors()函数查询有名字的颜色。 用rainbow(n)函数产生连续变化的颜色。 font=2参数，字体，一般font=1是正体,2是粗体, 3是斜体,4是粗斜体。 adj=-0.1指定文本相对于给定坐标的对齐方式。 取0表示左对齐,取1表示右对齐,取0.5表示居中。 此参数的值实际代表的是出现在给定坐标左边的文本的比例。 cex=1.5 绘点符号大小倍数，基本值为1。 28.3.3 坐标轴与坐标刻度 mgp=c(3,1,0) 坐标轴的标签、刻度值、坐标轴线 到实际的坐标轴位置的距离，以行高为单位。 经常用来缩小坐标轴所占的空间, 如mgp=c(1.5, 0.5, 0)。 lab=c(5,7,12) 提供刻度线多少的建议， 第一个数为x轴刻度线个数， 第二个数为y轴刻度线个数， 第三个数是坐标刻度标签的字符宽度。 las=1 坐标刻度标签的方向。 0表示总是平行于坐标轴, 1表示总是水平, 2表示总是垂直于坐标轴。 tck=0.01 坐标轴刻度线长度，以绘图区域大小为单位1。 xaxs=\"s\", yaxs=\"e\": 控制x轴和y轴标刻度的方法。 取\"s\"(即standard)或\"e\"(即extended) 的时候数据范围控制在最小刻度和最大刻度之间。 取\"e\"时如果有数据点十分靠近边缘轴的范围会略微扩大。 取值为\"i\"（即internal）或\"r\"（此为缺省） 使得刻度线都落在数据范围内部,而\"r\"方式所留的边空较小。 取值设为\"d\"时会锁定此坐标轴, 后续的图形都使用与它完全相同的坐标轴, 这在要生成一系列可比较的图形的时候是有用的。 要解除锁定需要把这个图形参数设为其它值。 28.3.4 图形边空 一个单独的图由绘图区域(绘图的点、线等画在这个区域中)和包围绘图区域的边空组成, 边空中可以包含坐标轴标签、坐标轴刻度标签、标题、小标题等, 绘图区域一般被坐标轴包围。 边空的大小由mai参数或mar参数控制, 它们都是四个元素的向量, 分别规定下方、左方、上方、右方的边空大小, 其中mai取值的单位是英寸, 而mar的取值单位是文本行高度。 例如： opar &lt;- par(mar=c(2,2,0.5,0.5), mgp=c(0.5, 0.5, 0), tck=0.005) with(d.class, plot(height, weight, xlab=&#39;&#39;, ylab=&#39;&#39;)) par(opar) 28.3.5 一页多图 R可以在同一页面开若干个按行、列排列的窗格, 在每个窗格中可以作一幅图。 每个图有自己的内边空, 而所有图的外面可以包一个“外边空”。 一页多图用mfrow参数或mfcol参数规定。 用oma指定四个外边空的行数。 用mtext加outer=T指定在外边空添加文本。 如果没有outer=T则在内边空添加文本。 如 opar &lt;- par(mfrow=c(2,2), oma=c(0,0,2,0)) with(d.class, {hist(height); boxplot(height); qqnorm(height); qqline(height); plot(height); rug(height,side=2)}) mtext(side=3, text=&#39;身高分布&#39;, cex=2, outer=T) par(opar) 28.4 图形输出 只要启用了高级绘图函数会自动选用当前绘图设备， 缺省为屏幕窗口。 28.4.1 PDF 输出 用pdf函数可以指定输出到PDF文件。如 pdf(file=&#39;fig-hw.pdf&#39;, height=10/2.54, width=10/2.54, family=&#39;GB1&#39;) with(d.class, plot(height, weight, main=&#39;体重与身高关系&#39;)) dev.off() 用dev.off()关闭当前设备并生成输出文件 （如果是屏幕窗口则没有保存结果）。 28.4.2 PNG输出 png(file=&#39;fig-hw.png&#39;, height=1000, width=1000) with(d.class, plot(height, weight, main=&#39;体重与身高关系&#39;)) dev.off() 类似地， 用jpeg()函数启用JPEG图形设备, 用bmp()函数启用BMP图形设备, 用postscript()函数启用PostScript图形设备。 28.5 包含多种中文字体的图形 为了使用MS Windows系统字体， 一种办法是安装showtext包。 该包替换画图时的添加文本函数命令， 把文本内容替换成多边形（PDF或PS图）或点阵（点阵图）。 需要的工作： 查看Windows的font目录内容，看文件名与字体名的对应关系。 下面的程序中的列表是我的中文Windows 10的部分中文字体。 找到自己希望使用的中文字体的文件名。 用font.add()命令，增加一套自定义字体family， 一套中可以指定四种：常规(regular), 粗体(bold), 斜体(italic), 粗斜体(bolditalic) 程序中调入showtext包并运行showtext.auto()命令，这个命令使得文本命令采用showtext包 用par(family=)指定自定义的字体family。 作图（主要是PDF）。关闭图形设备。 test.chinese &lt;- function(){ require(showtext); showtext.auto() ## 建立文件名到字体名对照表 fmap &lt;- c( &#39;msyh&#39;=&#39;微软雅黑常规&#39;, &#39;msyhbd&#39;=&#39;微软雅黑粗体&#39;, &#39;msyhl&#39;=&#39;微软雅黑细体&#39;, &#39;simsun&#39;=&#39;宋体&#39;, &#39;simfang&#39;=&#39;仿宋&#39;, &#39;simkai&#39;=&#39;楷体&#39;, &#39;simhei&#39;=&#39;黑体&#39;, &#39;SIMLI&#39;=&#39;隶书&#39;, &#39;SIMYOU&#39;=&#39;幼圆&#39;, &#39;STSONG&#39;=&#39;华文宋体&#39;, &#39;STZHONGS&#39;=&#39;华文中宋&#39;, &#39;STFANGSO&#39;=&#39;华文仿宋&#39;, &#39;STKAITI&#39;=&#39;华文楷体&#39;, &#39;STXIHEI&#39;=&#39;华文细黑&#39;, &#39;STLITI&#39;=&#39;华文隶书&#39;, &#39;STXINGKA&#39;=&#39;华文行楷&#39;, &#39;STXINWEI&#39;=&#39;华文新魏&#39;, &#39;STCAIYUN&#39;=&#39;华文彩云&#39;, &#39;STHUPO&#39;=&#39;华文琥珀&#39; ) fmapr &lt;- names(fmap); names(fmapr) &lt;- unname(fmap) cat(&#39;==== 字体文件名与字体名称对应:\\n&#39;) print(fmap) cat(&#39;==== 字体名与字体文件名对应:\\n&#39;) print(fmapr) ## 找到某个字体的字体文件 ## font.name是字体名称 find.font &lt;- function(font.name){ fname &lt;- fmapr[font.name] flist0 &lt;- font.files() flist1 &lt;- sapply(strsplit(flist0, &#39;[.]&#39;), function(it) it[1]) flist0[flist1==fname] } ff1 &lt;- find.font(&#39;宋体&#39;) ff2 &lt;- find.font(&#39;黑体&#39;) ff3 &lt;- find.font(&#39;仿宋&#39;) ff4 &lt;- find.font(&#39;隶书&#39;); font.add(&#39;cjk4&#39;, regular=ff1, bold=ff2, italic=ff3, bolditalic=ff4) ##browser() pdf(&#39;test-chinese.pdf&#39;); on.exit(dev.off()) par(family=&#39;cjk4&#39;) plot(c(0,1), c(0,1), type=&#39;n&#39;, axes=FALSE, xlab=&#39;&#39;, ylab=&#39;&#39;) text(0.1, 0.9, &#39;正体&#39;, font=1) text(0.1, 0.8, &#39;粗体&#39;, font=2) text(0.1, 0.7, &#39;斜体&#39;, font=3) text(0.1, 0.6, &#39;粗斜体&#39;, font=4) } test.chinese() 注意：图形参数font=1表示正体， font=2表示粗体, font=3表示斜体, font=4表示粗斜体。 28.6 其它图形 28.6.1 相关系数图 用cor(x)可以计算数据框x的各列的相关系数阵。 corrgram包的corrgram()函数可以将相关系数阵用图形表示， 系数绝对值大小用色块颜色深浅表示， 正负用两种颜色区分。 例如， 计算iris数据框中四个测量值的相关系数并用矩阵表示： library(corrgram) ## Registered S3 method overwritten by &#39;seriation&#39;: ## method from ## reorder.hclust gclus R.iris &lt;- cor(iris[,1:4]) print(round(R.iris, 2)) ## Sepal.Length Sepal.Width Petal.Length Petal.Width ## Sepal.Length 1.00 -0.12 0.87 0.82 ## Sepal.Width -0.12 1.00 -0.43 -0.37 ## Petal.Length 0.87 -0.43 1.00 0.96 ## Petal.Width 0.82 -0.37 0.96 1.00 corrgram( R.iris, order=TRUE, lower.panel=panel.shade, upper.panel = panel.pie, text.panel = panel.txt ) 左下方用颜色代表正负相关， 蓝色为正相关，红色为负相关， 可以看出花萼长(Sepal.Length)、花瓣宽(Petal.Width)和花瓣长(Petal.Length)相互为较强的正相关， 但是花萼宽与其它三个变量为负相关。 这个相关结果实际是虚假的， 因为样本不是单一总体而是来自三个总体。 图形右上方用阴影部分大小和颜色深度代表相关系数绝对值， 用颜色区分正负。 "],["ggplot2.html", "29 ggplot作图入门 29.1 介绍 29.2 作图的一般原则 29.3 散点图：ggplot入门 29.4 折线图、分组、小图 29.5 数据变换与条形图 29.6 直方图与密度估计 29.7 绘图语法介绍 29.8 更多图形种类 29.9 刻度(scale) 29.10 如何使用颜色 29.11 标题、标注、指南、拼接 29.12 图形定制调整 29.13 主题 29.14 参考文献", " 29 ggplot作图入门 29.1 介绍 Hadley Wickem的ggplot2包是R的一个作图用的扩展包， 它实现了“图形的语法”， 将一个作图任务分解为若干个子任务， 只要完成各个子任务就可以完成作图。 在作常用的图形时， 只需要两个步骤： 首先将图形所展现的数据输入到ggplot()函数中， 然后调用某个geom_xxx()函数， 指定图形类型，如散点图、曲线图、盒形图等。 如果需要进一步控制图形细节， 只要继续调用其它函数， 就可以控制变量值的表现方式(scale)、图例、配色等。 这使得我们很容易做出基本的图形， 在有需要时再深入学习， 做出更为满意的图形。 与基本R中的作图系统相比， ggplot2的作图有规律可循， 作图结果直接达到出版印刷质量， 除了可以按照一些既定模式做出常见种类的图形， 也很容易将不同图形种类组合在一起， 或者设计新颖的图形。 基本R的作图结果通常不够美观， 如果要将不同种类图形组合在一起比较困难， 对设计新的图形类型支持也不够好。 ggplot2的作图一般步骤为： 准备数据，一般为数据框， 且一般为长表， 即每个观测时间占一行， 每个观测变量占一列。 将数据输入到ggplot()函数中， 并指定参与作图的每个变量分别映射到哪些图形特性， 比如映射为x坐标、y坐标、颜色、形状等。 这些映射称为aesthetic mappings或aesthetics。 选择一个合适的图形类型， 函数名以geom_开头， 如geom_point()表示散点图。 图形类型简称为geom。 将ggplot()部分与geom_xxx()部分用加号连接。 到此已经可以作图，下面的步骤是进一步的细化设定。 设定适当的坐标系统， 如coord_cartesian(), scale_x_log10()等。 仍用加号连接。 设定标题和图例位置等，如labs()。 仍用加号连接。 这个流程的一个大致的模板为： p &lt;- ggplot(data=&lt;输入数据框&gt;, mapping=aes(&lt;维度&gt;=&lt;变量名&gt;, &lt;维度&gt;=&lt;变量名&gt;, &lt;...&gt;)) p + geom_&lt;图形类型&gt;(&lt;...&gt;) + scale_&lt;映射&gt;_&lt;类型&gt;(&lt;...&gt;) + coord_&lt;类型&gt;(&lt;...&gt;) + labs(&lt;...&gt;) 其中&lt;...&gt;表示额外的选项。 变量p包含做出的图形的所有数据与设定， 变量名可以任意取。 本章内容主要来自： Healy, Kieran (2018). Data Visualization: A Practical Introduction. Princeton University Press. https://socviz.co/index.html 这本书讲了R的ggplot的使用， 也讲了一些可视化的一般性原则。 Claus O. Wilke(2019). Fundamentals of Data Visualization. O’Reilly Media. https://serialmentor.com/dataviz/ 这本书虽然也使用R的ggplot2包， 但正文中没有代码， 主要讲作图有哪些考虑、各种图形类型。 代码在github上可下载。 Winston Chang(2018). R Graphics Cookbook. O’Relly Media. 网站：https://r-graphics.org/ 为第二版。 讲了各种图的R程序。 Wickham, Hadley (2016). Ggplot2: Elegant graphics for data analysis. New York: Springer. RStudio的ggplot2概览： data-visualization-2.1.pdf ggplot2的扩展汇集：http://www.ggplot2-exts.org/gallery/ Wickham的书主要需要安装tidyverse扩展包， 安装时会自动安装其它一些有关扩展包。 Healy的的书需要通过如下程序安装socviz软件包： devtools::install_github(&quot;kjhealy/socviz&quot;) 后续的例子中用到一些数据集: 来自gapminder扩展包的gapminder数据集， 有若干个国家不同年份的一些数据， 包括所属洲、期望寿命、人口数、人均GDP。 有1704个观测和6个变量。 socviz包的gss_sm数据集，是2016年美国一般社会调查数据的部分内容。 有2867个观测，32个变量。 社会调查数据的变量主要取属性值， 比如无序分类、有序分类、分组的数值、整数值等。 socviz包的organdata数据集， 是17个OECD国家历年的器官捐献情况以及一些其它记录。 socviz扩展包的elections_historic数据集。 包括美国历次总统大选当选人、所属党派、支持比例等。 socviz扩展包的asasec数据集。 这是美国社会学学会(ASA)的各分会2005年到2015年的一些数据。 ggplot2包中的midwest数据集包含了美国中西部的一些县的统计数据， 如面积等。 来自ggplot2包的钻石数据集。 gapminder的头部： library(gapminder) head(gapminder, 20) ## # A tibble: 20 x 6 ## country continent year lifeExp pop gdpPercap ## &lt;fct&gt; &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; ## 1 Afghanistan Asia 1952 28.8 8425333 779. ## 2 Afghanistan Asia 1957 30.3 9240934 821. ## 3 Afghanistan Asia 1962 32.0 10267083 853. ## 4 Afghanistan Asia 1967 34.0 11537966 836. ## 5 Afghanistan Asia 1972 36.1 13079460 740. ## 6 Afghanistan Asia 1977 38.4 14880372 786. ## 7 Afghanistan Asia 1982 39.9 12881816 978. ## 8 Afghanistan Asia 1987 40.8 13867957 852. ## 9 Afghanistan Asia 1992 41.7 16317921 649. ## 10 Afghanistan Asia 1997 41.8 22227415 635. ## 11 Afghanistan Asia 2002 42.1 25268405 727. ## 12 Afghanistan Asia 2007 43.8 31889923 975. ## 13 Albania Europe 1952 55.2 1282697 1601. ## 14 Albania Europe 1957 59.3 1476505 1942. ## 15 Albania Europe 1962 64.8 1728137 2313. ## 16 Albania Europe 1967 66.2 1984060 2760. ## 17 Albania Europe 1972 67.7 2263554 3313. ## 18 Albania Europe 1977 68.9 2509048 3533. ## 19 Albania Europe 1982 70.4 2780097 3631. ## 20 Albania Europe 1987 72 3075321 3739. gss_sm的头部： head(gss_sm, 20) ## # A tibble: 20 x 32 ## year id ballot age childs sibs degree race sex region income16 ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; ## 1 2016 1 1 47 3 2 Bache~ White Male New E~ $170000~ ## 2 2016 2 2 61 0 3 High ~ White Male New E~ $50000 ~ ## 3 2016 3 3 72 2 3 Bache~ White Male New E~ $75000 ~ ## 4 2016 4 1 43 4 3 High ~ White Fema~ New E~ $170000~ ## 5 2016 5 3 55 2 2 Gradu~ White Fema~ New E~ $170000~ ## 6 2016 6 2 53 2 2 Junio~ White Fema~ New E~ $60000 ~ ## 7 2016 7 1 50 2 2 High ~ White Male New E~ $170000~ ## 8 2016 8 3 23 3 6 High ~ Other Fema~ Middl~ $30000 ~ ## 9 2016 9 1 45 3 5 High ~ Black Male Middl~ $60000 ~ ## 10 2016 10 3 71 4 1 Junio~ White Male Middl~ $60000 ~ ## 11 2016 11 2 33 5 4 High ~ Black Fema~ Middl~ under $~ ## 12 2016 12 1 86 4 4 High ~ White Fema~ Middl~ under $~ ## 13 2016 13 2 32 3 3 High ~ Black Male Middl~ $8 000 ~ ## 14 2016 14 3 60 5 6 High ~ Black Fema~ Middl~ $12500 ~ ## 15 2016 15 2 76 7 0 Lt Hi~ White Male New E~ $40000 ~ ## 16 2016 16 3 33 2 1 High ~ White Fema~ New E~ $50000 ~ ## 17 2016 17 3 56 6 3 High ~ White Male New E~ $50000 ~ ## 18 2016 18 2 62 5 8 Lt Hi~ Other Fema~ New E~ $5 000 ~ ## 19 2016 19 2 31 0 2 Gradu~ Black Male New E~ $35000 ~ ## 20 2016 20 1 43 2 0 High ~ Black Male New E~ $25000 ~ ## # ... with 21 more variables: relig &lt;fct&gt;, marital &lt;fct&gt;, padeg &lt;fct&gt;, ## # madeg &lt;fct&gt;, partyid &lt;fct&gt;, polviews &lt;fct&gt;, happy &lt;fct&gt;, partners &lt;fct&gt;, ## # grass &lt;fct&gt;, zodiac &lt;fct&gt;, pres12 &lt;dbl&gt;, wtssall &lt;dbl&gt;, income_rc &lt;fct&gt;, ## # agegrp &lt;fct&gt;, ageq &lt;fct&gt;, siblings &lt;fct&gt;, kids &lt;fct&gt;, religion &lt;fct&gt;, ## # bigregion &lt;fct&gt;, partners_rc &lt;fct&gt;, obama &lt;dbl&gt; 29.2 作图的一般原则 关于什么是好的图形和坏的图形， William S. Cleveland， Edward R. Tufte等人有很多的研究。 坏的图形可能有如下缺点： 坏的品味。统计图形应该用尽可能少的图形元素表示尽可能多的数据， 从打印图形而言，即数据量与所用墨水比例越大越好。 没有必要的颜色、三维形态经常会影响读者对图形的认读。 这是Edward R. Tufte的观点， 但是过于极端也不好。 坏的数据。 即使图形本身的做法没有问题， 选择了错误的或者不合适的数据也会误导读者， 甚至于用错误数据做的很专业的图形会比粗陋的图形更能误导读者。 坏的感知。 不好的颜色选择、三维形状、坐标轴范围、宽高比都有可能对读者的认知有影响。 作图时应考虑的一些因素： 数值型变量的不同值可以表示为： 同一坐标轴上的不同位置、 不同轴上的位置、 不同长度、 不同角度或者斜率、 不同面积、 三维空间中的不同位置、 颜色的不同明暗度、 不同颜色饱和度、 曲线的不同曲率、 三维体积， 这些表示的选择项越往后越难以被读者正确辨识。 使用颜色时，应该使用渐变的明暗度或者渐变色。 分类变量的不同值可以表示为： 不同分组、 不同颜色、 三维动态、 不同符号。 这些表示的选择项越往后越难辨识。 使用颜色时，应该使用明显不同的颜色而不应该使用渐变色。 对于最少是零的变量， 是否应该以零作为坐标轴的最低值需要考虑， 但没有一定的规则。 同一组数据在不同的坐标范围或者长宽比下曲线的斜率会有很大差别。 29.3 散点图：ggplot入门 29.3.1 基本的散点图 以gapminder数据集作为输入数据， 做出简单的散点图， 并逐步进行改善。 这个数据集有多个国家在多个年份的期望寿命与人均GDP值， 作期望寿命对人均GDP的散点图， 每个国家的每个年份作为一个点。 散点图最重要的映射是x轴与y轴两个维度。 首先调用ggplot()函数， 指定数据集， 将人均GDP映射到x轴， 将期望寿命映射到y轴， 结果保存为一个R变量： p &lt;- ggplot(data = gapminder, mapping = aes( x = gdpPercap, y = lifeExp)) x、y轴是最常见的映射， 也可以将变量映射为颜色、符号、线型等， 这时不需要指定具体的颜色、符号、线型， 而是将变量映射为这些图形元素类型。 ggplot()的调用中， 可以省略data =, mapping =, x =, y =， 写成： p &lt;- ggplot(gapminder, aes(gdpPercap, lifeExp)) 在如上指定了数据和映射后， 只要用geom_xxx()指定一个图形类型， 并与ggplot()的结果用加号连接就可以作图了，如： p + geom_point() 实际上，上面的程序等同于调用print(p + geom_point())。 在R函数中或者在循环中需要显式地调用print()， 否则不会显示结果。 当载入了tidyverse系统时可以写成 (p + geom_point()) %&gt;% print()。 29.3.2 逐步改善 指定数据集、指定映射、选择适当的图形类型就可以做出基本的图形， 随后可以逐步对坐标系、坐标系刻度、标签与图例、配色等进行改善。 实际上，ggplot2包已经提供了十分合理的预设值， 用户只要进行一些必要的改动即可。 作图步骤之间用加号连接，这是ggplot包特有的语法。 例如， 用相同的映射做出拟合曲线图： p + geom_smooth() ## `geom_smooth()` using method = &#39;gam&#39; and formula &#39;y ~ s(x, bs = &quot;cs&quot;)&#39; 用相同的映射做出散点图并叠加拟合曲线图： p + geom_point() + geom_smooth() ## `geom_smooth()` using method = &#39;gam&#39; and formula &#39;y ~ s(x, bs = &quot;cs&quot;)&#39; geom_smooth()的默认设置调用了gam()函数来拟合曲线， 可以用geom_smooth()的参数选择不同的拟合方法， 如直线拟合： p + geom_point() + geom_smooth(method=&quot;lm&quot;) ## `geom_smooth()` using formula &#39;y ~ x&#39; 注意geom_xxx()函数计算所需的变量值是从ggplot()函数保存在变量p中的信息提取的。 在以上的所有图形中， x轴变量（人均GDP）分布非正态，严重右偏， 使得大多数散点重叠地分布在直角坐标系的左下角。 将x轴用对数刻度可以改善， 函数为scale_x_log10(): p + geom_point() + geom_smooth(method=&quot;gam&quot;) + scale_x_log10() ## `geom_smooth()` using formula &#39;y ~ s(x, bs = &quot;cs&quot;)&#39; 广义可加模型拟合的曲线基本是一条直线。 注意， 对数刻度实际上是对原始数据进行对数变换， 而geom_smooth()的拟合计算是在对数变换之后进行的。 刚刚的图形的横坐标轴刻度不太友好， 可以调用scales扩展包的适当函数进行改善， 作为scale_x_log10()的labels选项： p + geom_point() + geom_smooth(method=&quot;gam&quot;) + scale_x_log10(labels=scales::dollar) ## `geom_smooth()` using formula &#39;y ~ s(x, bs = &quot;cs&quot;)&#39; scale_xxx()的labels选项指定如何标出坐标刻度数字， 参数值是一个函数对象， 如果scales包中找不到适当的功能， 可以自定义一个函数将数值转换为字符串。 scales包提供了comma, date, dollar, math, number, ordinal, pvalue, scientific, time等坐标刻度值转换函数。 29.3.3 颜色、符号、线型等映射 在ggplot()函数的mapping参数的aes()设定中将变量映射到x、y轴， 颜色、符号、线型等图形元素类型， 也可以作为图形设置将某些图形元素设置为固定值。 例如， 用不同颜色表示不同大洲， 就是将continent变量映射到color: p &lt;- ggplot(data=gapminder, mapping = aes( x = gdpPercap, y = lifeExp, color = continent)) 程序中仅指定了将大洲映射到颜色维， 并不具体指定所用的颜色。 作带有局部多项式曲线拟合的散点图： p + geom_point() + geom_smooth(method=&quot;loess&quot;) + scale_x_log10(labels=scales::dollar) ## `geom_smooth()` using formula &#39;y ~ x&#39; 可以看出， 不同散点用了不同颜色表示其continent变量的值， 五个大洲分别进行了曲线拟合， 曲线使用了不同颜色但置信域颜色相同， 使得难以认读。 在图形右侧自动生成了颜色与continent变量值的对应关系图例。 下面的图形仍分不同大洲作曲线拟合， 并将置信区间阴影的颜色也用不同大洲区分， 方法是在aes()中将color和fill都指定为变量continent: p &lt;- ggplot(data=gapminder, mapping = aes( x = gdpPercap, y = lifeExp, color = continent, fill = continent)) p + geom_point() + geom_smooth(method=&quot;loess&quot;) + scale_x_log10(labels=scales::dollar) ## `geom_smooth()` using formula &#39;y ~ x&#39; 尝试将颜色指定为一个固定值，如： p &lt;- ggplot(data=gapminder, mapping = aes( x = gdpPercap, y = lifeExp, color = &quot;chartreuse4&quot;)) p + geom_point() + geom_smooth(method=&quot;loess&quot;) + scale_x_log10(labels=scales::dollar) ## `geom_smooth()` using formula &#39;y ~ x&#39; 我们发现， 散点并没有使用草绿色， 而且图形右侧有一个chartreuse4图例。 这是因为， aes()仅用来指定变量与图形元素类型的映射， 所以实际上是生成了一个仅有一个常数值\"chartreuse4\"的新变量， 用颜色表示这个新变量。 为了指定固定颜色， 应将color=作为geom_xxx()函数的选项， 而不是放在aes()映射中， 如： p &lt;- ggplot(data=gapminder, mapping = aes( x = gdpPercap, y = lifeExp)) p + geom_point(color=&quot;chartreuse4&quot;) + geom_smooth(method=&quot;loess&quot;) + scale_x_log10(labels=scales::dollar) ## `geom_smooth()` using formula &#39;y ~ x&#39; geom_xxx()函数接受许多关于颜色、透明度、符号、线型的设置参数。 比如， 下面的程序指定了散点的透明度， 以及拟合直线的粗细： p + geom_point(alpha=0.5) + geom_smooth(method=&quot;lm&quot;, color=&quot;cadetblue1&quot;, se = FALSE, size = 4, alpha = 0.3) + scale_x_log10(labels=scales::dollar) ## `geom_smooth()` using formula &#39;y ~ x&#39; 程序中size指定了线的以毫米为单位的粗细， se = FALSE关闭了置信区间显示。 用alpha =设置了透明度， 取0和1之间的值， 数值越小越透明。 在有许多个点时适当设置透明度可以比较好地显示出重叠的点， 重叠点越多点的颜色越深。 虽然这里设置了固定的透明度， 也可以在aes()中将透明度alpha映射到某个变量， 使得该变量值大小用点的透明度表示。 画线时可以用linetype参数指定线型， 0表示实线， 1到6分别表示不同的虚线线型。 下面用labs()函数给图形加上适当的标题： p &lt;- ggplot(data=gapminder, mapping = aes( x = gdpPercap, y = lifeExp)) p + geom_point(alpha = 0.3) + geom_smooth(method=&quot;gam&quot;) + scale_x_log10(labels=scales::dollar) + labs( x = &quot;人均GDP&quot;, y = &quot;期望寿命（年数）&quot;, title = &quot;经济增长与期望寿命&quot;, subtitle = &quot;数据点为每个国家每年&quot;, caption = &quot;数据来源: gapminder&quot; ) ## `geom_smooth()` using formula &#39;y ~ s(x, bs = &quot;cs&quot;)&#39; 可以看出， labs()规定了上方的标题、小标题， x轴、y轴的标题， 右下方的标注(caption)。 坐标轴刻度数值的规定则需要在scale_xxx()函数中给出。 29.3.4 在geom函数中映射变量 在前面的一个例图中， 在ggplot()函数中将color和fill映射到了continent变量， 使得不仅散点颜色代表了不同大洲， 还使得每个大洲单独拟合了曲线。 如果希望所有大洲拟合同一条曲线怎么办？ 在必要时， 可以在geom_xxx()函数中用mapping = aes(&lt;...&gt;)单独指定变量映射。 例如， 下面的程序在geom_point()中将不同大洲映射为不同颜色， 而不影响geom_smooth()中的颜色以及分组： p &lt;- ggplot(data=gapminder, mapping = aes( x = gdpPercap, y = lifeExp)) p + geom_point(mapping = aes(color = continent)) + geom_smooth(method=&quot;loess&quot;) + scale_x_log10(labels=scales::dollar) ## `geom_smooth()` using formula &#39;y ~ x&#39; 也可以将一个分类变量映射到不同绘图符号。 例如，取gapminder 2007年数据子集， 将大洲映射到符号(shape)： p &lt;- ggplot(data = filter(gapminder, year == 2007), mapping = aes( x = gdpPercap, y = lifeExp, shape = continent)) p + geom_point(alpha = 0.4, size = 4) + scale_x_log10(labels=scales::dollar) 这种映射仅适用于点数比较少的情况， 还用了size参数指定符号的大小（单位：毫米）。 如果所有点使用同一符号并需要指定符号， 可以在geom_point()中用shape参数指定， 可以用0到25的整数值表示， 比如19为实心点， 也可以用字符串符号名称表示， 如\"circle\"表示实心点。 参见ggplot2帮助目录中的vignette ggplot2: ggplot2-specs。 注意， 绘图时参与映射的分类变量会自动产生分类效果， color映射与fill映射到分类变量时常常会起到与添加group维相同的作用， 但为了逻辑清晰起见， 需要分组时还应该显式地映射group维。 29.3.5 连续变量的颜色映射 也可以将连续变量映射为渐变色。 除了表示二元函数的等值线图以外这种方法并不利于读者认读。 例如， 将人口数取自然对数映射为渐变色： p &lt;- ggplot(data=gapminder, mapping = aes( x = gdpPercap, y = lifeExp, color = log(pop))) p + geom_point() + geom_smooth(method=&quot;loess&quot;) + scale_x_log10(labels=scales::dollar) ## `geom_smooth()` using formula &#39;y ~ x&#39; 这里不同散点的颜色是连续变化的， 右侧的图例仅显示了有限的一些代表值。 29.3.6 保存图像 如果使用Rmarkdown制作图文， 图像会自动进入编译的结果（如PDF、Word、HTML）中， 图像大小、输出大小可以用Rmarkdown的设置调整。 为了将最近生成的图形保存为PNG格式，用命令如 ggsave(filename=&quot;文件名.png&quot;) 保存为PDF格式： ggsave(filename=&quot;文件名.pdf&quot;) 可以将制作的图形保存到了一个R变量中， 在ggsave()中可以用plot=参数指定，如 ggout01 &lt;- p + geom_point() ggsave(filename=&quot;文件名.pdf&quot;, plot=ggout01) 在ggsave()中可以用scale =指定放大比例， 用height =指定高度， 用width =指定宽度，用units =指定高度和宽度的单位，如： ggsave(filename=&quot;文件名.pdf&quot;, plot=ggout01, height=12, width=8, units=&quot;cm&quot;) 单位可以是in, cm, mm。 29.4 折线图、分组、小图 29.4.1 图形中的分组和折线图 考虑gapminder数据集中每个国家的期望寿命随时间（年）的变化。 用geom_line()可以画折线图。 因为有许多国家，所以仅指定x、y变量无法得到所需图形，如： p &lt;- ggplot(data = gapminder, mapping = aes( x = year, y = lifeExp)) p + geom_line() 没有得出我们希望的每个国家一条曲线的效果。 这是因为程序中没有指定需要按照国家分组， 使得同一年的不同国家的坐标连成了一条竖线。 要注意的是， geom_line()会自动将x坐标从小到大排序， 然后再连接相邻的点。 如果希望按输入数据的次序连接相邻的点， 需要用geom_path()函数。 为了解决上图的问题， 加入按照国家分组的设定。 实际上， 分组(group)与x、y、color、fill一样可以映射到一个变量， 但仅能映射到分类变量。 上述程序的改进如下： p &lt;- ggplot(data = gapminder, mapping = aes( x = year, y = lifeExp, group = country)) p + geom_line() 结果图形中每一条曲线对应一个国家。 为了查探其中最下方的不稳定曲线是哪一个国家，使用筛选观测的功能： gapminder %&gt;% filter(lifeExp &lt; 30, year &gt;= 1990) ## # A tibble: 1 x 6 ## country continent year lifeExp pop gdpPercap ## &lt;fct&gt; &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; ## 1 Rwanda Africa 1992 23.6 7290203 737. 该国家为Rwanda。 如果需要按照两个或多个分类变量交叉分组， 可以给group维指定interaction(...)， 其中...是分类变量表。 geom_line()用来绘制从左向右连接的折线。 比如， 仅绘制Rwanda的期望寿命时间序列： p &lt;- ggplot(data = filter(gapminder, country == &quot;Rwanda&quot;), mapping = aes( x = year, y = lifeExp)) p + geom_line() 如果需要每个点画出散点符号， 可以同时使用geom_point()，如： p + geom_line() + geom_point() 用geom_area()作类似图形， 但在折线下方填充颜色： p &lt;- ggplot(data = filter(gapminder, country == &quot;Rwanda&quot;), mapping = aes( x = year, y = lifeExp)) p + geom_area(fill = &quot;darkseagreen1&quot;, alpha = 0.5) 这种图形的纵坐标应该从0开始， 使得阴影部分的大小与纵坐标值成比例， 这也是ggplot2的默认做法。 连线图还有一个问题， 就是如果x坐标不是数值型变量而是因子或者字符型， 则两点之间不会相连。 比如，将gapminder的Rwanda子集中的year转换成因子，再画折线图： d &lt;- gapminder %&gt;% filter(country == &quot;Rwanda&quot;) %&gt;% mutate(year = factor(year, levels = seq(1952, 2007, by=5))) p &lt;- ggplot(data = d, mapping = aes( x = year, y = lifeExp)) p + geom_line() ## geom_path: Each group consists of only one observation. Do you need to adjust ## the group aesthetic? 没有得到应有的结果。 这是因为因子year起到了分组作用， 相当于每个年份为一组， 连线只能在组内连， 但每组仅有一个观测。 这时， 显式地指定group变量可以解决问题： d &lt;- gapminder %&gt;% filter(country == &quot;Rwanda&quot;) %&gt;% mutate(year = factor(year, levels = seq(1952, 2007, by=5))) p &lt;- ggplot(data = d, mapping = aes( x = year, y = lifeExp, group = country)) p + geom_line() 对于折线图， 可以在geom_line()函数中用color参数指定颜色， 用linetype参数指定线型， 用size参数指定以毫米为单位的粗细。 线型包括： 0：不画线； 1：实线； 2：dashed； 3：dotted； 4：dotdash； 5：longdash； 6：twodash。 29.4.1.1 找出期望寿命增长不稳定的国家 我们编程找出寿命增长不稳定的国家。 这部分内容与作图关系不大，可以跳过。 对每个国家做线性回归， 以期望寿命为因变量， 以年份为自变量， 找出残差方差很大的，以及直线斜率为负的国家。 extract_lmr &lt;- function(lmr){ summ = summary(lmr) tibble( sigma = summ$sigma, rate = lmr$coefficients[2] ) } lmres &lt;- gapminder %&gt;% select(country, year, lifeExp) %&gt;% group_by(country) %&gt;% nest(data = c(year, lifeExp)) %&gt;% mutate(lmr = map(data, ~ lm(lifeExp ~ year, data = .x))) %&gt;% mutate(info = map(lmr, extract_lmr)) %&gt;% select(-data, -lmr) %&gt;% unnest(info) %&gt;% arrange(desc(sigma)) summary(lmres) ## country sigma rate ## Afghanistan: 1 Min. :0.2118 Min. :-0.09302 ## Albania : 1 1st Qu.:0.7111 1st Qu.: 0.20832 ## Algeria : 1 Median :1.2843 Median : 0.32145 ## Angola : 1 Mean :1.6587 Mean : 0.32590 ## Argentina : 1 3rd Qu.:1.9272 3rd Qu.: 0.44948 ## Australia : 1 Max. :7.2054 Max. : 0.77218 ## (Other) :136 head(lmres, 10) ## # A tibble: 10 x 3 ## # Groups: country [10] ## country sigma rate ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Zimbabwe 7.21 -0.0930 ## 2 Swaziland 6.64 0.0951 ## 3 Rwanda 6.56 -0.0458 ## 4 Botswana 6.11 0.0607 ## 5 Lesotho 5.93 0.0956 ## 6 Cambodia 5.63 0.396 ## 7 Namibia 4.96 0.231 ## 8 South Africa 4.74 0.169 ## 9 Zambia 4.53 -0.0604 ## 10 Kenya 4.38 0.207 这些排名靠前的国家都是期望寿命增长不稳定的。 29.4.2 小图(facet) 前面所有国家的图包含了过多的曲线， 使得图形表现得很拥挤。 可以将一个作图区域拆分成若干个小块， 称为小图（facet）， 按照某一个或两个分类变量的不同值将数据分为若干个子集， 每个数据子集分别在小图上作图。 对于上面的例子， 可以将每个大洲的图形分别放置在一个小图上。 小图不是一种变量映射， 而是一种图形摆放方法， 所以不设置在aes()函数内， 而是用facet_wrap()函数规定。 这种功能与group映射的功能有些重复， 所以有时需要与group映射配合使用， 有时则不需要。 程序如： p &lt;- ggplot(data = gapminder, mapping = aes( x = year, y = lifeExp, group = country)) p + geom_line() + facet_wrap(~ continent) 区分不同小图的标签写在每个小图的上方。 可以用facet_wrap()参数strip_position和参数switch调整标签的上下左右。 小图之间默认公用了横坐标和纵坐标且坐标范围保持一致。 如果不保持一致， 读者可能会有误解。 但是x轴或y轴映射为分类变量且不同小图的分类完全不同时， 可以令各小图中该轴的取值不统一。 facet_wrap()选项scales默认为\"fixed\"， 即所有小图的x轴、y轴都范围一致， 取\"free_x\"则允许各小图的x轴不统一， \"free_y\"允许各小图的y轴不统一， \"free\"允许各小图的x轴和y轴都不统一。 在facet_wrap()中可以用ncol参数指定小图的列数， 用nrow指定小图的行数。 各个小图的次序应该设定为一定的合理次序， 比如用来分类的变量本身有序， 或者令各小图中的数据值有一定的增减次序。 下面的程序将曲线颜色变浅， 对每个大洲增加了拟合曲线， 增加了适当的标题和坐标轴标签。 注意，这时不能使用统一的group = country映射， 否则拟合曲线就是对每个国家都单独有一条拟合曲线， 而不是每幅小图中仅有一条拟合曲线。 办法是仅在geom_line()中给出group = country的映射， 但在geom_smooth()中则不用group维。 程序如下： p &lt;- ggplot(data = gapminder, mapping = aes( x = year, y = lifeExp)) p + geom_line(mapping = aes(group = country), color = &quot;gray70&quot;) + geom_smooth(method = &quot;loess&quot;, color=&quot;cyan&quot;, se = FALSE, size = 1.1) + facet_wrap(~ continent, ncol = 2) + labs( x = &quot;年份&quot;, y = &quot;期望寿命&quot;, title = &quot;五个大洲各国期望寿命变化趋势&quot; ) ## `geom_smooth()` using formula &#39;y ~ x&#39; 注意group = country的设置从ggplot()函数中转移到了geom_line()函数中， 否则就意味着拟合线也需要按照国家分组， 而不是按大洲分组。 facet_wrap()主要适用于按照一个分类变量的值将不同观测在不同小图中表现， 可以人为指定小图的行数和列数。 如果需要按照两个分类变量交叉分组分配小图， 可以用facet_grid()函数。 例如， 对gss_sm数据集，作小孩个数对年龄的散点图： p &lt;- ggplot(data=gss_sm, mapping = aes( x = age, y = childs)) p + geom_point(alpha = 0.2) ## Warning: Removed 18 rows containing missing values (geom_point). 有过多的重叠点。 将观测按照性别(sex)和种族(race)交叉分组， 分配到不同的小图上： p + geom_point(alpha = 0.2) + facet_grid(sex ~ race) ## Warning: Removed 18 rows containing missing values (geom_point). 交叉分组时作小图时， sex ~ race这种写法使得不同性别对应到不同行， 不同种族对应到不同列。 在图形中增加拟合曲线： p + geom_point(alpha = 0.2) + geom_smooth() + facet_grid(sex ~ race) ## `geom_smooth()` using method = &#39;gam&#39; and formula &#39;y ~ s(x, bs = &quot;cs&quot;)&#39; ## Warning: Removed 18 rows containing non-finite values (stat_smooth). ## Warning: Removed 18 rows containing missing values (geom_point). 这里虽然没有映射group维， 但还是按性别和种族对数据集分成了6个子集， 每个小图中仅有一个自己的数据。 29.5 数据变换与条形图 有些geom_xxx()函数直接按照数据值作图， 如geom_point()、geom_line()， 而geom_smooth()这样的函数则会按照某种算法计算并对计算结果作图。 geom_xxx()都有默认的stat_xxx()函数用来计算， 也可以人为指定不同的统计规则。 考虑条形图的例子。 ggplot2中的条形图函数geom_bar()可以对一个分类变量自动统计频数， 并作频数条形图。 比如对gss_sm数据集的bigregion变量作频数条形图： p &lt;- ggplot(data = gss_sm, mapping = aes(x = bigregion)) p + geom_bar() 结果是每个大区的受访者人数的条形图。 图形中x映射是用户指定的， 而y轴则是自动计算的频数。 实际上， geom_bar()自动调用了统计函数stat_freq()对每个大区计算频数， 生成新变量count和prop。 geom_bar()默认使用count(频数)。 虽然ggplot2能够自动统计频数， 但最好还是预先统计好频数， 仅用ggplot2绘图。 所以，上例可以用tidyverse的count和ggplot2的geom_col改写成： df1 &lt;- gss_sm %&gt;% select(bigregion) %&gt;% count(bigregion) %&gt;% mutate(ratio = n / sum(n)) p &lt;- ggplot(data = df1, mapping = aes(x = bigregion, y = n)) p + geom_col() + labs(y = &quot;Count&quot;) 下面的程序将纵坐标改成了比例： p &lt;- ggplot(data = df1, mapping = aes(x = bigregion, y = ratio)) p + geom_col() + labs(y = &quot;Ratio&quot;) 下面的例子作gss_sm数据集中religion变量的频数条形图， 并给不同的条形自动分配不同的颜色， 方法是指定fill = religion： df2 &lt;- gss_sm %&gt;% select(religion) %&gt;% count(religion) ## Warning: Factor `religion` contains implicit NA, consider using ## `forcats::fct_explicit_na` p &lt;- ggplot(data = df2, mapping = aes( x = religion, y = n, fill = religion)) p + geom_col() + labs(y = &quot;Count&quot;) 因为将religion同时映射到x维与fill维， 所以对应fill维在图形右侧出现了图例， 这是多余的。 调用guides(fill = FALSE)可以人为指定不做关于填充色的图例： p + geom_col() + guides(fill = FALSE) + labs(y = &quot;Count&quot;) 从可视化理论的角度看， 上图中的不同颜色是多余的， 用同一颜色更能强度数据本身。 29.5.1 分段与并列条形图 上面的条形图展现了单个分类变量的频数分布。 两个分类变量的交叉频数分布可以用分段条形图或者并列条形图表现。 例如，对gss_sm数据集， 按照bigregion分组计算频数， 每组内再按照religion计算频数， 用tidyverse统计后作图如下： df3 &lt;- gss_sm %&gt;% select(bigregion, religion) %&gt;% group_by(bigregion, religion) %&gt;% summarise(n = n()) %&gt;% mutate(ratio = n / sum(n)) %&gt;% ungroup() ## Warning: Factor `religion` contains implicit NA, consider using ## `forcats::fct_explicit_na` p &lt;- ggplot(data = df3, mapping = aes( x = bigregion, y = n, fill = religion)) p + geom_col() 这样的图形可以很容易地比较大类(这里是bigregion)的频数比例， 但大类内的小类(这里是religion)可以比较容易地在大类内部比较， 但是在大类之间比较则较困难。 如果仅有两个小类， 则小类在大类之间的比较也没有问题。 另一种做法是将大类的高度拉平， 图形仅表示每一大类内部小类的比例， 没有大类频数信息， 也不能比较两个大类之间的小类频数， 但可以大致地在大类之间比较小类的比例： p + geom_col(position = &quot;fill&quot;) + labs(y = NULL) 上面的程序在geom_col()中用了position = \"fill\"选项。 并排的条形图可以表现每个交叉类的频数， 可以比较容易地比较每个大类内部的小类比例以及小类的频数， 但是不容易比较大类的比例： p + geom_col(position = &quot;dodge&quot;) 将上图中的纵轴改为大类内的比例（每个大区的比例之和等于1）： p &lt;- ggplot(data = df3, mapping = aes( x = bigregion, y = ratio, fill = religion)) p + geom_col(position = &quot;dodge&quot;) 为了在不同大区之间比较宗教比例分布， 可以借助于小图， 将每个大区分配到一个小图： p &lt;- ggplot(data = df3, mapping = aes(x = religion, y = ratio, fill=religion)) p + geom_col(position=&quot;dodge&quot;) + labs(x=NULL, y=&quot;比例&quot;) + coord_flip() + facet_grid(~ bigregion) + guides(fill=FALSE) 有时用来绘图的数据已经是一个频数表， 比如泰坦尼克号乘客生存与性别的频数表： titanic ## fate sex n percent ## 1 perished male 1364 62.0 ## 2 perished female 126 5.7 ## 3 survived male 367 16.7 ## 4 survived female 344 15.6 这是一个长表格式的列联表， 对于table()生成的列联表可以用as.data.frame将其转换为长表格式。 作fate为大组的sex的并排条形图： p &lt;- ggplot(data=titanic, mapping = aes( x = fate, y = n, fill = sex)) p + geom_col(position = &quot;dodge&quot;) 也可以按照性别分成大组： p &lt;- ggplot(data=titanic, mapping = aes( x = sex, y = n, fill = fate)) p + geom_col(position = &quot;dodge&quot;) 用theme()函数的legend.position参数可以指定图例的位置，如： p + geom_col(position = &quot;dodge&quot;) + theme(legend.position = &quot;top&quot;) 做成堆叠形式： p + geom_col(position = &quot;stack&quot;) position = \"stack\"也是geom_col()函数的默认选项。 实际上， 还可以用适当程序将存亡状态以及频数直接标在条形的色块内， geom_text()函数可以在指定坐标位置标注指定的文字标签， 见29.8.2。 datasets包的Titanic数据集包含了泰坦尼克号乘客更详细的信息。 我们按照存亡结果和舱位等级分小图作男女频数条形图： titanic2 &lt;- as.data.frame(Titanic) %&gt;% group_by(Class, Sex, Survived) %&gt;% summarise(n = sum(Freq)) %&gt;% filter(Class != &quot;Crew&quot;) %&gt;% mutate(Survived = factor( Survived, levels = c(&quot;Yes&quot;, &quot;No&quot;), labels = c(&quot;survived&quot;, &quot;perished&quot;))) p &lt;- ggplot(data = titanic2, mapping = aes( x = Sex, y = n, fill = Sex)) p + geom_col() + facet_grid(Class ~ Survived) + guides(fill = FALSE) 这里将fill映射到了Sex， 使得表示男女的条形填充了不同的颜色。 如果不满意上面的颜色， 可以用scale_fill_manual()函数人为地指定颜色、对应离散值和图例标签。 R扩展包colourpicker提供了很好交互图形界面用来挑选颜色。 29.5.2 条形图的其它应用 geom_col()不仅限于画频数或者比例的条形图， 此函数可以将一般用折线图表现的内容画成条形图， 但一定要注意一点：y坐标轴必须从0开始， 这也是geom_col()和geom_bar()函数默认的设置。 如果坐标轴不从零开始， 则条形的长度就不能正确表示对应的y变量数值。 举一个用条形图表示不是频数和比例的量的例子。 socviz包的oecd_sum数据集包含各年的美国以及OECD国家的期望寿命： oecd_sum ## # A tibble: 57 x 5 ## # Groups: year [57] ## year other usa diff hi_lo ## &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 1960 68.6 69.9 1.3 Below ## 2 1961 69.2 70.4 1.2 Below ## 3 1962 68.9 70.2 1.30 Below ## 4 1963 69.1 70 0.9 Below ## 5 1964 69.5 70.3 0.800 Below ## 6 1965 69.6 70.3 0.7 Below ## 7 1966 69.9 70.3 0.400 Below ## 8 1967 70.1 70.7 0.6 Below ## 9 1968 70.1 70.4 0.3 Below ## 10 1969 70.1 70.6 0.5 Below ## # ... with 47 more rows 我们用geom_col()作diff变量的条形图， 并按照hi_lo变量对正负差值分别使用不同颜色： p &lt;- ggplot(data = oecd_sum, mapping = aes( x = year, y = diff, fill = hi_lo)) p + geom_col() + guides(fill = FALSE) + # 正负号的不同颜色不使用图例标注 labs(x = NULL, y = &quot;期望寿命差值&quot;, title = &quot;美国期望寿命差值&quot;, subtitle = &quot;1960-2015年美国与OECD国家期望寿命差值&quot;, caption=&quot;来自socviz扩展包&quot;) ## Warning: Removed 1 rows containing missing values (position_stack). 29.6 直方图与密度估计 条形图(barplot)反映分类变量的频数分布或者比例， 直方图(histogram)反映连续取值的数值变量的分布。 geom_histogram()作直方图， 可以自动选取合适的分组个数， 也可以人为指定分组个数。 ggplot2包中的midwest数据集包含了美国中西部的一些县的统计数据， 如面积（单位：平方英里）。 下面的程序对连续取值的数值型变量area作频数直方图， 自动确定分组个数： p &lt;- ggplot(data = midwest, mapping = aes(x = area)) p + geom_histogram() ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. 上面图形的纵坐标是频数(count)，是每个组的频数。 geom_histogram()默认调用stat_bin()进行分组及频数统计。 直方图的形状比较依赖于分组数与分组起始点位置， 可以用bins参数控制分组数， 用binwidth参数控制分组宽度， 用center或者boundary参数控制组中心或者组边界对齐位置， 如： p + geom_histogram(bins = 15) 可以利用fill映射将构成直方图的观测按照某个分类变量分组， 然后每个条形内部按照该分类变量的值分段染色， 段内各颜色的长度代表该条形所在组某一类的频数， 如： midwest_sub &lt;- midwest %&gt;% filter(state %in% c(&quot;OH&quot;, &quot;WI&quot;)) p &lt;- ggplot(data=midwest_sub, mapping = aes(x = area, fill = state)) p + geom_histogram(bins = 10) 可见面积较小的县主要来自OH州， 面积较大的县主要来自WI州。 geom_density()可以对连续变量绘制密度估计曲线，如： p &lt;- ggplot(data = midwest, mapping = aes(x = area)) p + geom_density() 下面的程序写法制作每个州的各县的面积密度估计， 画在同一坐标系中： p &lt;- ggplot(data = midwest, mapping = aes( x = area, color = state, fill = state)) p + geom_density(alpha = 0.3) 可以看出，IN与MI州各县的面积偏小。 WI州各县的面积较大。 上面的图形可以借助于geom_line(stat = \"density\")改成仅有多条曲线： p &lt;- ggplot(data = midwest, mapping = aes( x = area, color = state)) p + geom_line(stat = &quot;density&quot;) geom_density()的纵轴是密度估计。 为了能够将直方图与密度估计画在同一坐标系中， 需要将直方图的纵轴也改为密度估计，如： p &lt;- ggplot(data = midwest, mapping = aes(x = area)) p + geom_histogram(mapping = aes(y = ..density..), alpha = 0.6) + geom_density(size = 1.1) ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. 进一步地， geom_freqpoly()将直方图做成折线格式； geom_bin2d()作二维的直方图，用不同颜色代表密度； geom_density_2d()作二维密度估计等值线图。 29.7 绘图语法介绍 29.7.1 绘图语法 ggplot2的不仅仅是能够做一些固定格式的图形， 而是按照一种图形语法构建图形。 小图功能可以将数据集分成若干子集作多幅小图， 每幅小图中， 有可以分层， 每层有不同类型的图， 各层叠加显示在一起。 所以，分层语法作图结构如下： 有一个主要的数据集， 以及从数据集变量到坐标位置、颜色、填充、大小、符号等的映射关系(aesthetics); 有一到多个图层， 比如散点图和平滑曲线图层， 每个图层有几何对象、必要的统计变换、位置调整， 还可以有额外的数据集以及额外的映射关系； 对每个映射关系有一个刻度(scaling)， 对x、y维，一般需要线性变换，偶尔用到对数变换之类的其它变换， 颜色、填充等维度需要一些复杂的对应关系。 无特殊需要时只要使用默认刻度； 有一个坐标系统， 如直角坐标系、极坐标系、球面坐标系等， 一般只要使用默认的坐标系统； 可以划分小图(facetting)。 利用绘图语法既可以做出常见的统计图形， 也可以做出各种新颖的图形， 当然， 就像语法正确的语句不一定有意义， 用绘图语法做得新颖图形不一定有实际意义， 还是要按照可视化的一般原则做出能说服读者的图形。 29.7.2 图形种类 geom_xxx()提供了各种基本图形。 列表如下： 基础图形： geom_blank()不画图，可以按映射的变量设定坐标范围； geom_point()每个观测为一个散点； geom_hline(), geom_vline(), geom_abline()画线； geom_path()每个观测提供\\((x,y)\\)坐标，在相邻观测之间连线； geom_ribbon()需要x和ymin, ymax维，在从小到大排序后的相邻观测之间连接阴影区域； geom_segment()需要x, y和xend, yend，为每个观测画一条线段； geom_rect()需要xmin, xmax, ymin, ymax，为每个观测画一个长方形，可有填充色； geom_polygon()需要x, y，将相邻观测连续并连接成一个闭合的多边形，中间填充颜色； geom_text()需要x, y和lable，每个观测画一条文字标签。 单变量图层： geom_bar(), geom_col()作条形图； geom_histogram()对连续变量x作直方图； geom_density()对连续变量x作一元密度估计曲线； geom_dotplot()用原点作直方图； geom_freqpoly()用折线作直方图。 两变量图形： 两个连续变量x, y： geom_point()散点图； geom_quantile()拟合分位数回归曲线； geom_rug()在坐标轴处画数值对应的短须线； geom_smooth()画各种拟合曲线； geom_text()在指定的x, y位置画label给出的文字标签； 显示二元分布: geom_bin2d()作长方形分块的二维直方图； geom_density2d()作二元密度估计等值线图； geom_hex()作正六边形分块的二维直方图。 两个变量中有分类变量时： geom_count()：重叠点越多画点越大； geom_jitter(): 随机扰动散点位置避免重叠，数值变量有重叠时也可以用； 一个连续变量和一个分类变量： geom_col()作条形图，对分类变量的每个值画一个条形，长度与连续变量值成比例； geom_boxplot()对每个类做一个盒形图； geom_violin()对每个类做一个小提琴图。 一个时间变量和一个连续变量： geom_area()作阴影曲线图，曲线下方填充阴影色； geom_line()作折线图，在相邻两个时间之间连接线段； geom_step()作阶梯函数图，在相邻两个时间之间连接阶梯函数线。 不确定性： geom_crossbar()对每个观测输入的x, y, ymin, ymax画中间有线的纵向条形； geom_errbar()对每个观测输入的x, ymin, ymax画纵向误差条； geom_linerange()对每个观测输入的x, ymin, ymax画一条竖线； geom_pointrnage()对每个观测输入的x, y, ymin, ymax画一条中间有点的竖线。 地图： geom_map(): 用区域边界坐标数据画边界线地图。 三个变量： geom_contour(): 用输入的x, y, z数据画等值线图。 geom_tile()用输入的x, y位置, width, height大小和指定的fill维画长方形色块填充图。 geom_raster()是geom_tile()的长方形大小相同时的快速版本。 29.8 更多图形种类 29.8.1 连续变量的分组图形 选用socviz包的organdata数据集， 这是17个OECD国家历年的器官捐献情况以及一些其他变量的记录。 其中前6列的一些抽样数据： organdata %&gt;% select(1:6) %&gt;% sample_n(size = 10) ## # A tibble: 10 x 6 ## country year donors pop pop_dens gdp ## &lt;chr&gt; &lt;date&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; ## 1 Netherlands 1992-01-01 15.1 15184 36.6 19285 ## 2 Finland NA NA NA NA NA ## 3 Denmark 1999-01-01 14.3 5322 12.4 26985 ## 4 Finland 1992-01-01 19.4 5042 1.49 16943 ## 5 Belgium 1999-01-01 25.2 10226 30.9 24521 ## 6 Belgium 1993-01-01 21 10085 30.5 19733 ## 7 Belgium 1991-01-01 21 10005 30.2 18796 ## 8 United States NA NA NA NA NA ## 9 Austria NA NA 7678 9.16 18914 ## 10 Italy 1994-01-01 7.9 57204 19.0 19903 变量donors是每百万人中器官捐献数。 作donors对year的散点图： p &lt;- ggplot(data = organdata, mapping = aes( x = year, y = donors)) p + geom_point() ## Warning: Removed 34 rows containing missing values (geom_point). 每年有多个数值， 是不同国家的捐献数。 这个图形不能反映一种时间趋势， 不太有用。 可以对每个国家画一条折线图： p &lt;- ggplot(data = organdata, mapping = aes( x = year, y = donors, color = country)) p + geom_line() ## Warning: Removed 34 row(s) containing missing values (geom_path). 共有17个国家，每个国家做了器官捐赠率随时间变化的折线图。 用小图的方法将其分配到不同的小图： p &lt;- ggplot(data = organdata, mapping = aes( x = year, y = donors)) p + geom_line() + facet_wrap(~ country, ncol=4) ## Warning: Removed 2 row(s) containing missing values (geom_path). 用geom_boxplot()可以做盒形图， 能够画出连续型变量的主要分位数，表现变量分布，如： p &lt;- ggplot(data = organdata, mapping = aes(y = donors)) p + geom_boxplot() ## Warning: Removed 34 rows containing non-finite values (stat_boxplot). 这是所有国家所有年的捐献率分布情况。 类似函数还有geom_violin()。 每个国家的捐献率单独做盒形图并且放在同一坐标系中： p &lt;- ggplot(data = organdata, mapping = aes(y = donors, x = country)) p + geom_boxplot() + coord_flip() ## Warning: Removed 34 rows containing non-finite values (stat_boxplot). 这个图形很好地比较了不同国家的历年捐献率的分布， 比如， Spain的捐献率最高。 为了将图形中的各个国家按照捐献率的某个统计量排序， 可以使用stats包的reorder()函数， 调整因子的水平次序。 为了能够比较容易地标出国家名称， 交换x轴与y轴的作用， 如： p &lt;- ggplot(data = organdata, mapping = aes( y = donors, x = reorder(country, donors, median, na.rm=TRUE))) p + geom_boxplot() + coord_flip() + labs(y = &quot;捐献率(单位: 百万分之一)&quot;, x = NULL) ## Warning: Removed 34 rows containing non-finite values (stat_boxplot). 这里盒形图是横向的， 如果仍然纵向作图， 国家名称在横轴， 许多个国家名称就会重叠在一起， 只好仅显示其中一部分名称。 当每组（这里是每个国家）的观测个数很少时， 也可以做成散点图，如： p &lt;- ggplot(data = organdata, mapping = aes( y = donors, x = reorder(country, donors, median, na.rm=TRUE))) p + geom_point(alpha = 0.4) + coord_flip() + labs(y = &quot;捐献率(单位: 百万分之一)&quot;, x = NULL) ## Warning: Removed 34 rows containing missing values (geom_point). 因为有的观测点完全重叠， 所以用了alpha参数指定一定的透明度， 重叠越多的点显示的颜色越深。 但是， 如果两个不同颜色的点完全重叠， 半透明不能显示两个不同颜色的效果。 在作这样的散点图时， 为了避免重叠的点， 可以将geom_point()改为geom_jitter()，如: p + geom_jitter(alpha = 0.4) + coord_flip() + labs(y = &quot;捐献率(单位: 百万分之一)&quot;, x = NULL) ## Warning: Removed 34 rows containing missing values (geom_point). 上图的点的扰动过大了， 使得不同国家的区分不明显了。 作扰动的散点图时， 可以用width指定左右扰动范围， 用height指定上下扰动范围， 这里只需要指定左右扰动范围， 因为坐标轴对调所以就变成了上下扰动： p + geom_jitter(alpha = 0.4, width = 0.2, height = 0) + coord_flip() + labs(y = &quot;捐献率(单位: 百万分之一)&quot;, x = NULL) ## Warning: Removed 34 rows containing missing values (geom_point). geom_boxplot()也支持color, fill维度。 organdata中的变量world是一个国家的福利类型， 用不同填充色表示world变量： p &lt;- ggplot(data = organdata, mapping = aes( y = donors, x = reorder(country, donors, median, na.rm=TRUE), fill = world)) p + geom_boxplot() + coord_flip() + labs(y = &quot;捐献率(单位: 百万分之一)&quot;, x = NULL, fill = &quot;福利类型&quot;) + theme(legend.position = &quot;top&quot;) ## Warning: Removed 34 rows containing non-finite values (stat_boxplot). 下面做不同国家的平均捐赠率的图形。 首先得到统计数据： organdata2 &lt;- organdata %&gt;% group_by(country) %&gt;% summarize( donors_n = sum(!is.na(donors)), donors_mean = mean(donors, na.rm=TRUE), donors_sd = sd(donors, na.rm=TRUE), donors_se = donors_sd / sqrt(donors_n)) organdata2 ## # A tibble: 17 x 5 ## country donors_n donors_mean donors_sd donors_se ## &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Australia 12 10.6 1.14 0.330 ## 2 Austria 12 23.5 2.42 0.697 ## 3 Belgium 12 21.9 1.94 0.559 ## 4 Canada 12 14.0 0.751 0.217 ## 5 Denmark 12 13.1 1.47 0.424 ## 6 Finland 12 18.4 1.53 0.441 ## 7 France 12 16.8 1.60 0.461 ## 8 Germany 12 13.0 0.611 0.176 ## 9 Ireland 12 19.8 2.48 0.715 ## 10 Italy 12 11.1 4.28 1.23 ## 11 Netherlands 12 13.7 1.55 0.448 ## 12 Norway 12 15.4 1.11 0.320 ## 13 Spain 12 28.1 4.96 1.43 ## 14 Sweden 12 13.1 1.75 0.506 ## 15 Switzerland 12 14.2 1.71 0.493 ## 16 United Kingdom 12 13.5 0.775 0.224 ## 17 United States 12 20.0 1.33 0.383 用条形图表现不同国家的平均捐献率： p &lt;- ggplot(data = organdata2, mapping = aes( x = reorder(country, donors_mean), y = donors_mean)) p + geom_col() + coord_flip() + labs(x = NULL, y = &quot;平均捐赠率(单位: 百万分之一)&quot;) 这样的图形也可以做成点图， 称为Cleveland点图。 不需要再颠倒横纵坐标， 直接规定x轴为平均捐赠率即可： p &lt;- ggplot(data = organdata2, mapping = aes( y = reorder(country, donors_mean), x = donors_mean)) p + geom_point() + labs(y = NULL, x = &quot;平均捐赠率(单位: 百万分之一)&quot;) organdata数据集中变量consent_law是关于一个国家中器官捐赠是必须告知还是默认捐赠的区别。 为了在上面的点图中用不同颜色区分这两种做法， 需要在分组汇总阶段就将consent_law也作为分组变量。 这是因为summarize()函数会自动舍弃分组变量和统计结果之外的原有变量。 organdata3 &lt;- organdata %&gt;% group_by(consent_law, country) %&gt;% summarize( donors_n = sum(!is.na(donors)), donors_mean = mean(donors, na.rm=TRUE), donors_sd = sd(donors, na.rm=TRUE), donors_se = donors_sd / sqrt(donors_n)) %&gt;% ungroup() organdata3 ## # A tibble: 17 x 6 ## consent_law country donors_n donors_mean donors_sd donors_se ## &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Informed Australia 12 10.6 1.14 0.330 ## 2 Informed Canada 12 14.0 0.751 0.217 ## 3 Informed Denmark 12 13.1 1.47 0.424 ## 4 Informed Germany 12 13.0 0.611 0.176 ## 5 Informed Ireland 12 19.8 2.48 0.715 ## 6 Informed Netherlands 12 13.7 1.55 0.448 ## 7 Informed United Kingdom 12 13.5 0.775 0.224 ## 8 Informed United States 12 20.0 1.33 0.383 ## 9 Presumed Austria 12 23.5 2.42 0.697 ## 10 Presumed Belgium 12 21.9 1.94 0.559 ## 11 Presumed Finland 12 18.4 1.53 0.441 ## 12 Presumed France 12 16.8 1.60 0.461 ## 13 Presumed Italy 12 11.1 4.28 1.23 ## 14 Presumed Norway 12 15.4 1.11 0.320 ## 15 Presumed Spain 12 28.1 4.96 1.43 ## 16 Presumed Sweden 12 13.1 1.75 0.506 ## 17 Presumed Switzerland 12 14.2 1.71 0.493 p &lt;- ggplot(data = organdata3, mapping = aes( y = reorder(country, donors_mean), x = donors_mean, color = consent_law)) p + geom_point(size = 3) + labs(y = NULL, x = &quot;平均捐赠率(单位: 百万分之一)&quot;) + theme(legend.position = &quot;top&quot;) 平均捐赠率最高的三个国家都是不需告知预先假定同意的。 也可以将两种告知规定分成两个小图： p &lt;- ggplot(data = organdata3, mapping = aes( y = reorder(country, donors_mean), x = donors_mean)) p + geom_point(size = 3) + facet_wrap(~ consent_law, ncol=1, scales = &quot;free_y&quot;) + labs(y = NULL, x = &quot;平均捐赠率(单位: 百万分之一)&quot;) 因为纵轴是分类变量，程序中的scales = \"free_y\"使得纵轴仅对存在的类留出空间。 用了ncol = 1使得两种告知规定的小图上下排列， 便于比较横坐标值。 当每个类别仅有一个数值时， 一般推荐使用Cleveland点图， 而不是条形图或者折线图。 Cleveland点图总是将类别值绘制在y轴， 将要比较的数量值用x坐标表示， 并将各类按照数量值大小次序排列。 可以表示平均值的点图上增加一条线， 表示误差大小，所用函数为geom_pointrange()。 这个函数仅支持对y轴加误差线， 所以需要用交换坐标轴的办法将分类变量放在y轴。 比如， 画出近似95%置信区间范围： p &lt;- ggplot(data = organdata3, mapping = aes( x = reorder(country, donors_mean), y = donors_mean)) p + geom_pointrange( mapping = aes(ymin = donors_mean - 1.96*donors_se, ymax = donors_mean + 1.96*donors_se)) + coord_flip() + facet_wrap(~ consent_law, ncol=1, scales = &quot;free_y&quot;) + labs(x = NULL, y = &quot;平均捐赠率(单位: 百万分之一)及95%置信区间&quot;) 类似的函数还有geom_linerange()、geom_crossbar()、geom_errorbar()。 29.8.2 坐标系中的文字 类似于散点图， 可以将指定的文字绘制在指定的坐标位置， 使用geom_text(mapping = aes(label = 字符型变量))。 例如，gapminder数据集中各大洲的平均寿命与平均gdp的文字散点图： gapminder2 &lt;- gapminder %&gt;% group_by(continent) %&gt;% summarize(lifeExp = mean(lifeExp, na.rm=TRUE), gdpPercap = mean(gdpPercap)) p &lt;- ggplot(data=gapminder2, mapping = aes( x = gdpPercap, y = lifeExp, label = continent)) p + geom_text() 可以同时绘制散点： p + geom_text() + geom_point(size = 2, col=&quot;blue&quot;) ggrepel扩展包提供了增强的图形文本功能。 geom_text_repel()提供了与geom_text()类似的功能。 考虑socviz扩展包的elections_historic数据集， 这是美国历次总统选举情况数据。 部分数据显示： elections_historic %&gt;% select(2:7) %&gt;% head(10) ## # A tibble: 10 x 6 ## year winner win_party ec_pct popular_pct popular_margin ## &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1824 John Quincy Adams D.-R. 0.322 0.309 -0.104 ## 2 1828 Andrew Jackson Dem. 0.682 0.559 0.122 ## 3 1832 Andrew Jackson Dem. 0.766 0.547 0.178 ## 4 1836 Martin Van Buren Dem. 0.578 0.508 0.142 ## 5 1840 William Henry Harrison Whig 0.796 0.529 0.0605 ## 6 1844 James Polk Dem. 0.618 0.495 0.0145 ## 7 1848 Zachary Taylor Whig 0.562 0.473 0.0479 ## 8 1852 Franklin Pierce Dem. 0.858 0.508 0.0695 ## 9 1856 James Buchanan Dem. 0.588 0.453 0.122 ## 10 1860 Abraham Lincoln Rep. 0.594 0.396 0.101 取popular_pct(popular投票支持率)为横坐标， 取ec_pct(election college投票支持率)为纵坐标， 将历次结果标在坐标系中： p &lt;- ggplot(data = elections_historic, mapping = aes( x = popular_pct, y = ec_pct, label = winner_label)) p + geom_text() 因为点比较多，文字也比较长，有很多重叠。 ggrepel包的geom_text_repel()则很好地处理了这个问题： library(ggrepel) ## Warning: 程辑包&#39;ggrepel&#39;是用R版本3.6.3 来建造的 p + geom_text_repel() 可以看出，其解决重叠问题的方式是用短线指向实际的坐标位置。 在Rmd文件中， 还是有少量的重叠， 可以通过在R代码段选项中增大fig.width和fig.height参数实现， 下面的代码段用了选项fig.width=20, fig.height=16： p + geom_text_repel() 可以用scale_x_continuous()和scale_y_continuous()将坐标轴的比例值转换成百分数， 用geom_hline(yintercept)添加横线， 用geom_vline(xintercept)添加竖线， 适当地用标注改善图形： p + geom_hline(yintercept = 0.5, size = 1.4, col = &quot;gray80&quot;) + geom_vline(xintercept = 0.5, size = 1.4, col = &quot;gray80&quot;) + geom_point() + geom_text_repel() + scale_x_continuous(labels = scales::percent) + scale_y_continuous(labels = scales::percent) + labs( x = &quot;Winner&#39;s share of Popular Vote&quot;, y = &quot;Winner&#39;s share of Electoral College Votes&quot;, title = &quot;Presidential Elections: Popular &amp; Electoral College Margins&quot;, subtitle = &quot;1824-2016&quot;, caption = &quot;Data for 2016 are provisional.&quot; ) 为了画斜线，可以用geom_abline()函数。 29.8.3 文字选项 用geom_text()添加文字时， 可以使用一些图形选项。 可以用size选项（不是aes映射）指定字符大小， 单位为毫米。如： d &lt;- tibble( x = 1:2, y = c(1,1), label = c(&quot;较小&quot;, &quot;较大&quot;)) p &lt;- ggplot() p + geom_text(data = d[1,], mapping = aes( x = x, y = y, label = label), size = 4) + geom_text(data = d[2,], mapping = aes( x = x, y = y, label = label), size = 8) 文字的大小是按毫米计算的， 不是按照坐标系中单位计算的， 而且放大或者缩小坐标系时文字大小不变。 程序不自动判断文字是否超出坐标系边界， 所以有时需要人为将坐标范围适当放大。 可以用family选项选择不同的字体种类， 在所有操作系统与绘图输出中都可选的种类包括\"sans\"(这是缺省值，等线字体)、\"serif\"(有笔画粗细的字体)、\"mono\"(类似于打字机字体)。family可以作为选项，也可以作为映射，如： d &lt;- tibble( x = 1, y = 3:1, label = c(&quot;sans默认字体&quot;, &quot;serif等线字体&quot;, &quot;mono字体&quot;), family = c(&quot;sans&quot;, &quot;serif&quot;, &quot;mono&quot;)) p &lt;- ggplot() p + geom_text(data = d, mapping = aes( x = x, y = y, label = label, family = family), size = 5) 要使用其它字体则比较复杂， 可参考扩展包showtext和extrafonts。 在R Markdown文件中作图使用中文字体要更麻烦一些， 很容易变成乱码，需要在文件开始设置： pdf.options(height=10/2.54, width=10/2.54, family=&quot;GB1&quot;) # 其中height和width选项可以修改为其它高度、宽度值。 如果还是有乱码， 可以在作图的代码段中指定选项dev=\"png\"， 使用栅格图而不是PDF默认的矢量图作为输出。 可以用fontface映射或选项指定\"plain\"(缺省值)、\"bold\"(粗体)、\"italic\"(斜体)。 可以用hjust映射或选项指定文字的横向对齐方式， 包括\"left\"、\"center\"、\"right\"、\"inward\"、\"outward\"。 可以用vjust映射或选项指定文字的纵向对齐方式， 可取\"bottom\"、\"middle\"、\"top\"、\"inward\"、\"outward\"。 默认为居中对齐。 \"inward\"可以使文字向中心移动， 避免边界的文字出界。 可以用angle映射或选项指定文字的旋转方向。 可以用nudge_x和nudge_y选项指定对每条标签文字的横向和纵向微调， 单位是坐标系中的单位。 可以用选项check_overlap = TRUE要求重叠的文字不全显示出来， 使得结果不重叠。 geom_text()函数的一个变种是geom_label()， 标签文字会有一个圆角的背景框， 可以指定填充颜色。 29.8.4 标出特殊点 在坐标系中标注文字的功能更经常用来标出图形中的特殊点。 考虑organdata中各国的平均捐赠率数据。 作平均捐赠率对平均gdp的散点图： organdata4 &lt;- organdata %&gt;% group_by(country) %&gt;% summarize( donors_mean = mean(donors, na.rm=TRUE), gdp_mean = mean(gdp, na.rm=TRUE) ) p &lt;- ggplot(data = organdata4, mapping = aes(x = gdp_mean, y = donors_mean)) p + geom_point() + labs(x = &quot;平均GDP&quot;, y = &quot;平均器官捐赠率(单位：百万分之一)&quot;) 如果需要标出其中的特殊点， 就要生成一个数据子集， 并在geom_text()中指定输入数据为此子集： p + geom_point() + geom_text(data = subset(organdata4, gdp_mean &gt; 27500 | donors_mean &gt; 25), mapping = aes(label = country)) + labs(x = &quot;平均GDP&quot;, y = &quot;平均器官捐赠率(单位：百万分之一)&quot;) 上面标的文字有超出边界的问题， 可以在geom_text()中加选项hjust = \"inward\": library(ggrepel) p + geom_point() + geom_text(data = subset(organdata4, gdp_mean &gt; 27500 | donors_mean &gt; 25), mapping = aes(label = country), hjust = &quot;inward&quot;) + labs(x = &quot;平均GDP&quot;, y = &quot;平均器官捐赠率(单位：百万分之一)&quot;) 29.9 刻度(scale) 在ggplot()的mapping参数中指定x维、y维、color维等， 实际上每一维度都有一个对应的默认刻度(scale)， 即将数据值映射到图形中的映射方法。 如果需要修改刻度对应的变换或者标度方法， 可以调用相应的scale_xxx()函数。 刻度在绘图过程中依次起到三个作用： 某些刻度对原始数据进行变换，比如对数变换； 如果有多个图层，比如即有散点图又有曲线拟合， 各图层的坐标范围要统一考虑， 如果不人为指定范围会自动设定范围使得各个图层的元素都可以容纳在刻度范围内； 将数据变量映射到具体的位置、颜色、填充色、大小、符号等。 可以映射的维度包括x、y、color、fill、shape、size等。 其中x、y维度多用于表示连续变量， 但是也可以用于分类变量， 如Cleveland点图就是将y维度分配给一个分类变量。 color、fill可以用于连续变量， 用于有序变量， 也可以用于无序的分类变量。 shape只能用于无序的分类变量。 数值或者不同类别可以用平面上的不同位置表示， 一般使用直角坐标系， 有有一对相互垂直的x轴和y轴， 但也可以有其他选择， 比如y轴可以不与x轴垂直， 某个轴的刻度可以不是线性的而是经过对数变换的， 可以用极坐标系，等等。 普通的直角坐标系不需要用scale_xxx()函数。 直角坐标系中的位置有x坐标与y坐标， 可以分别代表两个变量， 这两个变量经常是不同单位的， 比如， 身高与体重。 这时， x轴与y轴的数值之间没有可比性， 两个轴的数值范围与轴的实际长度只要不过于极端就没有什么关系。 但是， 应该尽可能使用比较合适的高宽比。 如果两个轴的变量含义相同， 最好使用完全相同的坐标轴范围与坐标轴长度， 使得水平与垂直方向上的等长距离在对应的坐标轴上也代表相等的距离。 用coord_fixed()函数指定两个轴的单位为1:1长度的坐标系， 其中参数xlim和ylim可以用来指定坐标范围。 也可以用ratio参数指定一个其他的宽高比。 如 d &lt;- data.frame( t &lt;- seq(0, 2*pi, length.out=100) ) d$x &lt;- cos(d$t) d$y &lt;- sin(d$t) p &lt;- ggplot(data = d, mapping = aes( x = x, y = y)) p + geom_path() + coord_fixed() 上面的程序中， geom_path()按照输入数据集的次序将坐标点连接在一起。 如果改用geom_line()， 会将数据先按照x坐标值排序然后再顺序相连。 可以看出， 结果是一个正圆； 如果不使用coord_fixed()，结果不一定是正圆。 在coord_fixed()函数中， 还可以用expand = FALSE要求坐标轴范围严格等于数据范围或xlim和ylim的规定， 否则会比数据范围略宽一些。 scale_x_log10()和scale_y_log10()可以将x轴或者y轴用对数刻度， 这实际上是将数据做常用对数变换， 但是相应的坐标轴刻度的数值还标成变换之前的原始值。 对数轴方向相同的距离代表相差相同的倍数。 经济、金融数据常常需要用对数刻度。 对数轴最好用来代表比例， 尤其是使用条形图时， 应该从1开始而不是从0开始。 下图是我国2000-2015年的居民消费水平（元）, 可以看出， 增长是指数型的： d &lt;- data.frame( x = 2000:2015, y = c(3721L, 3987L, 4301L, 4606L, 5138L, 5771L, 6416L, 7572L, 8707L, 9514L, 10919L, 13134L, 14699L, 16190L, 17778L, 19308L)) p &lt;- ggplot(data=d, mapping = aes( x = x, y = y)) p + geom_point(size = 2) 将y轴用对数刻度，则散点可以呈现为线性： p + geom_point(size = 2) + scale_y_log10() 用geom_smooth()添加线性拟合线： p + geom_point(size = 2) + geom_smooth(method=&quot;lm&quot;) + scale_y_log10() ## `geom_smooth()` using formula &#39;y ~ x&#39; 注意geom_smooth(method=\"lm\")在计算拟合时会自动采用log10(y)的值。 scale_x_sqrt()和scale_y_sqrt()与对数轴类似， 做的是平方根变换。 对于面积值， 这种变换有一定意义。 用coord_polar()指定极坐标系， 用theta=\"x\"或者theta=\"y\"指定那一维映射到极角。 如： d &lt;- data.frame( x &lt;- (0:11)/12*2*pi, y &lt;- 11:22 ) p &lt;- ggplot(data=d, mapping = aes( x = x, y = y)) p + geom_point(size=2) + scale_x_continuous(limits=c(0, 2*pi)) + scale_y_continuous(limits=c(0, 22)) + coord_polar(theta=&quot;x&quot;, start=-pi/2, direction=-1) 上图中y轴为极径的刻度， 圆周上的数字表示极角刻度。 程序中start指定极角为0的射线与12点方向的夹角弧度， direction=1表示顺时针计算角度， direction=-1表示逆时针。 scale_continuous_x()和scale_continuous_y()指定了两个维度的坐标范围。 用scale_xxx()函数指定非默认的刻度， 一般模式为scale_映射维度_类型()， “类型”包括continuous、discrete、log10等。 可以用来人为指定坐标轴的刻度值， 修改color或者fill维度所利用的颜色表，等等， 用其中的参数指定这些内容。 注意坐标轴的标签（标题）用labs()函数指定， 而不是用scale_xxx()函数指定。 例如， 在organdata中， 作donors对roads(每十万人的道路交通事故死亡率)的散点图， 并按world(不同福利类型)对散点染色， x、y、color这三个维度都用了默认的刻度: p &lt;- ggplot(data = organdata, mapping = aes( x = roads, y = donors, color = world )) p + geom_point() ## Warning: Removed 34 rows containing missing values (geom_point). 这里有三个维度：连续型的x、y维度与无序分类值的color维度。 color维度既可以取连续型， 也可以取有序或者无序的分类型。 x、y维度有自动的坐标轴， color维度有图例在图形右侧。 如果没有特殊要求，不必调用scale_xxx()函数。 下面将y轴的刻度值进行人为的规定， 将color维的标签人为指定： p + geom_point() + scale_y_continuous( breaks = c(5, 15, 25), labels = c(&quot;百万分之五&quot;, &quot;百万分之十五&quot;, &quot;百万分二十五&quot;) ) + scale_color_discrete(labels = c( &quot;社团主义&quot;, &quot;自由&quot;, &quot;社会民主&quot;, &quot;无分类&quot; )) ## Warning: Removed 34 rows containing missing values (geom_point). 在scale_维度_contiuous()函数中， 可以用breaks指定坐标刻度标线的坐标数值表， 用minor_breaks指定细刻度的坐标数值表， 用labels指定在坐标刻度标线处标出的坐标值标签字符串表， 用limits指定坐标系的范围（两个数的向量）， 用expand指定在将坐标轴范围比数据的范围在两侧分别扩充多少， 取c(0,0)要求不扩充，默认会左右各扩充5%。 ggplot2的散点图默认使用灰色背景并带有白色的网格线。 theme()函数的panel.background可以指定背景色， panel.grid、panel.grid.xxx可以指定网格线做法。 29.10 如何使用颜色 可以用颜色来表示分组， 比如， 不同组的散点用不同颜色， 多条曲线用不同颜色； 可以用颜色表示数值， 用颜色深浅表示绝对值大小； 可以用颜色来突出某些要强调的图形元素。 将变量值映射为颜色， 可以分为如下四种情况： 无序的分类变量； 有序的分类变量，仅有大小次序，没有正反； 有序的分类变量，有正有反； 连续数值变量。 29.10.1 名义型变量的颜色 将无序的分类值映射到颜色， 应该使用完全不相像、很容易区分的颜色， 各个颜色应该没有明显次序、没有哪一个与其他明显不同。 可以用RColorBrewer扩展包提供的调色盘， ggsci包也提供了一些调色盘。 在ggplot2中用scale_color_brewer(palette)和scale_fill_brewer(palette)选择RColorBrewer中的调色盘。 图29.1为无序分类适用的调色盘。 称这样的调色盘为名义型(qualitative)。 色盲的人会分辨不出某些颜色， 比如红绿色盲的人无法分辨红色和绿色， 蓝绿色盲的人无法分辨蓝色和绿色。 男性中有8%的人有色盲， 所以绘图时应该考虑到这个问题。 (Wilke 2019)提供了8种对色盲也可区分的颜色： 表29.1: 8种对色盲可区分的颜色 name code black #000000 orange #E69F00 sky blue #56B4E9 bluish green #009E73 yellow #F0E442 blue #0072B2 vermilion #D55E00 reddish purple #CC79A7 图29.1: 无序分类适用的调色板 例如， 作gapminder数据集中各国在2007年期望寿命对人均GDP的散点图， 不同大洲使用不同的颜色， 指定ColorBrewer的Set1调色板： p &lt;- ggplot(data = subset(gapminder, year == 2007), mapping = aes( x = gdpPercap, y = lifeExp)) p + geom_point(mapping = aes(color = continent)) + scale_color_brewer(palette = &quot;Set1&quot;) 使用颜色进行强调时， 可以将要强调的点、线、条形用鲜明的颜色， 而非强调的用褪色的颜色。 最简单的做法是仅对要强调的内容指定一个鲜明的颜色。 29.10.2 色块图 geom_tile()、geom_rect()、geom_raster()可以用颜色画长方块。 geom_tile()指定每个长方块的中心位置(x和y)、宽度(width)和高度， geom_rect()指定每个长方块的四个角的左右和上限坐标(xmin, xmax, ymin, ymax)， geom_raster()是geom_tile()在长方块大小相同时的快速版本。 例如，表29.1中的颜色图： d &lt;- tibble( x = rep(1:4, 2), y = rep(1:2, each=4), fill = dcolorqua$code, label = dcolorqua$name) p &lt;- ggplot(data = d, mapping = aes( x = x, y = y, fill = fill, label = label)) p + geom_raster() + geom_text(color = &quot;white&quot;) + guides(fill = FALSE) 29.10.3 有序型变量的颜色 将连续的或者有序的值映射到颜色， 应该使用渐变色， 如果都是正值， 可以使用从浅到深或者从深到浅的颜色， 并且应该使用同一个颜色，只是深浅程度不同。 图29.2为单向的有序分类适用的调色板。 称这样的调色板为有序型(sequential)。 图29.2: 有序单向分类适用的调色板 29.10.4 相异型变量的颜色 如果颜色代表有正有负的数值（比如反对、中立、支持）， 则应该以浅色为接近零值， 正值与负值分别用两个不同的颜色。 另外， 如果要代表的数值有明显的中间值， 为了强调较低的值与较高的值的对比， 也可以使用这样的颜色刻度。 图29.3为有正有负的有序分类适用的调色板。 称这样的调色板为相异型(diverging)。 相异型的渐变色有可能对色盲的人不可辨识， Colorbrewer::PiYG刻度对色盲人群也可以分辨。 图29.3: 有序正负分类适用的调色板 29.10.5 连续数值变量的颜色 可以将数值变量映射到颜色(color或者fill维)， ggplot2可以自动选择映射关系， 也可以用scale_color_gradient()或scale_color_gradient()函数自己指定一个渐变色， 只需要指定渐变色的low和high两段颜色， 一般需要用颜色代码表示， R扩展包colorpicker可以帮助挑选颜色。 对于只取非负值的变量， 对应的渐变色应该是仅从前到深或者从深到浅的， 使用默认参数调用scale_color_gradient()产生这种效果； 对于有正有负的变量， 就应该使用两种截然不同的颜色表示正负值， 用浅色表示接近0的值， 使用默认参数调用scale_color_gradient2()产生这种效果。 29.11 标题、标注、指南、拼接 除了ggplot()指定数据与映射， geom_xxx()作图， 还可以用许多辅助函数增强图形。 labs()可以设置适当的标题和标签。 annotate()函数可以直接在坐标系内进行文字、符号、线段、箭头、长方形的绘制。 guides()函数可以控制图例的取舍以及做法。 theme()函数可以控制一些整体的选项如背景色、字体类型、图例的摆放位置等。 在需要修改图形时， 如果修改会影响到相应的geom_xxx()的主要结果， 一般需要在ggplot()或者该geom_xxx()函数中将适当的变量映射为某一维度， 或者用scale_xxx()函数进行变换。 如果仅仅是一些显示效果的修改， 则一般作为geom_xxx()的选项， 或者调用labs()、theme()、guides()完成。 29.11.1 标题 函数labs()可以用来指定图形上方的标题(title)、副标题(subtitle)、右下方的标注(caption)、左上方的标签以及坐标轴标题和其它维的名称。 例如： p &lt;- ggplot(data = gapminder, mapping = aes( x = gdpPercap, y = lifeExp)) p + geom_point(alpha = 0.4) + labs( title = &quot;各国各年度人均GDP与期望寿命的关系&quot;, subtitle = &quot;1952-2007&quot;, tag = &quot;散点图&quot;, caption = &quot;数据来源：gapminder&quot;, x = &quot;人均GDP(单位：美元)&quot;, y = &quot;期望寿命&quot; ) 在labs()中用x=、y=、color=之类的选项指定坐标轴的标签或者其它维的名称， 如果该维用了scale_xxx()函数， 则应该则scale_xxx()函数中用name=指定轴标签（名字）。 数值型的维度除非是显然的应在标签中包含单位。 labs()中或者scale_xxx(name=)中如果指定文字为NULL则取消该标题或标签， 但是取消坐标轴标签必须是取消标签后含义也显而易见， 没有任何疑问的情况。 labs()只是提供了这些标题功能， 一般并不会同时使用这些功能。 在出版图书内， 图形下方一般伴随有图形说明， 这时一般就不再使用标题、副标题、标签、标注， 而只需写在图的伴随说明文字中， 当然，坐标轴标签一般还是需要的。 有一点要注意， 默认的标题、坐标轴标签、图例标签中的文字往往偏小， 如果单独放大这些图形来看并没有问题， 但是作为插图放在书中或者网页中就偏小了。 可以用theme()函数调整字体大小。 29.11.2 标注功能 通过annotate(geom = \"text\")调用geom_text()的功能， 可以在一个散点图中标注多行文字， 多行之间用\"\\n\"分开： p &lt;- ggplot(data = gapminder, mapping = aes( x = gdpPercap, y = lifeExp)) p + geom_point() + geom_smooth(method=&quot;gam&quot;) + scale_x_log10() + annotate( geom = &quot;text&quot;, x = 1E2, y = 85, hjust = 0, label=&quot;期望寿命与人均GDP的对数值呈线性关系，\\n建议建立相应的线性回归模型。&quot;) ## `geom_smooth()` using formula &#39;y ~ s(x, bs = &quot;cs&quot;)&#39; 在annotate()中选geom = \"rect\"， 给出长方形的左右和上限界限， 可以将上面图形中最右侧偏低的点用长方形填充标出。 可以在annotate()中选geom = \"line\"画线， 需要给出线的起点和终点坐标， 可以arrow选项要求画箭头， 用arrow()函数给出箭头的大小、角度等设置， 如： p + geom_point() + geom_smooth(method=&quot;gam&quot;) + scale_x_log10() + annotate(geom = &quot;rect&quot;, xmin = 5.5E4, xmax = 1.2E5, ymin = 54, ymax = 71, fill = &quot;red&quot;, alpha = 0.2) + annotate(geom = &quot;line&quot;, x = c(5.9E4, 3.16E4), y = c(53, 40), arrow = arrow(angle = 20, length = unit(4, &quot;mm&quot;))) + annotate(geom = &quot;text&quot;, x = 3.16E4, y = 38, label = &quot;这些国家的期望寿命低于预期&quot;) ## `geom_smooth()` using formula &#39;y ~ s(x, bs = &quot;cs&quot;)&#39; 这样标注的缺点是坐标都需要读图并试错摆放。 上述被标注的国家是： gapminder %&gt;% filter(gdpPercap &gt; 5.5E4 &amp; gdpPercap &lt; 1.2E5, lifeExp &gt; 54 &amp; lifeExp &lt; 71) %&gt;% select(country, gdpPercap, lifeExp) ## # A tibble: 6 x 3 ## country gdpPercap lifeExp ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Kuwait 108382. 55.6 ## 2 Kuwait 113523. 58.0 ## 3 Kuwait 95458. 60.5 ## 4 Kuwait 80895. 64.6 ## 5 Kuwait 109348. 67.7 ## 6 Kuwait 59265. 69.3 可以用geom_hline()、geom_vline()和geom_abline()画横线、竖线、斜线。 ggplot2的默认主题会自动画参考线， 可以用theme()函数指定参考线画法。 29.11.3 指南(guides) 对于颜色、填充色等维度， 会自动生成图例。 用guides(color = FALSE)这样的方法可以取消指定维度的图例。 theme()可以调整一些整体的设置， 如背景色、字体、图例的摆放位置。 用theme()的legend.position改变图例的位置， 如theme(legend.position = \"top\")可以将图例放置在上方， 默认是放置在右侧的。 可取值有\"none\"、\"left\"、\"right\"、\"bottom\"、\"top\"，如： p &lt;- ggplot(data = iris, mapping = aes( x = Petal.Length, y = Petal.Width, color = Species)) p + geom_point(alpha = 0.4) + theme(legend.position = &quot;top&quot;) 图例位置legend.position还可以指定在作图区域内部用两个百分比数字给定， 同时可以用legend.just指定位置对准图例框的哪一个角，也是用两个百分比数字， 比如放在左上角内部： p + geom_point(alpha = 0.4) + theme( legend.position = c(0.02, 0.98), legend.justification = c(0,1) ) 某一维的图例做法可以在相应的scale_xxx()函数中用guide=指定， 或者在guides()中用维名称=指南方法指定， 如guides(fill = \"guides\")或者guides(fill = \"colorbar\")。 指定的指南还可以是guide_legend()或者guide_colorbar()的结果， 在这两个函数中可以用多个选项指定指南或颜色条的具体做法。 有一个directlabels包， 可以巧妙地将各类的图例直接就进标在坐标系内部。 29.11.4 拼接图形 facet_wrap()和facet_grid()可以按照某一个或两个分类变量的值将输入数据集分为若干个子集， 将每个子集分别在一个小图上绘图。 有时还需要将几幅不同图形拼在一起， 这些图形可以是同一数据的不同类型图形， 也可以是完全无关的图形。 在拼接图形时， 各个小图应该具有类似的风格， 即背景、配色、字体等应该尽可能一致， 上下和左右的坐标轴应尽可能对齐， 小图的标签应该尽可能不显眼。 cowplot包提供了拼接图形的办法， 使用时先将每个小图分别赋值给一个R变量， 然后用plot_grid()函数摆放在一幅图中。 例如， 19个学生的性别、年龄、身高、体重数据： library(cowplot) dclass &lt;- read_csv( &quot;class.csv&quot;, col_types=cols( .default = col_double(), name=col_character(), sex=col_factor(levels=c(&quot;M&quot;, &quot;F&quot;)) )) p1 &lt;- ggplot(data = dclass, mapping = aes(x = sex, fill = sex)) + geom_bar() + scale_fill_manual( guide = FALSE, values = c(&quot;F&quot; = &quot;chocolate1&quot;, &quot;M&quot; = &quot;skyblue1&quot;) ) p2 &lt;- ggplot(data = dclass, mapping = aes( x = height, y = weight, color = sex)) + geom_jitter(size = 3) + scale_color_manual( values = c(&quot;F&quot; = &quot;chocolate1&quot;, &quot;M&quot; = &quot;skyblue1&quot;) ) plot_grid( p1, p2, labels = &quot;auto&quot;, rel_widths = c(0.3, 0.6), align = &quot;h&quot;) plot_grid()中用rel_widths指定了左右图的相对比例， 默认是均分的。 当图形上下排列时，可以用rel_height指定上下排的比例。 程序中用了align = \"h\"使得左右图上下对齐， align默认取\"none\"， 也可以取\"h\"、\"v\"或\"hv\"。 可以用ncol指定图的列数， 用nrow指定图的行数。 还可以通过嵌套调用plot_grid()方式实现非网格的排列。 29.12 图形定制调整 ggplot2的默认设置一般能够满足我们的要求， 只有在有特殊的图形类型需求或者制作出版用的图形时， 才需要对图形进行定制调整。 图形调整可以包括： 配色、位置摆放等审美方面的调整； 面向目标出版物或者目标读者的调整； 增加有意义的标注； 调整整体的观感。 29.12.1 图形逐步调整例子 socviz扩展包的asasec数据集是美国社会学学会(ASA)的各分会2005年到2015年的一些数据， 其中的财务数据(Beginning, Revenues, Expenses, Ending)虽然各年都有值， 但实际是用2015年的值填进去的。 作2014年收入对会员数的散点图与拟合曲线， 每个散点是一个分会： p &lt;- ggplot(data = subset(asasec, Year == 2014), mapping = aes( x = Members, y = Revenues, label = Sname)) p + geom_point() + geom_smooth() ## `geom_smooth()` using method = &#39;loess&#39; and formula &#39;y ~ x&#39; 程序中的映射label = Sname暂时不起作用， 在geom_text()中才需要这一维度。 下面按照有无期刊染色， 将平滑方法改为线性回归： p + geom_point(mapping = aes(color = Journal)) + geom_smooth(method = &quot;lm&quot;) ## `geom_smooth()` using formula &#39;y ~ x&#39; 注意color = Journal的映射仅对geom_point()有效， 如果写在ggplot()中， 就对geom_smooth()也有效了。 下面标出异常值： p + geom_point(mapping = aes(color = Journal)) + geom_smooth(method = &quot;lm&quot;) + geom_text_repel(data = subset(asasec, Year == 2014 &amp; Revenues &gt; 7000)) ## `geom_smooth()` using formula &#39;y ~ x&#39; 下面用labs()调整标题、用scale_y_continuous()调整y轴刻度标法、用theme()调整图例位置： p + geom_point(mapping = aes(color = Journal)) + geom_smooth(method = &quot;lm&quot;) + geom_text_repel(data = subset(asasec, Year == 2014 &amp; Revenues &gt; 7000)) + labs( title = &quot;ASA分会&quot;, subtitle = &quot;2014年&quot;, x = &quot;分会会员数&quot;, y = &quot;收益&quot;, color = &quot;分会有无期刊&quot;, caption = &quot;数据来源：ASA年报&quot; ) + scale_y_continuous(labels = scales::dollar) + theme(legend.position = &quot;bottom&quot;) ## `geom_smooth()` using formula &#39;y ~ x&#39; 29.13 主题 ggplot2包作图可以实现内容与设计的分离， 这里内容就是指数据、映射、统计、图形类型等方面， 而设计就是指背景色、颜色表、字体、坐标轴做法、图例位置等的安排。 将作图任务分解为内容与设计两个方面， 可以让数据科学家不必关心设计有关的元素， 而设计可以让专门的艺术设计人才来处理。 这种工作分配已经在图书出版、网站、游戏开发等行业发挥了重要作用。 theme()函数用来指定设计元素，称为主题(theme)， 而且可以单独开发R扩展包来提供适当的主题。 ggthemes扩展包是一个这样的包。 theme(legend.position)可以用来选择图例位置。 theme_set()可以改变后续ggplot2作图的主题（配色、字体等）。 如theme_set(theme_bw()), theme_set(theme_dark())等。 对单次绘图， 可以直接用加号连接theme_gray()等这些主题函数。 主题包括theme_gray()（默认主题）、 theme_minimal()、theme_classic()等。 ggthemes扩展包提供了更多的主题选择。 theme()函数还可以直接指定颜色、字体、大小等设置。 29.14 参考文献 Cleveland, W. S. (1993). The elements of graphing data. Hobart Press. Cleveland, W. S. (1994). Visualizing data. Hobart Press. Cleveland, W. S., &amp; McGill, R. (1984). Graphical perception: Theory, experimentation, and application to the development of graphical methods. Journal of the American Statistical Association, 79, 531–534. Cleveland, W. S., &amp; McGill, R. (1987). Graphical perception: The visual decoding of quantitative information on graphical displays of data. Journal of the Royal Statistical Society Series A, 150, 192–229. Edward R. Tufte((1983) The Visual Display of Quantitative Information Tufte, E. R. (1983). The visual display of quantitative information. Cheshire, CT: Graphics Press. Tufte, E. R. (1990). Envisioning information. Cheshire, CT: Graphics Press. Tufte, E. R. (1997). Visual explanations: Images and quantities, evidence and narrative. Cheshire, CT: Graphics Press. Wickham, H. (2016). Ggplot2: Elegant graphics for data analysis. New York: Springer. Wickham, H., &amp; Chang, W. (2018). Ggplot2: Create elegant data visualisations using the grammar of graphics. Wilkinson, L. (2005). The grammar of graphics (Second). New York: Springer. References "],["ggplotvis.html", "30 ggplot的各种图形 30.1 介绍 30.2 表现数量 30.3 表现分布 30.4 表现比例 30.5 表现多个变量间的关系 30.6 时间序列图 30.7 拟合曲线图 30.8 表现不确定性", " 30 ggplot的各种图形 30.1 介绍 ggplot2包提供了许多种图形， 其作用可以大致地分为： 表现数量； 表现一维或者二维分布； 表现两个变量之间的数量关系，等等。 下面按照其作用分别进行介绍。 主要参考： Claus O. Wilke(2019). Fundamentals of Data Visualization. O’Reilly Media. https://serialmentor.com/dataviz/ 30.2 表现数量 30.2.1 条形图 设有若干个类， 每个类有一个数量属性值。 经常用条形图表现数量。 30.2.1.1 简单的条形图 例如， 有25个共同基金， 分为三个类别， 各类别的频数为： d_funds_type &lt;- tibble( type = c(&quot;国内股本&quot;, &quot;国际股本&quot;, &quot;固定收益&quot;), freq = c(16, 4, 5) ) knitr::kable(d_funds_type) type freq 国内股本 16 国际股本 4 固定收益 5 用ggplot()输入数据并指定映射， 用geom_col()作条形图， x轴为类别，y轴为每个类别对应的数值，这里是输入数据中的频数： p &lt;- ggplot(data = d_funds_type, mapping = aes( x = type, y = freq )) p + geom_col() 上面的最后一行程序也可以用geom_bar()函数写成p + geom_bar(stat = \"identity\")。 geom_bar()可以对分类变量的原始值自动统计频数然后做频数条形图， 如果输入数据已经是频数， 就需要加stat = \"identity\"选项。 上面的三个类的次序并不是输入的次序， 这是因为字符型变量会自动转换为因子型， 因子水平一般按字典序排列。 可以在输入时用factor(x, levels=&lt;指定的因子水平表&gt;)定义因子并人为指定因子次序， 或者用forcats包的fct_relevel()函数，如： d &lt;- d_funds_type %&gt;% mutate(type = fct_relevel(type, &quot;国内股本&quot;, &quot;国际股本&quot;, &quot;固定收益&quot;)) p &lt;- ggplot(data = d, mapping = aes( x = type, y = freq )) p + geom_col() 可以用forcats包的fct_reorder()函数， 将各个水平按照频数大小排序，如： p &lt;- ggplot(data = d, mapping = aes( x = fct_reorder(type, desc(freq)), y = freq )) p + geom_col() 注意， 条形图中这种对各条形按照高度重排序的做法仅适用于各类没有自然的次序的情形， 如果各类有自然的次序， 比如年份、月份、季度、年龄组、收入高低分组等， 就应该按照各类的自然次序， 可以在输入数据时用factor(x, levels=&lt;指定的因子水平表&gt;)定义因子并人为指定因子次序， 或者在输入数据后用forcats包的fct_relevel()函数重排次序。 当分类的标签值（如“固定收益”）较长而且类个数较多时， 横轴的宽度可能不够用，使得相邻两项的标签重叠， 只好省略部分标签。 这时， 一种办法是将类标签方向变成45度角： p + geom_col() + theme( axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1) ) 针对条形图的各条形的标签太长的问题， 更好的办法是将条形横向放置， 这样类标签就到了y轴， 可以横向显示。 这可以在映射中直接修改， 但最好还是用coord_flip()函数颠倒x轴与y轴的作用， 因为有些图形是不允许修改映射的。 程序如 p + geom_col() + coord_flip() 下面用labs()去掉分类标签轴的标题并修改频数轴的标题： p + geom_col() + coord_flip() + labs(x = NULL, y = &quot;频数&quot;) 如果需要将频数替换成比例或者百分数， 只要修改输入数据增加相应的变量即可。 30.2.1.2 并列和堆叠的条形图 在某次对某物业公司服务的4个社区的居民的抽样调查中抽查了80位居民， 其性别与所属社区如下： mat_comm &lt;- matrix( c(9, 10, 13, 4, 18, 7, 8, 11), nrow=4, ncol=2, dimnames = list(c(&quot;A社区&quot;, &quot;B社区&quot;, &quot;C社区&quot;, &quot;D社区&quot;), c(&quot;男&quot;, &quot;女&quot;)) ) knitr::kable(mat_comm) 男 女 A社区 9 18 B社区 10 7 C社区 13 8 D社区 4 11 将表格数据转换为数据框： d_comm &lt;- as.data.frame(as.table(mat_comm)) names(d_comm) &lt;- c(&quot;社区&quot;, &quot;性别&quot;, &quot;频数&quot;) knitr::kable(d_comm) 社区 性别 频数 A社区 男 9 B社区 男 10 C社区 男 13 D社区 男 4 A社区 女 18 B社区 女 7 C社区 女 8 D社区 女 11 现在数据中有两个分类变量， 频数是交叉分类的结果， 这样的数据称为“列联表”。 这时， 将两个分类变量中一个作为大类， 映射到x维度， 另一个作为小类， 映射到fill维度， 频数映射到y维度。 使用geom_col()或者geom_bar(stat = \"identity\")。 如： p &lt;- ggplot(data = d_comm, mapping = aes( x = `性别`, fill = `社区`, y = `频数` )) p + geom_col() 结果为堆叠的条形图， 每个大类画一个分段的条形， 条形的程度等于各段长度之和。 这需要各段长度之和相当于每个大类的某种总计， 对于频数，这当然是合理的， 每段长度每个交叉小类的频数， 而一个条形的总长度是一个大类的频数。 当y轴映射到其它指标时堆叠条形图不一定合适， 比如， 如果y映射到每个交叉小类的某个指标的标准差， 因为标准差的和并不是标准差， 所以就不能用堆叠条形图表示。 下面将社区作为大类，性别作为小类： p &lt;- ggplot(data = d_comm, mapping = aes( x = `社区`, fill = `性别`, y = `频数` )) p + geom_col() 在geom_col()和geom_bar()中加选项position = \"dodge\"可以将小类并列放置： p &lt;- ggplot(data = d_comm, mapping = aes( x = `性别`, fill = `社区`, y = `频数` )) p + geom_col(position = &quot;dodge&quot;) 这样得到并列的条形图。 并列条形图就不需要像堆叠条形图那样要求各个小类的y轴变量和有意义。 堆叠条形图相当于在geom_col()中加position = \"stack\"。 也可以将不同的大类放置到不同的小图， 用facet_wrap()或者facet_grid()函数： p &lt;- ggplot(data = d_comm, mapping = aes( x = `社区`, y = `频数` )) p + geom_col() + facet_wrap(~ `性别`) 注意各小图默认使用相同的坐标范围。 30.2.1.3 百分数的条形图 对于只有一个分类变量的条形图， 如果y轴代表频数， 为了转换成比例或者百分比， 修改输入数据增加像相应的变量， 如： d_funds_type %&gt;% mutate(ratio = freq / sum(freq), pct = 100*ratio) -&gt; d 对于有两个分类变量的列联表， 如果希望y轴表现总百分数， 只要修改输入数据集增加相应的变量。 如果y轴希望表现每个大类内的百分数， 首先增加大类内的百分数， 比如下面的程序将社区居民调查数据按社区分为大类， 每个社区内计算不同性别的百分数： d_comm %&gt;% group_by(`社区`) %&gt;% mutate(`百分数` = `频数` / sum(`频数`) * 100) %&gt;% ungroup() -&gt; d 这样，与对频数作图类似就可以做堆叠条形图， 每个社区为一个大类， 每个大类总计100%： p &lt;- ggplot(data = d, mapping = aes( x = `社区`, fill = `性别`, y = `百分数` )) p + geom_col() 在geom_col()中加position = \"dodge\"可以变成并列条形图， 每个社区为一个大类， 每个大类中总计100%： p &lt;- ggplot(data = d, mapping = aes( x = `社区`, fill = `性别`, y = `百分数` )) p + geom_col(position = &quot;dodge&quot;) 与前一章29.5.1中类似问题相比， 对表格数据做比例或者百分数条形图， 比基于原始数据直接用geom_bar()做图要简单而且不易出错。 30.2.1.4 直接标记数字的条形图 比较简单的条形图， 可以不使用y坐标轴而是对每个条形或者堆叠的每个段标出数字。 用geom_text()函数标数字。 如： d &lt;- d_funds_type %&gt;% mutate(type = fct_relevel(type, &quot;国内股本&quot;, &quot;国际股本&quot;, &quot;固定收益&quot;)) p &lt;- ggplot(data = d, mapping = aes( x = type, y = freq )) p + geom_col(fill = &quot;lightblue&quot;) + geom_text(mapping = aes( y = freq / 2, label = paste(freq))) + scale_y_continuous(breaks = NULL) + coord_flip() + labs(x = NULL, y = NULL) 上述程序中， 用了scale_y_continuous()的breaks = NULL选项使得y轴（经过对换后画在了x轴）不画刻度和刻度值。 堆叠的条形图用数字而非坐标轴的例子如下： d_comm %&gt;% arrange(`性别`, desc(`社区`)) %&gt;% group_by(`性别`) %&gt;% mutate(ylabel = cumsum(`频数`) - 0.5*`频数`) -&gt; d p &lt;- ggplot(data = d, mapping = aes( x = `性别`, fill = `社区`, y = `频数` )) p + geom_col() + geom_text(mapping = aes( y = ylabel, label = paste(`频数`) )) + scale_y_continuous(breaks = NULL) + labs(y = NULL) 上述程序中预先计算了每段的纵坐标值， 保存在变量ylabel中。 注意计算过程中的排序与分组操作。 30.2.2 点图 条形图的y轴一般都代表数量， 最小值从0开始， 一般不画y轴最小值大于0的条形图。 对于不会取0的量， 可以取y轴的范围为某个区间而不必总是从0开始。 这时， 可以用散点位置表示y坐标。 考虑gapminder包的gapminder数据集中各国的平均期望寿命， 先求出每个大洲的期望寿命最大值： library(gapminder) gapminder %&gt;% select(continent, country, lifeExp) %&gt;% group_by(continent) %&gt;% summarise(lifeExp = max(lifeExp, na.rm=TRUE)) %&gt;% ungroup() -&gt; d_gap 用点图表现各大洲的期望寿命： p &lt;- ggplot(data = d_gap, mapping = aes( x = fct_reorder(continent, lifeExp), y = lifeExp )) p + geom_point() + coord_flip() 程序中并没有人为指定lifeExp轴的坐标范围， 作图程序自动选择了合适的范围。 对各大洲按照lifeExp的值做了排序。 这个图形很好地体现了不同大洲的最大期望寿命的差距。 如果使用条形图， 因为坐标轴从0开始， 各个条形的长度会很接近， 不利于体现差距： p + geom_col() + coord_flip() 30.2.3 热力图 如果交叉分类得到许多个交叉组， 每组有一个数量需要展示， 用堆叠或者并排条形图可能过于复杂， 结果很难判读； 如果用点图， 不同小类之间的区别也不容易认读。 可以用x轴和y轴分别表示两种分类， 在坐标交叉处用色块颜色代表数量， 称为热力图。 用geom_tile()作这种图， 将数量映射到fill维度。 例如， 考虑gapminder包的gapminder数据集中各国的平均期望寿命， 先得到每个大洲每年内各国期望寿命的中位数： gapminder %&gt;% select(continent, year, lifeExp) %&gt;% group_by(continent, year) %&gt;% summarise(lifeExp = median(lifeExp, na.rm=TRUE)) %&gt;% ungroup() -&gt; d_gap2a d_gap2a %&gt;% filter(year == 2007) %&gt;% arrange(desc(lifeExp)) -&gt; d_gap2b d_gap2a %&gt;% mutate(continent = factor(continent, levels = d_gap2b$continent)) -&gt; d_gap2 上面的程序中将各大洲的次序调整为最后一年的中位期望寿命。 作热力图： p &lt;- ggplot(data = d_gap2, mapping = aes( x = year, y = continent, fill = lifeExp)) p + geom_tile() + scale_fill_viridis_c() 函数scale_fill_viridis_c()提供了连续变量到颜色的一种映射， 在黑白显示时仍适用，且使用色盲的读者。 热力图中不易读出每个交叉组的数量的具体数值， 但是比较容易进行组间比较以及展示发展趋势。 30.3 表现分布 对于离散变量， 可以用频数、比例、百分数的条形图表现单个离散变量分布， 可以用热力图表现两个离散变量的分布。 对于连续型变量， 可以用直方图、密度估计图表现单个变量分布， 可以对多个变量同时做密度估计图。 可以用正态QQ图、盒形图、经验分布函数图等表现一元分布。 30.3.1 单个一元分布的直方图与密度估计图 直方图是最常用的表现一元连续变量分布的方法。 geom_histogram()作直方图， 可以自动选取合适的分组个数， 也可以人为指定分组个数。 直方图的结果受分组个数与分组的开始位置的影响较大， 所以使用直方图时应该尝试选用不同的分组数， 选择较适当的分组个数。 ggplot2包中的midwest数据集包含了美国中西部的一些县的统计数据， 如面积（单位：平方英里）。 下面的程序对连续取值的数值型变量area作频数直方图， 自动确定分组个数： p &lt;- ggplot(data = midwest, mapping = aes( x = area)) p + geom_histogram() ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. 不像R基本绘图的hist()函数， geom_histogram()默认使用30个分组， 而不是根据样本量大小决定分组， 所以一般应该自己指定分组数或者分组宽度。 在geom_histogram()中用bins =指定分组个数， 或者用width指定分组宽度，如： p + geom_histogram(bins = 15) 可以用boundary或者center指定某一个条形的边界或者中心， 用breaks指定所有分点位置。 如 p + geom_histogram(bins = 15, boundary = 0.0025) 可以将直方图画成连线形式，用geom_freqpoly()函数，如上图可以改为： p + geom_freqpoly(bins = 15, boundary = 0.0025) 上图虽然是连线形式，但本质上还是一个阶梯函数的不同画法。 geom_density()可以对连续变量先做核密度估计， 然后绘制密度估计曲线，如： p + geom_density() 密度曲线估计受到窗宽bw与核函数kernel的影响。 默认核函数为高斯核（标准正态分布密度作为核函数）。 除了估计曲线， 还可以用涂色区域表示密度估计， 用geom_area(stat = \"density\")函数： p + geom_area(stat = &quot;density&quot;, fill = &quot;cadetblue1&quot;) 因为核密度估计一般是连续曲线， 所以估计的曲线很可能在密度为零的地方估计为正数。 ggplot2在设计时已经考虑了避免这个问题， 但是用户自己用R的density()函数作核密度估计时还有这个问题。 可以将直方图与密度估计图合并在一起， 这时直方图的纵坐标需指定为密度估计， 这样两种图的纵坐标才处于相同的范围： p + geom_histogram(mapping = aes(y = stat(density))) + geom_density(color = &quot;red&quot;, size = 1) ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. 30.3.2 多个一元分布的直方图和密度图形 考虑ggplot2包的midwest数据集， 这是美国中西部若干个县的数据。 选取其中的IL和IN两个州的数据， 只要将州名映射为fill维， 就可以在geom_histogram()或者geom_line(stat = \"density\")对各县面积作直方图时按不同州分段显示： midwest %&gt;% filter(state %in% c(&quot;IL&quot;, &quot;IN&quot;)) -&gt; d p &lt;- ggplot(data = d, mapping = aes( x = area, fill = state)) p + geom_histogram() ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. 可以看出， IN州的县面积偏小， IL州的县面积较大。 这样的条形分段的直方图的缺点是， 下面的段的直方图形状是清楚的， 但是上面一段（上图中为IL州）的直方图则看不出形状。 如果将数据中所有的5个州都包含并在直方图中分段， 图形就变得更难认读： p &lt;- ggplot(data = midwest, mapping = aes( x = area)) p + geom_histogram(mapping = aes(fill = state)) ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. 可以用折线方式画直方图， 不同州用不同颜色： p + geom_freqpoly(mapping = aes(color = state)) ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. 可以将州映射到fill， 给geom_histogram()加position = \"fill\"选项： p + geom_histogram( mapping = aes(fill = state), position = &quot;fill&quot;, na.rm = TRUE) ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. 上图的每个条形长度都拉平了， 显示的是按area分组后每组内不同州的比例大小。 可以将不同的州分配到不同的小图，如： p &lt;- ggplot(data = midwest, mapping = aes( x = area)) p + geom_histogram() + facet_wrap(~ state) ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. 为了表现多个组的分布， 也可以将各组的具体数据用散点画出， 并添加随机扰动使其不重叠： p &lt;- ggplot(data = midwest, mapping = aes( x = area, y = state)) p + geom_jitter(width = 0, height = 0.3, alpha = 0.5) 对每个州作密度估计并将多条密度曲线画在同一坐标系可以较好地反映不同州的县面积分布： p &lt;- ggplot(data = midwest, mapping = aes( x = area, color = state)) p + geom_line(stat = &quot;density&quot;) 增加涂色，用透明度alpha使其可以重叠显示： p &lt;- ggplot(data = midwest, mapping = aes( x = area, color = state, fill = state)) p + geom_density(alpha = 0.4) 可以利用geom_text()或者geom_text_repl()将各曲线的标签标在曲线附近， 就可以取消图例显示。 30.3.3 经验分布函数图 直方图和密度估计图能够比较直观地了解数据的分布情况， 但是会受到窗宽、分组位置的影响， 所以可以看成是对数据的某种建模结果。 可以将所有数据观测值画出来， 用适当的透明度可以表现点的稠密程度， 但是当数据量特别大的时候这种方法就不合适， 而且对数据的概括性描述总是必要的。 经验分布函数图很好地描述和概括了数据的分布， 从中可以很容易得到样本分位数的估计， 而且不会受到任何参数选择影响。 一组观测值\\(X_1, X_2, \\dots, X_n\\)的经验分布函数定义为 \\[ F_n(x) = \\frac{\\#\\{X_i: X_i \\leq x \\}}{n} = \\frac{1}{n} \\sum_{i=1}^n I_{(-\\infty, x]}(x) \\] 其中\\(\\#\\{\\dots\\}\\)表示集合元素计数， \\(I_A(x)\\)是集合\\(A\\)的示性函数， 当\\(x \\in A\\)是取1，否则取0。 设有如下的10位学生的成绩： scores &lt;- c(63, 72, 74, 79, 82, 82, 87, 89, 90, 90) scores ## [1] 63 72 74 79 82 82 87 89 90 90 可以制作如下的经验分布函数表格： cdf_table &lt;- function(x){ x &lt;- sort(x) n &lt;- length(x) tab &lt;- unname(c(table(x))) pct = tab / n d &lt;- data.frame( x = sort(unique(x)), freq = tab, pct = pct, cumfreq = cumsum(tab), cumpct = cumsum(pct)) d } knitr::kable(cdf_table(scores)) x freq pct cumfreq cumpct 63 1 0.1 1 0.1 72 1 0.1 2 0.2 74 1 0.1 3 0.3 79 1 0.1 4 0.4 82 2 0.2 6 0.6 87 1 0.1 7 0.7 89 1 0.1 8 0.8 90 2 0.2 10 1.0 作经验分布函数(ECDF)图如下： d &lt;- data.frame( scores = c(63, 72, 74, 79, 82, 82, 87, 89, 90, 90)) p &lt;- ggplot(data = d, mapping = aes( x = scores, y = ..y.. )) p + stat_ecdf(geom = &quot;step&quot;) + scale_y_continuous( limits = c(-.01, 1.01), expand = c(0, 0), name = &quot;累计百分比&quot;) 从上图中， 可以看出80分及以下的人数40%左右， 最高分的25%学生分数至少为88分。 当然， 准确的数字还需要查看上面的频数分布表。 作经验分布函数图， 用了stat_ecdf()统计函数， 其中指定geom=\"step\"选项， 并将y轴映射为统计函数的结果..y..。 如果已经有经验分布函数， 则可以直接做阶梯函数图： d &lt;- data.frame( scores = c(63, 72, 74, 79, 82, 82, 87, 89, 90, 90)) dfreq &lt;- cdf_table(d$scores) p &lt;- ggplot(data = dfreq, mapping = aes( x = x, y = cumpct )) p + stat_ecdf(geom = &quot;step&quot;) + scale_y_continuous( limits = c(-.01, 1.01), expand = c(0, 0), name = &quot;累计百分比&quot;) 现实中有许多数据的分布呈现严重的偏态， 即有比较多的值偏离数据的中心。 比如， 全国各省的人口数、居民收入， 全世界各国的GDP， 等等。 下面是全国31个省（不含港澳台）2017年的人口（单位：万人）、居民年均可支配收入（单位：千元）数据，来自统计年鉴： dpop &lt;- data.frame( province =c( &quot;北京&quot;, &quot;天津&quot;, &quot;河北&quot;, &quot;山西&quot;, &quot;内蒙古&quot;, &quot;辽宁&quot;, &quot;吉林&quot;, &quot;黑龙江&quot;, &quot;上海&quot;, &quot;江苏&quot;, &quot;浙江&quot;, &quot;安徽&quot;, &quot;福建&quot;, &quot;江西&quot;, &quot;山东&quot;, &quot;河南&quot;, &quot;湖北&quot;, &quot;湖南&quot;, &quot;广东&quot;, &quot;广西&quot;, &quot;海南&quot;, &quot;重庆&quot;, &quot;四川&quot;, &quot;贵州&quot;, &quot;云南&quot;, &quot;西藏&quot;, &quot;陕西&quot;, &quot;甘肃&quot;, &quot;青海&quot;, &quot;宁夏&quot;, &quot;新疆&quot;), pop = c( 2171L, 1557L, 7520L, 3702L, 2529L, 4369L, 2717L, 3789L, 2418L, 8029L, 5657L, 6255L, 3911L, 4622L, 10006L, 9559L, 5902L, 6860L, 11169L, 4885L, 926L, 3075L, 8302L, 3580L, 4801L, 337L, 3835L, 2626L, 598L, 682L, 2445L), inc = c(57L, 37L, 21L, 20L, 26L, 28L, 21L, 21L, 59L, 35L, 42L, 22L, 30L, 22L, 27L, 20L, 24L, 23L, 33L, 20L, 23L, 24L, 20L, 17L, 18L, 15L, 20L, 16L, 19L, 21L, 20L)) knitr::kable(dpop) province pop inc 北京 2171 57 天津 1557 37 河北 7520 21 山西 3702 20 内蒙古 2529 26 辽宁 4369 28 吉林 2717 21 黑龙江 3789 21 上海 2418 59 江苏 8029 35 浙江 5657 42 安徽 6255 22 福建 3911 30 江西 4622 22 山东 10006 27 河南 9559 20 湖北 5902 24 湖南 6860 23 广东 11169 33 广西 4885 20 海南 926 23 重庆 3075 24 四川 8302 20 贵州 3580 17 云南 4801 18 西藏 337 15 陕西 3835 20 甘肃 2626 16 青海 598 19 宁夏 682 21 新疆 2445 20 作各省人均可支配收入的直方图以及密度估计图： p &lt;- ggplot(data = dpop, mapping = aes( x = inc)) p + geom_histogram() ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. p + geom_density() 这样的分布称为右偏分布， 特点是大部分数据取值集中在左侧， 但是有不可忽略的多个数据点出现在远离数据取值中心的右侧。 作收入的经验分布函数图： p &lt;- ggplot(data = dpop, mapping = aes( x = inc, y = ..y..)) p + stat_ecdf(geom = &quot;step&quot;) + labs(x = &quot;居民可支配收入（千元）&quot;, y = NULL) 如果将数据做适当的变换， 比如对数变换， 分布形状可能变得比较正态。 30.3.4 QQ图 对连续型随机变量\\(X\\)， 设其分布函数为\\(F(x)\\)， 其反函数\\(F^{-1}(p), p \\in (0, 1)\\)称为\\(X\\)的分位数函数(quantile function)。 为了估计\\(F^{-1}(p)\\)， 可以将观测值\\(X_1, X_2, \\dots, X_n\\)从小到大排序为 \\(X_{(1)}, X_{(2)}, \\dots, X_{(n)}\\)， 令\\(X_{(i)}\\)作为\\(F^{-1}(\\frac{i}{n})\\)的估计， 或者做连续性修正， 作为\\(F^{-1}(\\frac{i - 0.375}{n + 0.25})\\)的估计。 为了对比总体\\(X\\)的观测数据与某个理论分布比如正态分布之间的差距， 可以用上述的样本分位数为散点纵坐标， 以相应的理论分位数为横坐标作散点图， 称为QQ图。 如果总体服从所对比的分布， 散点应该在一条直线附近， 否则就会有明显的偏离。 最常见的QQ图是正态QQ图。 下面对一些模拟数据做正态QQ图。 首先是模拟的正态分布数据: set.seed(102) d &lt;- data.frame(x = 60 + rnorm(50, sd = 3)) p &lt;- ggplot(data = d, mapping = aes( sample = x )) p + geom_qq() + geom_qq_line() 模拟的对数正态数据： set.seed(101) d &lt;- data.frame(x = 10^(rnorm(50, sd = 1))) p &lt;- ggplot(data = d, mapping = aes( sample = x )) p + geom_qq() + geom_qq_line() 上图为典型的右偏分布正态QQ图形状。 作t(3)分布样本的正态QQ图： set.seed(104) d &lt;- data.frame(x = rt(50, df=3)) p &lt;- ggplot(data = d, mapping = aes( sample = x )) p + geom_qq() + geom_qq_line() 上图为典型的两侧都厚尾的分布的正态QQ图形状。 30.3.5 盒形图 如果需要同时表现多个分布， 上面给出了同时绘制多条密度曲线的方法， 但是这主要比较分布形状， 而不能比较分布的主要数字特征。 盒形图、小提琴图、脊线图(ridgeline plot)比较适合同时表现和比较多个分布。 比较多个分布的需求， 可能是比较多个类似的变量， 比如， 同一个学校的不同科目的成绩； 也可以是比较不同组的同一属性， 比如， 比较不同省的城镇居民收入。 如果想仅表现每个分布的均值和标准差， 可以对每个均值加减标准差画一个小的条形。 比如， ggplot2扩展包的diamonds数据集包含了5万多枚钻石的分级、大小、价格数据， 我们从中抽取不含缺失数据的1000个观测， 按5种不同品质（Fair, Good, Very Good, Premium, Ideal）分类， 对克拉重量计算每类的均值和标准差： set.seed(101) diamonds %&gt;% na.omit() %&gt;% sample_n(1000) -&gt; ddsmall ddsmall %&gt;% group_by(cut) %&gt;% summarise( mean_carat = mean(carat), sd_carat = sd(carat)) -&gt; ddsmall_summ 对每个类画以均值为中心、以均值加减标准差为两段的条形： p &lt;- ggplot(data = ddsmall_summ, mapping = aes( x = cut, y = mean_carat )) p + geom_point(size = 1.2) + geom_pointrange(mapping = aes( ymin = mean_carat - sd_carat, ymax = mean_carat + sd_carat)) + labs(x = &quot;Cut&quot;, y = &quot;Carat&quot;) 竖线的上下界也可以改为正态情形下的近似95%置信限， 即\\(\\bar x \\pm 1.96 S\\)。 可以用coord_flip()颠倒x轴和y轴。 这种图形对分布信息压缩过甚， 对于非正态的分布则不能表现分布的形状。 盒形图可以表现分布的中位数、四分之一和四分之三分位数， 最小值、最大值和可能的离群值。 geom_boxplot()作盒形图。 比如， diamonds数据集抽样1000个观测的克拉重量的盒形图： p &lt;- ggplot(data = ddsmall, mapping = aes( y = carat )) p + geom_boxplot() + scale_x_continuous(breaks = NULL) + labs(x = NULL, y = &quot;Carat&quot;) 从这个盒形图可以看出克拉重量呈现右偏分布。 比较不同品质的钻石的克拉重量，并将盒形图横向画出： p &lt;- ggplot(data = ddsmall, mapping = aes( x = cut, y = carat )) p + geom_boxplot() + coord_flip() + labs(x = &quot;Cut&quot;, y = &quot;Carat&quot;) 从克拉重量中位数看， 品质从Fair到Ideal基本上是逐步下降的， 只有Very Good级和Premium级的中位重量略有乱序。 除了Fair和Good级， 更好品质的三个等级的重量都呈右偏， 而Fair和Good级的分布则相对来说不偏态。 盒形图的轮廓线与盒子内部填充色可以用color和fill参数指定。 30.3.6 小提琴图 小提琴图是盒形图的一个改进版本， 比如， 钻石数据抽样数据集的克拉重量的小提琴图： p &lt;- ggplot(data = ddsmall, mapping = aes( x = 0, y = carat )) p + geom_violin() + scale_x_continuous(breaks = NULL) + labs(x = NULL, y = &quot;Carat&quot;) 这实际是将密度估计曲线旋转90度画出，并左右镜像画两条。 它提供了比盒形图更详细的分布信息， 比如， 可以表现出双峰分布。 下面是R的faithful数据集中变量eruptions的小提琴图： data(faithful) p &lt;- ggplot(data = faithful, mapping = aes( x = 0, y = eruptions )) p + geom_violin() + scale_x_continuous(breaks = NULL) + labs(x = NULL, y = &quot;Eruption Times&quot;) 钻石数据小数据集中各品质级别的钻石克拉重量的小提琴图比较， 横向放置： p &lt;- ggplot(data = ddsmall, mapping = aes( x = cut, y = carat )) p + geom_violin() + coord_flip() + labs(x = &quot;Cut&quot;, y = &quot;Carat&quot;) 对连续变量， 可以用ggplot2包的cut_width()函数分组， 然后可以分组作小提琴图或者盒形图。 例如， 按照钻石数据的carat变量分组， 对depth变量作小提琴图： p &lt;- ggplot(data = diamonds, mapping = aes( x = carat, y = depth, group = cut_width(carat, 0.1) )) p + geom_violin() + xlim(NA, 2.05) + labs(x = &quot;Cut&quot;, y = &quot;Carat&quot;) ## Warning: Removed 997 rows containing non-finite values (stat_ydensity). 其中xlim()函数用来指定x轴的左右边界， NA表示用数据的值确定。 30.3.7 多个密度的其它画法 30.3.2给出了将多个密度曲线叠加画出的方法。 在对多个组分别画某个连续变量的密度估计时， 可以将组别放置在y轴上， 仍用x轴表示该连续变量的取值范围。 这种图形尤其适用于考察随着时间或者地点变化的变量分布。 ggridges包提供了geom_density_ridges()函数作脊线图。 对钻石小数据集的各个级别的克拉重量作分布密度脊线图： library(ggridges) p &lt;- ggplot(data = ddsmall, mapping = aes( x = carat, y = cut)) p + geom_density_ridges() + labs(x = &quot;Carat&quot;, y = &quot;Cut&quot;) ## Picking joint bandwidth of 0.13 可以添加颜色和透明度： p &lt;- ggplot(data = ddsmall, mapping = aes( x = carat, y = cut, fill = cut)) p + geom_density_ridges(alpha = 0.5) + guides(fill = FALSE) + labs(x = &quot;Carat&quot;, y = &quot;Cut&quot;) ## Picking joint bandwidth of 0.13 可以看出不同级别的钻石的重量密度峰值的变化， 以及一定的多峰分布特征。 30.3.8 二元分布直方图和等值线图 对二元分布样本\\((x_i, y_i)\\)， 可以用散点图表现其分布情况； 当点比较多时， 可以使用alpha参数设定一定的透明度， 使得颜色深表示点比较密集， 颜色浅表示点比较稀疏。 但是， 当点的数量很大时， 设定透明度就效果不好了， 这时稀疏的地方可能基本看不到颜色， 稠密的地方就是一团黑，无法分别分布情况。 可以用类似直方图的想法将二元分布的取值区域分块， 每块统计频数， 然后用不同深浅的颜色为每个小块染色， 颜色的深浅代表频数高低。 这样的图形称为二维直方图。 每个小块可以是正方形或者正六边形。 例如，对iris数据的花瓣长、宽变量画正六边形的二维直方图： p &lt;- ggplot(data = iris, mapping = aes( x = Petal.Length, y = Petal.Width)) p + geom_hex(bins = 25) 在geom_bins()中可以用bins=指定分块的个数。 上图中颜色浅的值高， 颜色浅的值低。 可以用scale_color_gradient人为地指定代表频数的渐变色， 可以改为用深色代表高值， 如： p + geom_hex(bins = 25) + scale_fill_gradient( low = &quot;#9696F2&quot;, high = &quot;#0A0A3D&quot;) 可以利用colourpicker包的colourPicker函数或者该包的RStudio Addin – colourPicker挑选颜色。 下面做ggplot2包的diamonds数据集中的price和carat的散点图和二维直方图： p &lt;- ggplot(data = diamonds, mapping = aes( x = price, y = carat)) p + geom_jitter(alpha = 0.3) p + geom_hex(bins = 80) + scale_fill_gradient( low = &quot;#9696F2&quot;, high = &quot;#0A0A3D&quot;) 二维直方图估计的是二元阶梯函数， 也可以像一元情况估计分布密度那样估计连续的二元分布密度， 并用等值线图表示（类似于地图中的等高线）。 例如diamonds数据集中价格和重量的联合密度估计： p + stat_density_2d(color = &quot;black&quot;, size = 0.6) 其中color是等值线颜色， size是等值线粗细，单位是毫米。 密度很低的区域被忽略了， 为此， 将price用对数轴： p + stat_density_2d(color = &quot;black&quot;, size = 0.6) + scale_x_log10() 等值线图还可以与散点图叠加在一起： p + geom_point(alpha = 0.2, color = &quot;green4&quot;) + stat_density_2d(color = &quot;black&quot;) + scale_x_log10() 等值线图还可以配合不同密度区域的不同颜色填充， 如： p + stat_density_2d( mapping = aes(fill = ..level..), color = &quot;black&quot;, size = 0.5, geom = &quot;polygon&quot;) + scale_fill_gradient( low = &quot;#9696F2&quot;, high = &quot;#0A0A3D&quot;) + scale_x_log10() 对于已经估计的二元密度曲面， 可以用geom_contour()作等值线图， 用geom_raster()作密度热力图。 比如，faithfuld是Faithful喷泉的间隔与喷发时间的二维密度估计数据框， 作密度的等值线图： p &lt;- ggplot(data = faithfuld, mapping = aes( x = eruptions, y = waiting)) p + geom_contour(mapping = aes( z = density)) 可以用等值线颜色代表密度值大小： p + geom_contour(mapping = aes( z = density, color = ..level..)) 作密度估计的热力图： p + geom_raster(mapping = aes( fill = density)) 30.4 表现比例 条形图、堆叠条形图、并排条形图可以用来表现比例以及分组内的比例。 饼图经常用来表现单个分组方式的各组比例。 30.4.1 单个分布 考虑diamonds数据集中各级别， 首先计算其频数分布： ddstab &lt;- cdf_table(diamonds$cut) knitr::kable(ddstab) x freq pct cumfreq cumpct Fair 1610 0.0298480 1610 0.0298480 Good 4906 0.0909529 6516 0.1208009 Very Good 12082 0.2239896 18598 0.3447905 Premium 13791 0.2556730 32389 0.6004635 Ideal 21551 0.3995365 53940 1.0000000 ggplot2没有专门的饼图函数， 可以用geom_col()与coord_polar()配合， 或者用ggforce包的geom_arc_bar()。 下面作级别分布的饼图， 用饼图中色块大小代表不同级别的比例大小： p &lt;- ggplot(data = ddstab, mapping = aes( x = 1, y = freq, fill = x )) p + geom_col() + coord_polar(theta = &quot;y&quot;) + scale_x_continuous(name = NULL, breaks = NULL) + scale_y_continuous(name = NULL, breaks = NULL) + labs(fill = &quot;Cut&quot;) 用geom_arc_bar()函数需要直接指定各个分界线的角度。 程序如： library(ggforce) d &lt;- ddstab %&gt;% mutate( end_angle = cumpct * 2*pi, # 每块的结束角度 start_angle = lag(end_angle, default = 0), # 每块的开始角度 mid_angle = 0.5*(start_angle + end_angle), # 每块的中间角度，用于频数数值 hjust = ifelse(mid_angle&gt;pi, 1, 0), vjust = ifelse(mid_angle&lt;pi/2 | mid_angle&gt;3*pi/2, 0, 1) ) p &lt;- ggplot(data = d) p + geom_arc_bar(mapping = aes( x0 = 0, y0 = 0, r0 = 0, r = 1.0, start = start_angle, end = end_angle, fill = x )) + geom_text(aes( x = 1.05*sin(mid_angle), y = 1.05*cos(mid_angle), label = x, hjust = hjust, vjust = vjust), size = 6) + geom_text( aes( x = 0.6*sin(mid_angle), y = 0.6*cos(mid_angle), label = freq ), color = &quot;white&quot;, size = 6) + coord_fixed() + scale_x_continuous(expand = c(0.1, 0.4), breaks = NULL, name=NULL) + scale_y_continuous(breaks = NULL, name=NULL) + guides(fill = FALSE) ggstatsplot包提供了ggpiestats()函数， 可以自动标注比例， 但不能自动标注组标签在饼图边缘。 这样的频数或者比例分布， 当然可以用普通的条形图表示， 如： p &lt;- ggplot(data = ddstab, mapping = aes( x = x, y = freq )) p + geom_col() + labs(x = &quot;Cut&quot;, y = &quot;Freq&quot;) 这样的图形比较容易在各类之间比较。 也可以做成堆叠的条形图： p &lt;- ggplot(data = ddstab, mapping = aes( x = 1, fill = x, y = freq )) p + geom_col(position = &quot;stack&quot;) + scale_x_continuous(breaks = NULL, name = NULL) + labs(fill = &quot;Cut&quot;, y = &quot;Freq&quot;) 也可以横向放置，用cood_flip(): p &lt;- ggplot(data = ddstab, mapping = aes( x = 1, fill = x, y = freq )) p + geom_col(position = &quot;stack&quot;) + scale_x_continuous(breaks = NULL, name = NULL) + coord_flip() + labs(fill = &quot;Cut&quot;, y = &quot;Freq&quot;) 可以用geom_text()将各个类别标签和频数的数值直接标在色块上。 堆叠的条形图比较容易看到每个类占总数的比例大小。 30.4.2 组间的比例分布的比较 有时需要比较不同组的某个变量的比例分布。 比如， 我们将钻石按重量分为大和小两种， 在5种不同品质之间比较大小比例， 可以用堆叠的条形图或者并列的条形图。 程序： ddsmall %&gt;% mutate(size = factor( ifelse(carat &gt;= 1.0, &quot;big&quot;, &quot;small&quot;), levels=c(&quot;small&quot;, &quot;big&quot;))) %&gt;% count(cut, size) %&gt;% group_by(cut) %&gt;% mutate(pct = n / sum(n)) -&gt; ddssize p &lt;- ggplot(data = ddssize, mapping = aes( x = cut, fill = size, y = pct )) p + geom_col(position = &quot;stack&quot;) 可以很容易地在5个组直接比较两种大小各自的比例。 但是， 如果有多余两个的比例要比较， 则堆叠条形中位于中间的比例不易比较。 可以做并列的条形图，如： p + geom_col(position = &quot;dodge&quot;) 这样可以比较容易地在不同大类之间比较比例， 查看比例的变化趋势。 考虑diamonds数据集中随重量变化， 品质分布的变化。 因为重量是连续变化的， 所以图形需要变成曲线或者阴影图， 每条曲线表示某个品质的累积比例。 p &lt;- ggplot(data = diamonds, mapping = aes( x = carat, y = ..count.., fill = cut, color = cut)) p + geom_density(position = &quot;fill&quot;) + scale_x_continuous(name = &quot;Carat&quot;, expand=c(0,0)) + scale_y_continuous( name = &quot;Relative proportion&quot;, labels = scales::percent) 这样的图形仅表现了每个重量级别的品质比例， 无法表现不同重量级别的数量。 为此， 可以每种品质单独画总的重量分布密度图， 但在其中用阴影标出该品质所占比例： p &lt;- ggplot(data = diamonds, mapping = aes( x = carat, y = ..count..)) p + geom_density_line(data = select(diamonds, -cut), mapping = aes( fill = &quot;All diamonds&quot;), color = &quot;transparent&quot;) + geom_density_line(mapping = aes( fill = &quot;Highlighted cut&quot;), color = &quot;transparent&quot;) + scale_fill_brewer(type = &quot;qual&quot;) + facet_wrap(~ cut, nrow = 1) 因为程序中用了facet_wrap()分组， 所以密度图（纵轴为个数）本应只有某个品级的数据， 但是用了删除cut变量的方法， 将全集数据的密度图也画出来了。 这个数据集中， 高品质的钻石更多。 30.4.3 嵌套比例分布的比较 堆叠条形图、并列条形图都可以用来表现两重分类的列联表频数数据。 堆叠条形图中每个条形的高度可以用来表现大类频数， 每个条形内色块的大小可以用来表现大类内小类的频数和比例。 不同大类之间的小类频数和比例相对来说不易比较。 并列条形图中每个条形是一个交叉类的频数， 所以在大类之间比较小类频数比较容易， 但是每个大类的频数则表现得较为模糊。 马赛格图是另外一种表现列联表频数的图形， 用色块面积表示每个交叉类的频数。 与堆叠条形图相比， 这里用了条形宽度而不是条形高度表示大类频数。 diamonds %&gt;% mutate(size = factor( ifelse(carat &gt;= 1.0, &quot;big&quot;, &quot;small&quot;), levels=c(&quot;small&quot;, &quot;big&quot;))) %&gt;% count(cut, size) %&gt;% group_by(cut) %&gt;% mutate(cutfreq = sum(n)) %&gt;% ungroup() -&gt; ddssize0 p &lt;- ggplot(data = ddssize0, mapping = aes( x = cut, fill = size, y = n, width = cutfreq )) p + geom_col(position = &quot;fill&quot;, color=&quot;white&quot;, size=1) + facet_grid(~ cut, scales = &quot;free_x&quot;, space = &quot;free_x&quot;) ggplot2中没有专门的马赛克图。 上面的程序用了geom_col()、facet_grid()和width参数实现马赛克图。 与马赛克图类似的一种方法是在大类中再细分小类， 而且细分小类的办法不是单向划分的。 treemapify包的geom_treemap()函数可以做树状分类图。 如： library(treemapify) p &lt;- ggplot(data = ddssize0, mapping = aes( subgroup = cut, fill = interaction(size, cut), area = n)) p + geom_treemap(color=&quot;white&quot;, size=0.5*.pt, alpha=NA) + geom_treemap_subgroup_text( place = &quot;center&quot;, alpha = 0.5, grow = TRUE) + geom_treemap_text(mapping = aes( label = size), color = &quot;white&quot;, place = &quot;center&quot;, grow = FALSE) + guides(fill = FALSE) 还可以用平行集（parallel sets）方法表现多个分类之间的关系， 以一个分类为主分类染色， 可以看出每个主分类与其他子类的关系。 ggforce包的geom_paralles_sets()函数作这种图。 参见https://serialmentor.com/dataviz/nested-proportions.html。 30.5 表现多个变量间的关系 当数据集中有多个变量中， 我们除了关心每一个变量的类型、取值集合、分布情况， 还关心变量之间的关系， 观测的分组情况等。 为表现两个变量之间的关系， 最常用的是散点图。 多个变量之间可以用散点图矩阵、相关图， 可以在散点图中用符号大小、符号颜色、符号形状表示更多维数。 对于高维数据， 经常需要利用降维方法， 如主成分分析(PCA)对数据降维， 对降维数据作图。 30.5.1 散点图 R软件自带的iris数据集中包含了三种鸢尾花的150个样品的测量数据， 每种各50个样品， 每个样品测量了花瓣、花萼的长、宽。 下面画50个setosa样品的花瓣长、宽的散点图， 可以看出， 两种有明显的线性相关关系： p &lt;- ggplot( data = filter(iris, Species == &quot;setosa&quot;), mapping = aes(x = Petal.Length, y = Petal.Width)) p + geom_point() 应该有50个点， 但实际只看到23个点。 这是因为许多点重叠在一起了。 加上透明度参数可以使得重叠的点颜色更深： p + geom_point(alpha = 0.3, size = 2.0) 图的效果还是不够明显， 不太好判断重叠了多少个点， 另外如果不同颜色的点重叠， 就无法判断有哪些颜色的点重叠在一起。 如果不做说明， 读者也不一定了解颜色深浅代表重叠点的多少。 当点数很多，如数百、数千个点时， 可以用size参数画更小的点， 这时使用透明度的效果会比较显著。 注意， 透明度是一个0到1之间的数值， 1/3表示重叠3个点会变成不透明， 透明度1/10表示重叠10个点会变成不透明。 在点数较少时如果有重叠， 可以使用geom_jitter()， 使得每个点略有随机偏移， 就可以使得各个点基本上不重叠。 偏移可以是上下左右同时进行， 也可以要求仅上下或者仅左右偏移。 例如： p + geom_jitter(width=0.05, height=0.05) geom_jiter()中的width和height是左右和上下抖动的幅度百分比， 以数据间的最小差距为单位， 默认的抖动比例是40%， 一般不超过50%， 否则原来是两个不同坐标值的点可能会看起来是同一坐标值。 比如， 假设x变量的值是精确到小数点后1位的， 取值如1.3, 1.4， 抖动40%，坐标可以变成1.33, 1.46， 如果允许抖动60%， 则1.3可能变成1.36，1.4可能变成1.34， 就无法区分原来不同的值了。 如果做所有的150个样品的散点图， 则三点呈现出分组现象： p &lt;- ggplot(data = iris, mapping = aes( x = Petal.Length, y = Petal.Width)) p + geom_jitter(width=0.05, height=0.05) 为此， 应该设法在散点图中区分三种不同鸢尾花品种。 将Species映射到color属性即可区分： p &lt;- ggplot(data = iris, mapping = aes( x = Petal.Length, y = Petal.Width, color = Species)) p + geom_jitter(width=0.05, height=0.05) 如果希望将花萼长度也添加到图形中， 因为已经有x维、y维和颜色， 只能通过符号大小来添加。 将花萼长度映射到size维： p &lt;- ggplot(data = iris, mapping = aes( x = Petal.Length, y = Petal.Width, size = Sepal.Length, color = Species)) p + geom_point(alpha = 0.4) 这样的用符号大小代表一个变量数据的图形称为气泡图(bubble plot)。 符号大小是比较难认读的图形刻度。 30.5.2 散点图矩阵 多个变量之间的关系经常用散点图矩阵表示。 ggplot2包没有提供专门的散点图矩阵， 基础R图形中提供了pairs函数作散点图矩阵， GGally包提供了一个ggscatmat()函数作散点图矩阵。 例如， 对iris数据的四个测量值变量作散点图矩阵： library(GGally) ## Registered S3 method overwritten by &#39;GGally&#39;: ## method from ## +.gg ggplot2 ## ## 载入程辑包：&#39;GGally&#39; ## The following object is masked from &#39;package:dplyr&#39;: ## ## nasa ggscatmat(data = iris, columns = 1:4) 排列成矩阵的各个小图的下三角位置是两个变量的散点图， 对角线位置是单个变量的核密度估计， 上三角位置是两个变量的相关系数。 可以用color选项增加color映射， 可以用alpha指定透明度。如： ggscatmat(data = iris, columns = 1:4, color = &quot;Species&quot;) GGally的ggpairs()函数提供了另一种矩阵图， 可以比较变量两两分布或者关系。 例如， 取iris数据集的花瓣长、花萼长与种类： ggpairs( data = iris, columns = c(&quot;Petal.Length&quot;, &quot;Sepal.Length&quot;, &quot;Species&quot;)) ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. 可以看出，对角线位置是单个变量的密度估计或者离散分布条形图， 两个连续变量之间有散点图与相关系数， 连续变量与分类变量之间有按分类变量分组的直方图和盒形图。 30.5.3 相关系数矩阵图 多个变量之间的相关系数矩阵可以用色块图表示， ggplot2包没有提供专门的函数， 可以用数据变换和geom_tile()函数实现。 corrgram包提供了corrgram函数作相关系数矩阵图， 见28.6.1。 30.5.4 数据降维 当数据中有过多的变量时，比如变量达到数百、数千时， 即使是散点图矩阵都信息量过大难以认读。 这时常用主成分分析等降维方法将数据降维到若干个新变量， 对新变量作图。 主成分分析利用变量的协方差阵或者相关阵的特征值分解对原始变量进行线性组合， 产生若干个新变量。 当原始变量为相同单位且可比时， 可以基于协方差阵， 否则应该基于相关阵。 例如， 对iris数据集的4个测量值作主成分分析： pca1 &lt;- princomp(iris[,1:4], cor=FALSE) summary(pca1) ## Importance of components: ## Comp.1 Comp.2 Comp.3 Comp.4 ## Standard deviation 2.0494032 0.49097143 0.27872586 0.153870700 ## Proportion of Variance 0.9246187 0.05306648 0.01710261 0.005212184 ## Cumulative Proportion 0.9246187 0.97768521 0.99478782 1.000000000 load1 &lt;- loadings(pca1) print(load1) ## ## Loadings: ## Comp.1 Comp.2 Comp.3 Comp.4 ## Sepal.Length 0.361 0.657 0.582 0.315 ## Sepal.Width 0.730 -0.598 -0.320 ## Petal.Length 0.857 -0.173 -0.480 ## Petal.Width 0.358 -0.546 0.754 ## ## Comp.1 Comp.2 Comp.3 Comp.4 ## SS loadings 1.00 1.00 1.00 1.00 ## Proportion Var 0.25 0.25 0.25 0.25 ## Cumulative Var 0.25 0.50 0.75 1.00 ps1 &lt;- predict(pca1) ps1 &lt;- as.data.frame(ps1) ps1 &lt;- cbind(iris, ps1) 前两个主成分解释了原始变量中98%的方差。 作第一和第二主成分的散点图： p &lt;- ggplot(data = as.data.frame(ps1), mapping = aes( x = Comp.1, y = Comp.2, color = Species)) p + geom_point(size = 2.0, alpha = 0.4) 主成分分析取前两个主成分在各原始变量上的载荷可以做矢量图， 用来表示各个原始变量与主成分的关系： d &lt;- as.data.frame(load1[,1:2]) d$vlabel &lt;- rownames(d) p &lt;- ggplot(data = d, mapping = aes( x = Comp.1, y = Comp.2, label = vlabel)) p + geom_segment(mapping = aes( xend = Comp.1, yend = Comp.2), x = 0, y = 0, arrow = arrow(angle = 15)) + geom_text_repel() 可以将降维的散点图与变量的载荷图画在同一坐标系内： d &lt;- as.data.frame(load1[,1:2]) d$vlabel &lt;- rownames(d) ggplot() + geom_point(data = ps1, mapping = aes( x = Comp.1, y = Comp.2, color = Species), size = 2.0, alpha = 0.4) + geom_segment(data = d, mapping = aes( xend = Comp.1, yend = Comp.2), x = 0, y = 0, arrow = arrow(angle = 15)) + geom_text_repel(data = d, mapping = aes( x = Comp.1, y = Comp.2, label = vlabel), alpha = 0.5) 30.5.5 成对数据 成对数据指同一个变量在两个不同时间的测量值， 或者同一个体两个取值基本相同的变量。 作散点图时， 增加\\(y = x\\)直线是显然的一个增强显示。 另外， 还应该强调两个变量之间的差别。 考虑boot扩展包的cd4数据集， 这个数据集包含了20名临床试验受试者在开始时和一年以后的cd4指标测量值。 作这两个指标的散点图： data(cd4, package = &quot;boot&quot;) p &lt;- ggplot(data = cd4, mapping = aes( x = baseline, y = oneyear)) p + geom_point(size = 2.0) + geom_abline(slope = 1, intercept = 0) + coord_fixed(xlim = c(1.80, 6.40), ylim = c(1.80, 6.40)) 程序中用了geom_abline()作斜线， 用了coord_fixed()指定1:1的宽高比并设定x轴和y轴相同的坐标范围。 可以看出一年后的测量值普遍高于开始时的测量值。 当观测个数较少时， 可以用线段连接每个观测的两个变量值， 并标出每个观测的标签。 data(organdata, package = &quot;socviz&quot;) organdata %&gt;% select(country, year, donors) %&gt;% mutate(year = lubridate::year(year)) %&gt;% filter(year %in% c(1991, 2002)) -&gt; dorgans p &lt;- ggplot(data = dorgans, mapping = aes( x = year, y = donors)) p + geom_line(aes(group = country)) + geom_point(size = 2.0) + geom_text_repel(data = filter(dorgans, year == 2002), mapping = aes( x = year, y = donors, label = country), direction = &quot;x&quot;) + scale_x_continuous( breaks = c(1991, 2002), limits = c(1991, 2005), labels = c(&quot;1991&quot;, &quot;2002&quot;)) 可以看出，这种图可以表现超过两个变量。 30.6 时间序列图 某个指标随时间变化的数据称为时间序列， 可以以时间为横坐标、该指标为纵坐标作折线图， 称为时间序列图。 其它有次序的变量也可以用作横轴变量。 geom_line()函数会自动按照x轴变量的次序连线， 即使数据中的x变量没有从小到大排列都是如此。 geom_path()则按照数据集中原有次序连线。 30.6.1 一元时间序列 R软件中提供了一个示例用的时间序列数据AirPassengers， 是美国泛美航空公司1949-1960的国际航班订票数的月度数据（单位：千人）， 12 年144个月的数据。 作其散点图： dap &lt;- AirPassengers %&gt;% { tibble( time = as.vector(time(.)), passengers = as.vector(.)) } p &lt;- ggplot(data = dap, mapping = aes( x = time, y = passengers)) p + geom_point() 这样的图形在点数较少时还好， 点数较多时不易分辨出局部随时间的变化情况。 加上连线： p + geom_point() + geom_line() 也可以仅连线，不画散点： p + geom_line() 仅画线的时间序列图更强调变化趋势， 不强调个别数据， 当观测点很多时一般不画出散点。 这里的时间是time()函数返回的以年为单位的浮点数值。 时间序列的时间往往是日期值， 尤其是日数据， 可以用scale_x_date()函数标日期，如： library(xts) dap2 &lt;- AirPassengers %&gt;% as.xts() %&gt;% { tibble( yearmon = index(.), time = as.Date(yearmon), passengers = c(coredata(.))) } knitr::kable(head(dap2, 6)) yearmon time passengers 1月 1949 1949-01-01 112 2月 1949 1949-02-01 118 3月 1949 1949-03-01 132 4月 1949 1949-04-01 129 5月 1949 1949-05-01 121 6月 1949 1949-06-01 135 数据框dap2中的yearmon是年月格式的时间， time是年月日格式的时间。 先用年月格式的时间作图： p &lt;- ggplot(data = dap2, mapping = aes( x = yearmon, y = passengers)) p + geom_line() ggplot2不支持对年月类型的时间轴进行调整。 为了自定义时间轴，需要使用日期格式的坐标轴， 使用dap2数据框中的time列： p &lt;- ggplot(data = dap2, mapping = aes( x = time, y = passengers)) p + geom_line() + scale_x_date( name = &quot;year&quot;, date_breaks = &quot;5 years&quot;, date_labels = &quot;%Y&quot;, date_minor_breaks = &quot;1 year&quot;, expand = c(0, 0)) 程序中的time变量是Date类型的日期时间， 用date_breaks选项指定日期轴刻度值的频率， \"5 years\"就是每5年一个刻度值。 用date_minor_breaks选项指定细刻度的频率。 date_labels是日期刻度的一种格式规定， 比如\"%Y\"是四位数的年份，\"%Y-%m\"是年月格式， 等等。 因为是月度数据， 所以刻度线所在的数据点对应该年的1月份。 如果需要人为指定刻度位置， 可以去掉date_breaks参数， 改用breaks参数，如： p + geom_line() + scale_x_date( name = &quot;year&quot;, breaks = lubridate::make_date(c(1950, 1955, 1960)), date_labels = &quot;%Y&quot;, date_minor_breaks = &quot;1 year&quot;, expand = c(0, 0)) 还可以在线下加阴影， 但这时y轴应为正值变量且坐标范围从0开始， 如： library(ggridges) p &lt;- ggplot(data = dap2, mapping = aes( x = as.Date(time), height = passengers, y = 0)) p + geom_ridgeline() + scale_x_date( name = &quot;year&quot;, breaks = lubridate::make_date(c(1950, 1955, 1960)), date_labels = &quot;%Y&quot;, date_minor_breaks = &quot;1 year&quot;, expand = c(0, 0)) 上面的程序用了ggridges包的geom_ridgeline()函数， y轴对应于height维。 有时需要用不同阴影色标出不同的时间段， 可以使用annotate()函数， 指定geom为\"rect\"， 需要xmin, xmax, ymin, ymax参数， 可用用alpha指定一定透明度，用fill指定填充颜色。 例如，将时间分为1949-1954, 1955-1960两段， 用不同颜色填充： p &lt;- ggplot(data = dap2, mapping = aes( x = time, y = passengers)) p + geom_line() + annotate( geom = &quot;rect&quot;, ymin = -Inf, ymax = Inf, xmin = lubridate::make_date(c(1949, 1955)), xmax = lubridate::make_date(c(1955, 1961)), fill = c(&quot;lightgreen&quot;, &quot;lightblue&quot;), alpha = 0.3) + scale_x_date( name = &quot;year&quot;, breaks = lubridate::make_date(c(1949, 1955, 1960)), date_labels = &quot;%Y&quot;, date_minor_breaks = &quot;1 year&quot;, expand = c(0, 0)) + guides(fill = FALSE) 分时间段染色的另一种办法是使用geom_rect()函数， 这时需要有另一个输入数据框， 填充色可以自动映射， 画曲线与染色的函数要分别输入数据内容： dap2b &lt;- data.frame( ymin = -Inf, ymax = Inf, xmin = lubridate::make_date(c(1949, 1955)), xmax = lubridate::make_date(c(1955, 1961)), period = c(&quot;First&quot;, &quot;Second&quot;)) p &lt;- ggplot() p + geom_line(data = dap2, mapping = aes( x = time, y = passengers)) + geom_rect(data = dap2b, mapping = aes( xmin = xmin, xmax = xmax, ymin = ymin, ymax = ymax, fill = period ), alpha = 0.3) + scale_x_date( name = &quot;year&quot;, breaks = lubridate::make_date(c(1949, 1955, 1960)), date_labels = &quot;%Y&quot;, date_minor_breaks = &quot;1 year&quot;, expand = c(0, 0)) + guides(fill = FALSE) 下面作一个日数据的时间序列图。 用quantmod包从雅虎金融下载标普500指数的日数据： library(quantmod) sp &lt;- getSymbols( &quot;^GSPC&quot;, src = &quot;yahoo&quot;, auto.assign = FALSE ) save(sp, file=&quot;sp500.RData&quot;) ## GSPC.Open GSPC.High GSPC.Low GSPC.Close GSPC.Volume GSPC.Adjusted ## 2007-01-03 1418.03 1429.42 1407.86 1416.60 3429160000 1416.60 ## 2007-01-04 1416.60 1421.84 1408.43 1418.34 3004460000 1418.34 ## 2007-01-05 1418.34 1418.34 1405.75 1409.71 2919400000 1409.71 ## 2007-01-08 1409.26 1414.98 1403.97 1412.84 2763340000 1412.84 ## 2007-01-09 1412.84 1415.61 1405.42 1412.11 3038380000 1412.11 ## 2007-01-10 1408.70 1415.99 1405.32 1414.85 2764660000 1414.85 quantmod包也能做时间序列图， 还可以做K线图、叠加各种技术曲线的图形。 用ggplot作标普500近10年的日收盘价时间序列图， 不对坐标轴作调整： dsp &lt;- sp[&quot;2010/&quot;] %&gt;% tibble( time = index(.), sp500 = coredata(.)[,&quot;GSPC.Close&quot;]) p &lt;- ggplot(data = dsp, mapping = aes( x = time, y = sp500)) p + geom_line() 刻度每年： dsp &lt;- sp[&quot;2010/&quot;] %&gt;% tibble( time = index(.), sp500 = coredata(.)[,&quot;GSPC.Close&quot;]) p &lt;- ggplot(data = dsp, mapping = aes( x = time, y = sp500)) p + geom_line() + scale_x_date( name = NULL, date_breaks = &quot;1 year&quot;, date_labels = &quot;%Y&quot;, date_minor_breaks = &quot;1 year&quot;) 30.6.2 多元时间序列 随时间记录的指标可以有多个。 当这些指标的取值范围相近时， 可以共用一个y轴， 每个指标单独做连线并画在同一坐标系中。 要注意的是， ggplot作多元时间序列图时需要长表数据而非宽表数据， 纵坐标变量必须保存在数据集的一个变量中， 用另外的变量区分不同的指标。 例如， 北京地区从1949年到1964年的受灾面积与成灾面积（单位：万亩）年数据。 dflood &lt;- as.data.frame(matrix(c( 1949 , 1 , 331.12 , 243.96 , 1950 , 2 , 380.44 , 293.90 , 1951 , 3 , 59.63 , 59.63, 1952 , 4 , 37.89 , 18.09, 1953 , 5 , 103.66 ,72.92, 1954 , 6 , 316.67 , 244.57, 1955 , 7 , 208.72 , 155.77, 1956 , 8 , 288.79 , 255.22, 1957 , 9 , 25.00 , 0.50, 1958 , 10 , 84.72 , 48.59, 1959 , 11 , 260.89 ,202.96, 1960, 12 , 27.18 ,15.02, 1961, 13 , 20.74 ,17.09, 1962 , 14 , 52.99 ,14.66, 1963 , 15 , 99.25 , 45.61, 1964 , 16 , 55.36 ,41.90), byrow=TRUE, ncol=4, dimnames=list(1949:1964, c(&quot;year&quot;, &quot;t&quot;, &quot;area1&quot;, &quot;area2&quot;)))) dflood2 &lt;- dflood %&gt;% gather(area1, area2, key = &quot;类型&quot;, value = &quot;面积&quot;) %&gt;% mutate(`类型` = factor( `类型`, levels = c(&quot;area1&quot;, &quot;area2&quot;), labels = c(&quot;受灾面积&quot;, &quot;成灾面积&quot;))) p &lt;- ggplot(data = dflood2, mapping = aes( x = year, y = `面积`, color = `类型`)) p + geom_line() 可以用guides(label.position)指定\"top\", \"bottom\", \"left\", \"right\"这样的图例位置， 还可以用theme()函数将图例指定在坐标系内部： p + geom_line() + theme( legend.position = c(0.98, 0.98), legend.justification = c(1,1) ) theme()函数中legend.position给出的是图例框在坐标系内的百分比位置， legend.justification给出的是图例框坐标的百分比对齐位置， c(1,1)是将图例框的右上角对齐到给定百分比坐标位置。 也可以去掉图例， 而是用y轴的第二坐标轴（画在右侧）的办法直接标出两个序列的标签。 如： p + geom_line() + guides(color = FALSE) + scale_y_continuous( sec.axis = dup_axis( name = NULL, breaks = subset(dflood2, year == 1964)[[&quot;面积&quot;]], labels = c(&quot;受灾面积&quot;, &quot;成灾面积&quot;))) 上面的做法需要将两条曲线的数据合并在一个变量中， 并用一个分组变量区分两条曲线。 如果数据原来在两列中， 可以调用两次geom_line()， 但颜色和图例就需要人为指定了，如： p &lt;- ggplot(data = dflood) p + geom_line(mapping = aes( x = year, y = area1, color = &quot;受灾面积&quot;)) + geom_line(mapping = aes( x = year, y = area2, color = &quot;成灾面积&quot;)) + scale_color_manual( name = NULL, breaks = c(&quot;受灾面积&quot;, &quot;成灾面积&quot;), values = c( &quot;受灾面积&quot; = &quot;orangered2&quot;, &quot;成灾面积&quot; = &quot;turquoise&quot;)) + labs(y = NULL) 为了获得适当的图例， 上面的程序在两个geom_line()调用中在aes()中将color映射到了两个序列的名称而不是具体颜色， 然后使用了scale_colormanual()函数， 用breaks参数指定了两个序列的次序， 使得“成灾面积”在前， “受灾面积”灾后， 与图中两条曲线的上下次序一致； 用了values参数指定了从序列名称到具体颜色的对应关系。 30.6.3 多个不同类型指标的时间序列 有时沿时间变化的多个指标是不可比的， 这时就不应将数据画在同一坐标系内， 一般可以画多个小图并上下按时间轴对齐， facet_wrap()可以做小图。 例如， 考虑我国2013-2017年人均国内生产总值和人均可支配收入数据。 dinc &lt;- data.frame( year = 2013:2017, `人均可支配收入` = c(18311, 20167, 21966, 23821, 25974), `人均国内生产总值` = c(43852, 47203, 50251, 53935, 59660)) dinc2 &lt;- dinc %&gt;% gather(`人均可支配收入`, `人均国内生产总值`, key = &quot;指标&quot;, value = &quot;value&quot;) p &lt;- ggplot(data = dinc2, mapping = aes( x = year, y = value)) p + geom_line() + geom_point() + facet_wrap(~ `指标`, ncol = 1, scales = &quot;free_y&quot;) + labs(caption = &quot;数据来源：国家统计局&quot;) 上述程序在facet_wrap()中用scales = \"free_y\"使得两幅小图的纵轴不需要使用相同坐标范围。 横轴默认还使用相同坐标范围并上下对齐。 对二元时间序列\\((x_t, y_t)\\)， 还可以画以\\((x_t, y_t)\\)为节点的轨迹图， 但需要标出关键的时间点的时间。 用geom_path()画轨迹， 用ggrepel包的geom_text_repel()标时间。 30.7 拟合曲线图 考虑两个变量之间的关系， 将其中的一个作为因变量， 另一个作为自变量， 散点图可以反映其互相影响， 可以用拟合曲线进一步概括两者的关系。 拟合曲线的方法可以是曲线平滑方法如核回归、局部多项式回归、样条平滑， 也可以用一些参数模型如线性回归、二次回归。 对于时间序列， 还经常分解成趋势项、季节项和不规则项。 30.7.1 平滑方法 考虑标普500指数2008年的收盘价。 为了平滑上面的曲线， 金融界常用滑动平均方法， 比如， 每10天画计算一个平均值并将该平均值的时间对准在10天时间窗的最后一天。 这样得到的滑动平均线会滞后于原始数据的变化。 先写一个计算滑动平均的函数： 计算10日、22日滑动平均并绘图： ## Warning: Removed 9 row(s) containing missing values (geom_path). ## Warning: Removed 21 row(s) containing missing values (geom_path). 将滑动平均结果对齐在时间窗口末尾的优点是可以实时地更新。 对历史数据， 可以将滑动平均结果对齐在时间窗口中间， 如果时间窗口中有偶数个点， 可以选择中间两个点的任何一个， 上面的滑动平均计算程序在偶数个点时选择与中间两个点当中第一个点对齐。 图形如下： ## Warning: Removed 9 row(s) containing missing values (geom_path). ## Warning: Removed 21 row(s) containing missing values (geom_path). 滑动平均平滑是金融数据分析中常用的方法， 但是也有明显的缺点。 因为需要多个点生成一个平均值， 所以在序列的开头和末尾有一部分点是没有平均值的。 当时间窗变宽时结果会更光滑， 但有时还是不够光滑， 这与滑动平均作为加窗平滑是等权而且在边缘处为间断有关。 统计学中提出了各种更复杂但效果更好而平滑方法， 比如LOESS(locally estimated scatterplot smoothing， 参见(Cleveland 1979))。 这是许多局部多项式回归回归方法中的一个典型代表， 每个\\(x\\)处用附近的点拟合一个局部模型， 距离\\(x\\)越远的点贡献越小。 这样的做法可以得到比滑动平均更平滑的结果。 局部多项式方法得到的结果类似于中心对准而且滑动窗口较宽的滑动平均。 ## `geom_smooth()` using formula &#39;y ~ x&#39; ## Warning: Removed 21 row(s) containing missing values (geom_path). geom_smooth()可以对输入的\\((x,y)\\)坐标数据进行平滑， 选项se = FALSE要求不做置信区间。 实际上， 不仅仅是时间序列数据可以添加如此的平滑曲线， 其它的散点图也都可以这样添加平滑曲线。 上图的结果是程序自动选择平滑程度的结果，有些过于平滑了。 可以人为地用参数控制结果的平滑程度。 用参数span控制平滑程度， span取0到1之间的值， 越大的span值越光滑： ## `geom_smooth()` using formula &#39;y ~ x&#39; ## Warning: Removed 21 row(s) containing missing values (geom_path). LOESS方法计算较慢， 所以ggplot2在输入点数超过1000时默认使用mgcv包的gam()函数进行平滑， 对应于method = \"gam\"。 用gam时可以指定formula = y ~ s(x)， 或者formula = y ~ s(x, bs = \"cs\")。 要注意的是， 平滑结果不仅依赖于平滑参数的选择， 也依赖于平滑方法和模型的选择， 不同模型可能给出差别很大的结果， 所以使用平滑结果做预测时一定要特别谨慎。 30.7.2 参数模型方法 LOESS等平滑方法属于非参数方法， 这些方法本质上没有一个不依赖于数据值的参数模型。 另一类建模和平滑方法是假定\\(y_i\\)与\\(x_i\\)之间服从一定的参数模型， 如线性回归模型 \\[ y_i = a + b x_i + \\varepsilon_i \\] 从数据估计模型参数， 然后可以得到模型的拟合值（或称预测值）。 geom_smooth()函数已经支持线性回归， 比如对2013-2017人均国内生产总值数据进行平滑： p &lt;- ggplot(data = dinc, mapping = aes( x = year, y = `人均国内生产总值`)) p + geom_point() + geom_smooth( method = &quot;lm&quot;, size = 1.1, se=FALSE ) ## `geom_smooth()` using formula &#39;y ~ x&#39; 可以用formula = poly(x, 2)将模型变成二次多项式曲线， 如： p &lt;- ggplot(data = dinc, mapping = aes( x = year, y = `人均国内生产总值`)) p + geom_point(size = 2) + geom_smooth(mapping = aes(col = &quot;lm&quot;), method = &quot;lm&quot;, size = 1.1, se=FALSE ) + geom_smooth(mapping = aes(col = &quot;quadreg&quot;), method = &quot;lm&quot;, formula = y ~ poly(x, 2), size = 1.1, se=FALSE) + scale_color_manual( name = NULL, values = c(`lm` = &quot;blue&quot;, `quadreg` = &quot;cyan&quot;), breaks = c(&quot;lm&quot;, &quot;quadreg&quot;), labels = c(&quot;线性模型&quot;, &quot;二次多项式模型&quot;) ) + theme( legend.position = c(0.05, 0.95), legend.justification = c(0, 1) ) + labs(x = NULL) ## `geom_smooth()` using formula &#39;y ~ x&#39; 与method = \"lm\"类似的是method = \"rlm\"， 是稳健线性回归模型，要调用MASS包。 geom_smooth()还支持gam()函数能支持的模型。 更一般的模型可以先用统计建模函数建模， 然后在自变量取值范围内取一个网格计算拟合值， 最后将原始数据与拟合曲线画在一起。 这里拟合曲线实际是将网格点对应的拟合值连接成一条折线。 比如， 对上面的数据拟合如下的指数增长模型： \\[ y_t = A e^{b t} + \\varepsilon_t \\] nls.inc &lt;- nls( `人均国内生产总值` ~ A * exp(b * (year-2000)), data = dinc, start = c(A = 4E4, b = 1E-6)) dinc.pred1 &lt;- data.frame( year = seq(2013, 2017, length.out = 100)) dinc.pred1 &lt;- dinc.pred1 %&gt;% mutate(pred = predict( nls.inc, newdata = data.frame(year = year ))) p &lt;- ggplot(data = dinc, mapping = aes( x = year, y = `人均国内生产总值`)) p + geom_point(size = 2) + geom_smooth(mapping = aes(col = &quot;lm&quot;), method = &quot;lm&quot;, size = 1.1, se=FALSE ) + geom_line(data = dinc.pred1, mapping = aes( x = year, y = pred, col = &quot;Expmod&quot; )) + scale_color_manual( name = NULL, values = c(`lm` = &quot;blue&quot;, `Expmod` = &quot;cyan&quot;), breaks = c(&quot;lm&quot;, &quot;Expmod&quot;), labels = c(&quot;线性模型&quot;, &quot;指数模型&quot;) ) + theme( legend.position = c(0.05, 0.95), legend.justification = c(0, 1) ) + labs(x = NULL) ## `geom_smooth()` using formula &#39;y ~ x&#39; \\(y = A e^{bx}\\)这样的模型可以将y轴改为对数尺度， 这时指数曲线可以表现为直线。 \\(y = A x^b\\)这样的模型可以将x轴和y轴都改为对数尺度， 曲线关系可以表现为直线关系。 30.8 表现不确定性 统计数据数据分析的建模结果都有一定的不确定性， 参数估计和模型预测的不确定性经常用置信区间和置信带表现， 绘图时可以画误差条(error bar)或置信带。 这些方法可以比较精确地描绘不确定性大小， 但需要一些概率统计知识才能正确理解。 也可以开发一些更直观的图形用来表现不确定性。 30.8.1 表现概率 不确定性用概率描述， 而概率可以通过多次独立重复试验的频率来理解。 可以用一个饼图来表现概率。 一种容易理解的做法是画100个色块， 用加亮显示部分表示成功部分， 加亮显示部分随机摆放以显示结果的随机性。 #dg &lt;- expand.grid(x = 1:10, y = 1:10) set.seed(101) dg &lt;- expand.grid(ratio = c(0.01, 0.1, 0.4), x = 1:10, y = 1:10) dg2 &lt;- dg %&gt;% group_by(ratio) %&gt;% mutate(value = { n &lt;- n() i &lt;- round(n * ratio[1]) sample(c(rep(&quot;S&quot;, i), rep(&quot;F&quot;, n-i))) }) %&gt;% ungroup() %&gt;% mutate(label = paste0(round(100*ratio), &quot;% chance&quot;) ) #set.seed(84524) ggplot(data = dg2, mapping = aes( x = x, y = y, fill = value)) + geom_tile(color = &quot;white&quot;, size = 1) + coord_fixed(expand = FALSE, clip = &quot;off&quot;) + scale_x_continuous(name = NULL, breaks = NULL) + scale_y_continuous(name = NULL, breaks = NULL) + scale_fill_manual( name = NULL, breaks = c(&quot;S&quot;, &quot;F&quot;), labels = c(&quot;success &quot;, &quot;failure&quot;), values = c( &quot;S&quot; = &quot;steelblue4&quot;, &quot;F&quot; = &quot;steelblue1&quot; ), guide = guide_legend(override.aes = list(size = 0)) ) + facet_wrap(~label) + theme( legend.position = &quot;bottom&quot;, legend.direction = &quot;horizontal&quot;, legend.justification = &quot;right&quot;, plot.margin = margin(0, 0, 3.5, 0) # crop plot a little more tightly ) 在只有两种随机结果时上图可以比较直观地表现两种结果的比例和随机性。 在有许多可能结果，甚至于随机结果可以在一个区间内随机取值时， 上面的方法不再有效， 概率分布和概率密度能更准确地描述这种随机取值， 但不一定容易理解。 分布密度下方的阴影面积比例可以代表某个事件的概率， 还可以用密度曲线下面画堆叠的圆的办法更直观地表现不同取值区域的概率大小。 30.8.2 表现点估计精度 统计学中将要了解的分布称为总体， 用参数概括总体的分布， 从总体中抽取的一部分称为样本， 从样本中计算统计量作为总体参数的估计， 标准误差是估计量的精度的度量。 可以用误差条同时画出参数估计值及对应的标准误差， 误差条的两端是点估计加减标准误差。 例如， iris数据集中setosa品种的花瓣长度均值及标准误差， 同时画了对应的数据值： d1 &lt;- iris %&gt;% filter(Species == &quot;setosa&quot;) d1summ &lt;- d1 %&gt;% summarise(mpl = mean(Petal.Length), sd = sd(Petal.Length), se = sd / sqrt(n())) p &lt;- ggplot(data = d1summ) p + geom_errorbar( mapping = aes( ymin = mpl - se, ymax = mpl + se, x = &quot;setosa&quot;), color = &quot;turquoise4&quot;, width = 0.05, size = 1) + geom_point( mapping = aes( y = mpl, x = &quot;setosa&quot;), color = &quot;turquoise4&quot;, size = 3) + geom_jitter(data = d1, mapping = aes( y = Petal.Length, x = &quot;setosa&quot;), width = 0.3, height = 0) + scale_x_discrete(name = NULL, breaks = NULL) + labs(y = &quot;Petal Length&quot;) 这里用了coord_flip()将图形x、y坐标对调， 使得原来纵向的误差条变成横向。 在geom_errorbar()中需要映射ymin, ymax和x维， 分别表示误差条的上下限与x位置。 置信区间也可以类似地画出。 下面对iris数据集中三个品种分别估计花瓣长度均值并画95%置信区间。 d2summ &lt;- iris %&gt;% group_by(Species) %&gt;% summarise(mpl = mean(Petal.Length), sd = sd(Petal.Length), se = sd / sqrt(n())) p &lt;- ggplot(data = d2summ, mapping = aes(x = Species)) p + geom_errorbar( mapping = aes( ymin = mpl - 1.96*se, ymax = mpl + 1.96*se), width = 0.05, size = 1) + labs(y = &quot;Petal Length&quot;) 选项width是端线宽度，用坐标系单位，横轴是因子时两个因子的间距为1； size是线粗细（毫米） 如果不需要端线，可以用geom_linerange(): p + geom_linerange( mapping = aes( y = mpl, ymin = mpl - 1.96*se, ymax = mpl + 1.96*se), size = 2) + labs(y = &quot;Petal Length&quot;) 为了画出中心点， 可以用geom_pointrange()函数： p + geom_pointrange( mapping = aes( y = mpl, ymin = mpl - 1.96*se, ymax = mpl + 1.96*se)) + labs(y = &quot;Petal Length&quot;) 用geom_crossbar()可以画成中心有线的盒形： p + geom_crossbar( mapping = aes( y = mpl, ymin = mpl - 1.96*se, ymax = mpl + 1.96*se), width = 0.1) + labs(y = &quot;Petal Length&quot;) 下面画三个置信区间以及数据散点， 并将x轴和y轴对调： p + geom_crossbar( mapping = aes( y = mpl, ymin = mpl - 1.96*se, ymax = mpl + 1.96*se), color = &quot;turquoise4&quot;, width = 0.1, size = 1) + geom_jitter(data = iris, mapping = aes( y = Petal.Length, x = Species), alpha = 0.3, width = 0.3, height = 0) + labs(y = &quot;Petal Length&quot;) + coord_flip() 置信区间是频率学派统计学的概念， 可以认为在多次独立重复同一置信区间问题时真实参数落入置信区间的比例为给定的置信度， 或者零假设下的参数值落入置信区间是对应的假设检验的接受域。 而贝叶斯学派统计学也有类似概念， 称为credible interval， 这是认为参数作为服从后验分布的随机变量的取值概率为给定置信度最可能取值区间。 误差条比较容易被不了解相关概念的人误认为数据范围或者参数估计取值范围， 所以使用时需要解释其含义。 误差条的一个优势是很容易与其他图形一起使用， 上面的误差条是与散点图一起使用的， 也可以与条形图配合给出条形图表示的比例的误差大小。 例如， iris数据中三个类别的4个测量值的均值用条形高度表示， 标准误差用误差条表示： d3summ &lt;- iris %&gt;% gather(Sepal.Length, Sepal.Width, Petal.Length, Petal.Width, key = &quot;variable&quot;, value = &quot;value&quot;) %&gt;% group_by(Species, variable) %&gt;% summarise( mean = mean(value), se = sd(value) / sqrt(n()), lbar = mean - 1.96*se, hbar = mean + 1.96*se) p &lt;- ggplot(data = d3summ, mapping = aes( x = variable, fill = Species, y = mean)) p + geom_col(position = &quot;dodge&quot;) + geom_errorbar(mapping = aes( ymin = lbar, ymax = hbar), position = position_dodge(width = 1), width = 0.1, size = 1) + labs(x = &quot;Measurements&quot;, y = &quot;Mean and SE&quot;) 这里geom_errorbar()的position参数用了position_dodge()函数说明两个条形之间的距离。 geom_errorbar()的width参数是条形端线的宽度， 如果width=0就没有了端线。 如果仅有一个变量则会比较简单， 比如， 花瓣长度的均值和加减标准误差： d3b &lt;- d3summ %&gt;% filter(variable == &quot;Petal.Length&quot;) p &lt;- ggplot(data = d3b, mapping = aes( x = Species, y = mean)) p + geom_col(alpha = 0.4) + geom_errorbar(mapping = aes( ymin = lbar, ymax = hbar), width = 0.1, size = 1) + labs(x = &quot;Species&quot;, y = &quot;Petal Length Mean and SE&quot;) 为了表现y的误差范围随一个连续的x变量的变化， 可以使用geom_ribbon()函数； 为了表现y的误差范围以及中心值随一个连续的x变量的变化， 可以使用geom_smooth(stat = \"identity\")。 30.8.3 拟合曲线的置信带 对成对变量数据\\((x_i, y_i)\\)可以拟合平滑曲线， 同时往往希望给出曲线类似于置信区间或者credible interval。 作为置信区间解释时， 虽然是置信带， 但是置信度是针对每个单独的\\(x\\)值成立的； 如果是贝叶斯置信区间(credible interval)， 则置信带可以理解为在模型参数的后验分布下取值概率为对应置信度的参数所对应的曲线集合。 geom_smooth()函数中加se = TRUE就可以做置信带。 例如，对iris数据集中setosa品种的花瓣长、宽作线性回归并加置信带： diris1 &lt;- iris %&gt;% filter(Species == &quot;setosa&quot;) p &lt;- ggplot(data = diris1, mapping = aes( x = Petal.Length, y = Petal.Width)) p + geom_point(size = 3, alpha = 0.3) + geom_smooth( method = &quot;lm&quot;, size = 1.1, se=TRUE) ## `geom_smooth()` using formula &#39;y ~ x&#39; 默认的置信度是0.95，用参数level控制。 geom_smooth()的置信带是逐点意义的。 LOESS等平滑曲线也可以加置信带，如： p + geom_point(size = 3, alpha = 0.3) + geom_smooth( method = &quot;loess&quot;, size = 1.1, se=TRUE) ## `geom_smooth()` using formula &#39;y ~ x&#39; 30.8.4 随机结果动态演示 随机结果是概率分布确定但每个结果预先未知的。 在讲课时， 可以用动图（gif或者mp4等格式）动态地演示不同的随机结果。 gganimate扩展包提供了制作动图的功能。 References "],["stat-basics.html", "31 R初等统计分析 31.1 概率分布 31.2 最大似然估计 31.3 假设检验和置信区间", " 31 R初等统计分析 这一部分讲授如何用R进行统计分析， 包括基本概括统计和探索性数据分析， 置信区间和假设检验， 回归分析与各种回归方法， 广义线性模型， 非线性回归与平滑， 判别树和回归树， 等等。 主要参考书： (Venables and Ripley 2002) (Kabacoff 2012) 31.1 概率分布 R中与xxx分布有关的函数包括： dxxx(x)， 即xxx分布的分布密度函数(PDF)或概率函数(PMF)\\(p(x)\\)。 pxxx(q)， 即xxx分布的分布函数(CDF)\\(F(q)=P(X \\leq q)\\)。 qxxx(p)， 即xxx分布的分位数函数\\(q(p)\\), \\(p \\in (0,1)\\)， 对连续型分布，\\(q(p) = F^{-1}(p)\\)， 即\\(F(x)=p\\)的解\\(x\\)。 rxxx(n)， 即xxx的随机数函数，可以生成\\(n\\)个xxx的随机数。 dxxx(x)函数可以加选项log=TRUE， 用来计算\\ln p(x)， 这在计算对数似然函数时有用， 比log(dxxx(x))更精确。 pxxx(q)可以加选项lower.tail=FALSE， 变成计算\\(P(X&gt;q) = 1 - F(q)\\)。 qxxx(p)可以加选项lower.tail=TRUE， 表示求\\(P(X&gt;x)=p\\)的解\\(x\\)； 可以加选项log.p=TRUE， 表示输入的\\(p\\)实际是\\(\\ln p\\)。 这些函数都可以带有自己的分布参数， 有些分布参数有缺省值， 比如正态分布的缺省参数值为零均值单位标准差。 具体的分布类型可以在R命令行用?Distributions查看列表。 常用的分布密度有： 离散分布有dbinom二项分布, dpois泊松分布， dgeom几何分布， dnbinom负二项分布， dmultinom多项分布， dhyper超几何分布。 连续分布有 dunif均匀分布， dnorm正态分布， dchisq卡方分布， dt t分布(包括非中心t)， df F分布， dexp指数分布， dweibull 威布尔分布， dgamma 伽马分布， dbeta 贝塔分布， dlnorm 对数正态分布， dcauchy 柯西分布, dlogis 逻辑斯谛分布。 R的扩展包提供了更多的分布， 参见R网站的如下链接： https://cran.r-project.org/web/views/Distributions.html 31.2 最大似然估计 R函数optim()、nlm()、optimize()可以用来求函数极值， 因此可以用来计算最大似然估计。 optimize()只能求一元函数极值。 31.2.1 一元正态分布参数最大似然估计 正态分布最大似然估计有解析表达式。 作为示例， 用R函数进行数值优化求解。 对数似然函数为： \\[ \\ln L(\\mu,\\sigma^2) = -\\frac{n}{2}\\ln(2\\pi) -\\frac{n}{2}\\ln\\sigma^2 - \\frac{1}{2\\sigma^2} \\sum(X_i - \\mu)^2 \\] 定义R的优化目标函数为上述对数似然函数去掉常数项以后乘以\\(-2\\)， 求其最小值点。 目标函数为： objf.norm1 &lt;- function(theta, x){ mu &lt;- theta[1] s2 &lt;- exp(theta[2]) n &lt;- length(x) res &lt;- n*log(s2) + 1/s2*sum((x - mu)^2) res } 其中\\(\\theta_1\\)为均值参数\\(\\mu\\)， \\(\\theta_2\\)为方差参数\\(\\sigma^2\\)的对数值。 x是样本数值组成的R向量。 可以用optim函数来求极小值点。下面是一个模拟演示: norm1d.mledemo1 &lt;- function(n=30){ mu0 &lt;- 20 sigma0 &lt;- 2 set.seed(1) x &lt;- rnorm(n, mu0, sigma0) theta0 &lt;- c(0,0) ores &lt;- optim(theta0, objf.norm1, x=x) print(ores) theta &lt;- ores$par mu &lt;- theta[1] sigma &lt;- exp(0.5*theta[2]) cat(&#39;真实mu=&#39;, mu0, &#39; 公式估计mu=&#39;, mean(x), &#39; 数值优化估计mu=&#39;, mu, &#39;\\n&#39;) cat(&#39;真实sigma=&#39;, sigma0, &#39;公式估计sigma=&#39;, sqrt(var(x)*(n-1)/n), &#39; 数值优化估计sigma=&#39;, sigma, &#39;\\n&#39;) } norm1d.mledemo1() ## $par ## [1] 20.166892 1.193593 ## ## $value ## [1] 65.83709 ## ## $counts ## function gradient ## 115 NA ## ## $convergence ## [1] 0 ## ## $message ## NULL ## ## 真实mu= 20 公式估计mu= 20.16492 数值优化估计mu= 20.16689 ## 真实sigma= 2 公式估计sigma= 1.817177 数值优化估计sigma= 1.816291 也可以用nlm()函数求最小值点， 下面是正态分布最大似然估计的另一个演示： norm1d.mledemo2 &lt;- function(){ set.seed(1) n &lt;- 30 mu &lt;- 20 sig &lt;- 2 z &lt;- rnorm(n, mean=mu, sd=sig) neglogL &lt;- function(parm) { -sum( dnorm(z, mean=parm[1], sd=exp(parm[2]), log=TRUE) ) } res &lt;- nlm(neglogL, c(10, log(10))) print(res) sig2 &lt;- exp(res$estimate[2]) cat(&#39;真实mu=&#39;, mu, &#39; 公式估计mu=&#39;, mean(z), &#39; 数值优化估计mu=&#39;, res$estimate[1], &#39;\\n&#39;) cat(&#39;真实sigma=&#39;, sig, &#39;公式估计sigma=&#39;, sqrt(var(z)*(n-1)/n), &#39; 数值优化估计sigma=&#39;, sig2, &#39;\\n&#39;) invisible() } norm1d.mledemo2() ## $minimum ## [1] 60.48667 ## ## $estimate ## [1] 20.1649179 0.5972841 ## ## $gradient ## [1] 1.444576e-05 9.094805e-06 ## ## $code ## [1] 2 ## ## $iterations ## [1] 28 ## ## 真实mu= 20 公式估计mu= 20.16492 数值优化估计mu= 20.16492 ## 真实sigma= 2 公式估计sigma= 1.817177 数值优化估计sigma= 1.817177 函数optim()缺省使用Nelder-Mead单纯型搜索算法， 此算法不要求计算梯度和海色阵， 算法稳定性好， 但是收敛速度比较慢。 可以用选项method=\"BFGS\"指定BFGS拟牛顿法。 这时可以用gr=选项输入梯度函数， 缺省使用数值微分计算梯度。 如： norm1d.mledemo1b &lt;- function(n=30){ mu0 &lt;- 20 sigma0 &lt;- 2 set.seed(1) x &lt;- rnorm(n, mu0, sigma0) theta0 &lt;- c(1,1) ores &lt;- optim(theta0, objf.norm1, x=x, method=&quot;BFGS&quot;) print(ores) theta &lt;- ores$par mu &lt;- theta[1] sigma &lt;- exp(0.5*theta[2]) cat(&#39;真实mu=&#39;, mu0, &#39; 公式估计mu=&#39;, mean(x), &#39; 数值优化估计mu=&#39;, mu, &#39;\\n&#39;) cat(&#39;真实sigma=&#39;, sigma0, &#39;公式估计sigma=&#39;, sqrt(var(x)*(n-1)/n), &#39; 数值优化估计sigma=&#39;, sigma, &#39;\\n&#39;) } norm1d.mledemo1b() ## $par ## [1] 20.164916 1.194568 ## ## $value ## [1] 65.83704 ## ## $counts ## function gradient ## 41 17 ## ## $convergence ## [1] 0 ## ## $message ## NULL ## ## 真实mu= 20 公式估计mu= 20.16492 数值优化估计mu= 20.16492 ## 真实sigma= 2 公式估计sigma= 1.817177 数值优化估计sigma= 1.817177 注意使用数值微分时， 参数的初值的数量级应该与最终结果相差不大， 否则可能不收敛， 比如上面程序取初值\\((0,0)\\)就会不收敛。 optim()函数支持的方法还有\"CG\"是一种共轭梯度法， 此方法不如BFGS稳健， 但是可以减少存储量使用， 对大规模问题可能更适用。 \"L-BFGS-B\"是一种区间约束的BFGS优化方法。 \"SANN\"是模拟退火算法， 有利于求得全局最小值点， 速度比其它方法慢得多。 函数optimize()进行一元函数数值优化计算。 例如，在一元正态分布最大似然估计中， 在对数似然函数中代入\\(\\mu = \\bar x\\)，目标函数（负2倍对数似然函数）为 \\[ h(\\sigma^2) = \\ln(\\sigma^2) + \\frac{1}{\\sigma^2} \\sum (X_i - \\bar X)^2 \\] 下面的例子模拟计算\\(\\sigma^2\\)的最大似然估计： norm1d.mledemo3 &lt;- function(n=30){ mu0 &lt;- 20 sigma0 &lt;- 2 set.seed(1) x &lt;- rnorm(n, mu0, sigma0) mu &lt;- mean(x) ss &lt;- sum((x - mu)^2)/length(x) objf &lt;- function(delta, ss) log(delta) + 1/delta*ss ores &lt;- optimize(objf, lower=0.0001, upper=1000, ss=ss) delta &lt;- ores$minimum sigma &lt;- sqrt(delta) print(ores) cat(&#39;真实sigma=&#39;, sigma0, &#39;公式估计sigma=&#39;, sqrt(var(x)*(n-1)/n), &#39; 数值优化估计sigma=&#39;, sigma, &#39;\\n&#39;) } norm1d.mledemo3() ## $minimum ## [1] 3.30214 ## ## $objective ## [1] 2.194568 ## ## 真实sigma= 2 公式估计sigma= 1.817177 数值优化估计sigma= 1.817179 31.3 假设检验和置信区间 31.3.1 均值的假设检验和置信区间 31.3.1.1 单样本均值 31.3.1.1.1 大样本情形 设总体\\(X\\)期望为\\(\\mu\\)，方差为\\(\\sigma^2\\)。 \\(X_1, X_2, \\dots, X_n\\)是一组样本。 在大样本时，令 \\[ Z = \\frac{\\bar x - \\mu}{S / \\sqrt{n}} \\stackrel{\\bullet}{\\sim} \\text{N}(0,1) \\] 其中\\(\\stackrel{\\bullet}{\\sim}\\)表示近似服从某分布。 \\(\\bar x\\)为样本均值，\\(S\\)为样本标准差。 \\(\\sigma\\)未知且大样本时， \\(\\mu\\)近似\\(1-\\alpha\\)置信区间为 \\[ \\bar x \\pm \\text{qnorm}(1-\\alpha/2) S / \\sqrt{n} \\] 用BSDA::z.test(x, sigma.x=sd(x), conf.level=1-alpha)可以计算如上的近似置信区间。 对于假设检验问题 \\[\\begin{aligned} &amp; H_0: \\mu = \\mu_0 \\longleftrightarrow H_a: \\mu \\neq \\mu_0 \\\\ &amp; H_0: \\mu \\leq \\mu_0 \\longleftrightarrow H_a: \\mu &gt; \\mu_0 \\\\ &amp; H_0: \\mu \\geq \\mu_0 \\longleftrightarrow H_a: \\mu &lt; \\mu_0 \\end{aligned}\\] 定义检验统计量 \\[ Z = \\frac{\\bar x - \\mu_0}{S / \\sqrt{n}} \\] 当\\(\\mu=\\mu_0\\)时\\(Z\\)近似服从N(0,1)分布。 可以用BSDA::z.test(x, mu=mu0, sigma.x=sd(x))进行双侧Z检验。 加选项alternative=\"greater\"作右侧检验， 加选项alternative=\"less\"作左侧检验。 如果上述问题中标准差\\(\\sigma\\)为已知， 应该在\\(Z\\)的公式用\\(\\sigma\\)替换\\(S\\)，即 \\[ Z = \\frac{\\bar x - \\mu_0}{\\sigma / \\sqrt{n}} \\] 计算\\(\\mu\\)的置信区间程序为BSDA::z.test(x, sigma.x=sigma0)， 计算\\(Z\\)检验的程序为BSDA::z.test(x, mu=mu0, sigma.x=sigma0)， 仍可用选项alternative=指定双侧、右侧、左侧。 31.3.1.1.2 小样本正态情形 如果样本量较小（小于30）， 则需要假定总体服从正态分布N(\\(\\mu, \\sigma^2\\))。 当\\(\\sigma\\)已知时， 有 \\[ Z = \\frac{\\bar x - \\mu_0}{\\sigma / \\sqrt{n}} \\sim \\text{N}(0,1) \\] 计算\\(\\mu\\)的置信区间程序为BSDA::z.test(x, sigma.x=sigma0)， 计算\\(Z\\)检验的程序为BSDA::z.test(x, mu=mu0, sigma.x=sigma0)。 可以自己写一个计算Z检验的较通用的R函数： z.test.1s &lt;- function( x, n=length(x), mu=0, sigma=sd(x), alternative=&quot;two.sided&quot;){ z &lt;- (mean(x) - mu) / (sigma / sqrt(n)) if(alternative==&quot;two.sided&quot;){ # 双侧检验 pvalue &lt;- 2*(1 - pnorm(abs(z))) } else if(alternative==&quot;less&quot;){ # 左侧检验 pvalue &lt;- pnorm(z) } else if(alternative==&quot;greater&quot;){ # 右侧检验 pvalue &lt;- 1 - pnorm(z) } else { stop(&quot;alternative unknown!&quot;) } c(stat=z, pvalue=pvalue) } 这个函数输入样本x和\\(\\sigma=\\sigma_0\\)， 或者输入\\(\\bar x\\)为x和\\(\\sigma=\\sigma_0\\)， 输出检验统计量值和p值。 如果\\(\\sigma\\)未知，应使用t统计量检验 \\[ T = \\frac{\\bar x - \\mu}{S / \\sqrt{n}} \\] 当\\(\\mu=\\mu_0\\)时\\(T \\sim t(n-1)\\)。 如果x保存了样本， 用t.test(x, conf.level=1-alpha)计算\\(\\mu\\)的置信区间； 用t.test(x, mu=mu0, alternative=\"two.side\")计算\\(H_0: \\mu=\\mu_0\\)的双侧检验， 称为单样本t检验。 如果已知的\\(\\bar x\\)和\\(S\\)而非具体样本数据， 可以自己写一个R函数计算t检验： t.test.1s &lt;- function( x, n=length(x), sigma=sd(x), mu=0, alternative=&quot;two.sided&quot;){ tstat &lt;- (mean(x) - mu) / (sigma / sqrt(n)) if(alternative==&quot;two.sided&quot;){ # 双侧检验 pvalue &lt;- 2*(1 - pt(abs(tstat), n-1)) } else if(alternative==&quot;less&quot;){ # 左侧检验 pvalue &lt;- pt(tstat, n-1) } else if(alternative==&quot;greater&quot;){ # 右侧检验 pvalue &lt;- 1 - pt(tstat, n-1) } else { stop(&quot;alternative unknown!&quot;) } c(stat=tstat, pvalue=pvalue) } 这个函数允许输入\\(\\bar x\\)到x中，输入\\(n\\)，输入\\(S\\)到sigma中， 然后计算t检验。 31.3.1.1.3 统计假设检验显著性的解释 统计假设检验如果拒绝了\\(H_0\\)， 也称“结果显著”、“有显著差异”等。 这只代表样本与零假设的差距足够大， 可以以比较小的代价（第一类错误概率） 排除这样的差距是由于随机样本的随机性引起的， 但是并不表明这样的差距是有科学意义或者有现实意义的。 尤其是超大样本时， 完全没有实际意义的差距也会检验出来是统计显著的。 这时，可以设定一个“有实际意义的差距”\\(\\delta\\)， 当差距超过\\(\\delta\\)时才认为有实际差距，如： \\[ H_0: |\\mu - \\mu_0| \\leq \\delta \\longleftrightarrow |\\mu - \\mu_0| &gt; \\delta \\] 统计假设检验如果不拒绝\\(H_0\\)， 也称为“结果不显著”、“没有显著差异”， 通常不认为\\(H_0\\)就是对的， 看法是没有充分理由推翻\\(H_0\\)。 进一步收集更多的数据， 有可能就会发现显著差异。 例如，\\(H_0\\)是嫌疑人无罪， 最后不拒绝\\(H_0\\)， 只能是没有充分证据证明有罪， 如果后来收集到了关键的罪证， 就还可以再判决嫌疑人有罪。 31.3.1.1.4 置信区间与双侧检验的关系 设总体为正态分布\\(\\text{N}(\\mu, \\sigma^2)\\), \\(\\sigma\\)已知。 随机抽取了\\(n\\)个样品，计算得\\(\\bar x\\)。 \\(\\mu\\)的\\(1-\\alpha\\)置信区间为 \\[ \\bar x \\pm z_{\\alpha/2} \\sigma/\\sqrt{n} \\] 置信区间理论依据： \\[ P\\left(\\frac{|\\bar x - \\mu|}{\\sigma/\\sqrt{n}} \\leq z_{\\alpha/2} \\right) = 1 - \\alpha \\tag{*} \\] 对双侧检验 \\[ H_0: \\mu = \\mu_0 \\longleftrightarrow H_a: \\mu \\neq \\mu_0 \\] 当 \\[ \\frac{|\\bar x - \\mu_0|}{\\sigma/\\sqrt{n}} \\leq z_{\\alpha/2}\\] 时接受\\(H_0\\)。 接受\\(H_0\\)的条件，就是\\(\\mu_0\\)满足(*)式的大括号中的条件， 即当且仅当\\(\\mu_0\\)落入\\(\\mu\\)的\\(1-\\alpha\\)置信区间时接受\\(H_0\\)。 其它检验也与置信区间有类似关系， 但是单侧检验对应于单侧置信区间。 31.3.1.1.5 单样本均值比较例子 载入假设检验部分示例程序所用数据： load(&quot;hyptest-data.RData&quot;) 31.3.1.1.5.1 咖啡标重的单侧检验 美国联邦贸易委员会定期检查商品标签是否与实际相符。 Hiltop Coffee大罐咖啡标签注明含量为3磅。 每罐具体多一些或少一些并不要紧， 只要总体平均值不少于3磅， 消费者利益就未受侵害。 只有在有充分证据时才应该做出分量不够的判决进而对厂家进行处罚。 所以零假设是\\(H_0: \\mu \\geq 3\\)， 对立假设是\\(H_a: \\mu &lt; 3\\)。 收集数据进行统计判决后， 如果不拒绝\\(H_0\\)， 就不需要采取行动； 如果拒绝了\\(H_0\\)， 就说明有足够证据认为厂商灌装分量不足， 应进行处罚。 随机抽取了36件样品， 计算平均净重\\(\\bar x\\)作为总体均值\\(\\mu\\)的估计。 如果\\(\\bar x &lt; 3\\)， 则\\(H_0\\)有理由被怀疑。 \\(\\bar x\\)比\\(\\mu_0 = 3\\)少多少， 才让我们愿意拒绝\\(H_0\\)? 做出拒绝\\(H_0\\)的决定可能会犯第一类错误， 如果差距很小， 这样的差距很可能是随机抽样的随机性引起的， 拒绝\\(H_0\\)有很大的机会犯错。 必须先确定一个能够容忍的第一类错误概率。 调查员认为，可以容忍1%的错误拒绝\\(H_0\\)的机会 （不该处罚时给出了处罚） 以换得能够在厂商分量不足时正确地做出处罚决定的机会。 即选检验水平\\(\\alpha=0.01\\)。 当\\(H_0\\)实际成立时， 边界\\(\\mu=\\mu_0=3\\)处犯第一类错误的概率最大 （这里最不容易区分）， 所以计算第一类错误概率只要在边界处计算。 统计假设检验第一步是确定零假设与对立假设， 第二步是确定检验水平\\(\\alpha\\)。 第三步是抽取随机样本，计算检验统计量。 以往经验证明净重的标准差是\\(\\sigma=0.18\\)， 且净重的分布为正态分布。 则\\(\\bar x\\)的抽样分布为\\(\\text{N}(\\mu, \\sigma^2/n)\\)， \\(\\bar x\\)的标准误差为\\(\\text{SE}(\\bar x) = 0.18 / \\sqrt{36} = 0.03\\)。 令 \\[ z = \\frac{\\bar x - \\mu_0}{\\text{SE}(\\bar x)} \\] 则\\(H_0\\)成立且\\(\\mu\\)取边界处的\\(\\mu_0\\)时\\(z \\sim \\text{N}(0,1)\\)。 当\\(\\bar x\\)比\\(\\mu_0=3\\)小很多时应拒绝\\(H_0\\)。 即检验统计量\\(z\\)很小时拒绝\\(H_0\\)。 如果\\(z = -1\\)， 标准正态分布取-1或比-1更小的值的概率是0.1586 (用R程序pnorm(-1)计算)， 这个概率不小， 不小于\\(\\alpha=0.01\\)， 这时不应该拒绝\\(H_0\\)。 如果\\(z = -2\\)， 标准正态分布取-2或比-2更小的值的概率是0.0228， (用R程序pnorm(-2)计算)， 这个概率已经比较小了， 但还不小于预先确定的第一类错误概率\\(\\alpha=0.01\\)， 这时不应该拒绝\\(H_0\\)。 如果\\(z = -3\\)， 标准正态分布取-3或比-3更小的值的概率是0.0013， (用R程序pnorm(-3)计算)， 这个概率已经很小了， 也小于预先确定的第一类错误概率\\(\\alpha=0.01\\)， 这时应该拒绝\\(H_0\\)。 对左侧检验问题\\(H_0: \\mu \\geq \\mu_0 \\longleftrightarrow H_a: \\mu &lt; \\mu_0\\), 若\\(Z\\)表示标准正态分布随机变量， \\(z\\)是检验统计量的值，在\\(\\mu=\\mu_0\\)时\\(z\\)的抽样分布是标准正态分布， 可以计算抽样分布中取到等于\\(z\\)以及比\\(z\\)更小的值的概率\\(P(Z \\leq z)\\)， 称为检验的p值。 p值越小，说明\\(\\bar x\\)比\\(\\mu_0\\)小得越多， 拒绝\\(H_0\\)也越有充分证据。 当且仅当p值小于检验水平\\(\\alpha\\)时拒绝\\(H_0\\)。 p值小于\\(\\alpha\\)，说明如果\\(H_0\\)真的成立， 出现\\(\\bar x\\)那么小的检验统计量值的概率也很小， 小于\\(\\alpha\\)，所以第一类错误概率小于等于\\(\\alpha\\)。 一般地，p值是从样本计算的一个在假定零假设成立情况下， 检验统计量取值更倾向于对立假设成立的概率。 p值越小，拒绝\\(H_0\\)越有依据。 设咖啡标称重量问题中抽取了36件样品，测得\\(\\bar x = 2.92\\)磅， 计算得 \\[ z = \\frac{\\bar x - \\mu_0}{\\sigma/\\sqrt{n}} = \\frac{2.92 - 3}{0.18/\\sqrt{36}} = -2.67 \\] p值为\\(P(Z \\leq -2.67)\\)(\\(Z\\)是标准正态分布随机变量)， 用R计算得pnorm(-2.67)\\(=0.0038 \\leq \\alpha=0.01\\)， 拒绝\\(H_0\\)， 应对该厂商进行处罚。 已经预先确定了检验水平\\(\\alpha=0.01\\)就不能在看到检验结果后更改检验水平。 但是， 报告出p值后， 其他的人可以利用这样的信息， 不同的人或利益方可能有不同的检验水平的选择， 这通过同一个p值都可以给出需要的结果。 p值也称为“观测显著性水平”， 因为它是能够拒绝\\(H_0\\)的最小的可选检验水平， 选取比p值更小的检验水平就不能拒绝\\(H_0\\)了。 用自定义的z.test.1s()计算： z.test.1s(x=2.92, mu=3, n=36, sigma=0.18, alternative=&quot;less&quot;) ## stat pvalue ## -2.666666667 0.003830381 p值为0.004，在0.01水平下拒绝原假设， 认为咖啡平均重量显著地低于标称的3磅。 设Coffee数据框的Weight是这36个样本值， 也可以将程序写成： z.test.1s(Coffee[[&quot;Weight&quot;]], mu=3, sigma=0.18, alternative=&quot;less&quot;) ## stat pvalue ## -2.666666667 0.003830381 或 BSDA::z.test(Coffee[[&quot;Weight&quot;]], mu=3, sigma.x=0.18, alternative=&quot;less&quot;) ## ## One-sample z-Test ## ## data: Coffee[[&quot;Weight&quot;]] ## z = -2.6667, p-value = 0.00383 ## alternative hypothesis: true mean is less than 3 ## 95 percent confidence interval: ## NA 2.969346 ## sample estimates: ## mean of x ## 2.92 31.3.1.1.5.2 例：高尔夫球性能的双侧检验 美国高尔夫协会对高尔夫运动器械有一系列的规定。 MaxFlight生产高品质的高尔夫球， 平均的飞行距离是295码。 生产线有时会有波动， 当生产的球平均飞行距离不足295码时， 用户会感觉不好用； 当生产的球平均飞行距离超过295码时， 美国高尔夫协会禁止使用这样的球。 该厂商定期抽检生产线上下来的产品， 每次抽取50只。 当平均飞行距离与295码没有显著差距时， 不需要采取措施； 如果有显著差距，就需要调整生产线。 所以取\\(H_0: \\mu = 295\\), \\(H_a: \\mu \\neq 295\\)。 选检验水平\\(\\alpha=0.05\\)。 随机抽取\\(n\\)个样品， 在可控条件下测试出每个的飞行距离， 计算出平均值\\(\\bar x\\)。 当\\(\\bar x\\)比\\(\\mu_0\\)(这里是295)小很多或者 \\(\\bar x\\)比\\(\\mu_0\\)大很多时拒绝\\(H_0\\)， 否则不拒绝\\(H_0\\)。 设已知总体标准差\\(\\sigma=12\\), 且飞行距离服从正态分布。 取统计量 \\[z = \\frac{\\bar x - \\mu_0}{\\sigma/\\sqrt{n}}\\] 在\\(H_0\\)成立时， \\(z\\)的抽样分布为标准正态分布。 设测得\\(\\bar x = 297.6\\)，超过了\\(\\mu_0=295\\)。 \\[ z = = \\frac{\\bar x - \\mu_0}{\\sigma/\\sqrt{n}} = \\frac{297.6 - 295}{12/\\sqrt{50}} = 1.53 \\] \\(H_0\\)成立时\\(z\\)抽样分布为标准正态分布， 设\\(Z\\)是标准正态分布随机变量， \\(Z\\)取到1.53或者比1.53更倾向于反对\\(H_0\\)的值概率？ 这包括\\(P(Z \\geq 1.53)\\)， 还应包括\\(P(Z \\leq -1.53)\\)。 所以p值是\\(P(|Z| \\geq |z|)\\)， R中计算为2*(1 - pnorm(abs(z)))。 p值等于0.1260， 超过检验水平， 不拒绝\\(H_0\\)， 不需要调整生产线。 用自定义的z.test.1s()检验： z.test.1s(GolfTest[[&#39;Yards&#39;]], mu=295, sigma=12, alternative=&quot;two.sided&quot;) ## stat pvalue ## 1.5320647 0.1255065 或用BSDA::z.test(): BSDA::z.test(GolfTest[[&#39;Yards&#39;]], mu=295, sigma.x=12, alternative=&quot;two.sided&quot;) ## ## One-sample z-Test ## ## data: GolfTest[[&quot;Yards&quot;]] ## z = 1.5321, p-value = 0.1255 ## alternative hypothesis: true mean is not equal to 295 ## 95 percent confidence interval: ## 294.2738 300.9262 ## sample estimates: ## mean of x ## 297.6 p值为0.13，在0.05水平下不拒绝\\(H_0\\)， 生产的球的平均飞行距离与标准的295码之间没有显著差异。 31.3.1.1.5.3 Heathrow机场打分的检验 某旅行杂志希望根据乘机进行商务旅行的意见给跨大西洋门户机场评分。 乘客评分取0到10分，超过7分算作是服务一流的机场。 在每个机场随机选取60位商务旅行乘客打分评价。 英国Heathrow机场的打分样本\\(\\bar x = 7.25\\), \\(S = 1.052\\)。 英国Heathrow机场可以算是服务一流吗？ 由于随机样本的随机性， 要判断的是\\(\\mu &gt; 7\\)是否成立， 这里\\(\\bar x = 7.25\\)并不能很确定第说\\(\\mu &gt; 7\\)成立。 因为将机场评为一流需要有充分证据， 所以将对立假设\\(H_a\\)设为\\(\\mu &gt; 7\\)， 然后取\\(H_0: \\mu \\leq 7\\)。 取检验水平\\(\\alpha=0.05\\)。 计算检验统计量 \\[ t = \\frac{\\bar x - \\mu_0}{S / \\sqrt{n}} = \\frac{7.25 - 7}{1.052/\\sqrt{60}} = 1.84 \\] 设\\(T\\)是服从\\(t(n-1)\\)分布的随机变量， p值为\\(P(T \\geq 1.84)\\)。 用R软件计算为1 - pt(1.84, 60-1)\\(=0.0354\\)。 p值小于\\(\\alpha\\)，拒绝\\(H_0\\)， 认为平均评分显著高于7， 可以认为Heathrow机场是服务一流。 从原始样本数据用t.test()检验： t.test(AirRating[[&quot;Rating&quot;]], mu=7, alternative=&quot;greater&quot;) ## ## One Sample t-test ## ## data: AirRating[[&quot;Rating&quot;]] ## t = 1.8414, df = 59, p-value = 0.03529 ## alternative hypothesis: true mean is greater than 7 ## 95 percent confidence interval: ## 7.023124 Inf ## sample estimates: ## mean of x ## 7.25 用自定义的t.test.1s()和样本统计量计算： t.test.1s(x=7.25, sigma=1.052, n=60, mu=7, alternative=&quot;greater&quot;) ## stat pvalue ## 1.84077155 0.03534255 31.3.1.1.5.4 玩具厂商订货量的假设检验 玩具厂商Holiday Toys通过超过1000家玩具商店售货。 为了准备即将到来的冬季销售季节， 销售主管需要确定今年某新款玩具的生产量。 凭经验判断平均每家商店需要40件。 为了确定，随机抽取了25家商店， 提供了新款玩具的特点、进货价和建议销售价， 让他们给出订货量估计。 目的是判断按每家40件来生产是否合适。 因为多生产或少生产都不合适， 所以取零假设为\\(H_0: \\mu=40\\)。 对立假设为\\(H_a: \\mu \\neq 40\\)。 只有拒绝\\(H_0\\)时才需要更改生产计划。 取检验水平\\(\\alpha=0.05\\)。 样本计算得\\(n=25\\)，\\(\\bar x = 37.4\\), \\(S = 11.79\\)。 检验统计量 \\[ t = \\frac{\\bar x - \\mu_0}{S / \\sqrt{n}} = \\frac{37.4 - 40}{11.79 / \\sqrt{25}} = -1.10 \\] 设\\(T\\)为服从t\\((n-1)\\)分布的随机变量， p值为\\(2 P(|T| &gt; |-1.10|)\\)， 用R计算为2*(1 - pt(abs(-1.10), 25-1))\\(=0.2822\\)。 不拒绝\\(H_0\\)，所以不需要更改生产计划。 从原始样本数据用t.test()检验： t.test(Orders[[&quot;Units&quot;]], mu=40, alternative=&quot;two.sided&quot;) ## ## One Sample t-test ## ## data: Orders[[&quot;Units&quot;]] ## t = -1.1026, df = 24, p-value = 0.2811 ## alternative hypothesis: true mean is not equal to 40 ## 95 percent confidence interval: ## 32.5334 42.2666 ## sample estimates: ## mean of x ## 37.4 用自定义的t.test.1s()和样本统计量计算： t.test.1s(x=37.4, sigma=11.79, n=25, mu=40, alternative=&quot;two.sided&quot;) ## stat pvalue ## -1.1026293 0.2811226 31.3.1.2 均值比较 31.3.1.2.1 独立两样本Z检验 假设有两个独立的总体\\(X, Y\\)，例如，男性与女性的寿命。 要比较两个总体的期望\\(\\mu_1=EX\\)和\\(\\mu_2=EY\\)。 设两个总体的方差分别为\\(\\sigma_1^2\\)和\\(\\sigma_2^2\\)。 可以对均值作双侧、左侧、右侧检验。 比如，双侧检验为 \\[ H_0: \\mu_1 = \\mu_2 \\longleftrightarrow H_a: \\mu_1 \\neq \\mu_2 \\] 如果两个总体都服从正态分布， 而且分别的方差\\(\\sigma_1^2\\)和\\(\\sigma_2^2\\)已知， 设\\(X\\)的样本量为\\(n_1\\)的样本得到样本均值\\(\\bar x\\)， 设\\(Y\\)的样本量为\\(n_2\\)的样本得到样本均值\\(\\bar y\\)， 取统计量 \\[ Z = \\frac{\\bar x - \\bar y} {\\sqrt{\\frac{\\sigma_1^2}{n_1} + \\frac{\\sigma_2^2}{n_2}}} \\] 其中分母是分子的标准误差。 当\\(\\mu_1 = \\mu_2\\)时\\(Z \\sim \\text{N}(0,1)\\)。 如果分布不一定是正态分布但是样本量足够大， 可以令 \\[ Z = \\frac{\\bar x - \\bar y} {\\sqrt{\\frac{S_x^2}{n_1} + \\frac{S_y^2}{n_2}}} \\] 当\\(\\mu_1 = \\mu_2\\)时\\(Z\\)近似服从\\(\\text{N}(0,1)\\)。 检验问题还可以变成\\(\\mu_1 - \\mu_2\\)与某个\\(\\delta\\)的比较，如 \\[ H_0: \\mu_1 \\leq \\mu_2 - \\delta \\longleftrightarrow H_a: \\mu_1 &gt; \\mu_2 - \\delta \\] 这个对立假设是“不次于”的结论。 可以写一个大样本方差未知或已知， 小样本独立两正态总体方差已知情况做Z检验的R函数： z.test.2s &lt;- function( x, y, n1=length(x), n2=length(y), delta=0, sigma1=sd(x), sigma2=sd(y), alternative=&quot;two.sided&quot;){ z &lt;- (mean(x) - mean(y) - delta) / sqrt(sigma1^2 / n1 + sigma2^2 / n2) if(alternative==&quot;two.sided&quot;){ # 双侧检验 pvalue &lt;- 2*(1 - pnorm(abs(z))) } else if(alternative==&quot;less&quot;){ # 左侧检验 pvalue &lt;- pnorm(z) } else if(alternative==&quot;greater&quot;){ # 右侧检验 pvalue &lt;- 1 - pnorm(z) } else { stop(&quot;alternative unknown!&quot;) } c(stat=z, pvalue=pvalue) } 函数允许输入两组样本到x和y中， 输入\\(\\sigma_1\\)和\\(\\sigma_2\\)到sigma1和sigma2中， 这时不输入sigma1和sigma2则从样本中计算样本统计量代替。 也允许输入\\(\\bar x\\)和\\(\\bar y\\)到x和y中， 输入\\(\\sigma_1\\)和\\(\\sigma_2\\)到sigma1和sigma2中， 或者输入S_x$和$S_y$到sigma1和sigma2中， 输入$n_1$到n1中， 输入$n_2$到n2`中， 计算独立两样本均值比较的\\(Z\\)检验。 31.3.1.2.2 独立两样本t检验 如果样本是小样本，但两个总体分别服从正态分布， 两个总体的方差未知， 但已知\\(\\sigma_1^2 = \\sigma_2^2\\)。 这时\\(\\sigma_1^2 = \\sigma_2^2\\)可以统一估计为 \\[ S_p^2 = \\frac{1}{n_1 + n_2 - 2}\\left( (n_1 - 1)S_x^2 + (n_2 - 1)S_y^2 \\right) \\] 取检验统计量 \\[ T = \\frac{\\bar x - \\bar y}{S_p \\sqrt{\\frac{1}{n_1} + \\frac{1}{n_2}}} \\] 当\\(\\mu_1 = \\mu_2\\)时\\(T \\sim \\text{t}(n_1 + n_2 - 2)\\)。 当x和y存放了两组独立样本时， 可以用t.test(x, y, var.equal=TRUE)计算两样本t检验， 用alternative=选项指定双侧、右侧、左侧检验。 可以自己写一个这样的R函数作两样本t检验， 允许只输入统计量而非具体样本值： t.test.2s &lt;- function( x, y, n1=length(x), n2=length(y), sigma1=sd(x), sigma2=sd(y), delta=0, alternative=&quot;two.sided&quot;){ sp &lt;- sqrt(1/(n1+n2-2) * ((n1-1)*sigma1^2 + (n2-1)*sigma2^2)) t &lt;- (mean(x) - mean(y) - delta) / (sp * sqrt(1 / n1 + 1 / n2)) if(alternative==&quot;two.sided&quot;){ # 双侧检验 pvalue &lt;- 2*(1 - pt(abs(t), n1+n2-2)) } else if(alternative==&quot;less&quot;){ # 左侧检验 pvalue &lt;- pt(t, n1+n2-2) } else if(alternative==&quot;greater&quot;){ # 右侧检验 pvalue &lt;- 1 - pt(t, n1+n2-2) } else { stop(&quot;alternative unknown!&quot;) } c(stat=t, pvalue=pvalue) } 如果两个独立正态总体的方差不相等，样本量不够大， 可以用如下的在\\(H_0\\)下近似服从t分布的检验统计量： \\[ T = \\frac{\\bar x - \\bar y}{\\sqrt{ \\frac{S_x^2}{n_1} + \\frac{S_y^2}{n_2} }} \\] 自由度为 \\[ m = \\frac{\\left( S_x^2 / n_1 + S_y^2 / n_2 \\right)^2} { \\frac{\\left( S_x^2 / n_1\\right)^2}{n_1 - 1} + \\frac{\\left(S_y^2 / n_2 \\right)^2}{n_2 - 1} } \\] 这个检验称为Welch两样本t检验，或Satterthwaite 两样本t检验 当x和y存放了两组独立样本时， 可以用t.test(x, y, var.equal=FALSE)计算Welch两样本t检验。 如果方差是否相等不易判断， 可以直接选用Welch检验。 因为大样本时t分布与标准正态分布基本相同， 所以非正态总体大样本Z检验也可以用t.test()计算。 31.3.1.2.3 成对均值比较问题 设总体包含两个\\(X, Y\\)分量， 比如， 一组病人的服药前血压与服药后血压。 这两个变量是相关的， 不能用独立两总体的均值比较方法比较\\(\\mu_1=EX\\)与\\(\\mu_2=EY\\)。 若\\(\\xi = X - Y\\)服从正态分布， 则可以对\\(\\xi\\)进行均值为零的单样本t检验。 这样的检验称为成对均值的t检验。 若x和y分别为\\(X\\)和\\(Y\\)的样本值， 可以用t.test(x, y, paired=TRUE)计算计算成对均值t检验。 31.3.1.2.4 均值比较的例子 31.3.1.2.4.1 顾客平均年龄差别比较 HomeStyle是一个连锁家具店， 两家分店一个在城区，一个在郊区。 经理发现同一种家具有可能在一个分店卖的很好， 另一个分店则不好。 怀疑是顾客人群的人口学差异（年龄、性别、种族等）。 独立地抽取两个分店的顾客样本，比较平均年龄。 设城内的分店顾客年龄\\(\\sigma_1=9\\)已知， 郊区的分店顾客年龄\\(\\sigma_2=10\\)已知。 城内调查了\\(n_1=36\\)位顾客，年龄的样本平均值\\(\\bar x=40\\); 郊区调查了\\(n_2=49\\)位顾客，年龄的样本平均值\\(\\bar y=35\\)。 \\(\\bar x - \\bar y = 5\\)。 作双侧检验，水平\\(\\alpha=0.05\\)。 计算\\(Z\\)统计量： \\[ Z = \\frac{40 - 35}{\\sqrt{ \\frac{9^2}{36} + \\frac{10^2}{49} }} = 2.4138 \\] p值为\\(P(|V| \\geq |2.4138|)\\)，其中\\(V\\)为标准正态分布随机变量。 用R计算为2*(1 - pnorm(abs(2.4138)))=0.016， 两个分店的顾客年龄有显著差异， 城里的顾客平均年龄显著地高。 基于样本统计量用自定义的z.test.2s()计算： z.test.2s(n1=36, x=40, sigma1=9, n2=49, y=35, sigma2=10, alternative=&quot;two.sided&quot;) ## stat pvalue ## 2.41379310 0.01578742 31.3.1.2.4.2 两个银行营业所顾客平均存款比较 某银行要比较两个营业所的支票账户的平均存款额。 作双侧检验，水平0.05。没有方差信息时可以直接选用Welch检验。 设第一个营业所随机抽查了\\(n_1=28\\)个支票账户， 均值为\\(\\bar x=1025\\)(美元)，样本标准差为\\(S_1=150\\)， 第二个营业所随机抽查了\\(n_2=22\\)个支票账户， 均值为\\(\\bar y=910\\), 样本标准差为\\(S_2=125\\)。 从原始数据出发计算检验： t.test(CheckAcct[[1]], CheckAcct[[2]], var.equal = FALSE, alternative = &quot;two.sided&quot;) ## ## Welch Two Sample t-test ## ## data: CheckAcct[[1]] and CheckAcct[[2]] ## t = 2.956, df = 47.805, p-value = 0.004828 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## 36.77503 193.25224 ## sample estimates: ## mean of x mean of y ## 1025.0000 909.9864 p值为0.005，在0.05水平下显著， 两个营业所的账户平均余额有显著差异。 31.3.1.2.4.3 两种工具软件的比较 考虑开发信息系统的两种工具软件的比较。 新的软件声称比旧的软件能加快进度。 设使用旧软件时平均项目完成时间为\\(\\mu_1\\)， 使用新软件时为\\(\\mu_2\\)。 检验： \\[ H_0: \\mu_1 \\leq \\mu_2 \\longleftrightarrow H_a: \\mu_1 &gt; \\mu_2 \\] (对立假设是新软件的工期更短) 取0.05水平。 t.test(SoftwareTest[[&#39;Current&#39;]], SoftwareTest[[&#39;New&#39;]], var.equal = FALSE, alternative = &#39;greater&#39;) ## ## Welch Two Sample t-test ## ## data: SoftwareTest[[&quot;Current&quot;]] and SoftwareTest[[&quot;New&quot;]] ## t = 2.2721, df = 21.803, p-value = 0.01665 ## alternative hypothesis: true difference in means is greater than 0 ## 95 percent confidence interval: ## 9.514309 Inf ## sample estimates: ## mean of x mean of y ## 325 286 p值为0.017, 使用新的工具软件的平均项目完成时间显著地少于使用旧工具软件。 31.3.1.2.4.4 两种工艺所需时间的比较 工厂希望比较同一生产问题两种工艺各自需要的时间， 将选用时间较短的工艺。 可以一组工人用工艺1，一组工人用工艺2， 随机分组。 两组之间工人的个体差异会使得差异的比较误差较大。 所以，让同一个工人分别采用两种工艺， 次序先后随机。 这样不会引入个体差异的影响， 精度较高。 使用成对检验。 用双侧检验，水平0.05。 t.test(Matched[[&quot;Method 1&quot;]], Matched[[&quot;Method 2&quot;]], paired=TRUE, alternative = &quot;two.sided&quot;) ## ## Paired t-test ## ## data: Matched[[&quot;Method 1&quot;]] and Matched[[&quot;Method 2&quot;]] ## t = 2.1958, df = 5, p-value = 0.07952 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## -0.05120834 0.65120834 ## sample estimates: ## mean of the differences ## 0.3 31.3.1.3 多元均值置信域 待补充。 31.3.2 比例的假设检验和置信区间 31.3.2.1 单个比例的问题 设要比较的是总体的某个比例， 如选民中对候选人甲的支持率。 这时总体是两点分布总体， 支持为1， 不支持为0，参数为\\(p=P(X=1)\\)。 其它的比例问题类似， \\(p\\)是“成功概率”。 关于单总体的比例，也有双侧、右侧、左侧检验问题： \\[\\begin{aligned} &amp; H_0: p=p_0 \\longleftrightarrow H_a: p \\neq p_0 \\\\ &amp; H_0: p \\leq p_0 \\longleftrightarrow H_a: p &gt; p_0 \\\\ &amp; H_0: p \\geq p_0 \\longleftrightarrow H_a: p &lt; p_0 \\end{aligned}\\] 在R中， 大样本情况下可以用prop.test(x, n, p=p0)作单个比例的检验， n是样本量，x是样本中符合条件（如支持）的个数， 检验使用近似卡方统计量， 用alternative选项选择双侧、右侧、左侧检验。 这个函数也给出比例\\(p\\)的近似\\(1-\\alpha\\)置信区间， 用conf.level选项指定置信度。 大样本时还有 \\[ \\frac{\\hat p - p}{\\sqrt{p(1-p)/n}} \\] 近似服从标准正态分布， 可以据此计算Z检验。 自定义的R函数如下： prop.test.1s &lt;- function(x, n, p=0.5, alternative=&quot;two.sided&quot;){ phat &lt;- x/n zstat &lt;- (phat - p)/sqrt(p*(1-p)/n) if(alternative==&quot;two.sided&quot;){ # 双侧检验 pvalue &lt;- 2*(1 - pnorm(abs(zstat))) } else if(alternative==&quot;less&quot;){ # 左侧检验 pvalue &lt;- pnorm(zstat) } else if(alternative==&quot;greater&quot;){ # 右侧检验 pvalue &lt;- 1 - pnorm(zstat) } else { stop(&quot;alternative unknown!&quot;) } c(stat=zstat, pvalue=pvalue) } 因为比例问题本质上是一个二项分布推断问题， 所以R还提供了binom.test(x, n, p=p0)函数进行精确检验并计算精确置信区间， 但其结果略保守。 用法与prop.test()类似。 31.3.2.2 两个比例的比较 设有\\(X\\)和\\(Y\\)两个独立的总体， 如男性和女性， 比较\\(p_1 = P(X=1)\\)和\\(p_2 = P(Y=1)\\)。 检验问题包括： \\[\\begin{aligned} H_0: p_1 = p_2 &amp; \\longleftrightarrow H_\\text{a}: p_1 \\neq p_2 \\\\ H_0: p_1 \\leq p_2 &amp; \\longleftrightarrow H_\\text{a}: p_1 &gt; p_2 \\\\ H_0: p_1 \\geq p_2 &amp; \\longleftrightarrow H_\\text{a}: p_1 &lt; p_2 \\end{aligned}\\] 在大样本情况下， 可以用R函数 prop.test(c(nsucc1, nsucc2), c(n1,n2), alternative=...) 进行独立两样本比例的比较检验， 其中n1和n2是两个样本量， nsucc1和nsucc2是两个样本中符合特征的个数（个数除以样本量即样本中的比例）， alternative的选择也是\"two.sided\"、\"less\"、\"greater\"。 还可以比较\\(p_1 - p_2\\)与某个\\(\\delta\\)。 设两个总体中分别抽取了\\(n_1\\)和\\(n_2\\)个样本点， 样本比例分别为\\(\\hat p_1\\)和\\(\\hat p_2\\)。 估计共同的样本比例 \\[ \\hat p = \\frac{n_1 \\hat p_1 + n_2 \\hat p_2}{n_1 + n_2} \\] 当\\(\\delta=0\\)时取统计量 \\[ Z = \\frac{\\hat p_1 - \\hat p_2} {\\sqrt{\\hat p (1 - \\hat p) \\left( \\frac{1}{n_1} + \\frac{1}{n_2} \\right)}} \\] 当\\(p_1 = p_2\\)时\\(Z\\)在大样本情况下近似服从标准正态分布。 当\\(\\delta\\neq 0\\)时取统计量 \\[ Z = \\frac{\\hat p_1 - \\hat p_2 - \\delta} {\\sqrt{\\frac{\\hat p_1(1 - \\hat p_1)}{n_1} + \\frac{\\hat p_2(1 - \\hat p_2)}{n_2}}} \\] 当\\(p_1 - p_2 = \\delta\\)时\\(Z\\)在大样本情况下近似服从N(0,1)分布。 可以定义Z检验R函数为： prop.test.2s &lt;- function(x, n, delta=0.0, alternative=&quot;two.sided&quot;){ phat &lt;- sum(x)/sum(n) p &lt;- x / n if(delta==0.0){ zstat &lt;- (p[1] - p[2])/sqrt(phat*(1-phat)*(1/n[1] + 1/n[2])) } else { zstat &lt;- (p[1] - p[2] - delta)/sqrt(p[1]*(1-p[1])/n[1] + p[2]*(1-p[2])/n[2]) } if(alternative==&quot;two.sided&quot;){ # 双侧检验 pvalue &lt;- 2*(1 - pnorm(abs(zstat))) } else if(alternative==&quot;less&quot;){ # 左侧检验 pvalue &lt;- pnorm(zstat) } else if(alternative==&quot;greater&quot;){ # 右侧检验 pvalue &lt;- 1 - pnorm(zstat) } else { stop(&quot;alternative unknown!&quot;) } c(stat=zstat, pvalue=pvalue) } 独立两总体比例比较的小样本情形意义不大， 可考虑使用Fisher精确检验， R函数为fisher.test()。 31.3.2.3 比例检验的例子 31.3.2.3.1 高尔夫培训女生比例检验例子 橡树溪高尔夫培训机构的女性学员比例较少，只有20%。 为了增加女性学员，设计了促销措施。一个月后调查， 希望证明女性学员比例增加了。 设女性学员比例为\\(p\\)， \\[ H_0: p \\leq 0.20 \\longleftrightarrow H_a: p &gt; 0.20 \\] 取检验水平0.05。 抽查了400名学员，其中100名是女性学员，\\(\\hat p = 0.25\\)。 用prop.test()检验： prop.test(100, 400, p=0.20, alternative = &quot;greater&quot;) ## ## 1-sample proportions test with continuity correction ## ## data: 100 out of 400, null probability 0.2 ## X-squared = 5.9414, df = 1, p-value = 0.007395 ## alternative hypothesis: true p is greater than 0.2 ## 95 percent confidence interval: ## 0.2149649 1.0000000 ## sample estimates: ## p ## 0.25 检验p值为0.0074，小于检验水平0.05， 所以女性学员比例已经显著地高于过去的20%了。 用自定义的大样本Z检验函数prop.test.1s(): prop.test.1s(100, 400, p=0.20, alternative = &quot;greater&quot;) ## stat pvalue ## 2.500000000 0.006209665 检验p值为0.0062，与基于卡方检验的prop.test()结果略有差别。 用基于二项分布的binom.test()检验: binom.test(100, 400, p=0.20, alternative = &quot;greater&quot;) ## ## Exact binomial test ## ## data: 100 and 400 ## number of successes = 100, number of trials = 400, p-value = 0.008595 ## alternative hypothesis: true probability of success is greater than 0.2 ## 95 percent confidence interval: ## 0.2146019 1.0000000 ## sample estimates: ## probability of success ## 0.25 p值为0.0086。 31.3.2.3.2 报税代理分理处的错误率比较 某个代理报税的机构希望比较下属的两个分理处申报纳税返还的出错率。 各自随机选取取了\\(n_1=250\\)和\\(n_2=300\\)件申报， 第一个分理处错了35件，错误率\\(\\hat p_1 = 0.14\\); 第二个分理处错了27件，错误率\\(\\hat p_2 = 0.09\\)。 作双侧检验，水平0.10。 用prop.test(): prop.test(c(35,27), c(250,300), alternative = &quot;two.sided&quot;) ## ## 2-sample test for equality of proportions with continuity correction ## ## data: c(35, 27) out of c(250, 300) ## X-squared = 2.9268, df = 1, p-value = 0.08712 ## alternative hypothesis: two.sided ## 95 percent confidence interval: ## -0.007506845 0.107506845 ## sample estimates: ## prop 1 prop 2 ## 0.14 0.09 p值0.087，有显著差异，第一处的错误率高。 因为比例需要较大样本量， 所以样本量不太大时， 有人用0.10这样的检验水平。 用自定义的prop.test.2s(): prop.test.2s(c(35,27), c(250,300), alternative = &quot;two.sided&quot;) ## stat pvalue ## 1.84618928 0.06486473 31.3.3 方差的假设检验和置信区间 31.3.3.1 单总体方差的假设检验和置信区间 方差和标准差是总体的重要数字特征， 在金融应用中标准差代表波动率， 在工业生产中标准差也是重要的质量指标， 如机床加工精度可以用标准差表示。 对总体方差\\(\\sigma^2\\)可以做双侧、左侧、右侧检验， 与某个\\(\\sigma_0^2\\)比较。 设总体为正态总体，检验问题： \\[\\begin{aligned} H_0:&amp; \\sigma^2 = \\sigma_0^2 \\longleftrightarrow H_\\text{a}: \\sigma^2 \\neq \\sigma_0^2 \\\\ H_0:&amp; \\sigma^2 \\geq \\sigma_0^2 \\longleftrightarrow H_\\text{a}: \\sigma^2 &lt; \\sigma_0^2 \\\\ H_0:&amp; \\sigma^2 \\leq \\sigma_0^2 \\longleftrightarrow H_\\text{a}: \\sigma^2 &gt; \\sigma_0^2 \\end{aligned}\\] 可以用如下的自定义函数计算单正态总体方差的检验： var.test.1s &lt;- function(x, n=length(x), var0, alternative=&quot;two.sided&quot;){ if(length(x)==1){ # 输入的是方差 varx &lt;- x } else { varx &lt;- var(x) } xi &lt;- (n-1)*varx/var0 if(alternative==&quot;less&quot;){ pvalue &lt;- pchisq(xi, n-1) } else if (alternative==&quot;right&quot;){ pvalue &lt;- pchisq(xi, n-1, lower.tail=FALSE) } else if(alternative==&quot;two.sided&quot;){ pvalue &lt;- 2*min(pchisq(xi, n-1), pchisq(xi, n-1, lower.tail=FALSE)) } c(statistic=xi, pvalue=pvalue) } 可以输入样本数据到x中， 输入\\(sigma_0^2\\)到var0中， 进行检验； 也可以输入\\(S^2\\)到x中，输入样本量\\(n\\)到n中， 输入\\(sigma_0^2\\)到var0中， 进行检验。 31.3.3.2 独立两总体方差的比较 设两个独立的正态总体的方差分别为\\(\\sigma_1^2\\), \\(\\sigma_2^2\\)， 有双侧、左侧、右侧检验： \\[\\begin{aligned} H_0:&amp; \\sigma_1^2 = \\sigma_2^2 \\longleftrightarrow H_\\text{a}: \\sigma_1^2 \\neq \\sigma_2^2 \\\\ H_0:&amp; \\sigma_1^2 \\geq \\sigma_2^2 \\longleftrightarrow H_\\text{a}: \\sigma_1^2 &lt; \\sigma_2^2 \\\\ H_0:&amp; \\sigma_1^2 \\leq \\sigma_2^2 \\longleftrightarrow H_\\text{a}: \\sigma_1^2 &gt; \\sigma_2^2 \\end{aligned}\\] 设两个总体分别抽取\\(n_1\\)和\\(n_2\\)个样本点， 样本方差分别为\\(S_x^2\\)和\\(S_y^2\\)。 检验统计量 \\[ F = \\frac{S_x^2}{S_y^2} \\] 在\\(\\sigma_1^2 = \\sigma_2^2\\)时\\(F\\)服从\\(F(n_1 - 1, n_2 - 1)\\)分布。 如果输入x, y为两个样本的具体值， 可以用var.test(x, y, alternative=...)检验， 其中alternative的选择是\"two.sided\"、\"less\"、\"greater\"。 var.test()假定总体都服从正态分布。 R中mood.test()是一种不要求正态分布假定的检验方法。 bartlett.test()检验多个独立正态总体方差是否全相等。 31.3.3.3 方差检验例子 (待补充) 31.3.4 拟合优度检验 31.3.4.1 各类比例相等的检验 设类别变量\\(X\\)有\\(m\\)个不同类别， 抽取\\(n\\)个样本点后， 各类的频数分别为\\(f_1, f_2, \\dots, f_m\\)。 零假设为所有类的比例相同； 对立假设为各类比例不完全相同。 在零假设下，每个类的期望频数为\\(n/m\\)。 检验统计量为 \\[ \\chi^2 = \\sum_{i=1}^m \\frac{(f_i - \\frac{n}{m})^2}{\\frac{n}{m}} \\] 当\\(\\chi^2\\)超过某一临界值时拒绝零假设。 在\\(H_0\\)成立且大样本情况下\\(\\chi^2\\)统计量近似服从\\(\\chi^2(m-1)\\)分布 （自由度为组数减1）。 设x中包含各类的频数， R函数chisq.test(x)作各类的总体比例相等的拟合优度卡方检验。 31.3.4.2 各类比例为指定值的检验 设分类变量\\(X\\)的各类每类有一个总体比例的假设， 希望作为零假设检验。 设共有\\(m\\)个类，在零假设中， 各类的比例分别为\\(p_1, p_2, \\dots, p_m\\)。 取了\\(n\\)个样本点组成的样本， 各类的频数分别为\\(f_1, f_2, \\dots, f_m\\)， 期望频数分别为\\(np_1, np_2, \\dots, np_m\\)。 检验统计量为 \\[ \\chi^2 = \\sum_{i=1}^m \\frac{(f_i - n p_i)^2}{n p_i} \\] 在\\(H_0\\)下成立且大样本情况下\\(\\chi^2\\)近似服从\\(\\chi^2(m-1)\\)， 自由度为组数减1。 因为是大样本检验法， 每个组的期望频数不能低于5， 否则可以合并较小的类。 设x中包含各类的频数， p中包含\\(H_0\\)假定的各类的概率， R函数chisq.test(x, p)作各类的总体比例为指定概率的拟合优度卡方检验。 例: 市场占有率的检验例子 某类产品中公司A占30%, 公司B占50%，公司C占20%。 近期C公司推出了新产品代替本公司的老产品。 Scott Marketing Research是一个调查公司， 公司C委托Scott Marketing Research调查分析新产品是否导致了市场占有率的变动。 设\\(p_1, p_2, p_3\\)分别为三个公司现在的市场占有率，零假设为: \\[ H_0: p_1 = 0.30, p_2 = 0.50, p_3 = 0.20 \\] 取检验水平0.05。 抽查了200位消费者， 购买三个公司的产品的人数分配为： \\[(48, 98, 54)\\] 卡方统计量 \\[ \\chi^2 = \\frac{(48 - 200\\times 0.3)^2}{200\\times 0.3} + \\frac{(98 - 200\\times 0.5)^2}{200\\times 0.5} + \\frac{(54 - 200\\times 0.2)^2}{200\\times 0.2} = 7.34 \\] p值\\(=P(\\chi^2(3-1) &gt; 7.34) = 0.02548\\)， 拒绝零假设， 认为市场占有率有变化。 用chisq.test()计算： chisq.test(c(48, 98, 54), p=c(0.3, 0.5, 0.2)) ## ## Chi-squared test for given probabilities ## ## data: c(48, 98, 54) ## X-squared = 7.34, df = 2, p-value = 0.02548 31.3.4.3 带有未知参数的单分类变量的拟合优度假设检验 如果\\(H_0\\)下的概率有未知参数， 先用最大似然估计法估计未知参数， 然后将未知参数代入计算各类的概率， 从而计算期望频数， 计算卡方统计量。 求\\(p\\)值时自由度要改为“组数减1减去未知参数个数”。 例： 设某次选举有5位候选人， 其中呼声最高的是甲和乙。 问：甲、乙的支持率相等吗？ 这不能用独立的两个比例的比较来解决， 因为这两个比例是互斥的， 不属于独立情况。 将类别简化为：甲，乙，其他。 零假设为“甲、乙的支持率都等于\\(p\\)， 其他三位候选人的支持率为\\(1-2p\\)，\\(p\\)未知”； 对立假设是甲、乙的支持率不相等。 假设调查了1000位选民， 其中300名支持甲，200名支持乙，500名支持其他三位候选人。 在假定零假设成立的情况下先用最大似然估计法估计未知参数\\(p\\)： \\(\\hat p = (300 + 200)/1000/2 = 0.25\\)。 这样，三个类的概率估计为\\((0.25, 0.25, 0.50)\\)。 然后，计算检验统计量： chisq.test(c(300, 200, 500), c(0.25, 0.25, 0.50)) ## Warning in chisq.test(c(300, 200, 500), c(0.25, 0.25, 0.5)): Chi-squared ## approximation may be incorrect ## ## Pearson&#39;s Chi-squared test ## ## data: c(300, 200, 500) and c(0.25, 0.25, 0.5) ## X-squared = 3, df = 2, p-value = 0.2231 其中的\\(p\\)值所用的自由度错误，我们需要自己计算p值： res &lt;- chisq.test(c(300, 200, 500), c(0.25, 0.25, 0.50)) ## Warning in chisq.test(c(300, 200, 500), c(0.25, 0.25, 0.5)): Chi-squared ## approximation may be incorrect c(statistic=res$statistic, pvalue=pchisq(res$statistic, res$parameter - 1, lower.tail=FALSE)) ## statistic.X-squared pvalue.X-squared ## 3.00000000 0.08326452 检验\\(p\\)值为0.08而非原来的0.22。 31.3.5 检验分布类型 vcd包提供了一个goodfit函数， 可以用来拟合指定的某种理论分布(包括泊松、二项、负二项分布）， 并检验服从该理论分布的零假设。 例如，我们生成一组速率参数为2的泊松随机数， 检验其分布是否泊松分布： library(vcd) ## Warning: 程辑包&#39;vcd&#39;是用R版本3.6.3 来建造的 ## 载入需要的程辑包：grid set.seed(101) datax &lt;- rpois(100, 2) summary(goodfit(datax, &quot;poisson&quot;)) ## ## Goodness-of-fit test for poisson distribution ## ## X^2 df P(&gt; X^2) ## Likelihood Ratio 4.289456 5 0.5085374 检验其是否服从二项分布，取二项分布试验数为10： summary(goodfit(datax, &quot;binomial&quot;, par = list(size = 10))) ## ## Goodness-of-fit test for binomial distribution ## ## X^2 df P(&gt; X^2) ## Likelihood Ratio 5.052451 5 0.4095126 与二项分布也相容。 在检验分布类型时， 这种两种分布都不能拒绝的情况是常见的。 31.3.6 列联表独立性卡方检验 设分类变量\\(X\\)有\\(m\\)个类， 分类变量\\(Y\\)有\\(k\\)个类， 抽取了样本量为\\(n\\)的样本， 设\\(X\\)的第\\(i\\)类与\\(Y\\)的第\\(j\\)类交叉的频数为\\(f_{ij}\\)。 零假设为\\(X\\)与\\(Y\\)相互独立， 即行变量与列变量相互独立。 交叉频数列成列联表形式，第\\(i\\)行第\\(j\\)列为\\(f_{ij}\\)。 第\\(i\\)行的行和为\\(f_{i\\cdot}\\), \\(X\\)的第\\(i\\)类的百分比为\\(r_{i} = f_{i\\cdot}/n\\); 第\\(j\\)列的列和为\\(f_{\\cdot j}\\), \\(Y\\)的第\\(j\\)类的百分比为\\(c_{j} = f_{\\cdot j}/n\\)。 当\\(X\\), \\(Y\\)独立时， \\((i,j)\\)格子的期望频数为 \\(E_{ij} = n \\times r_i \\times c_j\\)。 列联表独立性检验统计量 \\[ \\chi^2 = \\sum_{i=1}^m \\sum_{j=1}^k \\frac{(f_{ij} - E_{ij})^2}{E_{ij}} \\] 其中\\(E_{ij} = n r_i c_j\\)， \\(r_i\\)为\\(X\\)第\\(i\\)类的百分比， \\(c_j\\)为\\(Y\\)第\\(j\\)类的百分比。 在\\(H_0\\)下\\(\\chi^2\\)近似服从\\((m-1)(k-1)\\)自由度的卡方分布。 设统计量值为\\(c\\)， p值为\\(P(\\chi^2((m-1)(k-1)) &gt; c)\\)。 如果x, y分别是两个变量的原始观测值， chisq.test(x, y)可以做列联表独立性检验。 如果x保存了矩阵格式的列联表， 矩阵行名是\\(X\\)各个类的名称， 矩阵列名是\\(Y\\)各个类的名称， 则chisq.test(x)可以做列联表独立性检验。 列联表卡方检验法的检验统计量在零假设下的卡方分布是大样本情况的近似分布。 如果每个变量仅有两个类，每个类的期望频数不能少于5; 如果有多个单元格，期望频数少于5的单元格的个数不能超过20%， 否则应该合并较小的类。 31.3.6.1 列联表独立性卡方检验例子 31.3.6.1.1 性别与啤酒种类的独立性检验 Alber’s Brewery of Tucson, Arizona是啤酒制造与销售商。 有三类啤酒产品：淡啤酒，普通啤酒，黑啤酒。 了解不同顾客喜好有利于制定更精准的销售策略。 希望了解男女顾客对不同类型的偏好有没有显著差异， 实际就是检验性别与啤酒类型偏好的独立性。 抽查了150位顾客，得到如下的列联表： ctab.beer &lt;- rbind(c( 20, 40, 20), c(30,30,10)) colnames(ctab.beer) &lt;- c(&quot;Light&quot;, &quot;Regular&quot;, &quot;Dark&quot;) rownames(ctab.beer) &lt;- c(&quot;Male&quot;, &quot;Female&quot;) addmargins(ctab.beer) ## Light Regular Dark Sum ## Male 20 40 20 80 ## Female 30 30 10 70 ## Sum 50 70 30 150 列联表独立性检验： chisq.test(ctab.beer) ## ## Pearson&#39;s Chi-squared test ## ## data: ctab.beer ## X-squared = 6.1224, df = 2, p-value = 0.04683 在0.05水平下认为啤酒类型偏好与性别有关。 男性组的偏好分布、女性组的偏好分布、所有人的偏好分布： tab2 &lt;- round(prop.table(addmargins(ctab.beer, 1), 1), 3) rownames(tab2)[3] &lt;- &quot;All&quot; tab2 ## Light Regular Dark ## Male 0.250 0.500 0.250 ## Female 0.429 0.429 0.143 ## All 0.333 0.467 0.200 可以看出男性中对淡啤酒偏好偏少， 女性中对淡啤酒偏好偏多。 31.3.7 非参数检验 待完成。 References "],["stat-reg.html", "32 R相关与回归 32.1 相关分析 32.2 一元回归分析 32.3 多元线性回归 32.4 非参数回归 32.5 Logistic回归", " 32 R相关与回归 32.1 相关分析 考虑连续型随机变量之间的关系。相关系数定义为 \\[\\rho(X, Y) = \\frac{E\\left[ (X - EX)(Y-EY) \\right]} {\\sqrt{\\text{Var}(X)\\text{Var}(Y)}} \\] 又称Pearson相关系数。 \\(-1 \\leq \\rho \\leq 1\\)。\\(\\rho\\)接近于\\(+1\\)表示\\(X\\)和\\(Y\\)有正向的相关； \\(\\rho\\)接近于\\(-1\\)表示\\(X\\)和\\(Y\\)有负向的相关。 相关系数代表的是线性相关性， 对于\\(X\\)和\\(Y\\)的其它相关可能反映不出来， 比如\\(X \\sim \\text{N}(0,1)\\)，\\(Y = X^2\\)， 有\\(\\rho(X, Y) = 0\\)。 给定样本\\((X_i, Y_i), i=1,2,\\dots,n\\)，样本相关系数为 \\[r = \\frac{\\sum_{i=1}^n (X_i - \\bar X) (Y_i - \\bar Y)} {\\sqrt{\\sum_{i=1}^n (X_i - \\bar X)^2 \\sum_{i=1}^n (Y_i - \\bar Y)^2}} \\] 用散点图和散点图矩阵直观地查看变量间的相关。 例如，线性相关的模拟数据的散点图: set.seed(1) nsamp &lt;- 30 x &lt;- runif(nsamp, -10, 10) y &lt;- 20 + 0.5*x + rnorm(nsamp,0,0.5) plot(x, y) 图32.1: 线性相关数据 二次曲线相关的模拟数据散点图: set.seed(1) y2 &lt;- 0.5*x^2 + rnorm(nsamp,0,2) plot(x, y2) 图32.2: 二次曲线相关数据 指数关系的例子: set.seed(1) y3 &lt;- exp(0.2*(x+10)) + rnorm(nsamp,0,2) plot(x, y3) 图32.3: 指数关系相关数据 对数关系的例子: set.seed(1) y4 &lt;- log(10*(x+12)) + rnorm(nsamp,0,0.1) plot(x, y4) 图32.4: 对数关系相关数据 32.1.1 相关系数的性质 取值\\(-1 \\leq r \\leq 1\\)。 \\(r&gt;0\\)表示正线性相关； \\(r&lt;0\\)表示负线性相关。 当\\(r=1\\)时\\((x_i, y_i), i=1,\\dots,n\\)这\\(n\\)个点完全在一条正斜率的直线上， 属于确定性关系。 当\\(r=-1\\)时\\((x_i, y_i), i=1,\\dots,n\\)这\\(n\\)个点完全在一条负斜率的直线上， 属于确定性关系。 计算相关系数时与\\(x, y\\)的次序或记号无关。 如果对变量\\(x\\)或者\\(y\\)分别乘以倍数，再分别加上不同的平移量， 相关系数不变。 即：\\(a + bx\\)与\\(c + dy\\)的相关系数， 等于\\(x, y\\)的相关系数。 这样，相关系数不受单位、量纲的影响。 相关系数是无量纲的。 如果\\(x\\)和\\(y\\)之间是非线性相关， 相关系数不一定能准确反映其关系， 只能作为一定程度的近似。 设变量\\(X\\)和\\(Y\\)的样本存放于R向量x和y中， 用cor(x,y)计算样本相关系数。 set.seed(1) x &lt;- runif(30, 0, 10) xx &lt;- seq(0, 10, length.out = 100) y &lt;- 40 - (x-7)^2 + rnorm(30) yy &lt;- 40 - (xx-7)^2 plot(x, y, pch=16) lines(xx, yy) 图32.5: 曲线相关数据的相关系数例1 cor(x, y) ## [1] 0.8244374 x &lt;- runif(30, 0, 10) xx &lt;- seq(0, 10, length.out = 100) y &lt;- 40 - (x-5)^2 + rnorm(30) yy &lt;- 40 - (xx-5)^2 plot(x, y, pch=16) lines(xx, yy) 图32.6: 曲线相关数据的相关系数例2 cor(x, y) ## [1] -0.042684 x &lt;- runif(30, 0, 10) xx &lt;- seq(0, 10, length.out = 100) y &lt;- 40*exp(-x/2) + rnorm(30) yy &lt;- 40*exp(-xx/2) plot(x, y, pch=16) lines(xx, yy) 图32.7: 曲线相关数据的相关系数例3 cor(x, y) ## [1] -0.8841117 32.1.2 相关与因果 相关系数是从数据中得到的\\(x\\)和\\(y\\)两个变量关系的一种描述， 不能直接引申为因果关系。 例如，增加身高，不一定增长体重。 实际中有许多错误理解相关与因果性的例子。 例如：研究发现喝咖啡的人群比不喝咖啡的人群心脏病发病率高。 于是断言喝咖啡导致心脏病危险增加。 进一步研究更多的因素发现， 喝咖啡放糖很多的人心脏病发病率才增高了。 32.1.3 相关系数大小 相关系数绝对值在0.8以上认为高度相关。 在0.5到0.8之间认为中度相关。 在0.3到0.5之间认为低度相关。 在0.3以下认为不相关或相关性很弱以至于没有实际价值。 当然，在特别重要的问题中， 只要经过检验显著不等于零的相关都认为是有意义的。 32.1.4 相关系数的检验 相关系数\\(r\\)是总体相关系数\\(\\rho\\)的估计。 \\[H_0: \\rho=0 \\longleftrightarrow H_a: \\rho\\neq 0\\] 检验统计量 \\[t = \\frac{r \\sqrt{n-2}}{\\sqrt{1 - r^2}}\\] 当总体\\((X, Y)\\)服从二元正态分布且\\(H_0: \\rho=0\\)成立时， \\(t\\)服从\\(t(n-2)\\)分布。 设\\(t\\)统计量值为\\(t_0\\)，p值为 \\[P(|t(n-2)| &gt; |t_0|)\\] 在R中用cor.test(x,y)计算检验。 例如： cor.test(d.class$height, d.class$weight) ## ## Pearson&#39;s product-moment correlation ## ## data: d.class$height and d.class$weight ## t = 7.5549, df = 17, p-value = 7.887e-07 ## alternative hypothesis: true correlation is not equal to 0 ## 95 percent confidence interval: ## 0.7044314 0.9523101 ## sample estimates: ## cor ## 0.8777852 得身高与体重的相关系数为0.88，检验的p值为7.887e-07， 95%置信区间为\\([0.70, 0.95]\\)。 再例如: set.seed(1) nsamp &lt;- 30 x &lt;- runif(nsamp, -10, 10) y &lt;- 0.5*x^2 + rnorm(nsamp,0,2) cor.test(x, y) ## ## Pearson&#39;s product-moment correlation ## ## data: x and y ## t = 0.93076, df = 28, p-value = 0.3599 ## alternative hypothesis: true correlation is not equal to 0 ## 95 percent confidence interval: ## -0.1994815 0.5021658 ## sample estimates: ## cor ## 0.1732378 得x与y的样本相关系数为0.17, p值为0.36，不显著。 32.1.5 相关阵 如果x是一个仅包含数值型列的数据框， 则cor(x)计算样本相关系数矩阵； var(x)计算样本协方差阵。 corrgram::corrgram()可以绘制相关系数矩阵的图形， 用颜色和阴影浓度代表相关系数正负和绝对值大小， 用饼图中阴影部分大小代表相关系数绝对值大小。 如： library(corrgram) ## Registered S3 method overwritten by &#39;seriation&#39;: ## method from ## reorder.hclust gclus corrgram( baseball[,c(&quot;Assists&quot;,&quot;Atbat&quot;,&quot;Errors&quot;,&quot;Hits&quot;,&quot;Homer&quot;,&quot;logSal&quot;, &quot;Putouts&quot;,&quot;RBI&quot;,&quot;Runs&quot;,&quot;Walks&quot;,&quot;Years&quot;)], order=TRUE, main=&quot;Baseball data PC2/PC1 order&quot;, lower.panel=panel.shade, upper.panel=panel.pie) 图32.8: 相关阵图形 其中选项order=TRUE重排各列的次序使得较接近的列排列在相邻位置。 32.2 一元回归分析 32.2.1 模型 考虑两个变量\\(Y\\)与\\(X\\)的关系，希望用\\(X\\)值的变化解释\\(Y\\)值的变化。 \\(X\\)称为自变量(independent variable)，\\(Y\\)称为因变量(response variable)。 假设模型 \\[\\begin{aligned} Y = a + b X + \\varepsilon, \\quad \\varepsilon \\sim \\text{N}(0,\\sigma^2) \\end{aligned} \\] 设观测值为\\((X_i, Y_i), i=1,2,\\dots,n\\)，假设观测值满足上模型。 即 \\[\\begin{aligned} Y_i = a + b X_i + \\varepsilon_i, \\quad \\varepsilon_i \\text{ iid }\\sim \\text{N}(0,\\sigma^2) \\end{aligned} \\] 32.2.2 最小二乘法 直观上看，要找最优的直线\\(y=a+bx\\)使得直线与观测到的点最接近。 例如： plot(x, y) abline(lm(y ~ x), col=&quot;red&quot;, lwd=2) 图32.9: 一元线性回归最小二乘估计 \\(a,b\\)的解用最小二乘法得到: \\[\\min_{a,b} \\sum_{i=1}^n \\left( y_i - a - b x_i \\right)^2\\] 最小二乘解表达式为 \\[\\begin{aligned} \\hat b =&amp; \\frac{\\sum_i (x_i - \\bar x)(y_i - \\bar y)} {\\sum_i (x_i - \\bar x)^2} = r_{xy} \\frac{S_y}{S_x} \\\\ \\hat a =&amp; \\bar y - \\hat b \\bar x \\end{aligned}\\] 其中\\(r_{xy}\\)为\\(X\\)与\\(Y\\)的样本相关系数， \\(S_x\\)与\\(S_y\\)分别为\\(X\\)和\\(Y\\)的样本标准差。 随机误差方差\\(\\sigma^2\\)的估计取为 \\[ \\hat\\sigma^2 = \\frac{1}{n-2}\\sum_i (y_i - \\hat a - \\hat b x_i)^2 \\] 标准误差: 为衡量\\(\\hat a\\)和\\(\\hat b\\)的估计精度， 计算\\(\\text{SE}(\\hat a)\\)和\\(\\text{SE}(\\hat b)\\)。 估计结果: 拟合值(预测值) \\[\\hat y_i = \\hat a + \\hat b x_i, \\quad i=1,2,\\dots,n\\] 残差 \\[e_i = y_i - \\hat y_i, \\quad i=1,2,\\dots,n\\] \\(\\text{SSE}=\\sum_i e_i^2\\) 称为残差平方和，残差平方和小则拟合优。 32.2.3 回归有效性 32.2.3.1 拟合优度指标 按照最小二乘估计公式，只要\\(x_1, x_2, \\dots, x_n\\)不全相等， 不论\\(x, y\\)之间有没有相关关系， 都能计算出参数估计值。 得到的回归直线与观测数据的散点之间的接近程度代表了回归结果的优劣。 残差平方和 \\[\\text{SSE}=\\sum_{i=1}^n (y_i - \\hat a - \\hat b x_i)^2\\] 残差平方和越小， 说明回归直线与观测数据点吻合得越好。 \\(y\\)是因变量， 因变量的数据的离差平方和 \\[\\text{SST}=\\sum_{i=1}^n (y_i - \\bar y)^2\\] 代表了因变量的未知变动大小， 需要对这样的变动用自变量进行解释， 称SST为总平方和。 可以证明如下平方和分解公式： \\[\\text{SST} = \\text{SSR} + \\text{SSE}\\] 其中SSR称为回归平方和。 令\\(\\hat y_i = \\hat\\beta_0 + \\hat\\beta_1 x_i\\)称为第\\(i\\)个拟合值， 回归平方和为 \\[\\text{SSR}=\\sum_{i=1}^n (\\hat y_i - \\bar y)^2 = \\hat b^2 \\sum_{i=1}^n (x_i - \\bar x)^2 \\] 在总平方和中， 回归平方和是能够用回归斜率与自变量的变动解释的部分， 残差平方和是自变量不能解释的变动。 分解中，回归平方和越大，误差平方和越小， 拟合越好。 令 \\[R^2 = \\frac{\\text{SSR}}{\\text{SST}} = 1 - \\frac{\\text{SSE}}{\\text{SST}}\\] 称为回归的复相关系数，或判定系数。 \\(0 \\leq R^2 \\leq 1\\)。判定系数越大，回归拟合越好。 \\(R^2=1\\)时，观测点完全落在一条直线上面。 一元回归中\\(R^2\\)是\\(x\\)和\\(y\\)的样本相关系数的平方。 在多元回归时只能用复相关系数。 估计误差项方差\\(\\sigma^2\\)为 \\[ \\hat\\sigma^2 = \\frac{1}{n-2}\\sum_{i=1}^n (y_i - \\hat a - \\hat b x_i)^2 = \\frac{1}{n-2} \\text{SSE} \\] \\(\\hat\\sigma\\)是\\(\\sigma\\)的估计， R的回归结果中显示为“residual standard error”（残差标准误差）。 \\(\\hat\\sigma\\)是残差\\(e_i = y_i - \\hat y_i\\)的标准差的一个粗略估计。 32.2.3.2 线性关系显著性检验 当\\(b=0\\)时，模型退化为\\(Y = a + \\varepsilon\\)，\\(X\\)不出现在模型中， 说明\\(Y\\)与\\(X\\)不相关。检验 \\[ H_0: b=0 \\longleftrightarrow H_\\text{a}: b \\neq 0 \\] 取统计量 \\[F = \\frac{\\text{SSR}}{\\text{SSE}/(n-2)}\\] 检验p值为\\(P(F(1, n-2) &gt; c)\\)(设\\(c\\)为\\(F\\)统计量的值)。 取检验水平\\(\\alpha\\), p值小于等于\\(\\alpha\\)时拒绝\\(H_0\\)， 认为\\(y\\)与\\(x\\)有显著的线性相关关系， 否则认为\\(y\\)与\\(x\\)没有显著的线性相关关系。 也可以使用t统计量 \\[t = \\frac{\\hat b}{\\text{SE}_{\\hat b}}\\] 其中 \\[ \\text{SE}_{\\hat b} = \\hat\\sigma / \\sqrt{\\sum_{i=1}^n (x_i - \\bar x)^2} \\] 设t统计量的值为\\(c\\)， 检验p值为\\(P(|t(n-2)| &gt; |c|)\\)。 32.2.4 R程序 设数据保存在数据框d中，变量名为y和x，用R的lm()函数计算回归，如: set.seed(1) nsamp &lt;- 30 x &lt;- runif(nsamp, -10, 10) y &lt;- 20 + 0.5*x + rnorm(nsamp,0,0.5) d &lt;- data.frame(x=x, y=y) lm1 &lt;- lm(y ~ x, data=d); lm1 ## ## Call: ## lm(formula = y ~ x, data = d) ## ## Coefficients: ## (Intercept) x ## 20.0388 0.4988 结果只有回归系数。需要用summary()显示较详细的结果。如 summary(lm1) ## ## Call: ## lm(formula = y ~ x, data = d) ## ## Residuals: ## Min 1Q Median 3Q Max ## -1.03030 -0.16436 -0.05741 0.29511 0.64046 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 20.03883 0.07226 277.3 &lt;2e-16 *** ## x 0.49876 0.01244 40.1 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.3956 on 28 degrees of freedom ## Multiple R-squared: 0.9829, Adjusted R-squared: 0.9823 ## F-statistic: 1608 on 1 and 28 DF, p-value: &lt; 2.2e-16 结果中\\(H_0: b=0\\)的检验结果p值为\\(&lt;2e-16\\)。 又如对d.class数据集，建立体重对身高的回归方程: lm2 &lt;- lm(weight ~ height, data=d.class) summary(lm2) ## ## Call: ## lm(formula = weight ~ height, data = d.class) ## ## Residuals: ## Min 1Q Median 3Q Max ## -17.6807 -6.0642 0.5115 9.2846 18.3698 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -143.0269 32.2746 -4.432 0.000366 *** ## height 3.8990 0.5161 7.555 7.89e-07 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 11.23 on 17 degrees of freedom ## Multiple R-squared: 0.7705, Adjusted R-squared: 0.757 ## F-statistic: 57.08 on 1 and 17 DF, p-value: 7.887e-07 身高对体重的影响是显著的(p值7.89e-7)。 32.2.5 回归诊断 除了系数的显著性检验以外， 对误差项是否符合回归模型假定中的独立性、方差齐性、正态性等， 可以利用回归残差进行一系列的回归诊断。 还可以计算一些异常值、强影响点的诊断。 对\\(n\\)组观测值，回归模型为 \\[ y_i = a + b x_i + \\varepsilon_i \\] 拟合值为 \\[ \\hat y_i = \\hat a + \\hat b x_i \\] 残差（residual）为 \\[e_i = y_i - \\hat y_i\\] 残差相当于模型中的随机误差， 但仅在模型假定成立时才是随机误差的合理估计。 所以残差能够反映违反模型假定的情况。 \\(e_i\\)有量纲，不好比较大小。 定义标准化残差（内部学生化残差）： \\[ r_i = \\frac{e_i}{S_e\\sqrt{1 - \\frac{1}{n} - \\frac{(x_i - \\bar x)^2}{\\sum_{k=1}^n (x_k - \\bar x)^2}}} \\] 样本量较大时标准化残差近似服从标准正态分布， 于是取值于\\([-2,2]\\)范围外的点是可疑的离群点。 R中用residuals()从回归结果计算残差， 用rstandard()从回归结果计算标准化残差。 R中plot(lmres)(lmres为回归结果变量)可以做简单回归诊断。 plot(lm2) 第一个图是残差对预测值散点图， 散点应该随机在0线上下波动，不应该有曲线模式、分散程度增大模式、 特别突出的离群点等情况。 第二个图是残差的正态QQ图， 散点接近于直线时可以认为模型误差项的正态分布假定是合理的。 第三个图是误差大小(标准化残差绝对值的平方根)对拟合值的图形， 可以判断方差齐性假设(方差\\(\\sigma^2\\)不变)。 第四个图是残差对杠杆量图，并叠加了Cook距离等值线。 杠杆量代表了回归自变量对结果的影响大小， 超过\\(4/n\\)的值是需要重视的。 Cook距离考察删去第\\(i\\)个观测对回归结果的影响。 cbind(residuals(lm2), rstandard(lm2)) ## [,1] [,2] ## 1 6.7317083 0.64090788 ## 2 -13.5797581 -1.25514370 ## 3 -17.6807278 -1.62510342 ## 4 0.5115143 0.04884012 ## 5 -5.6350916 -0.51945382 ## 6 -4.2585944 -0.39749776 ## 7 -6.4933343 -0.69635607 ## 8 11.8375266 1.08337723 ## 9 0.6678176 0.06113186 ## 10 -13.5061701 -1.30222590 ## 11 -2.0615036 -0.18894975 ## 12 14.7918904 1.38780152 ## 13 2.6124840 0.24615612 ## 14 -16.6624734 -1.52495912 ## 15 12.4841326 1.15698074 ## 16 12.2967391 1.26478834 ## 17 18.3697570 1.69265472 ## 18 3.8326780 0.36028625 ## 19 -4.2585944 -0.39749776 可以用\\(e_i\\)或\\(r_i\\)作为纵坐标， \\(x_i\\)或者\\(\\hat y_i\\)作为横坐标， 作残差图。 下面给出残差图的几种常见的缺陷： 非线性: set.seed(1) x &lt;- runif(30, 0, 10) xx &lt;- seq(0, 10, length.out = 100) y &lt;- 40 - (x-7)^2 + rnorm(30) yy &lt;- 40 - (xx-7)^2 lms1 &lt;- lm(y ~ x) opar &lt;- par(mfrow=c(1,2)) plot(x, y, pch=16, main=&quot;数据和真实模型&quot;) lines(xx, yy) plot(x, rstandard(lms1), main=&quot;使用线性回归的残差&quot;) 图32.10: 残差中非线性模式 par(opar) 异方差: x &lt;- sort(runif(30, 0, 10)) y &lt;- 10 + 2*x + rnorm(30)*(seq(30)/10) lms2 &lt;- lm(y ~ x) opar &lt;- par(mfrow=c(1,2)) plot(x, y, pch=16, main=&quot;数据和真实模型&quot;) abline(a=10, b=2) plot(x, rstandard(lms2), main=&quot;线性模型的残差&quot;) par(opar) 序列自相关： 当数据随时间变化时，还需要考虑前后是否有序列自相关。 自相关残差图形例子： ar1 &lt;- arima.sim(list(ar=c(0.5)), n=30) plot(1:30, ar1[], type=&quot;l&quot;, xlab=&quot;time&quot;, ylab=&quot;residual&quot;, main=&quot;有序列自相关的残差图形&quot;) 图中横坐标是观测序号。 car::ncvTest()检验方差齐性。零假设是方差齐性成立。 如 car::ncvTest(lm2) ## Non-constant Variance Score Test ## Variance formula: ~ fitted.values ## Chisquare = 1.664307, Df = 1, p = 0.19702 用Durbin-Watson检验（DW检验）可以检验残差中是否有序列自相关， 零假设是没有序列自相关。 R中用car::durbinWatsonTest()检验。 序列自相关检验仅当数据中数据是延时间等间隔记录时有意义。 如 car::durbinWatsonTest(lm1) ## lag Autocorrelation D-W Statistic p-value ## 1 0.1959139 1.57293 0.21 ## Alternative hypothesis: rho != 0 也可以对回归残差绘制ACF图， 如果除了横坐标0之外都落在两条水平界限内则认为没有序列自相关， 如果有明显超出界限的就认为有序列自相关。 如 acf(residuals(lm1), lag.max = 10, main=&quot;&quot;) 32.2.6 预测区间 设\\(X\\)取\\(x_0\\)，\\(Y\\)的预测值为\\(\\hat y_0 = \\hat a + \\hat b x_0\\)。 置信水平为\\(1-\\alpha\\)的预测区间为 \\[\\hat y_0 \\pm \\lambda \\hat\\sigma \\sqrt{1 + \\frac{1}{n} + \\frac{(\\bar x - x_0)^2}{\\sum_i (x_i - \\bar x)^2}} \\] 其含义是\\(P(y_0 \\in \\text{预测区间}) = 1 - \\alpha\\)。 \\(\\lambda\\)是标准正态分布双侧\\(\\alpha\\)分位数qnorm(1 - alpha/2)。 用predict(lmres)得到\\(\\hat y_i, i=1,\\dots,n\\)的值， lmres表示回归结果变量。 用predict(lmres, interval=\"prediction\") 同时得到预测的置信区间， 需要的话加入level=选项设定置信度。 回归的置信区间有两种， 上述的区间是“预测区间”(CLI)， 使得\\(P(y_0 \\in \\text{预测区间}) = 1 - \\alpha\\); 另一种区间称为均值的置信区间(CLM)， 使得\\(P(Ey_0 \\in \\text{均值置信区间}) = 1 - \\alpha\\)。 32.2.7 控制 如果需要把\\(Y\\)的值控制在\\([y_l, y_u]\\)范围内，问如何控制\\(X\\)的范围， 可以求解\\(x_0\\)的范围使上面的置信区间包含在\\([y_l, y_u]\\)内。 近似地可以解不等式 \\[\\begin{aligned} \\hat a + \\hat b x_0 - z_{1-\\frac{\\alpha}{2}} \\hat \\sigma \\geq &amp; y_l \\\\ \\hat a + \\hat b x_0 + z_{1-\\frac{\\alpha}{2}} \\hat \\sigma \\leq &amp; y_u \\end{aligned}\\] 其中\\(z_{1-\\frac{\\alpha}{2}}\\)为标准正态分布双侧\\(\\alpha\\)分位数 （用qnorm(1-alpha/2)计算）。 32.3 多元线性回归 建模步骤： 确定要研究的因变量，以及可能对因变量有影响并且数据可以获得的自变量集合 假定因变量\\(y\\)与\\(p\\)个自变量之间为线性相关关系，建立模型 对模型进行评估和检验 判断模型中是否存在多重共线性，如果存在，应进行处理 预测 残差分析 32.3.1 模型 模型 \\[ y = \\beta_0 + \\beta_1 x_1 + \\dots + \\beta_p x_p + \\varepsilon \\] 其中 \\(y\\): 因变量，随机变量 \\(x_1, \\dots, x_p\\): 自变量，非随机 \\(\\varepsilon\\): 随机误差项，随机变量 \\(\\beta_0\\): 截距项 \\(\\beta_j\\): 对应于\\(x_j\\)的斜率项 模型表明因变量\\(y\\)近似等于自变量的线性组合 \\(E \\varepsilon=0\\), \\(\\text{Var}(\\varepsilon)=\\sigma^2\\) 对\\(n\\)组观测数据， 有 \\[ y_i = \\beta_0 + \\beta_1 x_{i1} + \\dots + \\beta_p x_{ip} + \\varepsilon_i, \\quad i=1,2,\\dots, n \\] 对其中的随机误差项\\(\\varepsilon_i\\), \\(i=1,2,\\dots,n\\)，假定： 期望为零，服从正态分布； 方差齐性: 方差为\\(\\sigma^2\\)与自变量值无关； 相互独立。 总之，\\(\\varepsilon_1, \\varepsilon_2, \\dots, \\varepsilon_n\\) 相互独立，服从\\(\\text{N}(0, \\sigma^2)\\)分布。 数据格式如： \\[ \\left(\\begin{array}{cccc|c} x_1 &amp; x_2 &amp; \\cdots &amp; x_p &amp; y\\\\ \\hline x_{11} &amp; x_{12} &amp; \\cdots &amp; x_{1p} &amp; y_1 \\\\ x_{21} &amp; x_{22} &amp; \\cdots &amp; x_{2p} &amp; y_2 \\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots &amp; \\vdots \\\\ x_{n1} &amp; x_{n2} &amp; \\cdots &amp; x_{np} &amp; y_n \\end{array}\\right) \\] R中回归数据放在一个数据框中，有一列\\(y\\)和\\(p\\)列自变量。 根据模型有 \\[ Ey = \\beta_0 + \\beta_1 x_1 + \\dots + \\beta_p x_p \\] 32.3.2 参数估计 未知的参数有回归系数\\(\\beta_0, \\beta_1, \\dots, \\beta_p, \\sigma^2\\)， 另外误差项也是未知的。 模型估计仍使用最小二乘法，得到系数估计 \\(\\hat\\beta_0, \\hat\\beta_1, \\dots, \\hat\\beta_p\\) 及误差方差估计\\(\\hat\\sigma^2\\)。 得到估计的多元线性回归方程： \\[ \\hat y = \\hat\\beta_0 + \\hat\\beta_1 x_1 + \\dots + \\hat\\beta_p x_p \\] 对第\\(i\\)组观测值，将自变量值代入估计的回归方程中得拟合值 \\[ \\hat y_i = \\hat\\beta_0 + \\hat\\beta_1 x_{i1} + \\dots + \\hat\\beta_p x_{ip} \\] \\(e_i = y_i - \\hat y_i\\)称为残差。 回归参数估计，用残差最小作为目标，令 \\[ Q = \\sum_{i=1}^n \\left[ y_i - (\\beta_0 + \\beta_1 x_{i1} + \\dots + \\beta_p x_{ip}) \\right]^2 \\] 取使得\\(Q\\)达到最小的\\((\\beta_0, \\beta_1, \\dots, \\beta_p)\\)作为参数估计， 称为最小二乘估计，记为\\((\\hat\\beta_0, \\hat\\beta_1, \\dots, \\hat\\beta_p)\\)。 称得到的最小值为SSE，\\(\\sigma^2\\)的估计为 \\[ \\hat\\sigma^2 = \\frac{1}{n-p-1} \\text{SSE} = \\frac{1}{n-p-1} \\sum_{i=1}^n e_i^2 \\] 32.3.3 R的多元回归程序 在R中用lm(y ~ x1 + x2 + x3, data=d)这样的程序来做多元回归， 数据集为d， 自变量为x1,x2,x3三列。 32.3.3.1 例：体重对身高和年龄的回归 考虑d.class数据集中体重对身高和年龄的回归: lm3 &lt;- lm(weight ~ height + age, data=d.class) summary(lm3) ## ## Call: ## lm(formula = weight ~ height + age, data = d.class) ## ## Residuals: ## Min 1Q Median 3Q Max ## -17.962 -6.010 -0.067 7.553 20.796 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -141.2238 33.3831 -4.230 0.000637 *** ## height 3.5970 0.9055 3.973 0.001093 ** ## age 1.2784 3.1101 0.411 0.686492 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 11.51 on 16 degrees of freedom ## Multiple R-squared: 0.7729, Adjusted R-squared: 0.7445 ## F-statistic: 27.23 on 2 and 16 DF, p-value: 7.074e-06 得到的回归模型可以写成 \\[ \\widehat{\\text{weight}} = -141.2 + 3.597 \\times \\text{height} + 1.278 \\times \\text{age} \\] 其中身高的系数3.597表示， 如果两个学生年龄相同， 则身高增加1个单位（这里是英寸）， 体重平均增加3.597个单位（这里是磅）。 注意在仅有身高作为自变量时， 系数为3.899。 年龄的系数1.278也类似解释， 在两个学生身高相同时， 如果一个学生年龄大1岁， 则此学生的体重平均多1.278个单位。 32.3.3.2 例：驾驶员行驶时间的模型 Butler Trucking Company是一个短途货运公司。 老板想研究每个驾驶员每天的行驶时间的影响因素。 随机抽取了10名驾驶员一天的数据。考虑行驶里程(Miles)对行驶时间的影响。 with(Butler, plot(Miles, Time)) 从散点图看，行驶里程与行驶时间有线性相关关系。 作一元线性回归： lmbut01 &lt;- lm(Time ~ Miles, data=Butler) summary(lmbut01) ## ## Call: ## lm(formula = Time ~ Miles, data = Butler) ## ## Residuals: ## Min 1Q Median 3Q Max ## -1.5565 -0.4913 0.1783 0.7120 1.2435 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 1.27391 1.40074 0.909 0.38969 ## Miles 0.06783 0.01706 3.977 0.00408 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 1.002 on 8 degrees of freedom ## Multiple R-squared: 0.6641, Adjusted R-squared: 0.6221 ## F-statistic: 15.81 on 1 and 8 DF, p-value: 0.00408 这里Miles的系数解释为：行驶里程增加1英里，时间平均增加0.068小时。 老板想进一步改进对行驶时间的预测， 增加“派送地点数”（Deliveries）作为第二个自变量。 作多元回归： lmbut02 &lt;- lm(Time ~ Miles + Deliveries, data=Butler) summary(lmbut02) ## ## Call: ## lm(formula = Time ~ Miles + Deliveries, data = Butler) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.79875 -0.32477 0.06333 0.29739 0.91333 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -0.868701 0.951548 -0.913 0.391634 ## Miles 0.061135 0.009888 6.182 0.000453 *** ## Deliveries 0.923425 0.221113 4.176 0.004157 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.5731 on 7 degrees of freedom ## Multiple R-squared: 0.9038, Adjusted R-squared: 0.8763 ## F-statistic: 32.88 on 2 and 7 DF, p-value: 0.0002762 这里Miles的系数从一元回归时的0.068改成了0.061， 解释为：在派送地点数相同的条件下，行驶里程每增加1英里， 行驶时间平均增加0.061小时。 Deliveries的系数解释为：在行驶里程相同的条件下， 派送地点数每增加一个地点，行驶时间平均增加0.92小时。 32.3.4 模型的检验 32.3.4.1 复相关系数平方 将总平方和分解为： \\[ \\text{SST} = \\text{SSR} + \\text{SSE} \\] 其中 - 总平方和 \\[\\text{SST} = \\sum_{i=1}^n (y_i - \\bar y)^2\\] - 回归平方和 \\[\\text{SSR} = \\sum_{i=1}^n (\\hat y_i - \\bar y)^2\\] 是能够用回归系数和自变量的变量解释的因变量变化。 - 残差平方和 \\[\\text{SSE} = \\sum_{i=1}^n (y_i - \\hat y_i)^2\\] 是回归模型不能解释的因变量变化。 回归平方和越大，残差平方和越小，回归拟合越好。 定义复相关系数平方（判定系数） \\[ R^2 = \\frac{\\text{SSR}}{\\text{SST}} = 1 - \\frac{\\text{SSE}}{\\text{SST}} \\] 则\\(0 \\leq R^2 \\leq 1\\)。 \\(R^2\\)越大，说明数据中的自变量拟合因变量值拟合越好。 但是，“拟合好”不是唯一标准。 仅考虑拟合好， 可能产生很复杂的仅对建模用数据有效但是对其它数据无效的模型， 这称为“过度拟合”。 定义调整的（修正的）复相关系数平方： \\[ R^{*2} = 1 - (1-R^2)\\frac{n-1}{n-p-1} \\] 克服了\\(R^2\\)的部分缺点。 在体重与身高、年龄的模型结果中， \\(R^2=0.7729\\)， \\(R^{*2}=0.7445\\)。 32.3.4.2 残差标准误差 模型中\\(\\varepsilon\\)的方差\\(\\sigma^2\\)的估计为\\(\\hat\\sigma_e^2\\), \\[ \\hat\\sigma^2 = \\frac{1}{n-p-1}\\text{SSE} \\] \\(\\hat\\sigma\\)是随机误差的标准差\\(\\sigma\\)的估计量， 称为“残差标准误差”（Residual standard error）。 这是残差\\(e_i = y_i - \\hat y_i\\)的标准差的一个较粗略的近似估计。 在体重与身高、年龄的模型结果中， \\(\\hat\\sigma=11.51\\)。 32.3.4.3 线性关系检验 为了检验整个回归模型是否都无效，考虑假设检验: \\[ H_0: \\beta_1 = \\dots = \\beta_p = 0 \\] 当\\(H_0\\)成立时模型退化成\\(y=\\beta_0 + \\varepsilon\\)， \\(y\\)与\\(x_1, x_2, \\dots, x_p\\)之间不再具有线性相关关系。 取统计量为 \\[ F = \\frac{\\text{SSR}/p}{\\text{SSE}/(n-p-1)} \\] 在模型前提条件都满足且\\(H_0\\)成立时\\(F\\)服从\\(F(p, n-p-1)\\)分布。 计算右侧\\(p\\)值，给出检验结论。 当检验显著时，各斜率项不全为零。 结果不显著时，当前回归模型不能使用。 在体重与身高、年龄的模型结果中， \\(F=27.23\\)，p值为\\(7.074\\times 10^{-6}\\)， 在0.05水平下显著， 模型有意义。 32.3.4.4 单个斜率项的显著性检验 为了检验某一个自变量\\(X_j\\)是否对因变量的解释有贡献 （在模型中已经包含了其它自变量的情况下），检验 \\[H_0: \\beta_j = 0\\] 如果不拒绝\\(H_0\\)， 相当于\\(x_j\\)可以不出现在模型中。 但是， 在多元线性回归中这不代表\\(x_j\\)与\\(y\\)之间没有线性相关， 可能是由于其它的自变量包含了\\(x_j\\)中的信息。 检验使用如下\\(t\\)统计量 \\[ t = \\frac{\\hat\\beta_j}{\\text{SE}_{\\hat\\beta_j}} \\] 在模型前提条件都满足且\\(H_0\\)成立时\\(t\\)服从\\(t(n-p-1)\\)分布。 给定检验水平\\(\\alpha\\)，计算双侧\\(p\\)值，做出检验结论。 对单个回归系数的检验，检验水平可取得略高，如0.10, 0.15。 在体重与身高、年龄的模型结果中， 身高的斜率项显著性p值为0.001, 在0.15水平下显著； 体重的斜率项显著性p值为0.686， 在0.15水平下不显著， 可考虑从模型中去掉体重变量。 32.3.5 回归自变量筛选 在19个学生的体重与身高、年龄的线性回归模型结果中， 发现关于年龄的系数为零的检验p值为0.686, 不显著， 说明在模型中已经包含身高的情况下， 年龄不提供对体重的额外信息。 但是如果体重对年龄单独建模的话，年龄的影响还是显著的： lm4 &lt;- lm(weight ~ age, data=d.class) summary(lm4) ## ## Call: ## lm(formula = weight ~ age, data = d.class) ## ## Residuals: ## Min 1Q Median 3Q Max ## -23.349 -7.609 -5.260 7.945 42.847 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -50.493 33.290 -1.517 0.147706 ## age 11.304 2.485 4.548 0.000285 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 15.74 on 17 degrees of freedom ## Multiple R-squared: 0.5489, Adjusted R-squared: 0.5224 ## F-statistic: 20.69 on 1 and 17 DF, p-value: 0.0002848 模型中不显著的自变量应该逐一剔除。可以用 step函数进行逐步回归变量选择，如: lm5 &lt;- step(lm(weight ~ height + age + sex, data=d.class)) ## Start: AIC=94.93 ## weight ~ height + age + sex ## ## Df Sum of Sq RSS AIC ## - age 1 113.76 1957.8 94.067 ## &lt;none&gt; 1844.0 94.930 ## - sex 1 276.09 2120.1 95.581 ## - height 1 1020.61 2864.6 101.299 ## ## Step: AIC=94.07 ## weight ~ height + sex ## ## Df Sum of Sq RSS AIC ## - sex 1 184.7 2142.5 93.780 ## &lt;none&gt; 1957.8 94.067 ## - height 1 5696.8 7654.6 117.974 ## ## Step: AIC=93.78 ## weight ~ height ## ## Df Sum of Sq RSS AIC ## &lt;none&gt; 2142.5 93.78 ## - height 1 7193.2 9335.7 119.75 summary(lm5) ## ## Call: ## lm(formula = weight ~ height, data = d.class) ## ## Residuals: ## Min 1Q Median 3Q Max ## -17.6807 -6.0642 0.5115 9.2846 18.3698 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -143.0269 32.2746 -4.432 0.000366 *** ## height 3.8990 0.5161 7.555 7.89e-07 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 11.23 on 17 degrees of freedom ## Multiple R-squared: 0.7705, Adjusted R-squared: 0.757 ## F-statistic: 57.08 on 1 and 17 DF, p-value: 7.887e-07 考虑另一个例子数据。 在数据框Resturant中包含25个餐馆的一些信息，包括： \\(y\\), 营业额, 日均营业额（万元） \\(x_1\\), 居民数, 周边居民人数（万人） \\(x_2\\), 人均餐费, 用餐平均支出(元/人) \\(x_3\\), 月收入, 周边居民月平均收入（元） \\(x_4\\), 餐馆数, 周边餐馆数（个） \\(x_5\\), 距离, 距市中心距离（km） 对营业额进行回归建模研究。 变量间的相关系数图： corrgram::corrgram( Resturant, order=TRUE, lower.panel=corrgram::panel.shade, upper.panel = corrgram::panel.pie, text.panel = corrgram::panel.txt) lmrst01 &lt;- lm(`营业额` ~ `居民数` + `人均餐费` + `月收入` + `餐馆数` + `距离`, data=Resturant) summary(lmrst01) ## ## Call: ## lm(formula = 营业额 ~ 居民数 + 人均餐费 + 月收入 + 餐馆数 + 距离, ## data = Resturant) ## ## Residuals: ## Min 1Q Median 3Q Max ## -16.7204 -6.0600 0.7152 3.2144 21.4805 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 4.2604768 10.4679833 0.407 0.68856 ## 居民数 0.1273254 0.0959790 1.327 0.20037 ## 人均餐费 0.1605660 0.0556834 2.884 0.00952 ** ## 月收入 0.0007636 0.0013556 0.563 0.57982 ## 餐馆数 -0.3331990 0.3986248 -0.836 0.41362 ## 距离 -0.5746462 0.3087506 -1.861 0.07826 . ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 10.65 on 19 degrees of freedom ## Multiple R-squared: 0.8518, Adjusted R-squared: 0.8128 ## F-statistic: 21.84 on 5 and 19 DF, p-value: 2.835e-07 在0.15水平上只有人均餐费和到市中心距离是显著的。 进行逐步回归筛选： lmrst02 &lt;- step(lmrst01) ## Start: AIC=123.39 ## 营业额 ~ 居民数 + 人均餐费 + 月收入 + 餐馆数 + 距离 ## ## Df Sum of Sq RSS AIC ## - 月收入 1 35.96 2189.0 121.81 ## - 餐馆数 1 79.17 2232.2 122.30 ## &lt;none&gt; 2153.0 123.39 ## - 居民数 1 199.42 2352.4 123.61 ## - 距离 1 392.54 2545.6 125.58 ## - 人均餐费 1 942.22 3095.2 130.47 ## ## Step: AIC=121.81 ## 营业额 ~ 居民数 + 人均餐费 + 餐馆数 + 距离 ## ## Df Sum of Sq RSS AIC ## - 餐馆数 1 78.22 2267.2 120.69 ## &lt;none&gt; 2189.0 121.81 ## - 距离 1 445.69 2634.7 124.44 ## - 人均餐费 1 925.88 3114.9 128.63 ## - 居民数 1 1133.27 3322.3 130.24 ## ## Step: AIC=120.69 ## 营业额 ~ 居民数 + 人均餐费 + 距离 ## ## Df Sum of Sq RSS AIC ## &lt;none&gt; 2267.2 120.69 ## - 距离 1 404.28 2671.5 122.79 ## - 人均餐费 1 1050.90 3318.1 128.21 ## - 居民数 1 1661.83 3929.0 132.43 summary(lmrst02) ## ## Call: ## lm(formula = 营业额 ~ 居民数 + 人均餐费 + 距离, data = Resturant) ## ## Residuals: ## Min 1Q Median 3Q Max ## -14.027 -5.361 -1.560 2.304 23.001 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -1.68928 6.25242 -0.270 0.78966 ## 居民数 0.19022 0.04848 3.923 0.00078 *** ## 人均餐费 0.15763 0.05052 3.120 0.00518 ** ## 距离 -0.56979 0.29445 -1.935 0.06656 . ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 10.39 on 21 degrees of freedom ## Multiple R-squared: 0.8439, Adjusted R-squared: 0.8216 ## F-statistic: 37.85 on 3 and 21 DF, p-value: 1.187e-08 最后进保留了周边居民人数、人均餐费、到市中心距离三个自变量， 删去了周边居民月收入和周边餐馆数两个自变量。 32.3.6 哑变量与变截距项的模型 32.3.6.1 哑变量 回归分析的因变量是连续型的，服从正态分布。 回归分析的自变量是数值型的，可以连续取值也可以离散取值。 但是，如果自变量是类别变量， 用简单的1,2,3编码并不能正确地表现不同类别的作用。 可以将类别变量转换成一个或者多个取0、1值的变量， 称为哑变量（dummy variables）或虚拟变量。 32.3.6.1.1 二值哑变量与平行线模型 如果\\(f\\)是一个二值分类变量，将其中一个类编码为1， 另一个类编码为零。 例如，\\(f=1\\)表示处理组，\\(f=0\\)表示对照组。 这样编码后二值分类变量可以直接用在回归模型中。 例如 \\[ Ey = \\beta_0 + \\beta_1 x + \\beta_2 f \\] 相当于 \\[\\begin{aligned} Ey = \\begin{cases} \\beta_0 + \\beta_1 x, &amp; \\text{对照组} \\\\ (\\beta_0 + \\beta_2) + \\beta_1 x, &amp; \\text{处理组} \\end{cases} \\end{aligned}\\] 这样的模型叫做平行线模型， 处理组的数据与对照组的数据服从斜率相同、截距不同的一元线性回归模型。 比每个组单独建模更有效。 如果检验： \\[H_0: \\beta_2 = 0\\] 则不显著时， 可以认为在处理组和对照组中\\(y\\)与\\(x\\)的关系没有显著差异。 进一步考虑 \\[ Ey = \\beta_0 + \\beta_1 x + \\beta_2 f + \\beta_3 f x \\] 相当于 \\[\\begin{aligned} Ey = \\begin{cases} \\beta_0 + \\beta_1 x, &amp; \\text{对照组} \\\\ (\\beta_0 + \\beta_2) + (\\beta_1 + \\beta_3) x, &amp; \\text{处理组} \\end{cases} \\end{aligned}\\] 比每个组单独建立回归模型更有效。 可以检验 \\[H_0: \\beta_3=0\\] 不显著时可以用平行线模型。 比如，为了表示男生和女生的体重有不同， 可以在以体重为因变量的回归中加入自变量性别: lm6 &lt;- lm(weight ~ height + sex, data=d.class) summary(lm6) ## ## Call: ## lm(formula = weight ~ height + sex, data = d.class) ## ## Residuals: ## Min 1Q Median 3Q Max ## -19.7627 -5.9583 -0.3682 8.7725 15.7758 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -126.1687 34.6352 -3.643 0.00219 ** ## height 3.6789 0.5392 6.823 4.09e-06 *** ## sexF -6.6208 5.3887 -1.229 0.23697 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 11.06 on 16 degrees of freedom ## Multiple R-squared: 0.7903, Adjusted R-squared: 0.7641 ## F-statistic: 30.15 on 2 and 16 DF, p-value: 3.74e-06 结果中的sexM项表示以女生为基数，男生体重的平均增加量。 这一项不显著。 有些例子中如果忽略了分类变量， 结论可能是错误的。 例如， 考察iris数据中花萼长宽之间的关系。 数据中有三个品种的花， 仅考虑其中的setosa和versicolor两个品种。 d &lt;- iris[iris[[&quot;Species&quot;]] %in% c(&quot;setosa&quot;, &quot;versicolor&quot;), c(&quot;Sepal.Length&quot;, &quot;Sepal.Width&quot;, &quot;Species&quot;)] d$Species &lt;- factor(as.character(d$Species)) lm7 &lt;- lm(Sepal.Width ~ Sepal.Length, data=d) with(d, plot(Sepal.Length, Sepal.Width, col=(2:3)[Species])) with(d, legend(&quot;topleft&quot;, pch=1, col=2:3, legend=levels(Species))) abline(lm7, lwd=2) summary(lm7) ## ## Call: ## lm(formula = Sepal.Width ~ Sepal.Length, data = d) ## ## Residuals: ## Min 1Q Median 3Q Max ## -1.17136 -0.26382 -0.04468 0.29966 1.33618 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 3.93951 0.40621 9.698 5.47e-16 *** ## Sepal.Length -0.15363 0.07375 -2.083 0.0398 * ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.4709 on 98 degrees of freedom ## Multiple R-squared: 0.04241, Adjusted R-squared: 0.03263 ## F-statistic: 4.34 on 1 and 98 DF, p-value: 0.03984 回归结果花萼长、宽是负相关的， 这明显不合理，出现了“悖论”。 实际是因为两个品种的样本混杂在一起了。 加入Species分类变量作为回归自变量： lm8 &lt;- lm(Sepal.Width ~ Species + Sepal.Length, data=d) summary(lm8) ## ## Call: ## lm(formula = Sepal.Width ~ Species + Sepal.Length, data = d) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.88917 -0.14677 -0.02517 0.16643 0.64444 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 1.06519 0.32272 3.301 0.00135 ** ## Speciesversicolor -1.09696 0.08170 -13.427 &lt; 2e-16 *** ## Sepal.Length 0.47200 0.06398 7.377 5.51e-11 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.2799 on 97 degrees of freedom ## Multiple R-squared: 0.665, Adjusted R-squared: 0.6581 ## F-statistic: 96.28 on 2 and 97 DF, p-value: &lt; 2.2e-16 现在花萼长度变量的系数为正而且高度显著。 两个品种区别的变量Speciesversicolor表示versicolor品种取1， setosa取0的哑变量。 versicolor品种的花萼宽度与setosa相比在长度相等的情况下平均较小。 作两条回归直线的图形： with(d, plot(Sepal.Length, Sepal.Width, col=(2:3)[Species])) with(d, legend(&quot;topleft&quot;, pch=1, col=2:3, legend=levels(Species)[1:2])) abline(a=coef(lm8)[1], b=coef(lm8)[3], col=2, lwd=2) abline(a=sum(coef(lm8)[1:2]), b=coef(lm8)[3], col=3, lwd=2) 32.3.6.1.2 多值哑变量 如果变量\\(f\\)是一个有\\(k\\)分类的变量， 可以将\\(f\\)变成\\(k-1\\)个取0、1值的哑变量 \\(z_1, z_2, \\dots, z_{k-1}\\)。 例如，\\(f\\)取三种不同的类别，可以转换为两个哑变量\\(z_1, z_2\\), 常用的编码方式为： \\[\\begin{aligned} &amp; f=1 \\Leftrightarrow (z_1, z_2)=(0,0), \\\\ &amp; f=2 \\Leftrightarrow (z_1, z_2)=(1,0), \\\\ &amp; f=3 \\Leftrightarrow (z_1, z_2)=(0,1) \\end{aligned}\\] 这是将\\(f=1\\)看成对照组。 在R中， 用model.matrix(y ~ x1 + f, data=d) 可以生成将因子f转换成哑变量后的包含因变量和自变量的矩阵。 32.3.7 残差诊断 先复习一些回归理论。 将模型写成矩阵形式 \\[ {\\boldsymbol Y} = {\\boldsymbol X}\\boldsymbol\\beta + \\boldsymbol\\varepsilon \\] \\({\\boldsymbol Y}\\)为\\(n \\times 1\\)向量, \\({\\boldsymbol X}\\)为\\(n \\times p\\)矩阵, 一般第一列元素全是1, 代表截距项。 \\(\\boldsymbol\\beta\\)为\\(p \\times 1\\)未知参数向量; \\(\\boldsymbol\\varepsilon\\)为\\(n \\times 1\\)随机误差向量, \\(\\varepsilon\\)的元素独立且方差为相等的\\(\\sigma^2\\)(未知)。 假设矩阵\\(\\boldsymbol X\\)满秩，系数的估计为 \\[\\begin{aligned} \\hat{\\boldsymbol\\beta} = \\left( {{\\boldsymbol X^T \\boldsymbol X}} \\right)^{-1} {\\boldsymbol X^T \\boldsymbol Y} \\end{aligned}\\] 拟合值(或称预报值)向量为 \\[\\begin{aligned} \\hat{\\boldsymbol Y} = {\\boldsymbol X} \\left( {{\\boldsymbol X \\boldsymbol X}} \\right)^{-1} {\\boldsymbol X^T \\boldsymbol Y} = {\\boldsymbol H \\boldsymbol Y} \\end{aligned}\\] 其中\\({\\boldsymbol H} = {\\boldsymbol X}\\left( {{\\boldsymbol X&#39;X}} \\right)^{-1} {\\boldsymbol X&#39;}\\) 是\\(R^n\\)空间的向量向\\({\\boldsymbol X}\\) 的列张成的线性空间\\(\\mu({\\boldsymbol X})\\) 投影的投影算子矩阵, 叫做帽子矩阵。 设\\(\\boldsymbol H = \\left( h_{ij} \\right)_{n\\times n}\\)。 拟合残差向量为 \\[\\begin{aligned} \\boldsymbol e = {\\boldsymbol Y} - \\hat{\\boldsymbol Y} = ({\\boldsymbol I} - {\\boldsymbol H}){\\boldsymbol Y} \\end{aligned}\\] 残差平方和为 \\[\\begin{aligned} \\mbox{ESS} = \\boldsymbol e^T \\boldsymbol e = \\sum\\limits_{i = 1}^n {\\left( {Y_i - \\hat Y_i } \\right)^2 } \\end{aligned}\\] 误差项方差的估计 (要求设计阵\\({\\boldsymbol X}\\)满秩)为均方误差(MSE) \\[\\begin{aligned} \\hat\\sigma^2 = \\mbox{MSE} = \\frac{1}{{n - p}} \\mbox{ESS} \\end{aligned}\\] （其中\\(p\\)在有截距项时是自变量个数加1） 在线性模型的假设下, 若设计阵\\({\\boldsymbol X}\\)满秩, \\(\\hat\\beta\\)和\\(\\hat\\sigma^2\\) 分别是\\(\\beta\\)和\\(\\sigma^2\\)的无偏估计。 系数估计的方差阵 \\[ \\text{Var}(\\hat{\\boldsymbol\\beta}) = \\sigma^2 \\left( {\\boldsymbol X}&#39; {\\boldsymbol X} \\right)^{-1} \\] 回归残差及其方差为 \\[\\begin{aligned} e_i =&amp; y_i - \\hat y_i, \\quad i=1,2,\\dots,n \\\\ \\text{Var}(e_i) =&amp; \\sigma^2 (1 - h_{ii}) \\quad(h_{ii}\\text{是}H\\text{的主对角线元素}) \\end{aligned}\\] 若lmres是R中lm()的回归结果， 用residuals(lmres)可以求残差。 把\\(e_i\\)除以其标准差估计， 称为标准化残差，或内部学生化残差： \\[\\begin{aligned} r_i = \\frac{e_i}{s \\sqrt{1 - h_{ii}}}, \\quad i=1,2,\\dots,n \\end{aligned}\\] \\(r_i\\)渐近服从正态分布。 若lmres是R中lm()的回归结果， 用rstandard(lmres)可以求标准化残差。 如果计算\\(y_i\\)的预测值时， 删除第\\(i\\)个观测后建立回归模型得到\\(\\sigma^2\\) 的估计\\(s_{(i)}^2\\)， 则外部学生化残差为 \\[\\begin{aligned} t_i = \\frac{e_i}{s_{(i)} \\sqrt{1 - h_{ii}}} \\end{aligned}\\] \\(t_i\\)近似服从\\(t(n-p-1)\\)分布 （有截距项时\\(p\\)等于自变量个数加1）。 其中\\(s_{(i)}\\)有简单公式： \\[\\begin{aligned} s_{(i)}^2 = \\frac{n-p-r_i^2}{n-p-1} \\hat\\sigma^2 \\end{aligned}\\] 若lmres是R中lm()的回归结果， 用rstudent(lmres)可以求外部学生化残差。 在R中， 与一元回归的诊断类似。 用plot()作4个残差诊断图。 可以用which=1指定仅作第一幅图。 如餐馆营业额例子的残差诊断： plot(lmrst02, which=1) 上图是残差对拟合值的散点图， 可以查看有无非线性。 有轻微的非线性关系。 plot(lmrst02, which=2) 上图是残差的正态QQ图， 查看残差是否正态分布。 残差分布略有右偏，不算太严重。 plot(lmrst02, which=3) 上图是标准化残差绝对值平方根对拟合值的散点图， 可以查看是否有异方差。 没有明显的异方差。 plot(lmrst02, which=4) 上图用来查看强影响点， 4号观测是一个强影响点。 货运公司例子的多元回归的残差诊断： plot(lmbut02) 有一定的异方差倾向，但是数据量不大就不做处理。 32.3.8 多重共线性 狭义的多重共线性（multicollinearity）： 自变量的数据存在线性组合近似地等于零， 使得矩阵求解回归系数时结果不稳定， 回归结果很差。 广义的多重共线性： 自变量之间存在较强的相关性， 这样自变量是联动的， 互相之间有替代作用。 甚至于斜率项的正负号都因为这种替代作用而可能是错误的方向。 例如， 餐馆营业额例子中， F检验显著， 5个自变量如果用在一元回归中斜率项都显著， 但是在多元回归中， 在0.15水平下仅有人均餐费和到市中心的距离的系数是显著的， 月收入、餐馆数、居民数的系数不显著。 但是实际上，单独使用这三个自变量作一元线性回归， 结果都是显著的： summary(lm(`营业额` ~ `月收入`, data=Resturant)) ## ## Call: ## lm(formula = 营业额 ~ 月收入, data = Resturant) ## ## Residuals: ## Min 1Q Median 3Q Max ## -32.151 -10.725 -0.696 6.033 47.819 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 0.484580 5.955478 0.081 0.936 ## 月收入 0.004995 0.000944 5.291 2.27e-05 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 16.88 on 23 degrees of freedom ## Multiple R-squared: 0.549, Adjusted R-squared: 0.5294 ## F-statistic: 27.99 on 1 and 23 DF, p-value: 2.273e-05 如何识别多重共线性？ 如果两个自变量之间的相关系数显著地不等于零， 这两个自变量就有广义的共线性。 如果线性关系的F检验显著但是单个回归系数都不显著， 可能是由于多重共线性。 如果有单个回归系数显著但是\\(F\\)检验不显著， 可能是由于多重共线性。 如果某些回归系数的正负号与通常的认识相反， 可能是由于多重共线性。 将第\\(i\\)个自变量\\(x_i\\)作为因变量， 用其它的\\(p-1\\)个自变量作为自变量作多元线性回归， 得到一个复相关系数平方\\(R_i^2\\)， 这个\\(R_i^2\\)接近于1时\\(x_i\\)与其他自变量之间存在多重共线性。 令\\(x_i\\)的容忍度（tolerance）等于\\(1-R_i^2\\)， 容忍度接近于0时存在多重共线性。 容忍度小于0.1时多重共线性为严重程度。 称容忍度的倒数为方差膨胀因子（VIF）， VIF大于10或者大于5作为严重的多重共线性。 为了计算VIF, 首先把矩阵\\(X^T X\\)看成一个协方差阵， 把它转换为相关系数阵设为\\(M\\)， 则\\(M^{-1}\\)的各主对角线元素就是各个VIF。 car包的vif()函数计算方差膨胀因子。 如： car::vif(lmrst01) ## 居民数 人均餐费 月收入 餐馆数 距离 ## 8.233159 2.629940 5.184365 1.702361 1.174053 可以认为变量“居民数”和“月收入”有共线问题。 做共线诊断还可以用条件数(Conditional Index): 这是一个正数，用来衡量\\((X^T X)^{-1}\\)的稳定性， 定义为\\(X^T X\\)的最大特征值与最小特征值之比。 条件数在0—100之间时认为无共线性， 在100—1000之间时认为自变量之间有中等或较强共线性， 在1000以上认为自变量之间有强共线性。 解决多重共线性问题， 最简单的方法是回归自变量选择， 剔除掉有严重共线性的自变量， 这些自变量的信息可以由其他变量代替。 还可以对自变量作变换，如用主成分分析降维。 可以用收缩方法如岭回归、lasso回归等。 32.3.9 强影响点分析 强影响点是删去以后严重改变参数估计值的观测。 包括自变量取值离群和因变量拟合离群的点。 杠杆(leverage)指帽子矩阵的对角线元素\\(h_{ii}\\), \\[\\begin{aligned} \\frac{1}{n} \\leq h_{ii} \\leq \\frac{1}{d_i} \\end{aligned}\\] 其中\\(d_i\\)是第\\(i\\)个观测的重复观测次数。 某观测杠杆值高说明该观测自变量有异常值。 杠杆值大于\\(2p/n\\)的观测需要仔细考察 （有截距项时\\(p\\)等于自变量个数加1）。 若lmres是R中lm()的回归结果， 用hatvalues(lmres)可以求杠杆值。 考察外学生化残差\\(t_i\\)， 绝对值超过2的观测拟合误差大， 在\\(y\\)方向离群，需要关注。 若lmres是R中lm()的回归结果， 用rstudent(lmres)可以求外学生化。 Cook距离统计量： \\[\\begin{aligned} D_i = \\frac{1}{p} r_i^2 \\frac{h_{ii}}{1 - h_{ii}} \\end{aligned}\\] 包含了\\(y\\)方向的离群\\(r_i\\)和\\(x\\)方向的离群\\(h_{ii}\\)的信息。 超过\\(\\frac{4}{n}\\)的值需要注意。 若lmres是R中lm()的回归结果， 用cooks.distance(lmres)可以求Cook距离。 R中的强影响点诊断函数还有 dfbetas(), dffits(), covratio()。 偏杠杆值衡量每个自变量(包括截距项)对杠杆的贡献。 把第j个自变量关于其它自变量回归得到残差， 第i个残差的平方占总残差平方和的比例为第j自变量在第i观测处的偏杠杆值。 偏杠杆值影响自变量选择时对该变量的选择。 32.3.10 过度拟合示例 \\(R^2\\)代表了模型对数据的拟合程度， 模型中加入的自变量越多， \\(R^2\\)越大。 是不是模型中的自变量越多越好？ 可能会发生“过度拟合”。 用来建模的数据都拟合误差很小， 但是模型很难有合理解释， 对新的数据的预测效果很差甚至于完全错误。 set.seed(10) n &lt;- 20 x &lt;- sample(1:n, size=n, replace=TRUE) a &lt;- 100 b &lt;- 2 sigma &lt;- 5 y &lt;- a + b*x + rt(n, 4)*sigma xnew &lt;- c(1.5, 2.5, 3.5) ynew &lt;- a + b*xnew + rnorm(length(xnew), 0, sigma) plot(x, y, pch=16, xlim=c(0, n+1), ylim=c(90,140)) points(xnew, ynew, pch=2, col=&quot;red&quot;) legend(&quot;topleft&quot;, pch=c(16,2), col=c(&quot;black&quot;, &quot;red&quot;), legend=c(&quot;拟合用&quot;, &quot;测试用&quot;)) 作线性回归： plot(x, y, pch=16, xlim=c(0, n+1), ylim=c(90,140)) points(xnew, ynew, pch=2, col=&quot;red&quot;) lmof1 &lt;- lm(y ~ x) abline(lmof1) 回归系数： summary(lmof1) ## ## Call: ## lm(formula = y ~ x) ## ## Residuals: ## Min 1Q Median 3Q Max ## -9.8206 -4.0691 -0.2855 3.9371 11.7011 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 97.9570 3.0244 32.388 &lt; 2e-16 *** ## x 2.0521 0.3163 6.489 4.21e-06 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 5.767 on 18 degrees of freedom ## Multiple R-squared: 0.7005, Adjusted R-squared: 0.6839 ## F-statistic: 42.1 on 1 and 18 DF, p-value: 4.209e-06 二次多项式回归： plot(x, y, pch=16, xlim=c(0, n+1), ylim=c(90,140)) points(xnew, ynew, pch=2, col=&quot;red&quot;) lmof2 &lt;- lm(y ~ x + I(x^2)) xx &lt;- seq(1, n, length=100) yy &lt;- predict(lmof2, newdata=data.frame(x=xx)) lines(xx, yy) 回归系数： summary(lmof2) ## ## Call: ## lm(formula = y ~ x + I(x^2)) ## ## Residuals: ## Min 1Q Median 3Q Max ## -11.175 -3.059 -0.439 3.358 9.400 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 102.59339 5.32854 19.254 5.57e-13 *** ## x 0.73688 1.28561 0.573 0.574 ## I(x^2) 0.07371 0.06985 1.055 0.306 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 5.749 on 17 degrees of freedom ## Multiple R-squared: 0.7189, Adjusted R-squared: 0.6859 ## F-statistic: 21.74 on 2 and 17 DF, p-value: 2.066e-05 这个回归结果出现了多重共线性问题。 也已经过度拟合。 三次多项式回归： 回归系数： summary(lmof3) ## ## Call: ## lm(formula = y ~ x + I(x^2) + I(x^3)) ## ## Residuals: ## Min 1Q Median 3Q Max ## -11.1976 -3.0835 -0.3567 3.6324 8.8020 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 105.162401 8.827478 11.913 2.29e-09 *** ## x -0.558534 3.734856 -0.150 0.883 ## I(x^2) 0.240987 0.456853 0.527 0.605 ## I(x^3) -0.006124 0.016518 -0.371 0.716 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 5.901 on 16 degrees of freedom ## Multiple R-squared: 0.7213, Adjusted R-squared: 0.6691 ## F-statistic: 13.8 on 3 and 16 DF, p-value: 0.0001053 这个回归结果出现了多重共线性问题。 也已经过度拟合。 四次多项式回归： 回归系数： summary(lmof4) ## ## Call: ## lm(formula = y ~ x + I(x^2) + I(x^3) + I(x^4)) ## ## Residuals: ## Min 1Q Median 3Q Max ## -9.8975 -3.5647 0.1241 4.7063 7.4675 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 122.380891 18.117315 6.755 6.47e-06 *** ## x -12.830942 11.890980 -1.079 0.298 ## I(x^2) 2.785077 2.385359 1.168 0.261 ## I(x^3) -0.206102 0.184800 -1.115 0.282 ## I(x^4) 0.005273 0.004854 1.086 0.294 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 5.868 on 15 degrees of freedom ## Multiple R-squared: 0.7416, Adjusted R-squared: 0.6727 ## F-statistic: 10.76 on 4 and 15 DF, p-value: 0.0002563 五次多项式回归： 已经明显过度拟合。 回归系数： summary(lmof5) ## ## Call: ## lm(formula = y ~ x + I(x^2) + I(x^3) + I(x^4) + I(x^5)) ## ## Residuals: ## Min 1Q Median 3Q Max ## -9.9204 -3.4541 0.2201 3.7495 8.5922 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 181.846244 41.023546 4.433 0.000568 *** ## x -65.530939 34.875410 -1.879 0.081224 . ## I(x^2) 18.157919 9.886841 1.837 0.087594 . ## I(x^3) -2.170388 1.242055 -1.747 0.102453 ## I(x^4) 0.118729 0.071167 1.668 0.117456 ## I(x^5) -0.002418 0.001513 -1.598 0.132453 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 5.586 on 14 degrees of freedom ## Multiple R-squared: 0.7815, Adjusted R-squared: 0.7034 ## F-statistic: 10.01 on 5 and 14 DF, p-value: 0.0003082 六次多项式回归： 回归系数： summary(lmof6) ## ## Call: ## lm(formula = y ~ x + I(x^2) + I(x^3) + I(x^4) + I(x^5) + I(x^6)) ## ## Residuals: ## Min 1Q Median 3Q Max ## -8.4627 -3.2409 -0.6654 3.1208 8.0410 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 2.699e+02 8.387e+01 3.218 0.00673 ** ## x -1.585e+02 8.483e+01 -1.868 0.08447 . ## I(x^2) 5.346e+01 3.103e+01 1.723 0.10864 ## I(x^3) -8.572e+00 5.481e+00 -1.564 0.14188 ## I(x^4) 7.158e-01 5.033e-01 1.422 0.17849 ## I(x^5) -2.999e-02 2.307e-02 -1.300 0.21606 ## I(x^6) 4.982e-04 4.159e-04 1.198 0.25229 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 5.501 on 13 degrees of freedom ## Multiple R-squared: 0.8032, Adjusted R-squared: 0.7124 ## F-statistic: 8.843 on 6 and 13 DF, p-value: 0.0005655 32.3.11 嵌套模型的比较 如果两个多元线性回归模型， 第一个模型中的自变量都在第二个模型中， 且第二个模型具有更多的自变量， 则称第一个模型嵌套在第二个模型中。 例如：第一个模型中自变量为\\(x_1, x_2, x_5\\), 第二个模型自变量为\\(x_1, x_2, x_3, x_4, x_5\\)， 则第一个模型嵌套在第二个模型中。 又如：第一个模型自变量为\\(x_1, x_2\\), 第二个模型自变量为\\(x_1, x_2, x_1^2, x_2^2, x_1 x_2\\)， 则第一个模型嵌套在第二个模型中。 这时令\\(x_3=x_1^2\\), \\(x_4=x_2^2\\), \\(x_5=x_1 x_2\\)， 第二个模型变成有5个自变量的多元线性回归模型。 在嵌套的模型中， 相对而言自变量多的模型叫做完全模型（full model）， 自变量少的模型叫做简化模型（reduced model）。 完全模型是否比简化模型更好？ 在回归模型选择中贯彻一个“精简性”原则（Ocam’s razor）： 在对建模数据拟合效果相近的情况下， 越简单的模型越好。 例如：全模型是 \\[ Ey = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\beta_3 x_3 + \\beta_4 x_4 \\] 精简模型是 \\[ Ey=\\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 \\] 判断两个模型是否没有显著差异，只要检验： \\[ H_0: \\beta_3 = \\beta_4 = 0 \\] 这可以构造一个方差分析F检验， 设全模型有\\(t\\)个自变量， 模型得到的回归残差平方和为\\(\\text{SSE}_f\\); 设精简模型有\\(s\\)个自变量（\\(s &lt; t\\)）， 模型得到的回归残差平方和为\\(\\text{SSE}_r\\)； 检验零假设为多出的自变量对应的系数都等于零。 检验统计量为 \\[ F = \\frac{(\\text{SSE}_r - \\text{SSE}_f)/(t-s)}{\\text{SSE}_f/(n-t-1)} \\] 在全模型成立且\\(H_0\\)成立时，\\(F\\)服从\\(F(t-s, n-t-1)\\)分布。 计算右侧p值。 在R中用anova()函数比较两个嵌套的线性回归结果可以进行这样的方差分析F检验。 例如，餐馆营业额回归模型的比较。 lmrst01是完全模型，包含5个自变量； lmrst02是嵌套的精简模型， 包含居民数、人均餐费、到市中心距离共3个自变量。 用anova()函数可以检验多出的变量是否有意义： anova(lmrst01, lmrst02) ## Analysis of Variance Table ## ## Model 1: 营业额 ~ 居民数 + 人均餐费 + 月收入 + 餐馆数 + 距离 ## Model 2: 营业额 ~ 居民数 + 人均餐费 + 距离 ## Res.Df RSS Df Sum of Sq F Pr(&gt;F) ## 1 19 2153.0 ## 2 21 2267.2 -2 -114.17 0.5038 0.6121 模型p值为0.61， 在0.05水平下不拒绝多出的月收入和餐馆数的系数全为零的零假设， 两个模型的效果没有显著差异， 应选择更精简的模型。 方差分析检验仅能比较嵌套模型。 对不同模型计算AIC， 取AIC较小的模型， 这可以对非嵌套的模型进行比较选择。 R中用AIC()函数比较两个回归结果的AIC值。 如： AIC(lmrst01, lmrst02) ## df AIC ## lmrst01 7 196.3408 ## lmrst02 5 193.6325 精简模型lmrst02的AIC更小，是更好的模型。 32.3.12 拟合与预测 32.3.12.1 拟合 有了参数最小二乘估计后，对建模用的每个数据点计算 \\[ \\hat y_i = \\hat\\beta_0 + \\hat\\beta_1 x_{i1} + \\dots + \\hat\\beta_p x_{ip} \\] 称为拟合值（fitted value）。 得到回归模型结果lmres后，要对原数据框中的观测值做预测， 只要使用predict(lmres)。 32.3.12.2 点预测 为了使用得到的模型结果lmres对新数据做预测， 建立包含了自变量的一组新的观测值的数据框dp, 用predict(lmres, newdata=dp)做预测。 如餐馆营业额的选择自变量的回归模型lmrst02的拟合值： predict(lmrst02) ## 1 2 3 4 5 6 7 ## 52.1892541 -4.5010247 21.9626575 65.1136964 6.1284803 22.4083426 1.2783244 ## 8 9 10 11 12 13 14 ## 34.7189934 10.6275869 37.8433996 62.8524888 18.2959990 -5.5101343 14.9558131 ## 15 16 17 18 19 20 21 ## 8.8598588 29.8309866 78.0159456 13.1673581 15.8469287 50.7274217 27.4608977 ## 22 23 24 25 ## 0.2331759 22.6274030 48.9610796 27.0050675 如果是一元回归，一般还画数据的散点图并画回归直线。 多元回归的图形无法在二维表现出来。 有了估计的回归方程后， 对一组新的自变量值\\((x_{01}, \\dots, x_{0p})\\)， 可以计算对应的因变量的预测值： \\[ \\hat y_0 = \\hat\\beta_0 + \\hat\\beta_1 x_{01} + \\dots + \\hat\\beta_p x_{0p} \\] 在R中，设lmres保存了回归结果， newd是一个保存了新的自变量值的数据框， 此数据框结构与原建模用数据框类似但是自变量与原来不同， 且不需要有因变量。 这时用predict(lm1, data=newd)预测。 例如，利用包含居民数、人均餐费、到市中心距离的模型lmrst02， 求居民数=50(万居民)，人均餐费=100(元)， 距市中心10千米的餐馆的日均营业额： predict( lmrst02, newdata=data.frame( `居民数`=50, `人均餐费`=100, `距离`=10 )) ## 1 ## 17.88685 预测的日均营业额为17.9千元。 函数expand.grid()可以对若干个变量的指定值， 生成包含所有组合的数据框，如： newd &lt;- expand.grid( `居民数`=c(60, 140), `人均餐费`=c(50, 130), `距离`=c(6, 16)) newd ## 居民数 人均餐费 距离 ## 1 60 50 6 ## 2 140 50 6 ## 3 60 130 6 ## 4 140 130 6 ## 5 60 50 16 ## 6 140 50 16 ## 7 60 130 16 ## 8 140 130 16 predict(lmrst02, newdata=newd) ## 1 2 3 4 5 6 7 8 ## 14.186636 29.404103 26.797108 42.014574 8.488759 23.706225 21.099230 36.316696 32.3.12.3 均值的置信区间 对\\(Ey=\\beta_0 + \\beta_1 x_1 + \\dots + \\beta_p x_p\\), 可以计算置信度为\\(1-\\alpha\\)的置信区间， 称为均值的置信区间。 在predict()中加选项interval=\"confidence\", 用level=指定置信度， 可以计算均值的置信区间。 如 predict( lmrst02, interval=&quot;confidence&quot;, level=0.95, newdata=data.frame( `居民数`=50, `人均餐费`=100, `距离`=10 )) ## fit lwr upr ## 1 17.88685 10.98784 24.78585 其中fit是预测值，lwr和upr分别是置信下限和置信上限。 32.3.12.4 个别值的预测区间 对\\(y=\\beta_0 + \\beta_1 x_1 + \\dots + \\beta_p x_p + \\varepsilon\\), 可以计算置信度为\\(1-\\alpha\\)的预测区间， 称为预测区间，预测区间比均值的置信区间要宽。 在predict()中加选项interval=\"prediction\", 用level=指定置信度， 可以计算预测区间。 如 predict( lmrst02, interval=&quot;prediction&quot;, level=0.95, newdata=data.frame( `居民数`=50, `人均餐费`=100, `距离`=10 )) ## fit lwr upr ## 1 17.88685 -4.795935 40.56963 其中fit是预测值，lwr和upr分别是预测下限和预测上限。 32.3.13 利用线性回归模型做曲线拟合 某些非线性关系可以通过对因变量和自变量的简单变换变成线性回归模型。 例如， 彩色显影中， 染料光学密度\\(Y\\)与析出银的光学密度\\(x\\) 有如下类型的关系 \\[ Y \\approx A e^{-B/x}, \\quad B &gt; 0 \\] 这不是线性关系。两边取对数得 \\[ \\ln Y \\approx \\ln A - B \\frac{1}{x} \\] 令 \\[ Y^* = \\ln Y, \\qquad x^* = \\frac{1}{x} \\] 则 \\[ Y^* \\approx \\ln A - B x^* \\] 为线性关系。 从\\(n\\)组数据 \\((x_1, y_1), (x_2, y_2), \\dots, (x_n, y_n)\\)得到变换的数据 \\((x_1^*, y_1^*), (x_2^*, y_2^*), \\dots, (x_n^*, y_n^*)\\)。 对变换后的数据建立线性回归方程 \\[\\hat y^* = \\hat a + \\hat b x^*\\] 反变换得 \\[\\hat A = e^{\\hat a}, \\qquad \\hat B = -b\\] 则有 \\[\\hat Y = \\hat A e^{-\\hat B / x}\\] 再考虑一个钢包容积的例子。 炼钢钢包随使用次数增加而容积增大。 测量了13组这样的数据: SteelBag &lt;- data.frame( x = c(2, 3, 4, 5, 7, 8, 10, 11, 14, 15, 16, 18, 19), y = c(106.42, 108.20, 109.58, 109.50, 110.0, 109.93, 110.49, 110.59, 110.60, 110.90, 110.76, 111.00, 111.20) ) knitr::kable(SteelBag) x y 2 106.42 3 108.20 4 109.58 5 109.50 7 110.00 8 109.93 10 110.49 11 110.59 14 110.60 15 110.90 16 110.76 18 111.00 19 111.20 散点图： with(SteelBag, plot( x, y, xlab=&quot;使用次数&quot;, ylab=&quot;钢包容积&quot; )) 散点图呈现非线性。 用线性回归近似： lmsb1 &lt;- lm(y ~ x, data=SteelBag) summary(lmsb1) ## ## Call: ## lm(formula = y ~ x, data = SteelBag) ## ## Residuals: ## Min 1Q Median 3Q Max ## -1.97615 -0.38502 0.04856 0.53724 0.80611 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 108.01842 0.44389 243.346 &lt; 2e-16 *** ## x 0.18887 0.03826 4.937 0.000445 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.7744 on 11 degrees of freedom ## Multiple R-squared: 0.689, Adjusted R-squared: 0.6607 ## F-statistic: 24.37 on 1 and 11 DF, p-value: 0.000445 结果显著。 \\(R^2=0.69\\)。 拟合图： with(SteelBag, plot( x, y, xlab=&quot;使用次数&quot;, ylab=&quot;钢包容积&quot;, main=&quot;线性近似&quot; )) abline(lmsb1, col=&quot;red&quot;, lwd=2) 残差诊断： plot(lmsb1, which=1) 残差图呈现非线性。 用双曲线模型： \\[ \\frac{1}{y} \\approx a + b \\frac{1}{x} \\] 令\\(x^* = 1/x, y^* = 1/y\\)，化为线性模型 \\[y^* \\approx a + b x^*\\] \\((x^*, y^*)\\)的散点图： with(SteelBag, plot( 1/x, 1/y, xlab=&quot;1/使用次数&quot;, ylab=&quot;1/钢包容积&quot;, main=&quot;x和y都做倒数变换&quot; )) \\(y^*\\)对\\(x^*\\)的回归： lmsb2 &lt;- lm(I(1/y) ~ I(1/x), data=SteelBag) summary(lmsb2) ## ## Call: ## lm(formula = I(1/y) ~ I(1/x), data = SteelBag) ## ## Residuals: ## Min 1Q Median 3Q Max ## -4.817e-05 -3.686e-06 4.000e-07 1.008e-05 2.642e-05 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 8.967e-03 8.371e-06 1071.14 &lt; 2e-16 *** ## I(1/x) 8.292e-04 4.118e-05 20.14 4.97e-10 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 1.903e-05 on 11 degrees of freedom ## Multiple R-squared: 0.9736, Adjusted R-squared: 0.9712 ## F-statistic: 405.4 on 1 and 11 DF, p-value: 4.97e-10 结果显著。 解得\\(\\hat a = 0.008967\\), \\(\\hat b = 0.0008292\\), 经验公式为 \\[ \\frac{1}{\\hat y} = 0.008967 + 0.0008292 \\frac{1}{x} \\] \\(R^2\\)从线性近似的0.69提高到了0.97。 拟合图： with(SteelBag, plot( x, y, xlab=&quot;使用次数&quot;, ylab=&quot;钢包容积&quot;, main=&quot;线性和非线性回归&quot; )) abline(lmsb1, col=&quot;red&quot;, lwd=2) curve(1/(0.008967 + 0.0008292/x), 1, 20, col=&quot;green&quot;, lwd=2, add=TRUE) legend(&quot;bottomright&quot;, lty=1, lwd=2, col=c(&quot;red&quot;, &quot;green&quot;), legend=c(&quot;线性回归&quot;, &quot;曲线回归&quot;)) 考虑Reynolds, Inc.销售业绩数据分析问题。 Reynolds, Inc.是一个工业和试验室量具厂商。 为研究销售业务员的业绩， 考察业务员从业年限(Months, 单位：月)与其销售的电子量具数量(Sales)的关系。 随机抽查了15名业务员。 knitr::kable(Reynolds) Months Sales 41 275 106 296 76 317 104 376 22 162 12 150 85 367 111 308 40 189 51 235 9 83 12 112 6 67 56 325 19 189 散点图： with(Reynolds, plot(Months, Sales)) 散点图呈现非线性。 用线性近似： lmre1 &lt;- lm(Sales ~ Months, data=Reynolds) summary(lmre1) ## ## Call: ## lm(formula = Sales ~ Months, data = Reynolds) ## ## Residuals: ## Min 1Q Median 3Q Max ## -67.166 -38.684 2.557 28.875 80.673 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 111.2279 21.6280 5.143 0.000189 *** ## Months 2.3768 0.3489 6.812 1.24e-05 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 49.52 on 13 degrees of freedom ## Multiple R-squared: 0.7812, Adjusted R-squared: 0.7643 ## F-statistic: 46.41 on 1 and 13 DF, p-value: 1.239e-05 结果显著。 \\(R^2=0.78\\)。 拟合图： with(Reynolds, plot(Months, Sales, main=&quot;线性近似&quot;)) abline(lmre1, col=&quot;red&quot;, lwd=2) 残差诊断： plot(lmre1, which=1) 残差图有明显的非线性。 考虑最简单的非线性模型： \\[ y = \\beta_0 + \\beta_1 x + \\beta_2 x^2 + \\varepsilon \\] 令\\(x_1 = x\\), \\(x_2=x^2\\)，有 \\[ y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\varepsilon \\] 是二元线性回归模型。 作二次多项式回归： lmre2 &lt;- lm(Sales ~ Months + I(Months^2), data=Reynolds) summary(lmre2) ## ## Call: ## lm(formula = Sales ~ Months + I(Months^2), data = Reynolds) ## ## Residuals: ## Min 1Q Median 3Q Max ## -54.963 -16.691 -6.242 31.996 43.789 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 45.347579 22.774654 1.991 0.06973 . ## Months 6.344807 1.057851 5.998 6.24e-05 *** ## I(Months^2) -0.034486 0.008948 -3.854 0.00229 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 34.45 on 12 degrees of freedom ## Multiple R-squared: 0.9022, Adjusted R-squared: 0.8859 ## F-statistic: 55.36 on 2 and 12 DF, p-value: 8.746e-07 模型显著。 \\(R^2\\)从线性近似的0.78提高到0.90。 \\(x^2\\)项的系数的显著性检验p值为0.002，显著不等于零， 说明二次项是必要的。 这样添加二次项容易造成\\(x\\)与\\(x^2\\)之间的共线性， 所以添加中心化的二次项： \\[x_2 = (x - 60)^2\\] lmre3 &lt;- lm(Sales ~ Months + I((Months-60)^2), data=Reynolds) summary(lmre3) ## ## Call: ## lm(formula = Sales ~ Months + I((Months - 60)^2), data = Reynolds) ## ## Residuals: ## Min 1Q Median 3Q Max ## -54.963 -16.691 -6.242 31.996 43.789 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 169.495742 21.331978 7.946 4.03e-06 *** ## Months 2.206535 0.246744 8.943 1.18e-06 *** ## I((Months - 60)^2) -0.034486 0.008948 -3.854 0.00229 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 34.45 on 12 degrees of freedom ## Multiple R-squared: 0.9022, Adjusted R-squared: 0.8859 ## F-statistic: 55.36 on 2 and 12 DF, p-value: 8.746e-07 with(Reynolds, plot(Months, Sales, main=&quot;线性和非线性回归&quot;)) abline(lmre1, col=&quot;red&quot;, lwd=2) curve(196.50 + 2.2065*x - 0.03449*(x-60)^2, 5, 110, col=&quot;green&quot;, lwd=2, add=TRUE) legend(&quot;bottomright&quot;, lty=1, lwd=2, col=c(&quot;red&quot;, &quot;green&quot;), legend=c(&quot;线性回归&quot;, &quot;曲线回归&quot;)) 32.3.14 分组建立多个模型 有时希望将数据按照一个或者几个分类变量分组， 每一组分别建立模型， 并将模型结果统一列表比较。 broom包可以用来将模型结果转换成规范的数据框格式。 以肺癌病人数据为例， 建立v1对v0和age的多元线性回归模型： print(d.cancer) ## # A tibble: 34 x 6 ## id age sex type v0 v1 ## &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 70 F 腺癌 26.5 2.91 ## 2 2 70 F 腺癌 135. 35.1 ## 3 3 69 F 腺癌 210. 74.4 ## 4 4 68 M 腺癌 61 35.0 ## 5 5 67 M 鳞癌 238. 128. ## 6 6 75 F 腺癌 330. 112. ## 7 7 52 M 鳞癌 105. 32.1 ## 8 8 71 M 鳞癌 85.2 29.2 ## 9 9 68 M 鳞癌 102. 22.2 ## 10 10 79 M 鳞癌 65.5 21.9 ## # ... with 24 more rows lmgr01 &lt;- lm(v1 ~ v0 + age, data = d.cancer) summary(lmgr01) ## ## Call: ## lm(formula = v1 ~ v0 + age, data = d.cancer) ## ## Residuals: ## Min 1Q Median 3Q Max ## -42.757 -11.010 -2.475 11.907 52.941 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 7.90818 33.14895 0.239 0.814 ## v0 0.43288 0.05564 7.780 1.79e-07 *** ## age -0.12846 0.53511 -0.240 0.813 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 21.76 on 20 degrees of freedom ## (11 observations deleted due to missingness) ## Multiple R-squared: 0.7683, Adjusted R-squared: 0.7451 ## F-statistic: 33.16 on 2 and 20 DF, p-value: 4.463e-07 用broom包的tidy()函数可以将系数估计结果转换成合适的tibble数据框格式: library(broom) ## Warning: 程辑包&#39;broom&#39;是用R版本3.6.3 来建造的 tidy(lmgr01) ## # A tibble: 3 x 5 ## term estimate std.error statistic p.value ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 (Intercept) 7.91 33.1 0.239 0.814 ## 2 v0 0.433 0.0556 7.78 0.000000179 ## 3 age -0.128 0.535 -0.240 0.813 用broom包的augment()函数可以获得拟合值、残差等每个观测的回归结果： knitr::kable(augment(lmgr01), digits=2) .rownames v1 v0 age .fitted .se.fit .resid .hat .sigma .cooksd .std.resid 1 2.91 26.51 70 10.39 7.92 -7.48 0.13 22.25 0.01 -0.37 2 35.08 135.48 70 57.56 5.43 -22.48 0.06 21.68 0.03 -1.07 3 74.44 209.74 69 89.84 6.92 -15.40 0.10 22.01 0.02 -0.75 4 34.97 61.00 68 25.58 6.06 9.39 0.08 22.21 0.01 0.45 5 128.34 237.75 67 102.22 8.06 26.12 0.14 21.37 0.09 1.29 6 112.34 330.24 75 141.23 12.50 -28.89 0.33 20.81 0.43 -1.62 7 32.10 104.90 52 46.64 7.83 -14.54 0.13 22.04 0.03 -0.72 8 29.15 85.15 71 35.65 6.31 -6.50 0.08 22.27 0.00 -0.31 9 22.15 101.65 68 43.18 5.10 -21.03 0.05 21.77 0.02 -0.99 10 21.94 65.54 79 26.13 10.19 -4.19 0.22 22.30 0.00 -0.22 11 12.33 125.31 55 55.09 6.88 -42.76 0.10 19.79 0.16 -2.07 12 99.44 224.36 54 98.09 10.54 1.35 0.23 22.32 0.00 0.07 13 2.30 12.93 55 6.44 7.58 -4.14 0.12 22.30 0.00 -0.20 14 23.96 40.21 75 15.68 9.24 8.28 0.18 22.23 0.01 0.42 15 7.39 12.58 61 5.52 6.93 1.87 0.10 22.32 0.00 0.09 16 112.58 231.04 76 98.16 8.81 14.42 0.16 22.03 0.03 0.72 17 91.62 172.13 65 74.07 5.57 17.55 0.07 21.93 0.02 0.83 18 13.95 39.26 66 16.42 6.37 -2.47 0.09 22.32 0.00 -0.12 20 122.45 161.00 63 69.51 5.43 52.94 0.06 18.47 0.14 2.51 21 68.35 105.26 67 44.87 4.84 23.48 0.05 21.63 0.02 1.11 22 5.25 13.25 51 7.09 8.67 -1.84 0.16 22.32 0.00 -0.09 23 3.34 18.70 49 9.71 9.27 -6.37 0.18 22.27 0.01 -0.32 24 50.36 60.23 49 27.69 8.91 22.67 0.17 21.59 0.09 1.14 用broom包的glance()函数可以将回归的复相关系数平方、F检验p值等整体结果做成一行的数据框： knitr::kable(glance(lmgr01), digits=2) r.squared adj.r.squared sigma statistic p.value df logLik AIC BIC deviance df.residual 0.77 0.75 21.76 33.16 0 3 -101.87 211.74 216.28 9470.34 20 下面将男病人与女病人分别建模， 并以表格形式合并分组的建模结果。 用dplyr包的group_by()函数分组， 用tidyr包的nest()函数可以将分组后的数据框转换成一个新的数据框， 新数据框中有一列是列表类型， 每个元素是一个子数据框： d.cancer %&gt;% group_by(sex) %&gt;% nest() ## # A tibble: 2 x 2 ## # Groups: sex [2] ## sex data ## &lt;chr&gt; &lt;list&gt; ## 1 F &lt;tibble [13 x 5]&gt; ## 2 M &lt;tibble [21 x 5]&gt; 这样， 可以用purr::map()函数对每一组分别建模， 建模结果可以借助broom包制作成合适的数据框格式， 然后用unnest()函数将不同组的结果合并成一个大数据框，如： d.cancer %&gt;% group_by(sex) %&gt;% nest() %&gt;% mutate(model = map(data, function(df) summary(lm(v1 ~ v0 + age, data=df))), tidied = map(model, tidy)) %&gt;% unnest(tidied, .drop = TRUE) ## Warning: The `.drop` argument of `unnest()` is deprecated as of tidyr 1.0.0. ## All list-columns are now preserved. ## This warning is displayed once every 8 hours. ## Call `lifecycle::last_warnings()` to see where this warning was generated. ## # A tibble: 6 x 8 ## # Groups: sex [2] ## sex data model term estimate std.error statistic p.value ## &lt;chr&gt; &lt;list&gt; &lt;list&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 F &lt;tibble [13 x~ &lt;smmry.~ (Interce~ 171. 147. 1.16 3.10e-1 ## 2 F &lt;tibble [13 x~ &lt;smmry.~ v0 0.485 0.136 3.56 2.35e-2 ## 3 F &lt;tibble [13 x~ &lt;smmry.~ age -2.74 2.39 -1.15 3.16e-1 ## 4 M &lt;tibble [21 x~ &lt;smmry.~ (Interce~ -17.2 30.5 -0.563 5.83e-1 ## 5 M &lt;tibble [21 x~ &lt;smmry.~ v0 0.486 0.0657 7.39 5.28e-6 ## 6 M &lt;tibble [21 x~ &lt;smmry.~ age 0.204 0.484 0.421 6.81e-1 当需要分组拟合许多个模型时， 这种方法比较方便。 32.4 非参数回归 32.4.1 模型 线性回归模型可以看成非线性回归模型的特例: \\[Y = f(X) + \\varepsilon\\] 其中\\(f(x)\\)为未知的回归函数。 参数方法：假定\\(f(x)\\)具有某种形式，如 \\(f(x) = a + b x\\): 线性回归； \\(f(x) = a + b x + c x^2\\): 二次多项式回归； \\(f(x) = A e^{bx}\\): 指数模型，等等。 二次多项式回归可以令\\(X_1 = x, X_2 = x^2\\)， 变成二元回归模型来解决。 指数模型可以令\\(z = \\ln Y\\), 模型化为\\(z = a + bx\\)。 有一些曲线模型可以通过变换化为线性回归。 在多元情形， 一般的非线性回归模型为 \\[ Y = f(x_1, x_2, \\dots, x_p) + \\varepsilon \\] 但是这样可选的模型就过于复杂， 难以把握。 比较简单的是不考虑变量之间交互作用的可加模型： \\[ Y = \\sum_{j=1}^p f_j(x_j) + \\varepsilon \\] 其中\\(f_j(\\cdot)\\)是未知的回归函数， 需要满足一定的光滑性条件。 \\(f_j(\\cdot)\\)可以是参数形式的， 比如二次多项式、三次多项式、阶梯函数等。 较好的一种选择是使用三次样条函数。 32.4.2 样条平滑 为了得到一般性的\\(Y\\)与\\(X\\)的曲线关系\\(f(x)\\)的估计， 可以使用样条函数。 三次样条函数将实数轴用若干个节点(knots) \\(\\{ z_k \\}\\)分成几段， 每一段上\\(\\hat f(x)\\)为三次多项式， 函数在节点处有连续的二阶导数。 样条函数是光滑的分段三次多项式。 用样条函数估计\\(f(x)\\)的准则是曲线接近各观测值点 \\((x_i, y_i)\\)，同时曲线足够光滑。 在R中用smooth.spline函数进行样条曲线拟合。 取每个自变量\\(x_i\\)处为一个节点， 对于给定的某个光滑度/模型复杂度系数值\\(\\lambda\\)， 求函数\\(f(x)\\)使得 \\[ \\min_{f(\\cdot)} \\left\\{ \\sum_i [y_i - f(x_i)]^2 + \\lambda \\int [f&#39;&#39;(x)]^2 \\,dx \\right\\} \\] \\(\\lambda\\)越大， 所得的曲线越光滑。 smooth.spline()函数可以通过交叉验证方法自动取得一个对于预测最优的光滑参数\\(\\lambda\\)值， 也可以通过df=选项指定一个等效自由度， 等效自由度越大， 模型越复杂， 曲线光滑程度越低。 df值相当于多元线性回归中的自变量个数。 如 set.seed(1) nsamp &lt;- 30 x &lt;- runif(nsamp, -10, 10) xx &lt;- seq(-10, 10, length.out=100) x &lt;- sort(x) y &lt;- 10*sin(x/10*pi)^2 + rnorm(nsamp,0,0.3) plot(x, y) curve(10*sin(x/10*pi)^2, -10, 10, add=TRUE, lwd=2) library(splines) res &lt;- smooth.spline(x, y) lines(spline(x, res$y), col=&quot;red&quot;) res2 &lt;- loess(y ~ x, degree=2, span=0.3) lines(xx, predict(res2, newdata=data.frame(x=xx)), col=&quot;blue&quot;) legend(&quot;top&quot;, lwd=c(2,1,1), col=c(&quot;black&quot;, &quot;red&quot;, &quot;blue&quot;), legend=c(&quot;真实函数关系&quot;, &quot;样条平滑结果&quot;, &quot;局部线性拟合&quot;)) 图32.11: 曲线平滑示例 其中res的元素y为拟合值，用spline(x,y)从一组散点输出 光滑曲线以便用lines()函数绘图。 R函数splines(x,y)不是做样条平滑， 而是做样条插值， 其结果是在原始的自变量x范围内产生等间隔距离的格子点值， 输出包含格子点上的样条插值x和y坐标的列表。 样条平滑曲线不需要穿过输入的各个散点， 但是插值则需要穿过输入的各个散点。 R函数approx(x,y)用线性插值方法产生线性插值后的连续函数在等间隔的横坐标上的坐标值。 32.4.3 局部多项式曲线平滑 另一种非参数的拟合非线性回归曲线\\(f(x)\\)的方法是对每个自变量\\(x\\) 处选一个局部的小邻域， 用这个小邻域附近的\\((x_i, y_i)\\)点拟合一个局部的零次、一次或二次多项式， 用拟合的局部多项式在\\(x\\)处的值作为回归函数在\\(x\\)处的值的估计。 局部零次多项式的方法叫做核回归， 公式为 \\[ \\hat f(x) = \\frac{\\sum\\limits_{i = 1}^n {K\\left( {\\frac{{x - X_i }}{h}} \\right)Y_i } } {\\sum\\limits_{i = 1}^n {K\\left( {\\frac{{x - X_i }}{h}} \\right)} } \\] 其中\\(K(\\cdot)\\)称为核函数， 是类似标准正态密度这样的中间高两边低的可以用来加权的函数， 比如， 双三次核函数： \\[ K(x) = \\left\\{ {\\begin{array}{*{20}c} {\\left( {1 - \\left| x \\right|^3 } \\right)^3 } &amp; {\\left| x \\right| \\leq 1} \\\\ 0 &amp; \\mbox{其它} \\\\ \\end{array}} \\right. \\] kernel.dcube &lt;- function(u){ y &lt;- numeric(length(u)) sele &lt;- (abs(u) &lt; 1) y[sele] &lt;- (1 - abs(u[sele])^3)^3 y } curve(kernel.dcube, -1.5, 1.5, main=&quot;双三次核函数&quot;) 图32.12: 双三次核函数 参数\\(h\\)称为窗宽， \\(h\\)越大，参与平均的点越多， 曲线越光滑， 回归复杂度越低。 \\(h\\)选取可以用交叉验证方法。 R扩展包KernSmooth的函数 locpoly(x, y, degree=1, bandwidth=0.25)可以计算核回归， 其中bandwidth是输入的窗宽， 函数dpill(x,y)可以帮助确定窗宽。 如 locpoly(x, y, degree=1, bandwidth=dpill(x,y))。 stats包的ksmooth()函数也可以计算核回归。 当局部拟合的是一次或者二次多项式时， 这种曲线拟合方法叫做局部多项式回归。 R函数loess(y ~ x, degree=1, span=0.75)拟合局部线性函数， 用span=控制结果的光滑度， span是局部拟合所用的点的比例， 越接近于1结果越光滑。 取degree=2拟合局部二次多项式函数。 见图32.11。 32.4.4 样条函数变换 \\(m\\)个节点的三次样条函数需要\\(n+4\\)个参数， 因为每段需要\\(4\\)个参数， \\(m+1\\)段需要\\(4m+4\\)个参数， 而在\\(m\\)个节点上连续、一阶导数连续、二阶导数连续构成三个约束条件， 所以参数个数为\\(m+4\\)个。 自然样条函数假定函数在最左边一段和最右边一段为线性函数， 这样\\(m\\)个节点需要\\(m+2\\)个参数。 R的lm()函数中对自变量x指定ns(x) 可以对输入的x指定作自然样条变换， ns()可以用df=指定自由度作为曲线复杂度的度量。 如 set.seed(1) nsamp &lt;- 30 x &lt;- runif(nsamp, -10, 10) xx &lt;- seq(-10, 10, length.out=100) x &lt;- sort(x) y &lt;- 10*sin(x/10*pi)^2 + rnorm(nsamp,0,0.3) plot(x, y) curve(10*sin(x/10*pi)^2, -10, 10, add=TRUE, lwd=2) res &lt;- lm(y ~ ns(x, df=4)) lines(xx, predict(res, newdata=data.frame(x=xx)), col=&quot;red&quot;) res2 &lt;- lm(y ~ ns(x, df=8)) lines(xx, predict(res2, newdata=data.frame(x=xx)), col=&quot;blue&quot;) legend(&quot;top&quot;, lwd=c(2,1,1), col=c(&quot;black&quot;, &quot;red&quot;, &quot;blue&quot;), legend=c(&quot;真实函数关系&quot;, &quot;ns(df=4)&quot;, &quot;ns(df=8)&quot;)) 图32.13: 自然样条回归示例 在多元回归中也可以用ns(x)对单个自变量引入非线性。 32.4.5 线性可加模型 虽然在用lm()作多元回归时可以用ns()、poly()等函数引入非线性成分， 但需要指定复杂度参数。 对可加模型 \\[ Y = \\sum_{j=1}^p f_j(x_j) + \\varepsilon \\] 最好能从数据中自动确定\\(f_j(\\cdot)\\)的复杂度（光滑度）参数。 R扩展包mgcv的gam()函数可以执行这样的可加模型的非参数回归拟合。 模型中可以用s(x)指定x的样条平滑， 用lo(x)指定x的局部多项式平滑。 具体的计算是迭代地对每个自变量\\(x_j\\)进行， 估计\\(x_j\\)的平滑函数\\(f_j(\\cdot)\\)时， 采用数据\\(\\tilde y = Y - \\sum_{k \\neq j} f_k(x_k)\\)， 迭代估计到结果基本不变为止。 例如，MASS包的rock数据框是石油勘探中12块岩石样本分别产生4个切片得到的测量数据， 共48个观测， 因变量是渗透率(permeability)， 自变量为area, peri, shape。 先作线性回归： lm.rock &lt;- lm(log(perm) ~ area + peri + shape, data=rock) summary(lm.rock) ## ## Call: ## lm(formula = log(perm) ~ area + peri + shape, data = rock) ## ## Residuals: ## Min 1Q Median 3Q Max ## -1.8092 -0.5413 0.1734 0.6493 1.4788 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 5.333e+00 5.487e-01 9.720 1.59e-12 *** ## area 4.850e-04 8.657e-05 5.602 1.29e-06 *** ## peri -1.527e-03 1.770e-04 -8.623 5.24e-11 *** ## shape 1.757e+00 1.756e+00 1.000 0.323 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.8521 on 44 degrees of freedom ## Multiple R-squared: 0.7483, Adjusted R-squared: 0.7311 ## F-statistic: 43.6 on 3 and 44 DF, p-value: 3.094e-13 其中shape变量不显著。 可能的原因有： shape与因变量没有关系； 样本量不足； shape与因变量之间有非线性关系，该非线性无法用线性近似。 用样条平滑的gam()建模： library(mgcv) ## 载入需要的程辑包：nlme ## Warning: 程辑包&#39;nlme&#39;是用R版本3.6.3 来建造的 ## ## 载入程辑包：&#39;nlme&#39; ## The following object is masked from &#39;package:dplyr&#39;: ## ## collapse ## This is mgcv 1.8-31. For overview type &#39;help(&quot;mgcv-package&quot;)&#39;. gam.rock1 &lt;- gam( log(perm) ~ s(area) + s(peri) + s(shape), data=rock) summary(gam.rock1) ## ## Family: gaussian ## Link function: identity ## ## Formula: ## log(perm) ~ s(area) + s(peri) + s(shape) ## ## Parametric coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 5.1075 0.1222 41.81 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Approximate significance of smooth terms: ## edf Ref.df F p-value ## s(area) 1.000 1.000 29.13 1.96e-06 *** ## s(peri) 1.000 1.000 71.30 4.12e-12 *** ## s(shape) 1.402 1.705 0.58 0.425 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## R-sq.(adj) = 0.735 Deviance explained = 75.4% ## GCV = 0.78865 Scale est. = 0.71631 n = 48 对gam()回归结果做单个变量的曲线拟合图： plot(gam.rock1) 图32.14: 渗透率gam建模 图32.15: 渗透率gam建模 图32.16: 渗透率gam建模 可以看出三条曲线都基本不需要非线性。 比较两个模型： anova(lm.rock, gam.rock1) ## Analysis of Variance Table ## ## Model 1: log(perm) ~ area + peri + shape ## Model 2: log(perm) ~ s(area) + s(peri) + s(shape) ## Res.Df RSS Df Sum of Sq F Pr(&gt;F) ## 1 44.000 31.949 ## 2 43.598 31.230 0.40237 0.71914 2.4951 0.125 结果也不显著， 说明线性模型是可取的。 32.5 Logistic回归 32.5.1 模型 当因变量\\(Y\\)是零壹变量时，即\\(Y\\)表示分两类的类别，取值1和0， 我们关心的是\\(P(Y=1)\\)。这是一个\\([0,1]\\)区间内的值。 如果把\\(Y\\)当作一般因变量做线性回归， 会给出不合理的结果，比如负值， 另外线性回归假定误差项为正态分布在这里也不适用。 为此考虑广义的回归模型(广义线性模型): \\[\\begin{aligned} Y \\sim &amp; F(y;\\theta) \\\\ g(\\theta) =&amp; \\beta_0 + \\beta_1 X_1 + \\dots + \\beta_p X_p \\end{aligned}\\] 特别地，定义logit函数 \\[ \\text{logit}(p) = \\ln \\left( \\frac{p}{1-p} \\right) \\] Logit模型: \\[\\begin{aligned} Y \\sim&amp; b(1, p) \\\\ \\text{logit}(p) =&amp; \\beta_0 + \\beta_1 X_1 + \\dots + \\beta_p X_p \\end{aligned}\\] 32.5.2 R程序 进行logistic回归的R程序如glm(y ~ x1 + x2, family=binomial, data=d), 其中y为取0或1的向量，输入数据集为d。 y也可以是一个两列的矩阵，第一列为成功数，第二列为失败数。 例如，“remiss.csv”中保存了癌症病人康复的数据， 变量remiss为康复与否(1为康复，0为未康复)， 另外的6个变量为可能影响康复概率的自变量。 程序: d.remiss &lt;- read.csv(&quot;remiss.csv&quot;, header=TRUE) glm1 &lt;- glm( remiss ~ cell+smear+infil+li+blast+temp, family=binomial, data=d.remiss) summary(glm1) ## ## Call: ## glm(formula = remiss ~ cell + smear + infil + li + blast + temp, ## family = binomial, data = d.remiss) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -1.95165 -0.66491 -0.04372 0.74304 1.67069 ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) 58.0385 71.2364 0.815 0.4152 ## cell 24.6615 47.8377 0.516 0.6062 ## smear 19.2936 57.9500 0.333 0.7392 ## infil -19.6013 61.6815 -0.318 0.7507 ## li 3.8960 2.3371 1.667 0.0955 . ## blast 0.1511 2.2786 0.066 0.9471 ## temp -87.4339 67.5735 -1.294 0.1957 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 34.372 on 26 degrees of freedom ## Residual deviance: 21.751 on 20 degrees of freedom ## AIC: 35.751 ## ## Number of Fisher Scoring iterations: 8 以p值0.30为界限，逐步删去不显著的自变量: glm1b &lt;- glm( remiss ~ cell + smear + infil + li + temp, family=binomial, data=d.remiss) summary(glm1b) ## ## Call: ## glm(formula = remiss ~ cell + smear + infil + li + temp, family = binomial, ## data = d.remiss) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -1.93753 -0.65855 -0.04328 0.75287 1.65475 ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) 57.128 69.977 0.816 0.414 ## cell 24.180 47.257 0.512 0.609 ## smear 18.370 56.218 0.327 0.744 ## infil -18.477 59.260 -0.312 0.755 ## li 3.987 1.902 2.097 0.036 * ## temp -86.137 64.785 -1.330 0.184 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 34.372 on 26 degrees of freedom ## Residual deviance: 21.755 on 21 degrees of freedom ## AIC: 33.755 ## ## Number of Fisher Scoring iterations: 8 glm1c &lt;- glm( remiss ~ cell + infil + li + temp, family=binomial, data=d.remiss) summary(glm1c) ## ## Call: ## glm(formula = remiss ~ cell + infil + li + temp, family = binomial, ## data = d.remiss) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -1.88516 -0.66796 -0.07282 0.78697 1.72442 ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) 70.6171 59.1148 1.195 0.2323 ## cell 9.1434 7.9124 1.156 0.2479 ## infil 0.9088 3.1356 0.290 0.7719 ## li 3.9005 1.8108 2.154 0.0312 * ## temp -85.2481 64.0897 -1.330 0.1835 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 34.372 on 26 degrees of freedom ## Residual deviance: 21.869 on 22 degrees of freedom ## AIC: 31.869 ## ## Number of Fisher Scoring iterations: 7 glm1d &lt;- glm( remiss ~ cell + li + temp, family=binomial, data=d.remiss) summary(glm1d) ## ## Call: ## glm(formula = remiss ~ cell + li + temp, family = binomial, data = d.remiss) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -2.02043 -0.66313 -0.08323 0.81282 1.65887 ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) 67.634 56.888 1.189 0.2345 ## cell 9.652 7.751 1.245 0.2130 ## li 3.867 1.778 2.175 0.0297 * ## temp -82.074 61.712 -1.330 0.1835 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 34.372 on 26 degrees of freedom ## Residual deviance: 21.953 on 23 degrees of freedom ## AIC: 29.953 ## ## Number of Fisher Scoring iterations: 7 或可用逐步回归: glm2 &lt;- step(glm( remiss ~ cell + smear + infil + li + blast + temp, family=binomial, data=d.remiss)) ## Start: AIC=35.75 ## remiss ~ cell + smear + infil + li + blast + temp ## ## Df Deviance AIC ## - blast 1 21.755 33.755 ## - infil 1 21.857 33.857 ## - smear 1 21.869 33.869 ## - cell 1 22.071 34.071 ## &lt;none&gt; 21.751 35.751 ## - temp 1 23.877 35.877 ## - li 1 26.095 38.095 ## ## Step: AIC=33.76 ## remiss ~ cell + smear + infil + li + temp ## ## Df Deviance AIC ## - infil 1 21.858 31.858 ## - smear 1 21.869 31.869 ## - cell 1 22.073 32.073 ## &lt;none&gt; 21.755 33.755 ## - temp 1 24.198 34.199 ## - li 1 30.216 40.216 ## ## Step: AIC=31.86 ## remiss ~ cell + smear + li + temp ## ## Df Deviance AIC ## - smear 1 21.953 29.953 ## &lt;none&gt; 21.858 31.858 ## - temp 1 24.292 32.292 ## - cell 1 24.477 32.477 ## - li 1 30.434 38.434 ## ## Step: AIC=29.95 ## remiss ~ cell + li + temp ## ## Df Deviance AIC ## &lt;none&gt; 21.953 29.953 ## - temp 1 24.341 30.341 ## - cell 1 24.648 30.648 ## - li 1 30.829 36.829 summary(glm2) ## ## Call: ## glm(formula = remiss ~ cell + li + temp, family = binomial, data = d.remiss) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -2.02043 -0.66313 -0.08323 0.81282 1.65887 ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) 67.634 56.888 1.189 0.2345 ## cell 9.652 7.751 1.245 0.2130 ## li 3.867 1.778 2.175 0.0297 * ## temp -82.074 61.712 -1.330 0.1835 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 34.372 on 26 degrees of freedom ## Residual deviance: 21.953 on 23 degrees of freedom ## AIC: 29.953 ## ## Number of Fisher Scoring iterations: 7 "],["stat-tsa.html", "33 R时间序列分析 33.1 基本概念 33.2 时间序列数据类型 33.3 基本分析与作图 33.4 ARIMA建模和模拟 33.5 谱密度估计 33.6 GARCH类模型 33.7 多元时间序列基础统计 33.8 VAR模型 33.9 协整分析 33.10 因果性检验", " 33 R时间序列分析 这里仅仅给出了部分常用的时间序列函数的用法， 更详细的说明参见作者的金融时间序列分析讲义。 33.1 基本概念 设\\(\\mathbb Z\\)为整数集， \\(\\{X_t, t \\in \\mathbb Z\\}\\)中\\(X_t\\)是随机变量， 称\\(\\{ X_t \\}\\)为时间序列。 如果\\(\\{ X_t \\}\\)的有限维联合分布不随时间推移而变化， 称\\(\\{ X_t \\}\\)为严平稳时间序列。 如果\\(\\{ X_t \\}\\)二阶矩有限， 期望和方差不随时间而变化， 两个时间点之间的协方差只依赖于时间距离而不依赖于具体时间， 则称\\(\\{ X_t \\}\\)为(宽)平稳时间序列。 如果\\(X_t\\)是随机向量， 称\\(\\{ X_t \\}\\)为多元（或多维）时间序列。 对宽平稳列\\(\\{ X_t \\}\\)， 定义其自协方差函数(ACVF)为 \\[ \\gamma_k = \\text{Cov}(X_{t+k}, X_t), \\ k \\in \\mathbb Z . \\] 定义其自相关函数(ACF)为 \\[ \\rho_k = \\text{corr}(X_{t+k}, X_t) = \\frac{\\gamma_k}{\\gamma_0}, \\ k \\in \\mathbb Z . \\] 偏自相关函数(PACF)定义请参考时间序列分析的教材。 如果\\(\\sum_k |\\gamma_k| &lt; \\infty\\)， 则平稳列\\(\\{ X_t \\}\\)有谱密度\\(f(\\lambda), \\lambda \\in [-\\pi, \\pi]\\)， \\(f(\\lambda)\\)是非负可积偶函数，使得 \\[\\begin{aligned} \\gamma_k =&amp; \\int_{-\\pi}^{\\pi} e^{ik\\lambda} f(\\lambda) \\,d\\lambda, \\ k \\in \\mathbb Z, \\\\ f(\\lambda) =&amp; \\frac{1}{2\\pi} \\sum_{k=-\\infty}^{\\infty} \\gamma_k e^{-ik\\lambda}, \\ \\lambda \\in [-\\pi, \\pi] . \\end{aligned}\\] 若平稳列\\(\\{ \\varepsilon_t \\}\\)的自协方差函数满足\\(\\gamma_0 = \\sigma^2\\), \\(\\gamma_k = 0, k \\neq 0\\)， 称\\(\\{ \\varepsilon_t \\}\\)为白噪声列。 如果均值为零，称为零均值白噪声列， 记为WN(0, \\(\\sigma^2\\))。 33.2 时间序列数据类型 时间序列的数据可以保存在R的向量中， 或者保存在R的数据框的一列或几列中， 对应的时间单独保存或者保存在同一数据框中。 也有一些专门的时间序列数据类型， 将时间序列的观测数据与对应的时间同时保存在一个专用的数据结构中。 33.2.1 ts类型 R中最基本的时间序列类型是ts类型， 可以保存一元或者多元时间序列数据， 其中的时间必须是等间隔的， 比如年数据、月数据、季度数据、日数据， 不能在中间有缺失的日期。 生成方法如 ts(x, start=c(2001, 1), frequency=12) 其中x是向量或者矩阵， 取矩阵值时矩阵的每一列是一个多元时间序列的一个分量。 frequency对月度数据是12， 对季度数据是4， 对年度数据可以缺省（值为1）。 start=c(2001,1)表示序列开始时间是2001年1月。 如果是年度数据， 用如ts(x, start=2001)即可。 例如： 用函数ts把一个向量转换为时间序列。 如 yd &lt;- ts( c(4, 8, 7, 7, 3, 1, 8, 9, 8, 6, 3, 5, 5, 8, 2, 5, 9, 2, 5, 2, 3, 2, 2, 4), frequency=1, start=2001); yd ## Time Series: ## Start = 2001 ## End = 2024 ## Frequency = 1 ## [1] 4 8 7 7 3 1 8 9 8 6 3 5 5 8 2 5 9 2 5 2 3 2 2 4 ym &lt;- ts( c(9, 6, 3, 5, 4, 8, 2, 5, 8, 4, 6, 3, 2, 2, 6, 4, 1, 4, 2, 1, 8, 9, 4, 6), frequency=12, start=c(2001,1)); ym ## Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec ## 2001 9 6 3 5 4 8 2 5 8 4 6 3 ## 2002 2 2 6 4 1 4 2 1 8 9 4 6 其中yd是年数据，从2001到2024年； ym是月度数据从2001年1月到2002年12月。 对于多元时间序列，可以用ts函数把一个矩阵转换为ts类型的多元时间序列对象。 用ts.intersect函数和ts.union函数可以把两个或多个时间序列合并为多元时间序列， 时间段取交集或者取并集。 为了使用序列数据进行计算、绘图等， 可以用as.vector把时间序列的数据转换成普通向量。 如： as.vector(ym) ## [1] 9 6 3 5 4 8 2 5 8 4 6 3 2 2 6 4 1 4 2 1 8 9 4 6 class(as.vector(ym)) ## [1] &quot;numeric&quot; 在R中已安装的时间列示例数据有美国泛美航空公司1949-1960 的国际航班订票数的月度数据（单位：千人），12年144个月。 用 data(AirPassengers) 调入名字空间。类型和属性如下： data(AirPassengers) attributes(AirPassengers) ## $tsp ## [1] 1949.000 1960.917 12.000 ## ## $class ## [1] &quot;ts&quot; 这里时间以年为单位， 数据类属为ts， 两个数据值之间的时间间隔为\\(1/12\\)。 AirPassengers的具体数值： AirPassengers ## Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec ## 1949 112 118 132 129 121 135 148 148 136 119 104 118 ## 1950 115 126 141 135 125 149 170 170 158 133 114 140 ## 1951 145 150 178 163 172 178 199 199 184 162 146 166 ## 1952 171 180 193 181 183 218 230 242 209 191 172 194 ## 1953 196 196 236 235 229 243 264 272 237 211 180 201 ## 1954 204 188 235 227 234 264 302 293 259 229 203 229 ## 1955 242 233 267 269 270 315 364 347 312 274 237 278 ## 1956 284 277 317 313 318 374 413 405 355 306 271 306 ## 1957 315 301 356 348 355 422 465 467 404 347 305 336 ## 1958 340 318 362 348 363 435 491 505 404 359 310 337 ## 1959 360 342 406 396 420 472 548 559 463 407 362 405 ## 1960 417 391 419 461 472 535 622 606 508 461 390 432 用start()求时间序列的开始点， end()求时间序列的结束点， frequency()求采样频率。 如 start(AirPassengers) ## [1] 1949 1 end(AirPassengers) ## [1] 1960 12 frequency(AirPassengers) ## [1] 12 aggregate()函数可以把月度数据加总成年数据。 如 AP.year &lt;- aggregate(AirPassengers); AP.year ## Time Series: ## Start = 1949 ## End = 1960 ## Frequency = 1 ## [1] 1520 1676 2042 2364 2700 2867 3408 3939 4421 4572 5140 5714 如果加参数FUN=mean可以取均值。 time()函数对ts类型数据返回序列中的每个时间点的时间， 结果是一个和原来时间序列形状相同的时间序列。 cycle()函数对月度数据返回序列每个时间点所在的月份, 结果是和原序列时间点相同的一个时间序列。如 cy.AP &lt;- cycle(AirPassengers); cy.AP ## Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec ## 1949 1 2 3 4 5 6 7 8 9 10 11 12 ## 1950 1 2 3 4 5 6 7 8 9 10 11 12 ## 1951 1 2 3 4 5 6 7 8 9 10 11 12 ## 1952 1 2 3 4 5 6 7 8 9 10 11 12 ## 1953 1 2 3 4 5 6 7 8 9 10 11 12 ## 1954 1 2 3 4 5 6 7 8 9 10 11 12 ## 1955 1 2 3 4 5 6 7 8 9 10 11 12 ## 1956 1 2 3 4 5 6 7 8 9 10 11 12 ## 1957 1 2 3 4 5 6 7 8 9 10 11 12 ## 1958 1 2 3 4 5 6 7 8 9 10 11 12 ## 1959 1 2 3 4 5 6 7 8 9 10 11 12 ## 1960 1 2 3 4 5 6 7 8 9 10 11 12 window()函数取出时间序列的一段， 如果指定frequency=TRUE还可以仅取出某个月（季度）。 如 AP.Jan &lt;- window(AirPassengers, start=c(1949,1), frequency=TRUE); AP.Jan ## Time Series: ## Start = 1949 ## End = 1960 ## Frequency = 1 ## [1] 112 115 145 171 196 204 242 284 315 340 360 417 ts.union可以形成多元时间序列。 33.2.2 xts类型与常用函数 xts也是一种时间序列数据类型， 既可以保存等间隔时间序列数据， 也可以保存不等间隔的时间序列数据， 并且xts类型的数据访问功能更为方便。 读入方法例如 xts(x, date) 其中x是向量、矩阵或数据框， date是日期或者日期时间。 x取矩阵或者数据框时每列是一个时间序列。 如 library(xts) ## 载入需要的程辑包：zoo ## ## 载入程辑包：&#39;zoo&#39; ## The following objects are masked from &#39;package:base&#39;: ## ## as.Date, as.Date.numeric library(lubridate) ## ## 载入程辑包：&#39;lubridate&#39; ## The following object is masked from &#39;package:base&#39;: ## ## date xts.1 &lt;- xts( c(5, 5, 4, 6, 4, 3, 3, 3, 4, 5, 5, 4), make_date(2018, 1, 1) + ddays(0:11)); xts.1 ## [,1] ## 2018-01-01 5 ## 2018-01-02 5 ## 2018-01-03 4 ## 2018-01-04 6 ## 2018-01-05 4 ## 2018-01-06 3 ## 2018-01-07 3 ## 2018-01-08 3 ## 2018-01-09 4 ## 2018-01-10 5 ## 2018-01-11 5 ## 2018-01-12 4 如果数据框中一列是日期时间， 其它列是时间序列数据， 就可以用xts()转化成xts类型。 其它时间序列类型可以用as.xts()转换成xts类型，如 as.xts(ym) ## [,1] ## 1月 2001 9 ## 2月 2001 6 ## 3月 2001 3 ## 4月 2001 5 ## 5月 2001 4 ## 6月 2001 8 ## 7月 2001 2 ## 8月 2001 5 ## 9月 2001 8 ## 10月 2001 4 ## 11月 2001 6 ## 12月 2001 3 ## 1月 2002 2 ## 2月 2002 2 ## 3月 2002 6 ## 4月 2002 4 ## 5月 2002 1 ## 6月 2002 4 ## 7月 2002 2 ## 8月 2002 1 ## 9月 2002 8 ## 10月 2002 9 ## 11月 2002 4 ## 12月 2002 6 有了xts类型的变量x后， 可以用coredata(x)返回x的不包含时间的纯数据； 用index(x)返回x的时间标签。 这两个函数很有用。 xts类型支持强大的子集提取功能。 若x是xts类型， 则x[i]可以取出行子集， x[i,j]可以取出行、列子集， 其中i可以是整数下标， 还可以是包含日期时间的字符串向量， 日期时间类型的向量等。 日期时间字符串的格式为CCYY-MM-DD HH:MM:SS， 而且可以省略后面的一部分， 其含义是取出前面部分能匹配的所有时间点， 这种设计使得取出某年、某月的数据变得十分方便。 如 data(AirPassengers) xts.ap &lt;- as.xts(AirPassengers) xts.ap[&quot;1949&quot;] ## [,1] ## 1月 1949 112 ## 2月 1949 118 ## 3月 1949 132 ## 4月 1949 129 ## 5月 1949 121 ## 6月 1949 135 ## 7月 1949 148 ## 8月 1949 148 ## 9月 1949 136 ## 10月 1949 119 ## 11月 1949 104 ## 12月 1949 118 又比如，设x是某个股票的每分钟的数据， 则x[\"2018-01-18 08\"]取出2018-1-18 8:00-9:00之间的所有数据。 也可以用\"from/to\"的格式指定一个日期时间范围， 而且也不需要开始点和结束点恰好有数据， from和to的时间精度也不需要与数据的实际采样频率相同。 省略from则从头开始， 省略to则直到末尾。 如 xts.1[&quot;2018-01-10/2018-01-14&quot;] ## [,1] ## 2018-01-10 5 ## 2018-01-11 5 ## 2018-01-12 4 first(x, n)和last(x, n)类似于head(x, n)和last(x, n)， 但是对xts对象x，n除了可以取正整数值以外， 还允许用字符串指定时间长度， 允许的单位包括 secs, seconds, mins, minutes, hours, days, weeks, months, quarters, years。 比如，取出开头的三个月： first(xts.ap, &quot;3 months&quot;) ## [,1] ## 1月 1949 112 ## 2月 1949 118 ## 3月 1949 132 字符串中取负值时表示扣除，如扣除开始的3个月： start(xts.ap) ## [1] &quot;1月 1949&quot; start(first(xts.ap, &quot;-3 months&quot;)) ## [1] &quot;4月 1949&quot; 取出的单位可以是比实际采样频率更大的时间单位， 比如， 分钟数据可以用last(x, \"1 day\")取出最后一天的的所有数据。 但是，取出的单位不能比实际采样频率更小， 比如，日数据不能用小时单位取出。 xts的时间下标也可以是一个日期或者日期时间类型的向量。 支持的类型包括 Date, POSIXct, chron, yearmon, yearqtr, timeDate。 可用index(x)函数来读取或者修改xts类型的时间下标。 用coredata(x)取出不包含日期时间线信息的实际数据。 可以用to.period(x, period)将其xts类型的时间序列降频成period指定的采样频率， 如to.period(x, period=\"days\")。 33.3 基本分析与作图 对ts和xts类型， 仍可用length(), mean(), sd()等函数计算基本的统计量。 对ts类型，plot()函数作曲线图，如： data(AirPassengers) plot(AirPassengers) 对xts类型， plot()函数作时间序列曲线图， 对多元时间序列， 可以选择每个分量单独在一个坐标系中作图也可以重叠在一个坐标系中(用multi.panel = TRUE选项)。 如 xts.ap &lt;- as.xts(AirPassengers) plot(xts.ap, main=&quot;Air Passengers&quot;, major.ticks=&quot;years&quot;, minor.ticks=NULL, grid.ticks.on=&quot;years&quot;, col=&quot;red&quot;) 对ts类型，可以用as.vector(x)提取不包含日期时间信息的数据，结果是向量； 对xts类型，可以用coredata(x)提取不包含日期时间信息的数据， 结果不论一元还是多元时间序列都是矩阵。 取出数据后， 用通常的统计估计、图形方法可以进行一些探索性分析， 如直方图(hist())、盒形图(boxplot())、QQ图(qqnorm()和qqline())、散点图(plot())等。 stats::lag()可以计算滞后序列， 对ts类型输入， lag()的作用是序列数值不变， 但是时间标签增加一个单位或者用k=指定的间隔。 所以， 为了得到通常理解的滞后1序列，应该使用stats::lag(x, k=-1)， 如 stats::lag(ts(1:5, start=2001), k=-1) ## Time Series: ## Start = 2002 ## End = 2006 ## Frequency = 1 ## [1] 1 2 3 4 5 diff(x)计算一阶差分， diff(x, lag, differences)计算滞后为lag的阶数位differences的差分。 acf和pacf函数可以作自相关、自协方差和偏自相关函数图， 并可返回这些函数的估计值。 参见33.4.2.1。 filter函数可以计算递推的或卷积的滤波。 arima可以拟合ARIMA模型。 arima.sim可以模拟生成ARIMA模型的数据。 33.4 ARIMA建模和模拟 33.4.1 模型公式 AR(\\(p\\))模型（零均值）： \\[\\begin{aligned} X_t = a_1 X_{t-1} + a_2 X_{t-2} + \\dots + a_p X_{t-p} + \\varepsilon_t, \\ \\{ \\varepsilon_t \\} \\sim \\text{WN}(0, \\sigma^2), \\end{aligned}\\] 参数为\\(a_1, \\dots, a_p, \\sigma^2\\)， 满足 \\[ A(z) = 1 - a_1 z - \\dots - a_p z^p \\neq 0, \\ \\forall |z| \\leq 1, \\ z \\in \\mathbb C, \\] \\(\\mathbb C\\)为复数域。 可逆MA(\\(q\\))模型（零均值）： \\[\\begin{aligned} X_t = \\varepsilon_t + b_1 \\varepsilon_{t-1} + \\dots + b_1 \\varepsilon_{t-q}, \\ \\{ \\varepsilon_t \\} \\sim \\text{WN}(0, \\sigma^2), \\end{aligned}\\] 满足 \\[ B(z) = 1 + b_1 z + \\dots + b_q z^q \\neq 0, \\ \\forall |z| \\leq 1, \\ z \\in \\mathbb C . \\] 零均值可逆ARMA(\\(p,q\\))模型： \\[\\begin{aligned} X_t = a_1 X_{t-1} + a_2 X_{t-2} + \\dots + a_p X_{t-p} + \\varepsilon_t + b_1 \\varepsilon_{t-1} + \\dots + b_1 \\varepsilon_{t-q}, \\ \\{ \\varepsilon_t \\} \\sim \\text{WN}(0, \\sigma^2) . \\end{aligned}\\] 记一阶差分为\\(\\Delta X_t = X_t - X_{t-1}\\)， \\(d\\)阶差分为\\(\\Delta^d X_t = \\Delta(\\Delta^{d-1} X_t)\\)， 事实上 \\[\\begin{aligned} \\Delta^d X_t = \\sum_{j=0}^d C_d^j (-1)^j X_{t-j} . \\end{aligned}\\] 其中\\(C_d^j\\)是\\(k\\)取\\(j\\)的组合个数。 ARIMA(\\(p,d,q\\))模型： 如果\\(\\{ \\Delta^d X_t \\}\\)满足零均值可逆ARMA(\\(p,q\\))模型， 就称\\(\\{ X_t \\}\\)满足ARIMA(\\(p,d,q\\))模型。 33.4.2 模拟 用arima.sim()函数可以模拟生成ARIMA模型的数据， 也可以用来模拟AR、MA、ARMA。 arima.sim()输出ts类型的时间序列， 并且在模型有一阶单位根时会比要求的个数多输出一个值， 第一个值为初值0。 33.4.2.1 AR(4)模拟例子 考虑如下的AR(4)模型： \\[\\begin{align} X_t =&amp; -0.9 X_{t-1} - 1.4 X_{t-2} - 0.7 X_{t-3} - 0.6 X_{t-4} \\\\ &amp; + \\varepsilon_t + 0.5\\varepsilon_{t-1} - 0.4\\varepsilon_{t-2}, \\quad t\\in \\mathbb Z, \\tag{33.1} \\end{align}\\] 其中\\(\\{\\varepsilon_t \\}\\)为WN(0, 4)。 用如下程序模拟生成长度为\\(N=100\\)的样本： set.seed(101) xar4 &lt;- arima.sim( model=list(ar=c(-0.9, -1.4, -0.7, -0.6)), n = 100, sd = sqrt(4) ) 作时间序列图： plot(xar4) 作ACF图： acf(xar4) 作PACF图（偏自相关函数图）： pacf(xar4) acf(x)加type选项和plot=FALSE选项可以返回估计的自协方差函数、自相关函数、偏自相关函数。 如： ## 前10个自相关函数值： round(c( acf(xar4, lag.max=10, type=&quot;correlation&quot;, plot=FALSE)$acf ), 4) ## [1] 1.0000 -0.2984 -0.5258 0.3435 0.0213 0.0134 0.0241 -0.2397 0.1273 ## [10] 0.1889 -0.1493 ## 前10个自协方差函数值： round(c( acf(xar4, lag.max=10, type=&quot;covariance&quot;, plot=FALSE)$acf ), 4) ## [1] 11.6502 -3.4762 -6.1260 4.0017 0.2478 0.1566 0.2809 -2.7920 1.4831 ## [10] 2.2008 -1.7390 ## 前9个偏自相关函数值： round(c( acf(xar4, lag.max=9, type=&quot;partial&quot;, plot=FALSE)$acf ), 4) ## [1] -0.2984 -0.6750 -0.2434 -0.5189 -0.0533 -0.0744 -0.1345 -0.1602 -0.1043 注意自相关函数、自协方差函数都是从滞后0开始（即\\(\\rho_0\\), \\(\\gamma_0\\)）， 而偏自相关函数从滞后1开始。 可以用polyroot()计算多项式的所有复根， 输入是从零次项到最高次项的系数。 可以用Mod()或abs()求复数模，如： a &lt;- c(-0.9, -1.4, -0.7, -0.6) Mod(polyroot(c(1, -a))) ## [1] 1.134452 1.137989 1.137989 1.134452 四个根都在单位圆外， 满足AR模型的最小相位条件。 33.4.2.2 MA(2)模拟例子 考虑如下的MA(2)模型： \\[\\begin{align} X_t =&amp; \\varepsilon_t + 0.5\\varepsilon_{t-1} - 0.4\\varepsilon_{t-2}, \\quad t\\in \\mathbb Z, \\tag{33.2} \\end{align}\\] 其中\\(\\{\\varepsilon_t \\}\\)为WN(0, 4)。 模拟生成长度为100的样本，作时间序列图， ACF，PACF图： set.seed(101) xma2 &lt;- arima.sim( model=list(ma=c(0.5, -0.4)), n = 100, sd = sqrt(4) ) plot(xma2) acf(xma2) pacf(xma2) 33.4.2.3 ARMA(4,2)模拟例子 考虑如下的ARMA(4,2)模型： \\[\\begin{align} X_t =&amp; -0.9 X_{t-1} - 1.4 X_{t-2} - 0.7 X_{t-3} - 0.6 X_{t-4} \\\\ =&amp; \\varepsilon_t + 0.5\\varepsilon_{t-1} - 0.4\\varepsilon_{t-2}, \\quad t\\in \\mathbb Z, \\tag{33.3} \\end{align}\\] 其中\\(\\{\\varepsilon_t \\}\\)为WN(0, 4)。 用如下程序模拟生成长度为\\(N=100\\)的样本， 并作时间序列图、ACF图、PACF图： set.seed(101) xarma42 &lt;- arima.sim( model=list( ar=c(-0.9, -1.4, -0.7, -0.6), ma=c(0.5, -0.4)), n = 100, sd = sqrt(4) ) plot(xarma42) acf(xarma42) pacf(xarma42) 33.4.2.4 ARIMA(4,1,2)模拟例子 用如下程序模拟生成长度为\\(N=100\\)的ARIMA(4,1,2)样本， 并作时间序列图、ACF图、PACF图。 要注意的是， arima.sim()在有一阶差分时会输出\\(n+1\\)个值。 set.seed(101) xarima412 &lt;- arima.sim( model=list( order = c(4,1,2), ar=c(-0.9, -1.4, -0.7, -0.6), ma=c(0.5, -0.4)), n = 100, sd = sqrt(4) )[-1] ts.plot(xarima412) acf(xarima412) pacf(xarima412) 33.4.3 AR建模 stats::ar(x, method=\"mle\")可以用最大似然估计方法估计模型参数并用AIC定阶。 如： resar &lt;- ar(xar4, method=&quot;mle&quot;); resar ## ## Call: ## ar(x = xar4, method = &quot;mle&quot;) ## ## Coefficients: ## 1 2 3 4 ## -0.7573 -1.2317 -0.5534 -0.5525 ## ## Order selected 4 sigma^2 estimated as 3.712 结果定阶为4阶， 模型可以写成： \\[\\begin{aligned} X_t =&amp; -0.7573 X_{t-1} - 1.2317 X_{t-2} - 0.5534 X_{t-3} - 0.5525 X_{t-4} + \\varepsilon_t, \\\\ &amp; \\{\\varepsilon_t \\} \\sim \\text{WN}(0, 3.712) . \\end{aligned}\\] ar()的结果是一个列表， 元素order是阶\\(p\\)估计， 元素ar是\\((a_1, \\dots, a_p)\\)估计向量， 元素var.pred是\\(\\sigma^2\\)估计。 33.4.4 ARMA建模 stats::arima()可以用最大似然方法估计AR、MA、ARMA和ARIMA模型， 需要人为指定\\((p,d,q)\\)值。 如： armares &lt;- arima( 100 + xarma42, order = c(4,0,2) ) armares ## ## Call: ## arima(x = 100 + xarma42, order = c(4, 0, 2)) ## ## Coefficients: ## ar1 ar2 ar3 ar4 ma1 ma2 intercept ## -0.6324 -1.0668 -0.4163 -0.4469 0.3191 -0.6423 99.9989 ## s.e. 0.1195 0.1384 0.1350 0.1080 0.1237 0.1267 0.0371 ## ## sigma^2 estimated as 3.582: log likelihood = -209.2, aic = 434.4 模型可以表示为： \\[\\begin{aligned} EX_t =&amp; 99.9989 \\\\ Y_t =&amp; X_t - E X_t \\\\ Y_t =&amp; -0.6324 X_{t-1} - 1.0668 X_{t-2} - 0.4163 X_{t-3} - 0.4469 X_{t-4} + \\varepsilon_t + 0.3191 \\varepsilon_{t-1} - 0.6423 \\varepsilon_{t-2}, \\\\ \\{\\varepsilon_t \\} \\sim&amp; \\text{WN}(0, 3.582) \\end{aligned}\\] 另外，AIC值为434.4。 可以试验不同的阶， 找到AIC最低的模型。 arima()的结果是一个列表， 其中coef是 \\((a_1, \\dots, a_p, b_1, \\dots, b_q, \\mu)\\)的估计。 sigma2是\\(\\sigma^2\\)的估计。 var.coef是\\((a_1, \\dots, a_p, b_1, \\dots, b_q, \\mu)\\)的估计的方差阵估计， 其对角线的平方根是相应的标准误差。 residuals是估计残差， 长度与输入时间序列相同。 33.4.5 模型诊断 将arima()的输出结果输入到tsdiag()函数， 可以进行模型诊断， 结果包括标准化残差、残差的ACF、残差的Ljung-Box白噪声检验p值， 检验对多个滞后值计算， p值高于横虚线(0.05线)表示模型适合。 tsdiag(armares) 33.4.6 白噪声检验 Ljung-Box检验是常用的白噪声检验， 零假设为数据来自白噪声列。 Box.test(x, type=\"Ljung-Box\", lag=m)执行Ljung-Box白噪声检验, m是用到的自相关函数个数。 如： Box.test(xarma42, type=&quot;Ljung-Box&quot;, lag = 10) ## ## Box-Ljung test ## ## data: xarma42 ## X-squared = 80.473, df = 10, p-value = 4.056e-13 如果要对ARMA或者ARIMA建模的残差进行白噪声检验， 需要加fitdf选项，取值为\\(p+q\\)，如： Box.test(armares$residuals, type=&quot;Ljung-Box&quot;, lag = 10, fitdf=4+2) ## ## Box-Ljung test ## ## data: armares$residuals ## X-squared = 6.2553, df = 4, p-value = 0.1809 在0.05水平下结果不显著， 提示模型是合适的。 33.4.7 稀疏系数估计 arima函数允许指定某些系数固定为预先确定的值， 不从数据中估计。 例如，考虑如下的稀疏系数的ARMA(4,2)模型 \\[\\begin{aligned} X_t =&amp; 100 + Y_t, \\\\ Y_t =&amp; 0.7 X_{t-4} + \\varepsilon_t - 0.4 \\varepsilon_{t-2},\\\\ \\varepsilon_t \\sim&amp; \\text{WN}(0, 4) \\end{aligned}\\] 产生模拟数据： set.seed(101) xsparma42 &lt;- 100 + arima.sim( model=list( ar=c(0, 0, 0, 0.7), ma=c(0, -0.4)), n = 100, sd = sqrt(4) ) plot(xsparma42) acf(xsparma42) pacf(xsparma42) 拟合ARMA(4,2)模型： spres1 &lt;- arima( xsparma42, order = c(4,0,2) ) spres1 ## ## Call: ## arima(x = xsparma42, order = c(4, 0, 2)) ## ## Coefficients: ## ar1 ar2 ar3 ar4 ma1 ma2 intercept ## 0.0761 -0.0908 0.0078 0.6437 -0.0276 -0.4091 99.7500 ## s.e. 0.1955 0.1963 0.1296 0.1314 0.2733 0.2860 0.3048 ## ## sigma^2 estimated as 4.066: log likelihood = -213.21, aic = 442.41 计算各个系数估计除以标准误差的比值， 在系数为0的条件下近似服从标准正态分布： zstat.arima &lt;- function(arimares){ with( arimares, { y &lt;- numeric(length(coef)) names(y) &lt;- names(coef) y[mask] &lt;- coef[mask] / sqrt(diag(var.coef)) y }) } round(zstat.arima(spres1), 2) ## ar1 ar2 ar3 ar4 ma1 ma2 intercept ## 0.39 -0.46 0.06 4.90 -0.10 -1.43 327.21 当近似Z统计量值在正负2之间时， 可认为相应的系数等于零， 用如下程序估计稀疏系数的ARMA模型： spres2 &lt;- arima( xsparma42, order = c(4,0,2), fixed = c(0, 0, 0, NA, 0, NA, NA), transform.pars = FALSE) spres2 ## ## Call: ## arima(x = xsparma42, order = c(4, 0, 2), transform.pars = FALSE, fixed = c(0, ## 0, 0, NA, 0, NA, NA)) ## ## Coefficients: ## ar1 ar2 ar3 ar4 ma1 ma2 intercept ## 0 0 0 0.6837 0 -0.5035 99.7432 ## s.e. 0 0 0 0.0757 0 0.0927 0.2996 ## ## sigma^2 estimated as 4.108: log likelihood = -213.71, aic = 435.42 round(zstat.arima(spres2), 2) ## ar1 ar2 ar3 ar4 ma1 ma2 intercept ## 0.00 0.00 0.00 9.03 0.00 -5.43 332.96 为了指定某些系数， 在arima中用fixed=选项， 需要指定的系数就输入指定的值， 需要从数据中估计的值就输入NA， 次序按arima显示结果时各个系数的次序。 33.4.8 单位根检验 单位根检验是一种平稳性检验， 零假设是有单位根， 即不平稳； 对立假设是平稳。 经常使用增强的Dickey-Fuller检验(ADF检验)。 fUnitRoots包的adfTest()函数可以执行单位根ADF检验。 tseries包的adf.test()函数也可以执行单位根ADF检验。 注意，ADF检验都是在拒绝\\(H_0\\)（显著）时否认有单位根， 不显著时承认有单位根。 例如，对模拟的ARMA(4,2)序列数据做单位根检验： fUnitRoots::adfTest(100 + xarma42, lags=8, type=&quot;c&quot;) ## Warning in fUnitRoots::adfTest(100 + xarma42, lags = 8, type = &quot;c&quot;): p-value ## smaller than printed p-value ## ## Title: ## Augmented Dickey-Fuller Test ## ## Test Results: ## PARAMETER: ## Lag Order: 8 ## STATISTIC: ## Dickey-Fuller: -5.2017 ## P VALUE: ## 0.01 ## ## Description: ## Fri Mar 27 17:22:20 2020 by user: user 在0.05水平下显著， 说明没有单位根。 函数中的lags参数是用来作为对立假设的AR模型的阶。 可以先尝试拟合AR模型， 并用适当方法定阶， 然后再进行ADF检验。 对模拟的ARIMA(4,1,2)序列数据检验： fUnitRoots::adfTest(xarima412, lags=8, type=&quot;c&quot;) ## ## Title: ## Augmented Dickey-Fuller Test ## ## Test Results: ## PARAMETER: ## Lag Order: 8 ## STATISTIC: ## Dickey-Fuller: -1.539 ## P VALUE: ## 0.4856 ## ## Description: ## Thu Apr 02 17:17:18 2020 by user: user 在0.05水平下结果不显著， 说明有单位根。 选项type选择基础模型， 可以取： \"nc\"，表示没有漂移项或截距项； \"c\"，表示带有一个漂移项或截距项； \"ct\"，表示基础模型中带有\\(a + bt\\)这样的线性项。 33.4.9 ARMA模型的一些自定义函数 这里列出一些与ARMA模型等时间序列理论有关的函数， 比如， 从模型参数计算Wold系数， 解Yule-Walker方程， 从模型参数计算协方差函数， 逆相关函数计算， ARMA谱密度绘图， MA矩估计， Levinson递推， 递推预测， 等等。 欠缺逆相关法等少数的程序。 AR模型理论谱密度图： ar.true.spectrum &lt;- function( a, ngrid=256, sigma=1, plot.it=TRUE, title=&quot;AR True Spectral Density&quot;){ p &lt;- length(a) freqs &lt;- seq(from=0, to=pi, length=ngrid) spec &lt;- numeric(ngrid) for(ii in seq(ngrid)){ spec[ii] &lt;- sigma^2 / (2*pi) / abs(1 - sum(complex(mod=a, arg=freqs[ii]*seq(p))))^2 } if(plot.it){ plot(freqs, spec, type=&#39;l&#39;, main=title, xlab=&quot;frequency&quot;, ylab=&quot;spectral density&quot;, axes=FALSE) axis(2) axis(1, at=(0:6)/6*pi, labels=c(0, expression(pi/6), expression(pi/3), expression(pi/2), expression(2*pi/3), expression(5*pi/6), expression(pi))) } list(frequencies=freqs, spectrum=spec, ar.coefficients=a, sigma=sigma) } MA理论谱密度图： ma.true.spectrum &lt;- function( a, ngrid=256, sigma=1, tit=&quot;True MA Spectral Density&quot;, plot.it=TRUE){ p &lt;- length(a) freqs &lt;- seq(from=0, to=pi, length=ngrid) spec &lt;- numeric(ngrid) for(ii in seq(ngrid)){ spec[ii] &lt;- 1 + sum(complex(mod=a, arg=freqs[ii]*seq(p))) } spec = sigma^2 / (2*pi) * abs(spec)^2 if(plot.it){ plot(freqs, spec, type=&#39;l&#39;, main=tit, xlab=&quot;frequency&quot;, ylab=&quot;spectrum&quot;, axes=FALSE) axis(2) axis(1, at=(0:6)/6*pi, labels=c(0, expression(pi/6), expression(pi/3), expression(pi/2), expression(2*pi/3), expression(5*pi/6), expression(pi))) box() } invisible(list(frequencies=freqs, spectrum=spec, ma.coefficients=a, sigma=sigma)) } 利用李雷的矩阵极限方法对MA模型参数作矩估计。 输入\\(\\gamma_0, \\gamma_1, \\dots, \\gamma_q\\)， 输出MA参数\\(b_1, \\dots, b_q, \\sigma^2\\)的估计。 ma.solve &lt;- function(gms, k=100){ q &lt;- length(gms)-1 if(q==1){ rho1 &lt;- gms[2] / gms[1] b &lt;- (1 - sqrt(1 - 4*rho1^2))/(2*rho1) s2 &lt;- gms[1] / (1 + b^2) return(list(b=b, s2=s2)) } A &lt;- matrix(0, nrow=q, ncol=q) for(j in seq(2,q)){ A[j-1,j] &lt;- 1 } cc &lt;- numeric(q); cc[1] &lt;- 1 gamma0 &lt;- gms[1] gammas &lt;- numeric(q+k) gammas[1:(q+1)] &lt;- gms gamq &lt;- gms[-1] Gammak &lt;- matrix(0, nrow=k, ncol=k) for(ii in seq(k)){ for(jj in seq(k)){ Gammak[ii,jj] &lt;- gammas[abs(ii-jj)+1] } } Omk &lt;- matrix(0, nrow=q, ncol=k) for(ii in seq(q)){ for(jj in seq(k)){ Omk[ii,jj] &lt;- gammas[ii+jj-1+1] } } PI &lt;- Omk %*% solve(Gammak, t(Omk)) s2 &lt;- gamma0 - c(t(cc) %*% PI %*% cc) b &lt;- 1/s2 * c(gamq - A %*% PI %*% cc) return(list(b=b, s2=s2)) } ARMA理论谱密度图： arma.true.spectrum &lt;- function( a, b, ngrid=256, sigma=1, tit=&quot;True ARMA Spectral Density&quot;, plot.it=TRUE){ p &lt;- length(a) q &lt;- length(b) freqs &lt;- seq(from=0, to=pi, length=ngrid) spec1 &lt;- numeric(ngrid) spec2 &lt;- numeric(ngrid) for(ii in seq(ngrid)){ spec1[ii] &lt;- 1 + sum(complex(mod=b, arg=freqs[ii]*seq(q))) spec2[ii] &lt;- 1 - sum(complex(mod=a, arg=freqs[ii]*seq(p))) } spec = sigma^2 / (2*pi) * abs(spec1)^2 / abs(spec2)^2 if(plot.it){ plot(freqs, spec, type=&#39;l&#39;, main=tit, xlab=&quot;frequency&quot;, ylab=&quot;spectrum&quot;, axes=FALSE) axis(2) axis(1, at=(0:6)/6*pi, labels=c(0, expression(pi/6), expression(pi/3), expression(pi/2), expression(2*pi/3), expression(5*pi/6), expression(pi))) } box() invisible(list(frequencies=freqs, spectrum=spec, ar.coefficients=a, ma.coefficients=b, sigma=sigma)) } 从ARMA模型参数计算Wold系数， n是需要计算的个数： arma.Wold &lt;- function(n, a, b=numeric(0)){ p &lt;- length(a) q &lt;- length(b) arev &lt;- rev(a) psi &lt;- numeric(n) psi[1] &lt;- 1 for(j in seq(n-1)){ if(j &lt;= q) bj=b[j] else bj=0 psis &lt;- psi[max(1, j+1-p):j] np &lt;- length(psis) if(np &lt; p) psis &lt;- c(rep(0,p-np), psis) psi[j+1] &lt;- bj + sum(arev * psis) } psi } 给定ARMA模型参数， 利用Wold系数计算自协方差函数。 这里对Wold系数进行了截断， nw值越大， 使用的Wold系数越多， 结果越精确， 但计算量也越大。 事实上， 对\\(k \\geq q+1\\)， 可以用Yule-Walker方程递推计算\\(\\gamma_k\\)。 arma.gamma.by.Wold &lt;- function(n, a, b=numeric(0), sigma=1, nw=100){ nn &lt;- n + nw psi &lt;- arma.Wold(nn, a, b, nw=nw) gam &lt;- numeric(n) for(ii in seq(0, n-1)){ gam[ii+1] &lt;- sum(psi[1:(nn-ii)] * psi[(ii+1):nn]) } gam &lt;- (sigma^2) * gam gam } 用矩估计法求ARMA参数估计， MA部分用李雷的矩阵极限算法。 arma.solve &lt;- function(gms, p, q){ Gpq &lt;- matrix(0, nrow=p, ncol=p) for(ii in seq(p)) for(jj in seq(p)){ Gpq[ii,jj] &lt;- gms[abs(q + ii - jj)+1] } gs &lt;- gms[(q+1+1):(q+p+1)] a &lt;- solve(Gpq, gs) aa &lt;- c(-1, a) gys &lt;- numeric(q+1) for(k in seq(0, q)){ gys[k+1] &lt;- sum(c(outer(0:p,0:p, function(ii,jj) aa[ii+1] * aa[jj+1] * gms[abs(k+jj-ii)+1]))) } res &lt;- ma.solve(gys) b &lt;- res$b sigma &lt;- sqrt(res$s2) list(a=a, b=b, sigma=sigma) } ARMA模型矩估计法，其中MA部分用逆相关函数法的R程序： ## 用输入的$\\gamma_0, \\dots, \\gamma_p$求解AR(p)模型参数 ar.yw &lt;- function(gam){ p &lt;- length(gam) - 1 G &lt;- matrix(0, p, p) for(i in 1:p){ for(j in 1:p){ G[i,j] = gam[1 + abs(i-j)] } } gri &lt;- gam[-1] a &lt;- solve(G, gri) sig2 &lt;- sum(gam * c(1, -a)) list(ar = a, var.pred = sig2) } ## 从AR模型参数计算逆相关函数 ar_racv &lt;- function(a, sig2){ p &lt;- length(a) a &lt;- c(-1, a) a2 &lt;- c(a, numeric(p+1)) res &lt;- numeric(p+1) for(k in seq(0, p, by=1)){ res[k+1] &lt;- sum(a * a2[(k+1):(k+p+1)]) } res/sig2 } ## 用长阶自回归方法和逆相关函数方法估计MA模型 ma.solve.racv &lt;- function(x, q=1){ ## 拟合长阶自回归，用来估计逆自协方差函数 n &lt;- length(x) plar &lt;- round(sqrt(n)) if(plar &lt; q) plar &lt;- q mod1 &lt;- ar(x, aic = FALSE, order.max = plar, method=&quot;yule-walker&quot;) a &lt;- mod1$ar sigsq &lt;- mod1$var.pred gamr &lt;- ar_racv(a, sigsq)[1:(q+1)] res2 &lt;- ar.yw(gamr) b &lt;- -res2$ar sig2 &lt;- 1/res2$var.pred list(ma = b, var.pred = sig2) } ## 用矩估计法估计ARMA，其中MA部分用逆相关函数法 ## gms输入$\\gamma_k$, $k=0,1,\\dots,p+q$。 arma.moment.racv &lt;- function(x, p=1, q=1){ n &lt;- length(x) pmax &lt;- round(sqrt(n)) if(pmax &lt; p+q) pmax &lt;- p+q ## 计算样本自协方差函数 gms &lt;- c(acf(x, lag.max=pmax+p, type=&quot;covariance&quot;, plot=FALSE)$acf) ## 求解AR部分 Gpq &lt;- matrix(0, nrow=p, ncol=p) for(ii in seq(p)) for(jj in seq(p)){ Gpq[ii,jj] &lt;- gms[abs(q + ii - jj)+1] } gs &lt;- gms[(q+1+1):(q+p+1)] a &lt;- solve(Gpq, gs) aa &lt;- c(-1, a) ## 从已有的自协方差估计与AR参数估计，计算MA部分的$\\gamma_j, j=0,1,\\dots,pmax$。 gys &lt;- numeric(pmax+1) for(k in seq(0, pmax)){ gys[k+1] &lt;- sum(c(outer(0:p,0:p, function(ii,jj) aa[ii+1] * aa[jj+1] * gms[abs(k+jj-ii)+1]))) } ## 从MA部分的自协方差估计，拟合长阶自回归模型 res1 &lt;- ar.yw(gys) ## 求MA部分的逆相关函数 gamr &lt;- ar_racv(res1$ar, res1$var.pred)[1:(q+1)] ## 利用逆相关函数为输入求解YW方程，得到MA参数估计 res2 &lt;- ar.yw(gamr) b &lt;- -res2$ar sig2 &lt;- 1/res2$var.pred ##sig2 &lt;- gys[1] / sum(c(1, b)^2) list(ar=a, ma=b, var.pred=sig2) } 时间序列递推预测系数计算。 输入一个\\(n\\times n\\)矩阵表示序列非平稳， 输入为观测向量的协方差阵； 输入一个向量表示序列平稳， 输入为平稳列的自协方差函数值\\(\\gamma_0, \\gamma_1, \\dots, \\gamma_{n-1}\\)。 输出是用新息预报方法对\\(Y_1, Y_2, \\dots, Y_n\\)进行一步最佳线性预报的系数和均方误差。 结果为列表， 元素theta是\\((n-1) \\times (n-1)\\)矩阵， 第\\(k\\)行为预报\\(Y_{k+1}\\)的样本新息系数： \\[ \\hat Y_{k+1} = \\theta[k,1] \\cdot W_k + \\theta[k,2] \\cdot W_{k-1} + \\dots + \\theta[k,k] \\cdot W_1 \\] \\[ W_1=Y_1, W_k = Y_k - \\hat Y_k, k=2,3,\\dots,n . \\] 元素nu是\\(n\\)个预报均方误差， nu[k]是预报\\(Y_k\\)的均方误差。 ### 非平稳时间序列新息递推预测的系数和一步预测误差方差计算。 ### 输入： ### Gam --- 如果序列非平稳，为自协方差矩阵n*n ### 如果序列平稳，为自协方差列\\gamma_0, \\gamma_1, \\dots, \\gamma_{n-1} ### 输出： ### 用新息预报方法对Y_1, Y_2, \\dots, Y_n进行一步最佳线性预报的系数和均方误差。 ### theta -- (n-1)*(n-1)矩阵。第k行为预报Y_{k+1}的样本新息系数： ### \\hat Y_{k+1} = theta[k,1]*W_k + theta[k,2]*W_{k-1} + \\dots + theta[k,k]*W_1 ### W_1=Y_1, W_k = Y_k - \\hat Y_k, k=2,3,\\dots,n ### nu --- n个元素，nu[k]为预报Y_k的均方误差。 ts.ipred.coef &lt;- function(Gam){ if(!is.matrix(Gam)){ n &lt;- length(Gam) Gam &lt;- outer(1:n, 1:n, function(i,j) Gam[abs(i-j)+1]) } else { n &lt;- nrow(Gam) } ## X_1, X_2, \\dots, X_{n-1}的自协方差矩阵为Gam ## 新息预报递推 theta &lt;- matrix(0, n-1, n-1) nu &lt;- numeric(n) nu[1] &lt;- Gam[1,1] theta[1,1] &lt;- Gam[2,1] / Gam[1,1] nu[2] &lt;- Gam[2,2] - theta[1,1]^2 * nu[1] for(k in 2:(n-1)){ theta[k, k] &lt;- Gam[k+1,0+1] / nu[1] for(j in 1:(k-1)){ theta[k,k-j] &lt;- (Gam[k+1,j+1] - sum(theta[j, j:1]*theta[k,k:(k-j+1)]*nu[1:j])) / nu[j+1] } nu[k+1] &lt;- Gam[k+1,k+1] - sum(theta[k,k:1]^2 * nu[1:k]) } list(theta=theta, nu=nu) } 随时间序列进行递推预报(新息预报)， 假定已知自协方差列（平稳时）或自协方差阵（非平稳时）。 输入x是时间序列观测数据， 可以包含要预报的部分作为对比。 输入gams向量或矩阵。向量时为平稳序列的自协方差列， 矩阵时为非平稳时间序列的自协方差阵。 输入demean表示是否减去均值再预报。 输入end表示预报到哪个时间点， 这受到gams大小的限制，只能预报到与自协方差阵阶数相同的时间点。 conf是计算预测区间的置信度。 ts.ipred &lt;- function(x, gams, demean=FALSE, end=length(x), conf=0.95){ stationary &lt;- !is.matrix(gams) res1 &lt;- ts.ipred.coef(gams) theta &lt;- res1$theta nu &lt;- res1$nu if(demean) {xmean &lt;- mean(x); x &lt;- x - xmean} if(!stationary) end &lt;- length(nu) W &lt;- numeric(end) pred &lt;- numeric(end) lb &lt;- numeric(end) ub &lt;- numeric(end) lam &lt;- qnorm(1 - (1-conf)/2) pred[1] &lt;- 0 W[1] &lt;- x[1] for(n in 1:(end-1)){ pred[n+1] &lt;- sum(theta[n, n:1]*W[1:n]) W[n+1] &lt;- x[n+1] - pred[n+1] } lb &lt;- pred - lam*sqrt(nu[1:end]) ub &lt;- pred + lam*sqrt(nu[1:end]) if(demean){ pred &lt;- xmean + pred lb &lt;- xmean + lb ub &lt;- xmean + ub } list(x=x, pred=pred, lb=lb, ub=ub, conf=conf) } 对平稳列， 已知自协方差列时用Levinson递推计算逐个一步预报系数(Y-W系数)和一步预测误差方差。 输入gams[1:n] 为\\(\\gamma_k, k=0,1,\\dots,n-1\\)。 输出是对\\(Y_1, Y_2, \\dots, Y_{n}\\)做滚动向前一步预报所需的系数和均方误差。 结果中元素coef.YW是\\((n-1)\\times (n-1)\\)矩阵， 第\\(k\\)行的\\(1:k\\)元素为 \\(a_{k,1}, a_{k,2}, \\dots, a_{k,k}\\)， 用来预报\\(Y_{k+1}\\): \\[ L(Y_{k+1} | Y_1, Y_2, \\dots, Y_k) = a_{k,1} Y_{k} + a_{k,2} Y_{k-1} + \\dots + a_{k,k} Y_1, \\ k=1,2,\\dots,n-1 \\] \\[ L(Y_1| ) = 0 \\] 结果中sigmasq是长度为\\(n\\)的向量， 保存预报\\(Y_1, Y_2, \\dots, Y_n\\)的一步预报均方误差。 Levinson.coef &lt;- function(gams){ n &lt;- length(gams) ## ayw保存Y-W系数a[i,j], i=1,2,\\dots,n-1, j=1,2,\\dots,i ayw &lt;- matrix(0, n-1, n-1) ## ss保存一步预报误差方差 ss &lt;- numeric(n) ss[1] &lt;- gams[0+1] ## 预报Y_1的均方误差, 等于\\gamma_0 ayw[1,1] &lt;- gams[1+1] / gams[0+1] ## 用Y_1预报Y_2的系数 ss[2] &lt;- ss[1] * (1 - ayw[1,1]^2) ## 用Y_1预报Y_2的均方误差 if(n&gt;2) for(k in 1:(n-2)){ ## 用Y_1, \\dots, Y_{k+1}预报Y_{k+2}的系数 ayw[k+1,k+1] &lt;- (gams[(k+1)+1] - sum(ayw[k,1:k] * gams[(k:1)+1])) / ss[k+1] ayw[k+1,1:k] &lt;- ayw[k, 1:k] - ayw[k+1,k+1]*ayw[k, k:1] ## 用Y_1, \\dots, Y_{k+1}预报Y_{k+2}的均方误差 ss[k+2] &lt;- ss[k+1] * (1 - ayw[k+1,k+1]^2) } list(coef.YW=ayw, sigmasq=ss) } 对平稳列用Levinson计算一步预测系数(Yule-Walker系数)进行一步预测的程序。 设已知自协方差列。 输入x是平稳时间序列观测数据\\(X_1, \\dots, X_n\\)。 输入gams是理论自协方差列\\(\\gamma_0, \\gamma_1, \\dots, \\gamma_{m-1}\\), \\(m \\leq n\\)。 输入max.lag表示最多使用多少个历史值预报。 缺省使用所有历史值，或理论自协方差列个数减一。 输入end表示计算一步预测到第end时刻为止， 默认对每个时间点计算一步预测。 输入demean选择预报时是否中心化。 输入conf是计算一步预测区间时的置信度。 输出为一个列表， 元素x是输入的原始时间序列， pred是时间序列每个点的一步预报， 长度与x相同。 lb和ub是每个点的预测下限和上限。 sts.pred.levinson &lt;- function(x, gams, max.lag=length(gams)-1, end=length(x), demean=FALSE, conf=0.95){ n &lt;- length(x) m &lt;- length(gams) if(max.lag &gt; m-1){ msg &lt;- paste(&#39;可用最大历史长度&#39;, max.lag, &#39;大于可用理论自协方差个数减一&#39;, m-1) stop(msg) } if(demean) { xmean &lt;- mean(x) x[] &lt;- x - xmean } pred &lt;- numeric(end) lb &lt;- numeric(end) ub &lt;- numeric(end) lam &lt;- qnorm(1 - (1-conf)/2) res1 &lt;- Levinson.coef(gams) ayw &lt;- res1$coef.YW ## (m-1)*(m-1)矩阵，第k行用于k个历史进行一步预报。 ss &lt;- res1$sigmasq ## 长度为m的向量，第k个为用k-1个历史预报下一步的均方误差。 pred[1] &lt;- 0 for(k in seq(end-1)){ if(k &lt;= max.lag) { pred[k+1] &lt;- sum(ayw[k, 1:k] * x[k:1]) } else { pred[k+1] &lt;- sum(ayw[max.lag, 1:max.lag] * x[k:(k-max.lag+1)]) } } if(demean) pred[] &lt;- pred + xmean ss2 &lt;- c(ss[1:min(end,max.lag+1)], rep(ss[max.lag+1], end-min(end,max.lag+1))) lb[] &lt;- pred - lam*sqrt(ss2) ub[] &lt;- pred + lam*sqrt(ss2) list(x=x, pred=pred, lb=lb, ub=ub, conf=conf) } 周期图计算： direct.periodogram &lt;- function( y, freqs=seq(0,pi,length=101), demean=FALSE){ N &lt;- length(y) if(demean) y &lt;- y - mean(y) II &lt;- numeric(length(freqs)) for(j in seq(along=freqs)){ II[j] &lt;- 1/(2*pi*N)*Mod(sum(y * complex(mod=1, arg=freqs[j]*seq(1,N))))^2 } list(frequencies=freqs, spectrum=II) } Daniell加窗谱估计： spec.Daniell &lt;- function( y, freqs=seq(0,pi,length=101), M = round(2*sqrt(length(y))), demean=FALSE){ N &lt;- length(y) if(demean) y &lt;- y - mean(y) spec &lt;- numeric(length(freqs)) gams &lt;- c(acf(y, lag.max=N-1, type=&quot;covariance&quot;, plot=FALSE)$acf) jjs &lt;- seq(N-1) for(j in seq(along=freqs)) spec[j] &lt;- 1/(2*pi)*(gams[1] + 2*sum(gams[jjs+1] * ( sin(jjs*pi/M) / (jjs*pi/M) ) * cos(jjs*freqs[j]))) list(frequencies=freqs, spectrum=spec) } 33.5 谱密度估计 spec.pgram(x)计算周期图。 如： spec.pgram(xar4) spec.pgram()可以使用Daniel谱窗作加窗谱估计， 用spans给出两个奇数组成的向量作为参数， 表示窗宽。 如： spec.pgram(xar4, spans=c(3,5)) 注意结果的横轴是频率而不是角频率， 为了转换到角频率需要乘以\\(2\\pi\\)。 输入的模拟AR(4)模型的两个谱峰频率为： a &lt;- c(-0.9, -1.4, -0.7, -0.6) Arg(polyroot(c(1, -a)))/(2*pi) ## [1] 0.2370723 0.3511244 -0.3511244 -0.2370723 用spec.ar(x)可以做极大熵谱估计（用AR模型做谱估计）。 如： spec.ar(xar4) 因为数据是模拟的AR(4)， 估计的模型也是AR(4)， 所以效果很好。 33.6 GARCH类模型 待完成。 33.7 多元时间序列基础统计 待完成。 33.8 VAR模型 待完成。 33.9 协整分析 待完成。 33.10 因果性检验 待完成。 "],["stat-learning.html", "34 统计学习介绍 34.1 统计学习的基本概念和一般步骤 34.2 Hitters数据分析 34.3 Heart数据分析 34.4 汽车销量数据分析 34.5 波士顿郊区房价数据 34.6 支持向量机方法 34.7 附录", " 34 统计学习介绍 统计学习介绍的主要参考书: (James et al. 2013): Gareth James, Daniela Witten, Trevor Hastie, Robert Tibshirani(2013) An Introduction to Statistical Learning: with Applications in R, Springer. 调入需要的扩展包: library(leaps) # 全子集回归 library(ISLR) # 参考书对应的包 library(glmnet) # 岭回归和lasso ## 载入需要的程辑包：Matrix ## Warning: 程辑包&#39;Matrix&#39;是用R版本4.0.3 来建造的 ## Loaded glmnet 4.0-2 library(tree) # 树回归 library(randomForest) # 随机森林和装袋法 ## randomForest 4.6-14 ## Type rfNews() to see new features/changes/bug fixes. library(MASS) ## Warning: 程辑包&#39;MASS&#39;是用R版本4.0.3 来建造的 library(gbm) # boosting ## Loaded gbm 2.1.8 library(e1071) # svm ## Warning: 程辑包&#39;e1071&#39;是用R版本4.0.3 来建造的 34.1 统计学习的基本概念和一般步骤 34.1.1 统计学习的基本概念和方法 统计学习（statistical learning）， 也有数据挖掘（data mining），机器学习（machine learning）等称呼。 主要目的是用一些计算机算法从大量数据中发现知识。 方兴未艾的数据科学就以统计学习为重要支柱。 方法分为有监督（supervised）学习与无监督（unsupervised）学习。 无监督学习方法如聚类问题、购物篮问题、主成分分析等。 有监督学习即统计中回归分析和判别分析解决的问题， 现在又有树回归、树判别、随机森林、lasso、支持向量机、 神经网络、贝叶斯网络、排序算法等许多方法。 无监督学习在给了数据之后， 直接从数据中发现规律， 比如聚类分析是发现数据中的聚集和分组现象， 购物篮分析是从数据中找到更多的共同出现的条目 （比如购买啤酒的用户也有较大可能购买火腿肠）。 有监督学习方法众多。 通常，需要把数据分为训练样本和检验样本， 训练样本的因变量（数值型或分类型）是已知的， 根据训练样本中自变量和因变量的关系训练出一个回归函数， 此函数以自变量为输入， 可以输出因变量的预测值。 训练出的函数有可能是有简单表达式的（例如，logistic回归）、 有参数众多的表达式的（如神经网络）， 也有可能是依赖于所有训练样本而无法写出表达式的（例如k近邻分类）。 34.1.2 偏差与方差折衷 对回归问题，经常使用均方误差\\(E|Ey - \\hat y|^2\\)来衡量精度。 对分类问题，经常使用分类准确率等来衡量精度。 易见\\(E|Ey - \\hat y|^2 = \\text{Var}(\\hat y) + (E\\hat y - E y)^2\\)，所以均方误差可以分解为 \\[ \\text{均方误差} = \\text{方差} + \\text{偏差}^2, \\] 训练的回归函数如果仅考虑对训练样本解释尽可能好， 就会使得估计结果方差很大，在对检验样本进行计算时因方差大而导致很大的误差， 所以选取的回归函数应该尽可能简单。 如果选取的回归函数过于简单而实际上自变量与因变量关系比较复杂， 就会使得估计的回归函数偏差比较大， 这样在对检验样本进行计算时也会有比较大的误差。 所以，在有监督学习时， 回归函数的复杂程度是一个很关键的量， 太复杂和太简单都可能导致差的结果， 需要找到一个折衷的值。 复杂程度在线性回归中就是自变量个数， 在一元曲线拟合中就是曲线的不光滑程度。 在其它指标类似的情况下，简单的模型更稳定、可解释更好， 所以统计学特别重视模型的简化。 34.1.3 交叉验证 即使是在从训练样本中修炼（估计）回归函数时， 也需要适当地选择模型的复杂度。 仅考虑对训练数据的拟合程度是不够的， 这会造成过度拟合问题。 为了相对客观地度量模型的预报误差， 假设训练样本有\\(n\\)个观测， 可以留出第一个观测不用， 用剩余的\\(n-1\\)个观测建模，然后预测第一个观测的因变量值， 得到一个误差；对每个观测都这样做， 就可以得到\\(n\\)个误差。 这样的方法叫做留一法。 更常用的是五折或十折交叉验证。 假设训练集有\\(n\\)个观测， 将其均分成\\(10\\)分， 保留第一份不用， 将其余九份合并在一起用来建模，然后预报第一份； 对每一份都这样做， 也可以得到\\(n\\)个误差， 这叫做十折(ten-fold)交叉验证方法。 因为要预报的数据没有用来建模， 交叉验证得到的误差估计更准确。 34.1.4 一般步骤 一个有监督的统计学习项目， 大致上按如下步骤进行： 将数据拆分为训练集和测试集； 在训练集上比较不同的模型， 可以用交叉验证方法比较； 使用训练集上找到的最优模型， 对测试集进行测试； 在整个数据集上使用找到的最优模型， 但预测效果的指标使用测试集上得到的预测效果指标。 34.2 Hitters数据分析 考虑ISLR包的Hitters数据集。 此数据集有322个运动员的20个变量的数据， 其中的变量Salary（工资）是我们关心的。 变量包括: names(Hitters) ## [1] &quot;AtBat&quot; &quot;Hits&quot; &quot;HmRun&quot; &quot;Runs&quot; &quot;RBI&quot; &quot;Walks&quot; &quot;Years&quot; &quot;CAtBat&quot; &quot;CHits&quot; &quot;CHmRun&quot; &quot;CRuns&quot; &quot;CRBI&quot; &quot;CWalks&quot; &quot;League&quot; &quot;Division&quot; &quot;PutOuts&quot; &quot;Assists&quot; &quot;Errors&quot; &quot;Salary&quot; &quot;NewLeague&quot; 数据集的详细变量信息如下: str(Hitters) ## &#39;data.frame&#39;: 322 obs. of 20 variables: ## $ AtBat : int 293 315 479 496 321 594 185 298 323 401 ... ## $ Hits : int 66 81 130 141 87 169 37 73 81 92 ... ## $ HmRun : int 1 7 18 20 10 4 1 0 6 17 ... ## $ Runs : int 30 24 66 65 39 74 23 24 26 49 ... ## $ RBI : int 29 38 72 78 42 51 8 24 32 66 ... ## $ Walks : int 14 39 76 37 30 35 21 7 8 65 ... ## $ Years : int 1 14 3 11 2 11 2 3 2 13 ... ## $ CAtBat : int 293 3449 1624 5628 396 4408 214 509 341 5206 ... ## $ CHits : int 66 835 457 1575 101 1133 42 108 86 1332 ... ## $ CHmRun : int 1 69 63 225 12 19 1 0 6 253 ... ## $ CRuns : int 30 321 224 828 48 501 30 41 32 784 ... ## $ CRBI : int 29 414 266 838 46 336 9 37 34 890 ... ## $ CWalks : int 14 375 263 354 33 194 24 12 8 866 ... ## $ League : Factor w/ 2 levels &quot;A&quot;,&quot;N&quot;: 1 2 1 2 2 1 2 1 2 1 ... ## $ Division : Factor w/ 2 levels &quot;E&quot;,&quot;W&quot;: 1 2 2 1 1 2 1 2 2 1 ... ## $ PutOuts : int 446 632 880 200 805 282 76 121 143 0 ... ## $ Assists : int 33 43 82 11 40 421 127 283 290 0 ... ## $ Errors : int 20 10 14 3 4 25 7 9 19 0 ... ## $ Salary : num NA 475 480 500 91.5 750 70 100 75 1100 ... ## $ NewLeague: Factor w/ 2 levels &quot;A&quot;,&quot;N&quot;: 1 2 1 2 2 1 1 1 2 1 ... 希望以Salary为因变量，查看其缺失值个数: sum( is.na(Hitters$Salary) ) ## [1] 59 为简单起见，去掉有缺失值的观测： d &lt;- na.omit(Hitters); dim(d) ## [1] 263 20 34.2.1 回归自变量选择 34.2.1.1 最优子集选择 用leaps包的regsubsets()函数计算最优子集回归， 办法是对某个试验性的子集自变量个数\\(\\hat p\\)值， 都找到\\(\\hat p\\)固定情况下残差平方和最小的变量子集， 这样只要在这些不同\\(\\hat p\\)的最优子集中挑选就可以了。 挑选可以用AIC、BIC等方法。 可以先进行一个包含所有自变量的全集回归： regfit.full &lt;- regsubsets(Salary ~ ., data=d, nvmax=19) reg.summary &lt;- summary(regfit.full) reg.summary ## Subset selection object ## Call: regsubsets.formula(Salary ~ ., data = d, nvmax = 19) ## 19 Variables (and intercept) ## Forced in Forced out ## AtBat FALSE FALSE ## Hits FALSE FALSE ## HmRun FALSE FALSE ## Runs FALSE FALSE ## RBI FALSE FALSE ## Walks FALSE FALSE ## Years FALSE FALSE ## CAtBat FALSE FALSE ## CHits FALSE FALSE ## CHmRun FALSE FALSE ## CRuns FALSE FALSE ## CRBI FALSE FALSE ## CWalks FALSE FALSE ## LeagueN FALSE FALSE ## DivisionW FALSE FALSE ## PutOuts FALSE FALSE ## Assists FALSE FALSE ## Errors FALSE FALSE ## NewLeagueN FALSE FALSE ## 1 subsets of each size up to 19 ## Selection Algorithm: exhaustive ## AtBat Hits HmRun Runs RBI Walks Years CAtBat CHits CHmRun CRuns CRBI CWalks LeagueN DivisionW PutOuts Assists Errors NewLeagueN ## 1 ( 1 ) &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot;*&quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; ## 2 ( 1 ) &quot; &quot; &quot;*&quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot;*&quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; ## 3 ( 1 ) &quot; &quot; &quot;*&quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot;*&quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot;*&quot; &quot; &quot; &quot; &quot; &quot; &quot; ## 4 ( 1 ) &quot; &quot; &quot;*&quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot;*&quot; &quot; &quot; &quot; &quot; &quot;*&quot; &quot;*&quot; &quot; &quot; &quot; &quot; &quot; &quot; ## 5 ( 1 ) &quot;*&quot; &quot;*&quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot;*&quot; &quot; &quot; &quot; &quot; &quot;*&quot; &quot;*&quot; &quot; &quot; &quot; &quot; &quot; &quot; ## 6 ( 1 ) &quot;*&quot; &quot;*&quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot;*&quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot;*&quot; &quot; &quot; &quot; &quot; &quot;*&quot; &quot;*&quot; &quot; &quot; &quot; &quot; &quot; &quot; ## 7 ( 1 ) &quot; &quot; &quot;*&quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot;*&quot; &quot; &quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot;*&quot; &quot;*&quot; &quot; &quot; &quot; &quot; &quot; &quot; ## 8 ( 1 ) &quot;*&quot; &quot;*&quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot;*&quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot;*&quot; &quot;*&quot; &quot; &quot; &quot;*&quot; &quot; &quot; &quot;*&quot; &quot;*&quot; &quot; &quot; &quot; &quot; &quot; &quot; ## 9 ( 1 ) &quot;*&quot; &quot;*&quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot;*&quot; &quot; &quot; &quot;*&quot; &quot; &quot; &quot; &quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot; &quot; &quot;*&quot; &quot;*&quot; &quot; &quot; &quot; &quot; &quot; &quot; ## 10 ( 1 ) &quot;*&quot; &quot;*&quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot;*&quot; &quot; &quot; &quot;*&quot; &quot; &quot; &quot; &quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot; &quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot; &quot; &quot; &quot; ## 11 ( 1 ) &quot;*&quot; &quot;*&quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot;*&quot; &quot; &quot; &quot;*&quot; &quot; &quot; &quot; &quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot; &quot; &quot; &quot; ## 12 ( 1 ) &quot;*&quot; &quot;*&quot; &quot; &quot; &quot;*&quot; &quot; &quot; &quot;*&quot; &quot; &quot; &quot;*&quot; &quot; &quot; &quot; &quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot; &quot; &quot; &quot; ## 13 ( 1 ) &quot;*&quot; &quot;*&quot; &quot; &quot; &quot;*&quot; &quot; &quot; &quot;*&quot; &quot; &quot; &quot;*&quot; &quot; &quot; &quot; &quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot; &quot; ## 14 ( 1 ) &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot; &quot; &quot;*&quot; &quot; &quot; &quot;*&quot; &quot; &quot; &quot; &quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot; &quot; ## 15 ( 1 ) &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot; &quot; &quot;*&quot; &quot; &quot; &quot;*&quot; &quot;*&quot; &quot; &quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot; &quot; ## 16 ( 1 ) &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot; &quot; &quot;*&quot; &quot;*&quot; &quot; &quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot; &quot; ## 17 ( 1 ) &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot; &quot; &quot;*&quot; &quot;*&quot; &quot; &quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; ## 18 ( 1 ) &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot; &quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; ## 19 ( 1 ) &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; 这里用nvmax=指定了允许所有的自变量都参加， 缺省行为是限制最多个数的。 上述结果表格中每一行给出了固定\\(\\hat p\\)条件下的最优子集。 试比较这些最优模型的BIC值: reg.summary$bic ## [1] -90.84637 -128.92622 -135.62693 -141.80892 -144.07143 -147.91690 -145.25594 -147.61525 -145.44316 -143.21651 -138.86077 -133.87283 -128.77759 -123.64420 -118.21832 -112.81768 -107.35339 -101.86391 -96.30412 plot(reg.summary$bic) 图34.1: Hitters数据最优子集回归BIC 其中\\(\\hat p=6, 8\\)的值相近，都很低， 取\\(\\hat p=6\\)。 用coef()加id=6指定第六种子集： coef(regfit.full, id=6) ## (Intercept) AtBat Hits Walks CRBI DivisionW PutOuts ## 91.5117981 -1.8685892 7.6043976 3.6976468 0.6430169 -122.9515338 0.2643076 这种方法实现了选取BIC最小的自变量子集。 34.2.1.2 逐步回归方法 在用做了全集回归后， 把全集回归结果输入到函数中可以执行逐步回归。 如: lm.full &lt;- lm(Salary ~ ., data=d) print(summary(lm.full)) ## ## Call: ## lm(formula = Salary ~ ., data = d) ## ## Residuals: ## Min 1Q Median 3Q Max ## -907.62 -178.35 -31.11 139.09 1877.04 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 163.10359 90.77854 1.797 0.073622 . ## AtBat -1.97987 0.63398 -3.123 0.002008 ** ## Hits 7.50077 2.37753 3.155 0.001808 ** ## HmRun 4.33088 6.20145 0.698 0.485616 ## Runs -2.37621 2.98076 -0.797 0.426122 ## RBI -1.04496 2.60088 -0.402 0.688204 ## Walks 6.23129 1.82850 3.408 0.000766 *** ## Years -3.48905 12.41219 -0.281 0.778874 ## CAtBat -0.17134 0.13524 -1.267 0.206380 ## CHits 0.13399 0.67455 0.199 0.842713 ## CHmRun -0.17286 1.61724 -0.107 0.914967 ## CRuns 1.45430 0.75046 1.938 0.053795 . ## CRBI 0.80771 0.69262 1.166 0.244691 ## CWalks -0.81157 0.32808 -2.474 0.014057 * ## LeagueN 62.59942 79.26140 0.790 0.430424 ## DivisionW -116.84925 40.36695 -2.895 0.004141 ** ## PutOuts 0.28189 0.07744 3.640 0.000333 *** ## Assists 0.37107 0.22120 1.678 0.094723 . ## Errors -3.36076 4.39163 -0.765 0.444857 ## NewLeagueN -24.76233 79.00263 -0.313 0.754218 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 315.6 on 243 degrees of freedom ## Multiple R-squared: 0.5461, Adjusted R-squared: 0.5106 ## F-statistic: 15.39 on 19 and 243 DF, p-value: &lt; 2.2e-16 lm.step &lt;- step(lm.full) ## Start: AIC=3046.02 ## Salary ~ AtBat + Hits + HmRun + Runs + RBI + Walks + Years + ## CAtBat + CHits + CHmRun + CRuns + CRBI + CWalks + League + ## Division + PutOuts + Assists + Errors + NewLeague ## ## Df Sum of Sq RSS AIC ## - CHmRun 1 1138 24201837 3044.0 ## - CHits 1 3930 24204629 3044.1 ## - Years 1 7869 24208569 3044.1 ## - NewLeague 1 9784 24210484 3044.1 ## - RBI 1 16076 24216776 3044.2 ## - HmRun 1 48572 24249272 3044.6 ## - Errors 1 58324 24259023 3044.7 ## - League 1 62121 24262821 3044.7 ## - Runs 1 63291 24263990 3044.7 ## - CRBI 1 135439 24336138 3045.5 ## - CAtBat 1 159864 24360564 3045.8 ## &lt;none&gt; 24200700 3046.0 ## - Assists 1 280263 24480963 3047.1 ## - CRuns 1 374007 24574707 3048.1 ## - CWalks 1 609408 24810108 3050.6 ## - Division 1 834491 25035190 3052.9 ## - AtBat 1 971288 25171987 3054.4 ## - Hits 1 991242 25191941 3054.6 ## - Walks 1 1156606 25357305 3056.3 ## - PutOuts 1 1319628 25520328 3058.0 ## ## Step: AIC=3044.03 ## Salary ~ AtBat + Hits + HmRun + Runs + RBI + Walks + Years + ## CAtBat + CHits + CRuns + CRBI + CWalks + League + Division + ## PutOuts + Assists + Errors + NewLeague ## ## Df Sum of Sq RSS AIC ## - Years 1 7609 24209447 3042.1 ## - NewLeague 1 10268 24212106 3042.2 ## - CHits 1 14003 24215840 3042.2 ## - RBI 1 14955 24216793 3042.2 ## - HmRun 1 52777 24254614 3042.6 ## - Errors 1 59530 24261367 3042.7 ## - League 1 63407 24265244 3042.7 ## - Runs 1 64860 24266698 3042.7 ## - CAtBat 1 174992 24376830 3043.9 ## &lt;none&gt; 24201837 3044.0 ## - Assists 1 285766 24487603 3045.1 ## - CRuns 1 611358 24813196 3048.6 ## - CWalks 1 645627 24847464 3049.0 ## - Division 1 834637 25036474 3050.9 ## - CRBI 1 864220 25066057 3051.3 ## - AtBat 1 970861 25172699 3052.4 ## - Hits 1 1025981 25227819 3052.9 ## - Walks 1 1167378 25369216 3054.4 ## - PutOuts 1 1325273 25527110 3056.1 ## ## Step: AIC=3042.12 ## Salary ~ AtBat + Hits + HmRun + Runs + RBI + Walks + CAtBat + ## CHits + CRuns + CRBI + CWalks + League + Division + PutOuts + ## Assists + Errors + NewLeague ## ## Df Sum of Sq RSS AIC ## - NewLeague 1 9931 24219377 3040.2 ## - RBI 1 15989 24225436 3040.3 ## - CHits 1 18291 24227738 3040.3 ## - HmRun 1 54144 24263591 3040.7 ## - Errors 1 57312 24266759 3040.7 ## - Runs 1 63172 24272619 3040.8 ## - League 1 65732 24275178 3040.8 ## &lt;none&gt; 24209447 3042.1 ## - CAtBat 1 266205 24475652 3043.0 ## - Assists 1 293479 24502926 3043.3 ## - CRuns 1 646350 24855797 3047.1 ## - CWalks 1 649269 24858716 3047.1 ## - Division 1 827511 25036958 3049.0 ## - CRBI 1 872121 25081568 3049.4 ## - AtBat 1 968713 25178160 3050.4 ## - Hits 1 1018379 25227825 3050.9 ## - Walks 1 1164536 25373983 3052.5 ## - PutOuts 1 1334525 25543972 3054.2 ## ## Step: AIC=3040.22 ## Salary ~ AtBat + Hits + HmRun + Runs + RBI + Walks + CAtBat + ## CHits + CRuns + CRBI + CWalks + League + Division + PutOuts + ## Assists + Errors ## ## Df Sum of Sq RSS AIC ## - RBI 1 15800 24235177 3038.4 ## - CHits 1 15859 24235237 3038.4 ## - Errors 1 54505 24273883 3038.8 ## - HmRun 1 54938 24274316 3038.8 ## - Runs 1 62294 24281671 3038.9 ## - League 1 107479 24326856 3039.4 ## &lt;none&gt; 24219377 3040.2 ## - CAtBat 1 261336 24480713 3041.1 ## - Assists 1 295536 24514914 3041.4 ## - CWalks 1 648860 24868237 3045.2 ## - CRuns 1 661449 24880826 3045.3 ## - Division 1 824672 25044049 3047.0 ## - CRBI 1 880429 25099806 3047.6 ## - AtBat 1 999057 25218434 3048.9 ## - Hits 1 1034463 25253840 3049.2 ## - Walks 1 1157205 25376583 3050.5 ## - PutOuts 1 1335173 25554550 3052.3 ## ## Step: AIC=3038.4 ## Salary ~ AtBat + Hits + HmRun + Runs + Walks + CAtBat + CHits + ## CRuns + CRBI + CWalks + League + Division + PutOuts + Assists + ## Errors ## ## Df Sum of Sq RSS AIC ## - CHits 1 13483 24248660 3036.5 ## - HmRun 1 44586 24279763 3036.9 ## - Runs 1 54057 24289234 3037.0 ## - Errors 1 57656 24292833 3037.0 ## - League 1 108644 24343821 3037.6 ## &lt;none&gt; 24235177 3038.4 ## - CAtBat 1 252756 24487934 3039.1 ## - Assists 1 294674 24529851 3039.6 ## - CWalks 1 639690 24874868 3043.2 ## - CRuns 1 693535 24928712 3043.8 ## - Division 1 808984 25044161 3045.0 ## - CRBI 1 893830 25129008 3045.9 ## - Hits 1 1034884 25270061 3047.4 ## - AtBat 1 1042798 25277975 3047.5 ## - Walks 1 1145013 25380191 3048.5 ## - PutOuts 1 1340713 25575890 3050.6 ## ## Step: AIC=3036.54 ## Salary ~ AtBat + Hits + HmRun + Runs + Walks + CAtBat + CRuns + ## CRBI + CWalks + League + Division + PutOuts + Assists + Errors ## ## Df Sum of Sq RSS AIC ## - HmRun 1 40487 24289148 3035.0 ## - Errors 1 51930 24300590 3035.1 ## - Runs 1 79343 24328003 3035.4 ## - League 1 114742 24363402 3035.8 ## &lt;none&gt; 24248660 3036.5 ## - Assists 1 283442 24532103 3037.6 ## - CAtBat 1 613356 24862016 3041.1 ## - Division 1 801474 25050134 3043.1 ## - CRBI 1 903248 25151908 3044.2 ## - CWalks 1 1011953 25260613 3045.3 ## - Walks 1 1246164 25494824 3047.7 ## - AtBat 1 1339620 25588280 3048.7 ## - CRuns 1 1390808 25639469 3049.2 ## - PutOuts 1 1406023 25654684 3049.4 ## - Hits 1 1607990 25856650 3051.4 ## ## Step: AIC=3034.98 ## Salary ~ AtBat + Hits + Runs + Walks + CAtBat + CRuns + CRBI + ## CWalks + League + Division + PutOuts + Assists + Errors ## ## Df Sum of Sq RSS AIC ## - Errors 1 44085 24333232 3033.5 ## - Runs 1 49068 24338215 3033.5 ## - League 1 103837 24392985 3034.1 ## &lt;none&gt; 24289148 3035.0 ## - Assists 1 247002 24536150 3035.6 ## - CAtBat 1 652746 24941894 3040.0 ## - Division 1 795643 25084791 3041.5 ## - CWalks 1 982896 25272044 3043.4 ## - Walks 1 1205823 25494971 3045.7 ## - AtBat 1 1300972 25590120 3046.7 ## - CRuns 1 1351200 25640348 3047.2 ## - CRBI 1 1353507 25642655 3047.2 ## - PutOuts 1 1429006 25718154 3048.0 ## - Hits 1 1574140 25863288 3049.5 ## ## Step: AIC=3033.46 ## Salary ~ AtBat + Hits + Runs + Walks + CAtBat + CRuns + CRBI + ## CWalks + League + Division + PutOuts + Assists ## ## Df Sum of Sq RSS AIC ## - Runs 1 54113 24387345 3032.0 ## - League 1 91269 24424501 3032.4 ## &lt;none&gt; 24333232 3033.5 ## - Assists 1 220010 24553242 3033.8 ## - CAtBat 1 650513 24983746 3038.4 ## - Division 1 799455 25132687 3040.0 ## - CWalks 1 971260 25304493 3041.8 ## - Walks 1 1239533 25572765 3044.5 ## - CRBI 1 1331672 25664904 3045.5 ## - CRuns 1 1361070 25694302 3045.8 ## - AtBat 1 1378592 25711824 3045.9 ## - PutOuts 1 1391660 25724892 3046.1 ## - Hits 1 1649291 25982523 3048.7 ## ## Step: AIC=3032.04 ## Salary ~ AtBat + Hits + Walks + CAtBat + CRuns + CRBI + CWalks + ## League + Division + PutOuts + Assists ## ## Df Sum of Sq RSS AIC ## - League 1 113056 24500402 3031.3 ## &lt;none&gt; 24387345 3032.0 ## - Assists 1 280689 24668034 3033.1 ## - CAtBat 1 596622 24983967 3036.4 ## - Division 1 780369 25167714 3038.3 ## - CWalks 1 946687 25334032 3040.1 ## - Walks 1 1212997 25600342 3042.8 ## - CRuns 1 1334397 25721742 3044.1 ## - CRBI 1 1361339 25748684 3044.3 ## - PutOuts 1 1455210 25842555 3045.3 ## - AtBat 1 1522760 25910105 3046.0 ## - Hits 1 1718870 26106215 3047.9 ## ## Step: AIC=3031.26 ## Salary ~ AtBat + Hits + Walks + CAtBat + CRuns + CRBI + CWalks + ## Division + PutOuts + Assists ## ## Df Sum of Sq RSS AIC ## &lt;none&gt; 24500402 3031.3 ## - Assists 1 313650 24814051 3032.6 ## - CAtBat 1 534156 25034558 3034.9 ## - Division 1 798473 25298875 3037.7 ## - CWalks 1 965875 25466276 3039.4 ## - CRuns 1 1265082 25765484 3042.5 ## - Walks 1 1290168 25790569 3042.8 ## - CRBI 1 1326770 25827172 3043.1 ## - PutOuts 1 1551523 26051925 3045.4 ## - AtBat 1 1589780 26090181 3045.8 ## - Hits 1 1716068 26216469 3047.1 print(lm.step) ## ## Call: ## lm(formula = Salary ~ AtBat + Hits + Walks + CAtBat + CRuns + ## CRBI + CWalks + Division + PutOuts + Assists, data = d) ## ## Coefficients: ## (Intercept) AtBat Hits Walks CAtBat CRuns CRBI CWalks DivisionW PutOuts Assists ## 162.5354 -2.1687 6.9180 5.7732 -0.1301 1.4082 0.7743 -0.8308 -112.3801 0.2974 0.2832 最后保留了10个自变量。 34.2.1.3 划分训练集与测试集 在整个数据集中随机选取一部分作为训练集，其余作为测试集。 下面的程序把原始数据一分为二： set.seed(1) train &lt;- sample(nrow(d), size = round(nrow(d)/2)) test &lt;- -train 仅用训练集估计模型。 为了在测试集上用模型进行预报并估计预测均方误差， 需要自己写一个预测函数： predict.regsubsets &lt;- function(object, newdata, id, ...){ form &lt;- as.formula(object$call[[2]]) mat &lt;- model.matrix(form, newdata) coefi &lt;- coef(object, id=id) xvars &lt;- names(coefi) mat[, xvars] %*% coefi } 然后，对每个子集大小，用最优子集在测试集上进行预报， 计算均方误差： regfit.best &lt;- regsubsets( Salary ~ ., data=d[train,], nvmax=19 ) val.errors &lt;- rep(as.numeric(NA), 19) for(i in 1:19){ #pred &lt;- predict.regsubsets(regfit.best, newdata=d[test,], id=i) pred &lt;- predict(regfit.best, newdata=d[test,], id=i) val.errors[i] &lt;- mean( (d[test, &#39;Salary&#39;] - pred)^2 ) } print(val.errors) ## [1] 188190.9 163306.2 152365.0 164857.0 152100.7 147120.0 148833.0 155546.5 167429.2 169949.1 173607.9 173039.5 168450.4 169300.5 169139.3 173575.1 175216.2 175080.2 175057.5 best.id &lt;- which.min(val.errors); best.id ## [1] 6 用测试集得到的最优子集大小为6。 模型子集和回归系数为: coef(regfit.best, id=best.id) ## (Intercept) Walks CAtBat CHits CHmRun DivisionW PutOuts ## 179.4442609 4.1205817 -0.5508342 2.1670021 2.3479409 -126.3067258 0.1840943 34.2.1.4 用10折交叉验证方法选择最优子集 下列程序对数据中每一行分配一个折号： k &lt;- 10 set.seed(1) folds &lt;- sample(1:k, nrow(d), replace=TRUE) 下面，对10折中每一折都分别当作测试集一次， 得到不同子集大小的均方误差： cv.errors &lt;- matrix( as.numeric(NA), k, 19, dimnames=list(NULL, paste(1:19)) ) for(j in 1:k){ # 对 best.fit &lt;- regsubsets(Salary ~ ., data=d[folds != j,], nvmax=19) for(i in 1:19){ pred &lt;- predict( best.fit, d[folds==j,], id=i) cv.errors[j, i] &lt;- mean( (d[folds==j, &#39;Salary&#39;] - pred)^2 ) } } head(cv.errors) ## 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 ## [1,] 98623.24 115600.61 120884.31 113831.63 120728.51 122922.93 155507.25 137753.36 149198.01 153332.89 155702.91 155842.88 158755.87 156037.17 157739.46 155548.96 156688.01 156860.92 156976.98 ## [2,] 155320.11 100425.87 168838.35 159729.47 145895.71 123555.25 119983.35 96609.16 99057.32 80375.78 91290.74 92292.69 100498.84 101562.45 104621.38 100922.27 102198.69 105318.26 106064.89 ## [3,] 124151.77 68833.50 69392.29 77221.37 83802.82 70125.41 68997.77 64143.70 65813.14 65120.27 68160.94 70263.77 69765.81 68987.54 69471.32 69294.21 69199.91 68866.84 69195.74 ## [4,] 232191.41 279001.29 294568.10 288765.81 276972.83 260121.22 276413.09 259923.88 270151.18 263492.31 259154.53 269017.80 265468.90 269666.65 265518.87 267240.44 267771.74 267670.66 267717.80 ## [5,] 115397.35 96807.44 108421.66 104933.55 99561.69 86103.05 89345.61 87693.15 91631.88 88763.37 89801.07 91070.44 92429.43 92821.15 95849.81 96513.70 95209.20 94952.21 94951.70 ## [6,] 103839.30 75652.50 69962.31 58291.91 65893.45 64215.56 65800.88 61413.45 60200.70 59599.54 59831.90 60081.48 59662.51 60618.91 62540.03 62776.81 62717.77 62354.97 62268.97 cv.errors是一个\\(10\\times 19\\)矩阵， 每行对应一折作为测试集的情形， 每列是一个子集大小， 元素值是测试均方误差。 对每列的10个元素求平均， 可以得到每个子集大小的平均均方误差: mean.cv.errors &lt;- apply(cv.errors, 2, mean) mean.cv.errors ## 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 ## 149821.1 130922.0 139127.0 131028.8 131050.2 119538.6 124286.1 113580.0 115556.5 112216.7 113251.2 115755.9 117820.8 119481.2 120121.6 120074.3 120084.8 120085.8 120403.5 best.id &lt;- which.min(mean.cv.errors) plot(mean.cv.errors, type=&#39;b&#39;) 图34.2: Hitters数据CV均方误差 这样找到的最优子集大小是10。 用这种方法找到最优子集大小后， 可以对全数据集重新建模但是选择最优子集大小为10: reg.best &lt;- regsubsets(Salary ~ ., data=d, nvmax=19) coef(reg.best, id=best.id) ## (Intercept) AtBat Hits Walks CAtBat CRuns CRBI CWalks DivisionW PutOuts Assists ## 162.5354420 -2.1686501 6.9180175 5.7732246 -0.1300798 1.4082490 0.7743122 -0.8308264 -112.3800575 0.2973726 0.2831680 事实上， 划分训练集和验证集与交叉验证方法经常联合运用。 取一个固定的较小规模的测试集， 此测试集不用来作子集选择， 对训练集用交叉验证方法选择最优子集， 然后再测试集上验证。 34.2.2 岭回归 当自变量个数太多时，模型复杂度高， 可能有过度拟合， 模型不稳定。 一种方法是对较大的模型系数施加二次惩罚， 把最小二乘问题变成带有二次惩罚项的惩罚最小二乘问题： \\[\\begin{aligned} \\min\\; \\sum_{i=1}^n \\left( y_i - \\beta_0 - \\beta_1 x_{i1} - \\dots - \\beta_p x_{ip} \\right)^2 + \\lambda \\sum_{j=1}^p \\beta_j^2 . \\end{aligned}\\] 这比通常最小二乘得到的回归系数绝对值变小， 但是求解的稳定性增加了，避免了共线问题。 实际上, 与线性模型\\(\\boldsymbol Y = \\boldsymbol X \\boldsymbol\\beta + \\boldsymbol\\varepsilon\\) 的普通最小二乘解 \\(\\hat{\\boldsymbol\\beta} = (\\boldsymbol X^T \\boldsymbol X)^{-1} \\boldsymbol X^T \\boldsymbol Y\\) 相比， 岭回归问题的解为 \\[ \\tilde{\\boldsymbol\\beta} = (\\boldsymbol X^T \\boldsymbol X + s \\boldsymbol I)^{-1} \\boldsymbol X^T \\boldsymbol Y \\] 其中\\(\\boldsymbol I\\)为单位阵，\\(s&gt;0\\)与\\(\\lambda\\)有关。 \\(\\lambda\\)称为调节参数，\\(\\lambda\\)越大，相当于模型复杂度越低。 适当选择\\(\\lambda\\)可以在方差与偏差之间找到适当的折衷， 从而减小预测误差。 由于量纲问题，在不同自变量不可比时，数据集应该进行标准化。 用R的glmnet包计算岭回归。 用glmnet()函数， 指定参数alpha=0时执行的是岭回归。 用参数lambda=指定一个调节参数网格， 岭回归将在这些调节参数上计算。 用coef()从回归结果中取得不同调节参数对应的回归系数估计， 结果是一个矩阵，每列对应于一个调节参数。 仍采用上面去掉了缺失值的Hitters数据集结果d。 如下程序把回归的设计阵与因变量提取出来： x &lt;- model.matrix(Salary ~ ., d)[,-1] y &lt;- d$Salary 岭回归涉及到调节参数\\(\\lambda\\)的选择， 为了绘图， 先选择\\(\\lambda\\)的一个网格： grid &lt;- 10^seq(10, -2, length=100) 用所有数据针对这样的调节参数网格计算岭回归结果， 注意glmnet()函数允许调节参数\\(\\lambda\\)输入多个值： ridge.mod &lt;- glmnet(x, y, alpha=0, lambda=grid) dim(coef(ridge.mod)) ## [1] 20 100 glmnet()函数默认对数据进行标准化。 coef()的结果是一个矩阵，每列对应一个调节参数值。 34.2.2.1 划分训练集与测试集 如下程序把数据分为一半训练、一半测试： set.seed(1) train &lt;- sample(nrow(x), size = nrow(x)/2) test &lt;- (-train) y.test &lt;- y[test] 仅用测试集建立岭回归： ridge.mod &lt;- glmnet(x[train,], y[train], alpha=0, lambda=grid, thresh=1E-12) 用建立的模型对测试集进行预测，并计算调节参数等于4时的均方误差： ridge.pred &lt;- predict( ridge.mod, s=4, newx=x[test,] ) mean( (ridge.pred - y.test)^2 ) ## [1] 142199.2 如果用因变量平均值作预测， 这是最差的预测： mean( (mean(y[train]) - y.test)^2 ) ## [1] 224669.9 \\(\\lambda=4\\)的结果要好得多。 事实上，取\\(\\lambda\\)接近正无穷时模型就相当于用因变量平均值预测。 取\\(\\lambda=0\\)就相当于普通最小二乘回归（但是glmnet()是对输入数据要做标准化的）。 34.2.2.2 用10折交叉验证选取调节参数 仍使用训练集， 但训练集再进行交叉验证。 cv.glmnet()函数可以执行交叉验证。 set.seed(1) cv.out &lt;- cv.glmnet(x[train,], y[train], alpha=0) plot(cv.out) 图34.3: Hitters数据岭回归参数选择 bestlam &lt;- cv.out$lambda.min 这样获得了最优调节参数\\(\\lambda=\\) 326.0827885。 用最优调节参数对测试集作预测， 得到预测均方误差： ridge.pred &lt;- predict(ridge.mod, s=bestlam, newx=x[test,]) mean( (ridge.pred - y.test)^2 ) ## [1] 139856.6 结果比\\(\\lambda=4\\)略有改进。 最后，用选取的最优调节系数对全数据集建模， 得到相应的岭回归系数估计： out &lt;- glmnet(x, y, alpha=0) predict(out, type=&#39;coefficients&#39;, s=bestlam)[1:20,] ## (Intercept) AtBat Hits HmRun Runs RBI Walks Years CAtBat CHits CHmRun CRuns CRBI CWalks LeagueN DivisionW PutOuts Assists Errors NewLeagueN ## 15.44383135 0.07715547 0.85911581 0.60103107 1.06369007 0.87936105 1.62444616 1.35254780 0.01134999 0.05746654 0.40680157 0.11456224 0.12116504 0.05299202 22.09143189 -79.04032637 0.16619903 0.02941950 -1.36092945 9.12487767 34.2.3 Lasso回归 另一种对回归系数的惩罚是\\(L_1\\)惩罚： \\[\\begin{align} \\min\\; \\sum_{i=1}^n \\left( y_i - \\beta_0 - \\beta_1 x_{i1} - \\dots - \\beta_p x_{ip} \\right)^2 + \\lambda \\sum_{j=1}^p |\\beta_j| . \\tag{34.1} \\end{align}\\] 奇妙地是，适当选择调节参数\\(\\lambda\\)，可以使得部分回归系数变成零， 达到了即减小回归系数的绝对值又挑选重要变量子集的效果。 事实上，(34.1)等价于约束最小值问题 \\[\\begin{aligned} &amp; \\min\\; \\sum_{i=1}^n \\left( y_i - \\beta_0 - \\beta_1 x_{i1} - \\dots - \\beta_p x_{ip} \\right)^2 \\quad \\text{s.t.} \\\\ &amp; \\sum_{j=1}^p |\\beta_j| \\leq s \\end{aligned}\\] 其中\\(s\\)与\\(\\lambda\\)一一对应。 这样的约束区域是带有顶点的凸集， 而目标函数是二次函数， 最小值点经常在约束区域顶点达到， 这些顶点是某些坐标等于零的点。 见图34.4。 knitr::include_graphics(&quot;figs/lasso-min.png&quot;) 图34.4: Lasso约束优化问题图示 对于每个调节参数\\(\\lambda\\)， 都应该解出(34.1)的相应解， 记为\\(\\hat{\\boldsymbol\\beta}(\\lambda)\\)。 幸运的是， 不需要对每个\\(\\lambda\\)去解最小值问题(34.1)， 存在巧妙的算法使得问题的计算量与求解一次最小二乘相仿。 通常选取\\(\\lambda\\)的格子点，计算相应的惩罚回归系数。 用交叉验证方法估计预测的均方误差。 选取使得交叉验证均方误差最小的调节参数（一般R函数中已经作为选项）。 用R的glmnet包计算lasso。 用glmnet()函数， 指定参数alpha=1时执行的是lasso。 用参数lambda=指定一个调节参数网格， lasso将输出这些调节参数对应的结果。 对回归结果使用plot()函数可以画出调节参数变化时系数估计的变化情况。 仍使用gmlnet包的glmnet()函数计算Lasso回归， 指定一个调节参数网格（沿用前面的网格）： lasso.mod &lt;- glmnet(x[train,], y[train], alpha=1, lambda=grid) plot(lasso.mod) ## Warning in regularize.values(x, y, ties, missing(ties), na.rm = na.rm): collapsing to unique &#39;x&#39; values 图34.5: Hitters数据lasso轨迹 对lasso结果使用plot()函数可以绘制延调节参数网格变化的各回归系数估计，横坐标不是调节参数而是调节参数对应的系数绝对值和， 可以看出随着系数绝对值和增大，实际是调节参数变小， 更多地自变量进入模型。 34.2.3.1 用交叉验证估计调节参数 按照前面划分的训练集与测试集， 仅使用训练集数据做交叉验证估计最优调节参数： set.seed(1) cv.out &lt;- cv.glmnet(x[train,], y[train], alpha=1) plot(cv.out) bestlam &lt;- cv.out$lambda.min; bestlam ## [1] 9.286955 得到调节参数估计后，对测试集计算预测均方误差： lasso.pred &lt;- predict(lasso.mod, s=bestlam, newx=x[test,]) mean( (lasso.pred - y.test)^2 ) ## [1] 143673.6 这个效果比岭回归效果略差。 为了充分利用数据， 使用前面获得的最优调节参数， 对全数据集建模： out &lt;- glmnet(x, y, alpha=1, lambda=grid) lasso.coef &lt;- predict(out, type=&#39;coefficients&#39;, s=bestlam)[1:20,]; lasso.coef ## (Intercept) AtBat Hits HmRun Runs RBI Walks Years CAtBat CHits CHmRun CRuns CRBI CWalks LeagueN DivisionW PutOuts Assists Errors NewLeagueN ## 1.27479059 -0.05497143 2.18034583 0.00000000 0.00000000 0.00000000 2.29192406 -0.33806109 0.00000000 0.00000000 0.02825013 0.21628385 0.41712537 0.00000000 20.28615023 -116.16755870 0.23752385 0.00000000 -0.85629148 0.00000000 lasso.coef[lasso.coef != 0] ## (Intercept) AtBat Hits Walks Years CHmRun CRuns CRBI LeagueN DivisionW PutOuts Errors ## 1.27479059 -0.05497143 2.18034583 2.29192406 -0.33806109 0.02825013 0.21628385 0.41712537 20.28615023 -116.16755870 0.23752385 -0.85629148 选择的自变量子集有11个自变量。 34.2.4 树回归的简单演示 决策树方法按不同自变量的不同值， 分层地把训练集分组。 每层使用一个变量， 所以这样的分组构成一个二叉树表示。 为了预测一个观测的类归属， 找到它所属的组， 用组的类归属或大多数观测的类归属进行预测。 这样的方法称为决策树(decision tree)。 决策树方法既可以用于判别问题， 也可以用于回归问题，称为回归树。 决策树的好处是容易解释， 在自变量为分类变量时没有额外困难。 但预测准确率可能比其它有监督学习方法差。 改进方法包括装袋法(bagging)、随机森林(random forests)、 提升法(boosting)。 这些改进方法都是把许多棵树合并在一起， 通常能改善准确率但是可解释性变差。 对Hitters数据，用Years和Hits作因变量预测log(Salaray)。 仅取Hitters数据集的Salary, Years, Hits三个变量， 并仅保留完全观测： d &lt;- na.omit(Hitters[,c(&#39;Salary&#39;, &#39;Years&#39;, &#39;Hits&#39;)]) print(str(d)) ## &#39;data.frame&#39;: 263 obs. of 3 variables: ## $ Salary: num 475 480 500 91.5 750 ... ## $ Years : int 14 3 11 2 11 2 3 2 13 10 ... ## $ Hits : int 81 130 141 87 169 37 73 81 92 159 ... ## - attr(*, &quot;na.action&quot;)= &#39;omit&#39; Named int 1 16 19 23 31 33 37 39 40 42 ... ## ..- attr(*, &quot;names&quot;)= chr &quot;-Andy Allanson&quot; &quot;-Billy Beane&quot; &quot;-Bruce Bochte&quot; &quot;-Bob Boone&quot; ... ## NULL 建立完整的树: tr1 &lt;- tree(log(Salary) ~ Years + Hits, data=d) 剪枝为只有3个叶结点: tr1b &lt;- prune.tree(tr1, best=3) 显示树: print(tr1b) ## node), split, n, deviance, yval ## * denotes terminal node ## ## 1) root 263 207.20 5.927 ## 2) Years &lt; 4.5 90 42.35 5.107 * ## 3) Years &gt; 4.5 173 72.71 6.354 ## 6) Hits &lt; 117.5 90 28.09 5.998 * ## 7) Hits &gt; 117.5 83 20.88 6.740 * 显示概括: print(summary(tr1b)) ## ## Regression tree: ## snip.tree(tree = tr1, nodes = c(6L, 2L)) ## Number of terminal nodes: 3 ## Residual mean deviance: 0.3513 = 91.33 / 260 ## Distribution of residuals: ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## -2.24000 -0.39580 -0.03162 0.00000 0.33380 2.55600 做树图: plot(tr1b); text(tr1b, pretty=0) 34.2.5 树回归 把数据随机地分成一半训练集，一半测试集： d &lt;- na.omit(Hitters) set.seed(1) train &lt;- sample(nrow(d), size=round(nrow(d)/2)) test &lt;- (-train) 对训练集，建立未剪枝的树： tr1 &lt;- tree(log(Salary) ~ ., data=d, subset=train) plot(tr1); text(tr1, pretty=0) 图34.6: Hitters数据训练集未剪枝树 对训练集上的未剪枝树用交叉验证方法寻找最优大小： cv1 &lt;- cv.tree(tr1) print(cv1) ## $size ## [1] 8 7 6 5 4 3 2 1 ## ## $dev ## [1] 44.55223 44.45312 44.57906 44.53469 46.93001 54.03823 57.53660 105.17743 ## ## $k ## [1] -Inf 1.679266 1.750440 1.836204 3.300858 6.230249 7.420672 56.727362 ## ## $method ## [1] &quot;deviance&quot; ## ## attr(,&quot;class&quot;) ## [1] &quot;prune&quot; &quot;tree.sequence&quot; plot(cv1$size, cv1$dev, type=&#39;b&#39;) best.size &lt;- cv1$size[which.min(cv1$dev)[1]] abline(v=best.size, col=&#39;gray&#39;) 最优大小为7。 获得训练集上构造的树剪枝后的结果： best.size &lt;- 4 tr1b &lt;- prune.tree(tr1, best=best.size) 在测试集上计算预测均方误差: pred.test &lt;- predict(tr1b, newdata=d[test,]) test.mse &lt;- mean( (d[test, &#39;Salary&#39;] - exp(pred.test))^2 ) test.mse ## [1] 128224.1 如果用训练集的因变量平均值估计测试集的因变量值， 均方误差为: worst.mse &lt;- mean( (d[test, &#39;Salary&#39;] - mean(d[train, &#39;Salary&#39;]))^2 ) worst.mse ## [1] 224692.1 用所有数据来构造未剪枝树： tr2 &lt;- tree(log(Salary) ~ ., data=d) 用训练集上得到的子树大小剪枝： tr2b &lt;- prune.tree(tr2, best=best.size) plot(tr2b); text(tr2b, pretty=0) 34.2.6 装袋法 判别树在不同的训练集、测试集划分上可以产生很大变化， 说明其预测值方差较大。 利用bootstrap的思想， 可以随机选取许多个训练集， 把许多个训练集的模型结果平均， 就可以降低预测值的方差。 办法是从一个训练集中用有放回抽样的方法抽取\\(B\\)个训练集， 设第\\(b\\)个抽取的训练集得到的回归函数为\\(\\hat f^{*b}(\\cdot)\\), 则最后的回归函数是这些回归函数的平均值: \\[\\begin{aligned} \\hat f_{\\text{bagging}}(x) = \\frac{1}{B} \\sum_{b=1}^b \\hat f^{*b}(x) \\end{aligned}\\] 这称为装袋法(bagging)。 装袋法对改善判别与回归树的精度十分有效。 装袋法的步骤如下： 从训练集中取\\(B\\)个有放回随机抽样的bootstrap训练集，\\(B\\)取为几百到几千之间。 对每个bootstrap训练集，估计未剪枝的树。 如果因变量是连续变量，对测试样品，用所有的树的预测值的平均值作预测。 如果因变量是分类变量，对测试样品，可以用所有树预测类的多数投票决定预测值。 装袋法也可以用来改进其他的回归和判别方法。 装袋后不能再用图形表示，模型可解释性较差。 但是，可以度量自变量在预测中的重要程度。 在回归问题中， 可以计算每个自变量在所有\\(B\\)个树种平均减少的残差平方和的量， 以此度量其重要度。 在判别问题中， 可以计算每个自变量在所有\\(B\\)个树种平均减少的基尼系数的量， 以此度量其重要度。 除了可以用测试集、交叉验证方法以外， 还可以使用袋外观测预测误差。 用bootstrap再抽样获得多个训练集时每个bootstrap训练集总会遗漏一些观测， 平均每个bootstrap训练集会遗漏三分之一的观测。 对每个观测，大约有\\(B/3\\)棵树没有用到此观测， 可以用这些树的预测值平均来预测此观测，得到一个误差估计， 这样得到的均方误差估计或错判率称为袋外观测估计（OOB估计）。 好处是不用很多额外的工作。 对训练集用装袋法： bag1 &lt;- randomForest(log(Salary) ~ ., data=d, subset=train, mtry=ncol(d)-1, importance=TRUE) bag1 ## ## Call: ## randomForest(formula = log(Salary) ~ ., data = d, mtry = ncol(d) - 1, importance = TRUE, subset = train) ## Type of random forest: regression ## Number of trees: 500 ## No. of variables tried at each split: 19 ## ## Mean of squared residuals: 0.2549051 ## % Var explained: 67.32 注意randomForest()函数实际是随机森林法， 但是当mtry的值取为所有自变量个数时就是装袋法。 对测试集进行预报: pred2 &lt;- predict(bag1, newdata=d[test,]) test.mse2 &lt;- mean( (d[test, &#39;Salary&#39;] - exp(pred2))^2 ) test.mse2 ## [1] 89851.48 结果与剪枝过的单课树相近。 在全集上使用装袋法： bag2 &lt;- randomForest(log(Salary) ~ ., data=d, mtry=ncol(d)-1, importance=TRUE) bag2 ## ## Call: ## randomForest(formula = log(Salary) ~ ., data = d, mtry = ncol(d) - 1, importance = TRUE) ## Type of random forest: regression ## Number of trees: 500 ## No. of variables tried at each split: 19 ## ## Mean of squared residuals: 0.1894008 ## % Var explained: 75.95 变量的重要度数值和图形： 各变量的重要度数值及其图形： importance(bag2) ## %IncMSE IncNodePurity ## AtBat 10.4186792 8.9315248 ## Hits 8.0033436 7.5938472 ## HmRun 3.6180992 1.9689157 ## Runs 7.2586283 3.9341954 ## RBI 5.9223739 5.9201328 ## Walks 7.6449979 6.6988173 ## Years 9.4732817 2.2977104 ## CAtBat 28.2381456 84.4338845 ## CHits 13.8405414 26.2455674 ## CHmRun 6.7109109 3.8246805 ## CRuns 13.6067783 29.1340423 ## CRBI 14.1694017 10.9852537 ## CWalks 7.7656943 4.1725799 ## League -1.0964577 0.2146176 ## Division 0.5534057 0.2307037 ## PutOuts 0.3157195 4.1169655 ## Assists -1.7730978 1.6599765 ## Errors 2.3420783 1.6852796 ## NewLeague -0.3091532 0.3747445 varImpPlot(bag2) 图34.7: Hitters数据装袋法的变量重要性结果 最重要的自变量是CAtBats, 其次有CRuns, CHits等。 34.2.7 随机森林 随机森林的思想与装袋法类似， 但是试图使得参加平均的各个树之间变得比较独立。 仍采用有放回抽样得到的多个bootstrap训练集， 但是对每个bootstrap训练集构造判别树时， 每次分叉时不考虑所有自变量， 而是仅考虑随机选取的一个自变量子集。 对判别树，每次分叉时选取的自变量个数通常取\\(m \\approx \\sqrt{p}\\)个。 比如，对Heart数据的13个自变量， 每次分叉时仅随机选取4个纳入考察范围。 随机森林的想法是基于正相关的样本在平均时并不能很好地降低方差， 独立样本能比较好地降低方差。 如果存在一个最重要的变量， 如果不加限制这个最重要的变量总会是第一个分叉， 使得\\(B\\)棵树相似程度很高。 随机森林解决这个问题的办法是限制分叉时可选的变量子集。 随机森林也可以用来改进其他的回归和判别方法。 装袋法和随机森林都可以用R扩展包randomForest的 randomForest()函数实现。 当此函数的mtry参数取为自变量个数时，执行的就是装袋法； mtry取缺省值时，执行随机森林算法。 执行随机森林算法时， randomForest()函数在回归问题时分叉时考虑的自变量个数取\\(m \\approx p/3\\)， 在判别问题时取\\(m \\approx \\sqrt{p}\\)。 对训练集用随机森林法： rf1 &lt;- randomForest(log(Salary) ~ ., data=d, subset=train, importance=TRUE) rf1 ## ## Call: ## randomForest(formula = log(Salary) ~ ., data = d, importance = TRUE, subset = train) ## Type of random forest: regression ## Number of trees: 500 ## No. of variables tried at each split: 6 ## ## Mean of squared residuals: 0.2422914 ## % Var explained: 68.94 当mtry的值取为缺省值时执行随机森林算法。 对测试集进行预报: pred3 &lt;- predict(rf1, newdata=d[test,]) test.mse3 &lt;- mean( (d[test, &#39;Salary&#39;] - exp(pred3))^2 ) test.mse3 ## [1] 95455.53 结果与剪枝过的单课树、装袋法相近。 在全集上使用随机森林： rf2 &lt;- randomForest(log(Salary) ~ ., data=d, importance=TRUE) rf2 ## ## Call: ## randomForest(formula = log(Salary) ~ ., data = d, importance = TRUE) ## Type of random forest: regression ## Number of trees: 500 ## No. of variables tried at each split: 6 ## ## Mean of squared residuals: 0.1789257 ## % Var explained: 77.28 各变量的重要度数值及其图形： importance(rf2) ## %IncMSE IncNodePurity ## AtBat 10.1010786 7.6235571 ## Hits 8.3614365 7.9201425 ## HmRun 3.7354302 2.4553471 ## Runs 7.9446786 4.6566217 ## RBI 6.6246470 6.0251832 ## Walks 8.8848565 5.9901840 ## Years 11.3153391 8.4097999 ## CAtBat 18.0377154 41.0851904 ## CHits 17.5110322 37.8686798 ## CHmRun 8.4476983 6.9078686 ## CRuns 14.8793512 30.8423409 ## CRBI 14.8308800 20.5339522 ## CWalks 9.7578555 14.9467745 ## League -0.6619015 0.3041459 ## Division -0.3583808 0.2954341 ## PutOuts 2.4366422 3.4901980 ## Assists -0.0965240 1.8105096 ## Errors 1.5007791 1.7068960 ## NewLeague 1.0593259 0.3453514 varImpPlot(rf2) 图34.8: Hitters数据随机森林法的变量重要度结果 最重要的自变量是CAtBats, CRuns, CHits, CWalks, CRBI等。 34.3 Heart数据分析 Heart数据是心脏病诊断的数据， 因变量AHD为是否有心脏病， 试图用各个自变量预测（判别）。 读入Heart数据集，并去掉有缺失值的观测： Heart &lt;- read.csv( &#39;Heart.csv&#39;, header=TRUE, row.names=1, stringsAsFactors=TRUE) Heart &lt;- na.omit(Heart) str(Heart) ## &#39;data.frame&#39;: 297 obs. of 14 variables: ## $ Age : int 63 67 67 37 41 56 62 57 63 53 ... ## $ Sex : int 1 1 1 1 0 1 0 0 1 1 ... ## $ ChestPain: Factor w/ 4 levels &quot;asymptomatic&quot;,..: 4 1 1 2 3 3 1 1 1 1 ... ## $ RestBP : int 145 160 120 130 130 120 140 120 130 140 ... ## $ Chol : int 233 286 229 250 204 236 268 354 254 203 ... ## $ Fbs : int 1 0 0 0 0 0 0 0 0 1 ... ## $ RestECG : int 2 2 2 0 2 0 2 0 2 2 ... ## $ MaxHR : int 150 108 129 187 172 178 160 163 147 155 ... ## $ ExAng : int 0 1 1 0 0 0 0 1 0 1 ... ## $ Oldpeak : num 2.3 1.5 2.6 3.5 1.4 0.8 3.6 0.6 1.4 3.1 ... ## $ Slope : int 3 2 2 3 1 1 3 1 2 3 ... ## $ Ca : int 0 3 2 0 0 0 2 0 1 0 ... ## $ Thal : Factor w/ 3 levels &quot;fixed&quot;,&quot;normal&quot;,..: 1 2 3 2 2 2 2 2 3 3 ... ## $ AHD : Factor w/ 2 levels &quot;No&quot;,&quot;Yes&quot;: 1 2 2 1 1 1 2 1 2 2 ... ## - attr(*, &quot;na.action&quot;)= &#39;omit&#39; Named int [1:6] 88 167 193 267 288 303 ## ..- attr(*, &quot;names&quot;)= chr [1:6] &quot;88&quot; &quot;167&quot; &quot;193&quot; &quot;267&quot; ... t(summary(Heart)) ## ## Age Min. :29.00 1st Qu.:48.00 Median :56.00 Mean :54.54 3rd Qu.:61.00 Max. :77.00 ## Sex Min. :0.0000 1st Qu.:0.0000 Median :1.0000 Mean :0.6768 3rd Qu.:1.0000 Max. :1.0000 ## ChestPain asymptomatic:142 nonanginal : 83 nontypical : 49 typical : 23 ## RestBP Min. : 94.0 1st Qu.:120.0 Median :130.0 Mean :131.7 3rd Qu.:140.0 Max. :200.0 ## Chol Min. :126.0 1st Qu.:211.0 Median :243.0 Mean :247.4 3rd Qu.:276.0 Max. :564.0 ## Fbs Min. :0.0000 1st Qu.:0.0000 Median :0.0000 Mean :0.1448 3rd Qu.:0.0000 Max. :1.0000 ## RestECG Min. :0.0000 1st Qu.:0.0000 Median :1.0000 Mean :0.9966 3rd Qu.:2.0000 Max. :2.0000 ## MaxHR Min. : 71.0 1st Qu.:133.0 Median :153.0 Mean :149.6 3rd Qu.:166.0 Max. :202.0 ## ExAng Min. :0.0000 1st Qu.:0.0000 Median :0.0000 Mean :0.3266 3rd Qu.:1.0000 Max. :1.0000 ## Oldpeak Min. :0.000 1st Qu.:0.000 Median :0.800 Mean :1.056 3rd Qu.:1.600 Max. :6.200 ## Slope Min. :1.000 1st Qu.:1.000 Median :2.000 Mean :1.603 3rd Qu.:2.000 Max. :3.000 ## Ca Min. :0.0000 1st Qu.:0.0000 Median :0.0000 Mean :0.6768 3rd Qu.:1.0000 Max. :3.0000 ## Thal fixed : 18 normal :164 reversable:115 ## AHD No :160 Yes:137 数据下载：Heart.csv 34.3.1 树回归 34.3.1.1 划分训练集与测试集 简单地把观测分为一半训练集、一半测试集： set.seed(1) train &lt;- sample(nrow(Heart), size=round(nrow(Heart)/2)) test &lt;- (-train) test.y &lt;- Heart[test, &#39;AHD&#39;] 在训练集上建立未剪枝的判别树: tr1 &lt;- tree(AHD ~ ., data=Heart[train,]) plot(tr1); text(tr1, pretty=0) 34.3.1.2 适当剪枝 用交叉验证方法确定剪枝保留的叶子个数，剪枝时按照错判率执行： cv1 &lt;- cv.tree(tr1, FUN=prune.misclass) cv1 ## $size ## [1] 12 9 6 4 2 1 ## ## $dev ## [1] 42 44 47 44 57 69 ## ## $k ## [1] -Inf 0.000000 1.666667 3.000000 7.000000 26.000000 ## ## $method ## [1] &quot;misclass&quot; ## ## attr(,&quot;class&quot;) ## [1] &quot;prune&quot; &quot;tree.sequence&quot; plot(cv1$size, cv1$dev, type=&#39;b&#39;, xlab=&#39;size&#39;, ylab=&#39;dev&#39;) best.size &lt;- cv1$size[which.min(cv1$dev)] 最优的大小是12。但是从图上看，4个叶结点已经足够好，所以取为4。 对训练集生成剪枝结果： best.size &lt;- 4 tr1b &lt;- prune.misclass(tr1, best=best.size) plot(tr1b); text(tr1b, pretty=0) 图34.9: Heart数据回归树 注意剪枝后树的显示中， 内部节点的自变量存在分类变量， 这时按照这个自变量分叉时， 取指定的某几个分类值时对应分支Yes， 取其它的分类值时对应分支No。 34.3.1.3 对测试集计算误判率 pred1 &lt;- predict(tr1b, Heart[test,], type=&#39;class&#39;) tab1 &lt;- table(pred1, test.y); tab1 ## test.y ## pred1 No Yes ## No 56 17 ## Yes 21 55 test.err &lt;- (tab1[1,2]+tab1[2,1])/sum(tab1[]); test.err ## [1] 0.2550336 对测试集的错判率约26%。 利用未剪枝的树对测试集进行预测, 一般比剪枝后的结果差: pred1a &lt;- predict(tr1, Heart[test,], type=&#39;class&#39;) tab1a &lt;- table(pred1a, test.y); tab1a ## test.y ## pred1a No Yes ## No 58 21 ## Yes 19 51 test.err1a &lt;- (tab1a[1,2]+tab1a[2,1])/sum(tab1a[]); test.err1a ## [1] 0.2684564 34.3.1.4 利用全集数据建立剪枝判别树 tr2 &lt;- tree(AHD ~ ., data=Heart) tr2b &lt;- prune.misclass(tr2, best=best.size) plot(tr2b); text(tr2b, pretty=0) 34.3.2 用装袋法 对训练集用装袋法： bag1 &lt;- randomForest(AHD ~ ., data=Heart, subset=train, mtry=13, importance=TRUE) bag1 ## ## Call: ## randomForest(formula = AHD ~ ., data = Heart, mtry = 13, importance = TRUE, subset = train) ## Type of random forest: classification ## Number of trees: 500 ## No. of variables tried at each split: 13 ## ## OOB estimate of error rate: 22.3% ## Confusion matrix: ## No Yes class.error ## No 71 12 0.1445783 ## Yes 21 44 0.3230769 注意randomForest()函数实际是随机森林法， 但是当mtry的值取为所有自变量个数时就是装袋法。 袋外观测得到的错判率比较差。 对测试集进行预报: pred2 &lt;- predict(bag1, newdata=Heart[test,]) tab2 &lt;- table(pred2, test.y); tab2 ## test.y ## pred2 No Yes ## No 66 17 ## Yes 11 55 test.err2 &lt;- (tab2[1,2]+tab2[2,1])/sum(tab2[]); test.err2 ## [1] 0.1879195 测试集的错判率约为19%。 对全集用装袋法: bag1b &lt;- randomForest(AHD ~ ., data=Heart, mtry=13, importance=TRUE) bag1b ## ## Call: ## randomForest(formula = AHD ~ ., data = Heart, mtry = 13, importance = TRUE) ## Type of random forest: classification ## Number of trees: 500 ## No. of variables tried at each split: 13 ## ## OOB estimate of error rate: 19.87% ## Confusion matrix: ## No Yes class.error ## No 134 26 0.1625000 ## Yes 33 104 0.2408759 各变量的重要度数值及其图形： importance(bag1b) ## No Yes MeanDecreaseAccuracy MeanDecreaseGini ## Age 5.01743888 4.54672209 6.8901260 11.8781808 ## Sex 10.62273160 5.93775833 11.8960286 3.8780605 ## ChestPain 12.12215333 18.01109966 21.4561091 24.2519995 ## RestBP 2.14912897 2.57544213 3.4350095 9.5279960 ## Chol -0.06740331 -3.34866905 -2.1319263 11.4615191 ## Fbs -0.19159212 -1.68286268 -1.2936067 0.6356754 ## RestECG -0.83204215 0.61823420 -0.1523007 1.8873928 ## MaxHR 6.95927941 -0.04284863 5.1956114 12.9777185 ## ExAng 2.15397190 4.67398101 4.8112183 3.5598518 ## Oldpeak 16.87683151 14.03391494 21.3056979 14.6968413 ## Slope 2.97366941 5.17314908 6.1189587 4.0774248 ## Ca 25.14524607 18.28904993 28.9768557 20.2200459 ## Thal 18.69773426 17.80713339 24.8961726 27.9615428 varImpPlot(bag1b) 最重要的变量是Thal, ChestPain, Ca。 34.3.3 用随机森林 对训练集用随机森林法： rf1 &lt;- randomForest(AHD ~ ., data=Heart, subset=train, importance=TRUE) rf1 ## ## Call: ## randomForest(formula = AHD ~ ., data = Heart, importance = TRUE, subset = train) ## Type of random forest: classification ## Number of trees: 500 ## No. of variables tried at each split: 3 ## ## OOB estimate of error rate: 21.62% ## Confusion matrix: ## No Yes class.error ## No 72 11 0.1325301 ## Yes 21 44 0.3230769 这里mtry取缺省值，对应于随机森林法。 对测试集进行预报: pred3 &lt;- predict(rf1, newdata=Heart[test,]) tab3 &lt;- table(pred3, test.y); tab3 ## test.y ## pred3 No Yes ## No 69 16 ## Yes 8 56 test.err3 &lt;- (tab3[1,2]+tab3[2,1])/sum(tab3[]); test.err3 ## [1] 0.1610738 测试集的错判率约为16%。 对全集用随机森林: rf1b &lt;- randomForest(AHD ~ ., data=Heart, importance=TRUE) rf1b ## ## Call: ## randomForest(formula = AHD ~ ., data = Heart, importance = TRUE) ## Type of random forest: classification ## Number of trees: 500 ## No. of variables tried at each split: 3 ## ## OOB estimate of error rate: 17.85% ## Confusion matrix: ## No Yes class.error ## No 138 22 0.1375000 ## Yes 31 106 0.2262774 各变量的重要度数值及其图形： importance(rf1b) ## No Yes MeanDecreaseAccuracy MeanDecreaseGini ## Age 6.647195 5.9142590 8.8592250 12.961695 ## Sex 12.271439 6.6415765 14.3610223 4.523229 ## ChestPain 11.068166 17.1308734 18.9981168 18.522923 ## RestBP 1.965647 0.2372161 1.7415606 10.555002 ## Chol 1.809381 -1.9169726 0.1992495 11.260342 ## Fbs 1.554259 -2.3732219 -0.4023229 1.368904 ## RestECG 1.160775 2.1910276 2.1228412 2.748856 ## MaxHR 10.136446 6.7175368 12.0958262 17.994290 ## ExAng 2.163296 8.7559583 8.0681465 7.536690 ## Oldpeak 12.115693 11.8649191 16.9461505 15.307598 ## Slope 3.082837 8.6440416 8.5035252 6.512301 ## Ca 21.461418 18.1222940 25.5933528 17.283850 ## Thal 19.599715 16.7413930 24.2539786 18.925007 varImpPlot(rf1b) 图34.10: Heart数据随机森林方法得到的变量重要度 最重要的变量是ChestPain, Thal, Ca。 34.4 汽车销量数据分析 Carseats是ISLR包的一个数据集，基本情况如下: {rstatl-car-summ01, cache=TRUE} str(Carseats) summary(Carseats) 把Salses变量按照大于8与否分成两组， 结果存入变量High，以High为因变量作判别分析。 d &lt;- na.omit(Carseats) d$High &lt;- factor(ifelse(d$Sales &gt; 8, &#39;Yes&#39;, &#39;No&#39;)) dim(d) ## [1] 400 12 34.4.1 判别树 34.4.1.1 全体数据的判别树 对全体数据建立未剪枝的判别树: tr1 &lt;- tree(High ~ . - Sales, data=d) summary(tr1) ## ## Classification tree: ## tree(formula = High ~ . - Sales, data = d) ## Variables actually used in tree construction: ## [1] &quot;ShelveLoc&quot; &quot;Price&quot; &quot;Income&quot; &quot;CompPrice&quot; &quot;Population&quot; &quot;Advertising&quot; &quot;Age&quot; &quot;US&quot; ## Number of terminal nodes: 27 ## Residual mean deviance: 0.4575 = 170.7 / 373 ## Misclassification error rate: 0.09 = 36 / 400 plot(tr1) text(tr1, pretty=0) 34.4.1.2 划分训练集和测试集 把输入数据集随机地分一半当作训练集，另一半当作测试集： set.seed(2) train &lt;- sample(nrow(d), size=round(nrow(d)/2)) test &lt;- (-train) test.high &lt;- d[test, &#39;High&#39;] 用训练数据建立未剪枝的判别树: tr2 &lt;- tree(High ~ . - Sales, data=d, subset=train) summary(tr2) ## ## Classification tree: ## tree(formula = High ~ . - Sales, data = d, subset = train) ## Variables actually used in tree construction: ## [1] &quot;Price&quot; &quot;Population&quot; &quot;ShelveLoc&quot; &quot;Age&quot; &quot;Education&quot; &quot;CompPrice&quot; &quot;Advertising&quot; &quot;Income&quot; &quot;US&quot; ## Number of terminal nodes: 21 ## Residual mean deviance: 0.5543 = 99.22 / 179 ## Misclassification error rate: 0.115 = 23 / 200 plot(tr2) text(tr2, pretty=0) 用未剪枝的树对测试集进行预测，并计算误判率： pred2 &lt;- predict(tr2, d[test,], type=&#39;class&#39;) tab &lt;- table(pred2, test.high); tab ## test.high ## pred2 No Yes ## No 104 33 ## Yes 13 50 test.err2 &lt;- (tab[1,2] + tab[2,1]) / sum(tab[]); test.err2 ## [1] 0.23 34.4.1.3 用交叉验证确定训练集的剪枝 set.seed(3) cv1 &lt;- cv.tree(tr2, FUN=prune.misclass) cv1 ## $size ## [1] 21 19 14 9 8 5 3 2 1 ## ## $dev ## [1] 74 76 81 81 75 77 78 85 81 ## ## $k ## [1] -Inf 0.0 1.0 1.4 2.0 3.0 4.0 9.0 18.0 ## ## $method ## [1] &quot;misclass&quot; ## ## attr(,&quot;class&quot;) ## [1] &quot;prune&quot; &quot;tree.sequence&quot; plot(cv1$size, cv1$dev, type=&#39;b&#39;) best.size &lt;- cv1$size[which.min(cv1$dev)] 用交叉验证方法自动选择的最佳树大小为21。 剪枝: tr3 &lt;- prune.misclass(tr2, best=best.size) summary(tr3) ## ## Classification tree: ## tree(formula = High ~ . - Sales, data = d, subset = train) ## Variables actually used in tree construction: ## [1] &quot;Price&quot; &quot;Population&quot; &quot;ShelveLoc&quot; &quot;Age&quot; &quot;Education&quot; &quot;CompPrice&quot; &quot;Advertising&quot; &quot;Income&quot; &quot;US&quot; ## Number of terminal nodes: 21 ## Residual mean deviance: 0.5543 = 99.22 / 179 ## Misclassification error rate: 0.115 = 23 / 200 plot(tr3) text(tr3, pretty=0) 用剪枝后的树对测试集进行预测，计算误判率： pred3 &lt;- predict(tr3, d[test,], type=&#39;class&#39;) tab &lt;- table(pred3, test.high); tab ## test.high ## pred3 No Yes ## No 104 32 ## Yes 13 51 test.err3 &lt;- (tab[1,2] + tab[2,1]) / sum(tab[]); test.err3 ## [1] 0.225 34.4.2 随机森林 对训练集用随机森林法： rf4 &lt;- randomForest(High ~ . - Sales, data=d, subset=train, importance=TRUE) rf4 ## ## Call: ## randomForest(formula = High ~ . - Sales, data = d, importance = TRUE, subset = train) ## Type of random forest: classification ## Number of trees: 500 ## No. of variables tried at each split: 3 ## ## OOB estimate of error rate: 25.5% ## Confusion matrix: ## No Yes class.error ## No 102 17 0.1428571 ## Yes 34 47 0.4197531 这里mtry取缺省值，对应于随机森林法。 对测试集进行预报: pred4 &lt;- predict(rf4, newdata=d[test,]) tab &lt;- table(pred4, test.high); tab ## test.high ## pred4 No Yes ## No 109 24 ## Yes 8 59 test.err4 &lt;- (tab[1,2]+tab[2,1])/sum(tab[]); test.err4 ## [1] 0.16 注意错判率结果依赖于训练集和测试集的划分， 另行选择训练集与测试集可能会得到很不一样的错判率结果。 对全集用随机森林: rf5 &lt;- randomForest(High ~ . - Sales, data=d, importance=TRUE) rf5 ## ## Call: ## randomForest(formula = High ~ . - Sales, data = d, importance = TRUE) ## Type of random forest: classification ## Number of trees: 500 ## No. of variables tried at each split: 3 ## ## OOB estimate of error rate: 18% ## Confusion matrix: ## No Yes class.error ## No 214 22 0.09322034 ## Yes 50 114 0.30487805 各变量的重要度数值及其图形： importance(rf5) ## No Yes MeanDecreaseAccuracy MeanDecreaseGini ## CompPrice 9.853176 7.84106962 12.3403571 21.895753 ## Income 3.901345 5.95859870 6.6820994 19.708699 ## Advertising 10.859513 16.36240814 19.1737947 22.799306 ## Population -1.788738 -3.80236686 -4.1421409 15.366835 ## Price 31.040118 27.34118336 37.7942812 43.588084 ## ShelveLoc 31.493614 34.00428243 40.3330521 30.992966 ## Age 9.033102 9.70947568 12.2385591 22.352854 ## Education 1.829310 -0.01953518 1.4315544 10.190089 ## Urban 0.193837 -1.09027048 -0.4997192 2.243931 ## US 2.182323 6.29992327 6.0770295 3.542851 varImpPlot(rf5) 图34.11: Carseats数据随机森林法得到的变量重要度 重要的自变量为Price, ShelfLoc, 其次有Age, Advertising, CompPrice, Income等。 34.5 波士顿郊区房价数据 MASS包的Boston数据包含了波士顿地区郊区房价的若干数据。 以中位房价medv为因变量建立回归模型。 首先把缺失值去掉后存入数据集d: d &lt;- na.omit(Boston) 数据集概况： str(d) ## &#39;data.frame&#39;: 506 obs. of 14 variables: ## $ crim : num 0.00632 0.02731 0.02729 0.03237 0.06905 ... ## $ zn : num 18 0 0 0 0 0 12.5 12.5 12.5 12.5 ... ## $ indus : num 2.31 7.07 7.07 2.18 2.18 2.18 7.87 7.87 7.87 7.87 ... ## $ chas : int 0 0 0 0 0 0 0 0 0 0 ... ## $ nox : num 0.538 0.469 0.469 0.458 0.458 0.458 0.524 0.524 0.524 0.524 ... ## $ rm : num 6.58 6.42 7.18 7 7.15 ... ## $ age : num 65.2 78.9 61.1 45.8 54.2 58.7 66.6 96.1 100 85.9 ... ## $ dis : num 4.09 4.97 4.97 6.06 6.06 ... ## $ rad : int 1 2 2 3 3 3 5 5 5 5 ... ## $ tax : num 296 242 242 222 222 222 311 311 311 311 ... ## $ ptratio: num 15.3 17.8 17.8 18.7 18.7 18.7 15.2 15.2 15.2 15.2 ... ## $ black : num 397 397 393 395 397 ... ## $ lstat : num 4.98 9.14 4.03 2.94 5.33 ... ## $ medv : num 24 21.6 34.7 33.4 36.2 28.7 22.9 27.1 16.5 18.9 ... summary(d) ## crim zn indus chas nox rm age dis rad tax ptratio black lstat medv ## Min. : 0.00632 Min. : 0.00 Min. : 0.46 Min. :0.00000 Min. :0.3850 Min. :3.561 Min. : 2.90 Min. : 1.130 Min. : 1.000 Min. :187.0 Min. :12.60 Min. : 0.32 Min. : 1.73 Min. : 5.00 ## 1st Qu.: 0.08204 1st Qu.: 0.00 1st Qu.: 5.19 1st Qu.:0.00000 1st Qu.:0.4490 1st Qu.:5.886 1st Qu.: 45.02 1st Qu.: 2.100 1st Qu.: 4.000 1st Qu.:279.0 1st Qu.:17.40 1st Qu.:375.38 1st Qu.: 6.95 1st Qu.:17.02 ## Median : 0.25651 Median : 0.00 Median : 9.69 Median :0.00000 Median :0.5380 Median :6.208 Median : 77.50 Median : 3.207 Median : 5.000 Median :330.0 Median :19.05 Median :391.44 Median :11.36 Median :21.20 ## Mean : 3.61352 Mean : 11.36 Mean :11.14 Mean :0.06917 Mean :0.5547 Mean :6.285 Mean : 68.57 Mean : 3.795 Mean : 9.549 Mean :408.2 Mean :18.46 Mean :356.67 Mean :12.65 Mean :22.53 ## 3rd Qu.: 3.67708 3rd Qu.: 12.50 3rd Qu.:18.10 3rd Qu.:0.00000 3rd Qu.:0.6240 3rd Qu.:6.623 3rd Qu.: 94.08 3rd Qu.: 5.188 3rd Qu.:24.000 3rd Qu.:666.0 3rd Qu.:20.20 3rd Qu.:396.23 3rd Qu.:16.95 3rd Qu.:25.00 ## Max. :88.97620 Max. :100.00 Max. :27.74 Max. :1.00000 Max. :0.8710 Max. :8.780 Max. :100.00 Max. :12.127 Max. :24.000 Max. :711.0 Max. :22.00 Max. :396.90 Max. :37.97 Max. :50.00 34.5.1 回归树 34.5.1.1 划分训练集和测试集 set.seed(1) train &lt;- sample(nrow(d), size=round(nrow(d)/2)) test &lt;- (-train) 对训练集建立未剪枝的树： tr1 &lt;- tree(medv ~ ., d, subset=train) summary(tr1) ## ## Regression tree: ## tree(formula = medv ~ ., data = d, subset = train) ## Variables actually used in tree construction: ## [1] &quot;rm&quot; &quot;lstat&quot; &quot;crim&quot; &quot;age&quot; ## Number of terminal nodes: 7 ## Residual mean deviance: 10.38 = 2555 / 246 ## Distribution of residuals: ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## -10.1800 -1.7770 -0.1775 0.0000 1.9230 16.5800 plot(tr1) text(tr1, pretty=0) 用未剪枝的树对测试集进行预测，计算均方误差： yhat &lt;-predict(tr1, newdata=d[test,]) mse1 &lt;- mean((yhat - d[test, &#39;medv&#39;])^2) mse1 ## [1] 35.28688 34.5.1.2 用交叉验证方法确定剪枝复杂度 cv1 &lt;- cv.tree(tr1) plot(cv1$size, cv1$dev, type=&#39;b&#39;) best.size &lt;- cv1$size[which.min(cv1$dev)]; best.size ## [1] 7 剪枝并对测试集进行预测： tr2 &lt;- prune.tree(tr1, best=best.size) plot(tr2) text(tr2, pretty=0) yhat &lt;-predict(tr2, newdata=d[test,]) mse2 &lt;- mean((yhat - d[test, &#39;medv&#39;])^2) mse2 ## [1] 35.28688 剪枝后效果没有改善。 34.5.2 装袋法 用randomForest包计算。 当参数mtry取为自变量个数时按照装袋法计算。 对训练集计算。 set.seed(1) bag1 &lt;- randomForest( medv ~ ., data=d, subset=train, mtry=ncol(d)-1, importance=TRUE) bag1 ## ## Call: ## randomForest(formula = medv ~ ., data = d, mtry = ncol(d) - 1, importance = TRUE, subset = train) ## Type of random forest: regression ## Number of trees: 500 ## No. of variables tried at each split: 13 ## ## Mean of squared residuals: 11.39601 ## % Var explained: 85.17 在测试集上计算装袋法的均方误差： yhat &lt;- predict(bag1, newdata=d[test,]) mean( (yhat - d[test, &#39;medv&#39;])^2 ) ## [1] 23.59273 比单棵树的结果有明显改善。 34.5.3 随机森林 用randomForest包计算。 当参数mtry取为缺省值时按照随机森林方法计算。 对训练集计算。 set.seed(1) rf1 &lt;- randomForest( medv ~ ., data=d, subset=train, importance=TRUE) rf1 ## ## Call: ## randomForest(formula = medv ~ ., data = d, importance = TRUE, subset = train) ## Type of random forest: regression ## Number of trees: 500 ## No. of variables tried at each split: 4 ## ## Mean of squared residuals: 10.23441 ## % Var explained: 86.69 在测试集上计算随机森林法的均方误差： yhat &lt;- predict(rf1, newdata=d[test,]) mean( (yhat - d[test, &#39;medv&#39;])^2 ) ## [1] 18.11686 比单棵树的结果有明显改善, 比装袋法的结果也好一些。 各变量的重要度数值及其图形： importance(rf1) ## %IncMSE IncNodePurity ## crim 15.372334 1220.14856 ## zn 3.335435 194.85945 ## indus 6.964559 1021.94751 ## chas 2.059298 69.68099 ## nox 14.009761 1005.14707 ## rm 28.693900 6162.30720 ## age 13.832143 708.55138 ## dis 10.317731 852.33701 ## rad 4.390624 162.22597 ## tax 7.536563 564.60422 ## ptratio 9.333716 1163.39624 ## black 8.341316 355.62445 ## lstat 27.132450 5549.25088 varImpPlot(rf1) 图34.12: Boston数据用随机森林法得到的变量重要度 34.5.4 提升法 提升法(Boosting)也是可以用在多种回归和判别问题中的方法。 提升法的想法是，用比较简单的模型拟合因变量， 计算残差， 然后以残差为新的因变量建模， 仍使用简单的模型， 把两次的回归函数作加权和， 得到新的残差后，再以新残差作为因变量建模， 如此重复地更新回归函数， 得到由多个回归函数加权和组成的最终的回归函数。 加权一般取为比较小的值， 其目的是降低逼近速度。 统计学习问题中降低逼近速度一般结果更好。 提升法算法: [(1)] 对训练集，设置\\(r_i = y_i\\)，并令初始回归函数为\\(\\hat f(\\cdot)=0\\)。 [(2)] 对\\(b=1,2,\\dots,B\\)重复执行： [(a)] 以训练集的自变量为自变量，以\\(r\\)为因变量，拟合一个仅有\\(d\\)个分叉的简单树回归函数， 设为\\(\\hat f_b\\)； [(b)] 更新回归函数，添加一个压缩过的树回归函数: \\[\\begin{aligned} \\hat f(x) \\leftarrow \\hat f(x) + \\lambda \\hat f_b(x); \\end{aligned}\\] [(c)] 更新残差: \\[\\begin{aligned} r_i \\leftarrow r_i - \\lambda \\hat f_b(x_i). \\end{aligned}\\] [(3)] 提升法的回归函数为 \\[\\begin{aligned} \\hat f(x) = \\sum_{b=1}^B \\lambda \\hat f_b(x) . \\end{aligned}\\] 用多少个回归函数做加权和，即\\(B\\)的选取问题。 取得\\(B\\)太大也会有过度拟合， 但是只要\\(B\\)不太大这个问题不严重。 可以用交叉验证选择\\(B\\)的值。 收缩系数\\(\\lambda\\)。 是一个小的正数， 控制学习速度， 经常用0.01, 0.001这样的值， 与要解决的问题有关。 取\\(\\lambda\\)很小，就需要取\\(B\\)很大。 用来控制每个回归函数复杂度的参数， 对树回归而言就是树的大小。 一个分叉的树往往就很好。 取单个分叉时结果模型是可加模型， 没有交互项， 这是因为每个加权相加得回归函数都只依赖于单一自变量。 \\(d&gt;1\\)时就加入了交互项。 使用gbm包。 在训练集上拟合： set.seed(1) bst1 &lt;- gbm(medv ~ ., data=d[train,], distribution=&#39;gaussian&#39;, n.trees=5000, interaction.depth=4) summary(bst1) ## var rel.inf ## rm rm 43.9919329 ## lstat lstat 33.1216941 ## crim crim 4.2604167 ## dis dis 4.0111090 ## nox nox 3.4353017 ## black black 2.8267554 ## age age 2.6113938 ## ptratio ptratio 2.5403035 ## tax tax 1.4565654 ## indus indus 0.8008740 ## rad rad 0.6546400 ## zn zn 0.1446149 ## chas chas 0.1443986 lstat和rm是最重要的变量。 在测试集上预报，并计算均方误差： yhat &lt;- predict(bst1, newdata=d[test,], n.trees=5000) mean( (yhat - d[test, &#39;medv&#39;])^2 ) ## [1] 18.84709 与随机森林方法结果相近。 如果提高学习速度： bst2 &lt;- gbm(medv ~ ., data=d[train,], distribution=&#39;gaussian&#39;, n.trees=5000, interaction.depth=4, shrinkage=0.2) yhat &lt;- predict(bst2, newdata=d[test,], n.trees=5000) mean( (yhat - d[test, &#39;medv&#39;])^2 ) ## [1] 18.33455 均方误差有改善。 34.6 支持向量机方法 支持向量机是1990年代有计算机科学家发明的一种有监督学习方法， 使用范围较广，预测精度较高。 支持向量机利用了Hilbert空间的方法将线性问题扩展为非线性问题。 线性的支持向量判别法， 可以通过\\(\\mathbb R^p\\)的内积将线性的判别函数转化为如下的表示： \\[\\begin{aligned} f(\\boldsymbol x) = \\beta_0 + \\sum_{i=1}^n \\alpha_i \\langle \\boldsymbol x, \\boldsymbol x_i \\rangle \\end{aligned}\\] 其中\\(\\beta_0, \\alpha_1, \\dots, \\alpha_n\\)是待定参数。 为了估计参数， 不需要用到各\\(\\boldsymbol x_i\\)的具体值， 而只需要其两两的内积值， 而且在判别函数中只有支持向量对应的\\(\\alpha_i\\)才非零， 记\\(\\mathcal S\\)为支持向量点集， 则线性判别函数为 \\[\\begin{aligned} f(\\boldsymbol x) = \\beta_0 + \\sum_{i \\in \\mathcal S} \\alpha_i \\langle \\boldsymbol x, \\boldsymbol x_i \\rangle \\end{aligned}\\] 支持向量机方法将\\(\\mathbb R^p\\)中的内积推广为如下的核函数值： \\[\\begin{aligned} K(\\boldsymbol x, \\boldsymbol x&#39;) \\end{aligned}\\] 核函数\\(K(\\boldsymbol x, \\boldsymbol x&#39;)\\), \\(\\boldsymbol x, \\boldsymbol x&#39; \\in \\mathbb R^p\\) 是度量两个观测点\\(\\boldsymbol x, \\boldsymbol x&#39;\\)的相似程度的函数。 比如， 取 \\[\\begin{aligned} K(\\boldsymbol x, \\boldsymbol x&#39;) = \\sum_{j=1}^p x_j x_j&#39; \\end{aligned}\\] 就又回到了线性的支持向量判别法。 核有多种取法。 例如， 取 \\[\\begin{aligned} K(\\boldsymbol x, \\boldsymbol x&#39;) = \\left\\{ 1 + \\sum_{j=1}^p x_j x_j&#39; \\right\\}^d \\end{aligned}\\] 其中\\(d&gt;1\\)为正整数， 称为多项式核， 则结果是多项式边界的判别法， 本质上是对线性的支持向量方法添加了高次项和交叉项。 利用核代替内积后， 判别法的判别函数变成 \\[\\begin{aligned} f(\\boldsymbol x) = \\beta_0 + \\sum_{i \\in \\mathcal S} K(\\boldsymbol x, \\boldsymbol x_i) \\end{aligned}\\] 另一种常用的核是径向核(radial kernel)， 定义为 \\[\\begin{aligned} K(\\boldsymbol x, \\boldsymbol x&#39;) = \\exp\\left\\{ - \\gamma \\sum_{j=1}^p (x_j - x_j&#39;)^2 \\right\\} \\end{aligned}\\] \\(\\gamma\\)为正常数。 当\\(\\boldsymbol x\\)和\\(\\boldsymbol x&#39;\\)分别落在以原点为中心的两个超球面上时， 其核函数值不变。 使用径向核时， 判别函数为 \\[\\begin{aligned} f(\\boldsymbol x) = \\beta_0 + \\sum_{i \\in \\mathcal S} \\exp\\left\\{ - \\gamma \\sum_{j=1}^p (x_{j} - x_{ij})^2 \\right\\} \\end{aligned}\\] 对一个待判别的观测\\(\\boldsymbol x^*\\)， 如果\\(\\boldsymbol x^*\\)距离训练观测点\\(\\boldsymbol x_i\\)较远， 则\\(K(\\boldsymbol x^*, \\boldsymbol x_i)\\)的值很小， \\(\\boldsymbol x_i\\)对\\(\\boldsymbol x^*\\)的判别基本不起作用。 这样的性质使得径向核方法具有很强的局部性， 只有离\\(\\boldsymbol x^*\\)很近的点才对其判别起作用。 为什么采用核函数计算观测两两的\\(\\binom{n}{2}\\)个核函数值， 而不是直接增加非线性项？ 原因是计算这些核函数值计算量是确定的， 而增加许多非线性项， 则可能有很大的计算量， 而且某些核如径向核对应的自变量空间维数是无穷维的， 不能通过添加维度的办法解决。 支持向量机的理论基于再生核希尔伯特空间(RKHS)， 可参见(Trevor Hastie 2009)节5.8和节12.3.3。 34.6.1 支持向量机用于Heart数据 考虑心脏病数据Heart的判别。 共297个观测， 随机选取其中207个作为训练集， 90个作为测试集。 set.seed(1) Heart &lt;- read.csv( &#39;Heart.csv&#39;, header=TRUE, row.names=1, stringsAsFactors=TRUE) d &lt;- na.omit(Heart) train &lt;- sample(nrow(d), size=207) test &lt;- -train d[[&quot;AHD&quot;]] &lt;- factor(d[[&quot;AHD&quot;]], levels=c(&quot;No&quot;, &quot;Yes&quot;)) 定义一个错判率函数： classifier.error &lt;- function(truth, pred){ tab1 &lt;- table(truth, pred) err &lt;- 1 - sum(diag(tab1))/sum(c(tab1)) err } 34.6.1.1 线性的SVM 支持向量判别法就是SVM取多项式核， 阶数\\(d=1\\)的情形。 需要一个调节参数cost， cost越大， 分隔边界越窄， 过度拟合危险越大。 先随便取调节参数cost=1试验支持向量判别法： res.svc &lt;- svm(AHD ~ ., data=d[train,], kernel=&quot;linear&quot;, cost=1, scale=TRUE) fit.svc &lt;- predict(res.svc) summary(res.svc) ## ## Call: ## svm(formula = AHD ~ ., data = d[train, ], kernel = &quot;linear&quot;, cost = 1, scale = TRUE) ## ## ## Parameters: ## SVM-Type: C-classification ## SVM-Kernel: linear ## cost: 1 ## ## Number of Support Vectors: 79 ## ## ( 38 41 ) ## ## ## Number of Classes: 2 ## ## Levels: ## No Yes 计算拟合结果并计算错判率： tab1 &lt;- table(truth=d[train,&quot;AHD&quot;], fitted=fit.svc); tab1 ## fitted ## truth No Yes ## No 105 9 ## Yes 18 75 cat(&quot;SVC错判率：&quot;, round((tab1[1,2] + tab1[2,1])/ sum(c(tab1)), 2), &quot;\\n&quot;) ## SVC错判率： 0.13 e1071函数提供了tune()函数， 可以在训练集上用十折交叉验证选择较好的调节参数。 set.seed(101) res.tune &lt;- tune(svm, AHD ~ ., data=d[train,], kernel=&quot;linear&quot;, scale=TRUE, ranges=list(cost=c(0.001, 0.01, 0.1, 1, 5, 10, 100, 1000))) summary(res.tune) ## ## Parameter tuning of &#39;svm&#39;: ## ## - sampling method: 10-fold cross validation ## ## - best parameters: ## cost ## 0.1 ## ## - best performance: 0.1542857 ## ## - Detailed performance results: ## cost error dispersion ## 1 1e-03 0.4450000 0.08509809 ## 2 1e-02 0.1695238 0.07062868 ## 3 1e-01 0.1542857 0.07006458 ## 4 1e+00 0.1590476 0.07793796 ## 5 5e+00 0.1590476 0.08709789 ## 6 1e+01 0.1590476 0.08709789 ## 7 1e+02 0.1590476 0.08709789 ## 8 1e+03 0.1590476 0.08709789 找到的最优调节参数为0.1， 可以用res.tune$best.model获得对应于最优调节参数的模型： summary(res.tune$best.model) ## ## Call: ## best.tune(method = svm, train.x = AHD ~ ., data = d[train, ], ranges = list(cost = c(0.001, 0.01, 0.1, 1, 5, 10, 100, 1000)), kernel = &quot;linear&quot;, scale = TRUE) ## ## ## Parameters: ## SVM-Type: C-classification ## SVM-Kernel: linear ## cost: 0.1 ## ## Number of Support Vectors: 90 ## ## ( 44 46 ) ## ## ## Number of Classes: 2 ## ## Levels: ## No Yes 在测试集上测试： pred.svc &lt;- predict(res.tune$best.model, newdata=d[test,]) tab1 &lt;- table(truth=d[test,&quot;AHD&quot;], predict=pred.svc); tab1 ## predict ## truth No Yes ## No 43 3 ## Yes 11 33 cat(&quot;SVC错判率：&quot;, round((tab1[1,2] + tab1[2,1])/ sum(c(tab1)), 2), &quot;\\n&quot;) ## SVC错判率： 0.16 34.6.1.2 多项式核SVM res.svm1 &lt;- svm(AHD ~ ., data=d[train,], kernel=&quot;polynomial&quot;, order=2, cost=0.1, scale=TRUE) fit.svm1 &lt;- predict(res.svm1) summary(res.svm1) ## ## Call: ## svm(formula = AHD ~ ., data = d[train, ], kernel = &quot;polynomial&quot;, order = 2, cost = 0.1, scale = TRUE) ## ## ## Parameters: ## SVM-Type: C-classification ## SVM-Kernel: polynomial ## cost: 0.1 ## degree: 3 ## coef.0: 0 ## ## Number of Support Vectors: 187 ## ## ( 92 95 ) ## ## ## Number of Classes: 2 ## ## Levels: ## No Yes tab1 &lt;- table(truth=d[train,&quot;AHD&quot;], fitted=fit.svm1); tab1 ## fitted ## truth No Yes ## No 114 0 ## Yes 82 11 cat(&quot;2阶多项式核SVM错判率：&quot;, round((tab1[1,2] + tab1[2,1])/ sum(c(tab1)), 2), &quot;\\n&quot;) ## 2阶多项式核SVM错判率： 0.4 尝试找到调节参数cost的最优值： set.seed(101) res.tune2 &lt;- tune(svm, AHD ~ ., data=d[train,], kernel=&quot;polynomial&quot;, order=2, scale=TRUE, ranges=list(cost=c(0.001, 0.01, 0.1, 1, 5, 10, 100, 1000))) summary(res.tune2) ## ## Parameter tuning of &#39;svm&#39;: ## ## - sampling method: 10-fold cross validation ## ## - best parameters: ## cost ## 5 ## ## - best performance: 0.2130952 ## ## - Detailed performance results: ## cost error dispersion ## 1 1e-03 0.4500000 0.08022549 ## 2 1e-02 0.4500000 0.08022549 ## 3 1e-01 0.4111905 0.09215957 ## 4 1e+00 0.2185714 0.09094005 ## 5 5e+00 0.2130952 0.09790737 ## 6 1e+01 0.2180952 0.07948562 ## 7 1e+02 0.2807143 0.09539966 ## 8 1e+03 0.2807143 0.09539966 fit.svm2 &lt;- predict(res.tune2$best.model) tab1 &lt;- table(truth=d[train,&quot;AHD&quot;], fitted=fit.svm2); tab1 ## fitted ## truth No Yes ## No 111 3 ## Yes 4 89 cat(&quot;2阶多项式核最优参数SVM错判率：&quot;, round((tab1[1,2] + tab1[2,1])/ sum(c(tab1)), 2), &quot;\\n&quot;) ## 2阶多项式核最优参数SVM错判率： 0.03 看这个最优调节参数的模型在测试集上的表现： pred.svm2 &lt;- predict(res.tune2$best.model, d[test,]) tab1 &lt;- table(truth=d[test,&quot;AHD&quot;], predict=pred.svm2); tab1 ## predict ## truth No Yes ## No 43 3 ## Yes 10 34 cat(&quot;2阶多项式核最优参数SVM测试集错判率：&quot;, round((tab1[1,2] + tab1[2,1])/ sum(c(tab1)), 2), &quot;\\n&quot;) ## 2阶多项式核最优参数SVM测试集错判率： 0.14 在测试集上的表现与线性方法相近。 34.6.1.3 径向核SVM 径向核需要的参数为\\(\\gamma\\)值。 取参数gamma=0.1。 res.svm3 &lt;- svm(AHD ~ ., data=d[train,], kernel=&quot;radial&quot;, gamma=0.1, cost=0.1, scale=TRUE) fit.svm3 &lt;- predict(res.svm3) summary(res.svm3) ## ## Call: ## svm(formula = AHD ~ ., data = d[train, ], kernel = &quot;radial&quot;, gamma = 0.1, cost = 0.1, scale = TRUE) ## ## ## Parameters: ## SVM-Type: C-classification ## SVM-Kernel: radial ## cost: 0.1 ## ## Number of Support Vectors: 179 ## ## ( 89 90 ) ## ## ## Number of Classes: 2 ## ## Levels: ## No Yes tab1 &lt;- table(truth=d[train,&quot;AHD&quot;], fitted=fit.svm3); tab1 ## fitted ## truth No Yes ## No 108 6 ## Yes 26 67 cat(&quot;径向核（gamma=0.1, cost=0.1）SVM错判率：&quot;, round((tab1[1,2] + tab1[2,1])/ sum(c(tab1)), 2), &quot;\\n&quot;) ## 径向核（gamma=0.1, cost=0.1）SVM错判率： 0.15 选取最优cost, gamma调节参数： set.seed(101) res.tune4 &lt;- tune(svm, AHD ~ ., data=d[train,], kernel=&quot;radial&quot;, scale=TRUE, ranges=list(cost=c(0.001, 0.01, 0.1, 1, 5, 10, 100, 1000), gamma=c(0.1, 0.01, 0.001))) summary(res.tune4) ## ## Parameter tuning of &#39;svm&#39;: ## ## - sampling method: 10-fold cross validation ## ## - best parameters: ## cost gamma ## 100 0.001 ## ## - best performance: 0.1492857 ## ## - Detailed performance results: ## cost gamma error dispersion ## 1 1e-03 0.100 0.4500000 0.08022549 ## 2 1e-02 0.100 0.4500000 0.08022549 ## 3 1e-01 0.100 0.2235714 0.09912346 ## 4 1e+00 0.100 0.1788095 0.08490543 ## 5 5e+00 0.100 0.1835714 0.06267781 ## 6 1e+01 0.100 0.1835714 0.07375788 ## 7 1e+02 0.100 0.1933333 0.09294732 ## 8 1e+03 0.100 0.1933333 0.09294732 ## 9 1e-03 0.010 0.4500000 0.08022549 ## 10 1e-02 0.010 0.4500000 0.08022549 ## 11 1e-01 0.010 0.3147619 0.11998992 ## 12 1e+00 0.010 0.1647619 0.06992960 ## 13 5e+00 0.010 0.1547619 0.07819776 ## 14 1e+01 0.010 0.1547619 0.08135598 ## 15 1e+02 0.010 0.2126190 0.06443790 ## 16 1e+03 0.010 0.2409524 0.08621108 ## 17 1e-03 0.001 0.4500000 0.08022549 ## 18 1e-02 0.001 0.4500000 0.08022549 ## 19 1e-01 0.001 0.4500000 0.08022549 ## 20 1e+00 0.001 0.2138095 0.11215945 ## 21 5e+00 0.001 0.1695238 0.07062868 ## 22 1e+01 0.001 0.1840476 0.08321647 ## 23 1e+02 0.001 0.1492857 0.08228019 ## 24 1e+03 0.001 0.1640476 0.07494392 fit.svm4 &lt;- predict(res.tune4$best.model) tab1 &lt;- table(truth=d[train,&quot;AHD&quot;], fitted=fit.svm4); tab1 ## fitted ## truth No Yes ## No 107 7 ## Yes 18 75 cat(&quot;径向核最优参数SVM错判率：&quot;, round((tab1[1,2] + tab1[2,1])/ sum(c(tab1)), 2), &quot;\\n&quot;) ## 径向核最优参数SVM错判率： 0.12 看这个最优调节参数的模型在测试集上的表现： pred.svm4 &lt;- predict(res.tune4$best.model, d[test,]) tab1 &lt;- table(truth=d[test,&quot;AHD&quot;], predict=pred.svm2); tab1 ## predict ## truth No Yes ## No 43 3 ## Yes 10 34 cat(&quot;径向核最优参数SVM测试集错判率：&quot;, round((tab1[1,2] + tab1[2,1])/ sum(c(tab1)), 2), &quot;\\n&quot;) ## 径向核最优参数SVM测试集错判率： 0.14 与线性方法结果相近。 34.7 附录 34.7.1 Hitters数据 knitr::kable(Hitters) AtBat Hits HmRun Runs RBI Walks Years CAtBat CHits CHmRun CRuns CRBI CWalks League Division PutOuts Assists Errors Salary NewLeague -Andy Allanson 293 66 1 30 29 14 1 293 66 1 30 29 14 A E 446 33 20 NA A -Alan Ashby 315 81 7 24 38 39 14 3449 835 69 321 414 375 N W 632 43 10 475.000 N -Alvin Davis 479 130 18 66 72 76 3 1624 457 63 224 266 263 A W 880 82 14 480.000 A -Andre Dawson 496 141 20 65 78 37 11 5628 1575 225 828 838 354 N E 200 11 3 500.000 N -Andres Galarraga 321 87 10 39 42 30 2 396 101 12 48 46 33 N E 805 40 4 91.500 N -Alfredo Griffin 594 169 4 74 51 35 11 4408 1133 19 501 336 194 A W 282 421 25 750.000 A -Al Newman 185 37 1 23 8 21 2 214 42 1 30 9 24 N E 76 127 7 70.000 A -Argenis Salazar 298 73 0 24 24 7 3 509 108 0 41 37 12 A W 121 283 9 100.000 A -Andres Thomas 323 81 6 26 32 8 2 341 86 6 32 34 8 N W 143 290 19 75.000 N -Andre Thornton 401 92 17 49 66 65 13 5206 1332 253 784 890 866 A E 0 0 0 1100.000 A -Alan Trammell 574 159 21 107 75 59 10 4631 1300 90 702 504 488 A E 238 445 22 517.143 A -Alex Trevino 202 53 4 31 26 27 9 1876 467 15 192 186 161 N W 304 45 11 512.500 N -Andy VanSlyke 418 113 13 48 61 47 4 1512 392 41 205 204 203 N E 211 11 7 550.000 N -Alan Wiggins 239 60 0 30 11 22 6 1941 510 4 309 103 207 A E 121 151 6 700.000 A -Bill Almon 196 43 7 29 27 30 13 3231 825 36 376 290 238 N E 80 45 8 240.000 N -Billy Beane 183 39 3 20 15 11 3 201 42 3 20 16 11 A W 118 0 0 NA A -Buddy Bell 568 158 20 89 75 73 15 8068 2273 177 1045 993 732 N W 105 290 10 775.000 N -Buddy Biancalana 190 46 2 24 8 15 5 479 102 5 65 23 39 A W 102 177 16 175.000 A -Bruce Bochte 407 104 6 57 43 65 12 5233 1478 100 643 658 653 A W 912 88 9 NA A -Bruce Bochy 127 32 8 16 22 14 8 727 180 24 67 82 56 N W 202 22 2 135.000 N -Barry Bonds 413 92 16 72 48 65 1 413 92 16 72 48 65 N E 280 9 5 100.000 N -Bobby Bonilla 426 109 3 55 43 62 1 426 109 3 55 43 62 A W 361 22 2 115.000 N -Bob Boone 22 10 1 4 2 1 6 84 26 2 9 9 3 A W 812 84 11 NA A -Bob Brenly 472 116 16 60 62 74 6 1924 489 67 242 251 240 N W 518 55 3 600.000 N -Bill Buckner 629 168 18 73 102 40 18 8424 2464 164 1008 1072 402 A E 1067 157 14 776.667 A -Brett Butler 587 163 4 92 51 70 6 2695 747 17 442 198 317 A E 434 9 3 765.000 A -Bob Dernier 324 73 4 32 18 22 7 1931 491 13 291 108 180 N E 222 3 3 708.333 N -Bo Diaz 474 129 10 50 56 40 10 2331 604 61 246 327 166 N W 732 83 13 750.000 N -Bill Doran 550 152 6 92 37 81 5 2308 633 32 349 182 308 N W 262 329 16 625.000 N -Brian Downing 513 137 20 90 95 90 14 5201 1382 166 763 734 784 A W 267 5 3 900.000 A -Bobby Grich 313 84 9 42 30 39 17 6890 1833 224 1033 864 1087 A W 127 221 7 NA A -Billy Hatcher 419 108 6 55 36 22 3 591 149 8 80 46 31 N W 226 7 4 110.000 N -Bob Horner 517 141 27 70 87 52 9 3571 994 215 545 652 337 N W 1378 102 8 NA N -Brook Jacoby 583 168 17 83 80 56 5 1646 452 44 219 208 136 A E 109 292 25 612.500 A -Bob Kearney 204 49 6 23 25 12 7 1309 308 27 126 132 66 A W 419 46 5 300.000 A -Bill Madlock 379 106 10 38 60 30 14 6207 1906 146 859 803 571 N W 72 170 24 850.000 N -Bobby Meacham 161 36 0 19 10 17 4 1053 244 3 156 86 107 A E 70 149 12 NA A -Bob Melvin 268 60 5 24 25 15 2 350 78 5 34 29 18 N W 442 59 6 90.000 N -Ben Oglivie 346 98 5 31 53 30 16 5913 1615 235 784 901 560 A E 0 0 0 NA A -Bip Roberts 241 61 1 34 12 14 1 241 61 1 34 12 14 N W 166 172 10 NA N -BillyJo Robidoux 181 41 1 15 21 33 2 232 50 4 20 29 45 A E 326 29 5 67.500 A -Bill Russell 216 54 0 21 18 15 18 7318 1926 46 796 627 483 N W 103 84 5 NA N -Billy Sample 200 57 6 23 14 14 9 2516 684 46 371 230 195 N W 69 1 1 NA N -Bill Schroeder 217 46 7 32 19 9 4 694 160 32 86 76 32 A E 307 25 1 180.000 A -Butch Wynegar 194 40 7 19 29 30 11 4183 1069 64 486 493 608 A E 325 22 2 NA A -Chris Bando 254 68 2 28 26 22 6 999 236 21 108 117 118 A E 359 30 4 305.000 A -Chris Brown 416 132 7 57 49 33 3 932 273 24 113 121 80 N W 73 177 18 215.000 N -Carmen Castillo 205 57 8 34 32 9 5 756 192 32 117 107 51 A E 58 4 4 247.500 A -Cecil Cooper 542 140 12 46 75 41 16 7099 2130 235 987 1089 431 A E 697 61 9 NA A -Chili Davis 526 146 13 71 70 84 6 2648 715 77 352 342 289 N W 303 9 9 815.000 N -Carlton Fisk 457 101 14 42 63 22 17 6521 1767 281 1003 977 619 A W 389 39 4 875.000 A -Curt Ford 214 53 2 30 29 23 2 226 59 2 32 32 27 N E 109 7 3 70.000 N -Cliff Johnson 19 7 0 1 2 1 4 41 13 1 3 4 4 A E 0 0 0 NA A -Carney Lansford 591 168 19 80 72 39 9 4478 1307 113 634 563 319 A W 67 147 4 1200.000 A -Chet Lemon 403 101 12 45 53 39 12 5150 1429 166 747 666 526 A E 316 6 5 675.000 A -Candy Maldonado 405 102 18 49 85 20 6 950 231 29 99 138 64 N W 161 10 3 415.000 N -Carmelo Martinez 244 58 9 28 25 35 4 1335 333 49 164 179 194 N W 142 14 2 340.000 N -Charlie Moore 235 61 3 24 39 21 14 3926 1029 35 441 401 333 A E 425 43 4 NA A -Craig Reynolds 313 78 6 32 41 12 12 3742 968 35 409 321 170 N W 106 206 7 416.667 N -Cal Ripken 627 177 25 98 81 70 6 3210 927 133 529 472 313 A E 240 482 13 1350.000 A -Cory Snyder 416 113 24 58 69 16 1 416 113 24 58 69 16 A E 203 70 10 90.000 A -Chris Speier 155 44 6 21 23 15 16 6631 1634 98 698 661 777 N E 53 88 3 275.000 N -Curt Wilkerson 236 56 0 27 15 11 4 1115 270 1 116 64 57 A W 125 199 13 230.000 A -Dave Anderson 216 53 1 31 15 22 4 926 210 9 118 69 114 N W 73 152 11 225.000 N -Doug Baker 24 3 0 1 0 2 3 159 28 0 20 12 9 A W 80 4 0 NA A -Don Baylor 585 139 31 93 94 62 17 7546 1982 315 1141 1179 727 A E 0 0 0 950.000 A -Dann Bilardello 191 37 4 12 17 14 4 773 163 16 61 74 52 N E 391 38 8 NA N -Daryl Boston 199 53 5 29 22 21 3 514 120 8 57 40 39 A W 152 3 5 75.000 A -Darnell Coles 521 142 20 67 86 45 4 815 205 22 99 103 78 A E 107 242 23 105.000 A -Dave Collins 419 113 1 44 27 44 12 4484 1231 32 612 344 422 A E 211 2 1 NA A -Dave Concepcion 311 81 3 42 30 26 17 8247 2198 100 950 909 690 N W 153 223 10 320.000 N -Darren Daulton 138 31 8 18 21 38 3 244 53 12 33 32 55 N E 244 21 4 NA N -Doug DeCinces 512 131 26 69 96 52 14 5347 1397 221 712 815 548 A W 119 216 12 850.000 A -Darrell Evans 507 122 29 78 85 91 18 7761 1947 347 1175 1152 1380 A E 808 108 2 535.000 A -Dwight Evans 529 137 26 86 97 97 15 6661 1785 291 1082 949 989 A E 280 10 5 933.333 A -Damaso Garcia 424 119 6 57 46 13 9 3651 1046 32 461 301 112 A E 224 286 8 850.000 N -Dan Gladden 351 97 4 55 29 39 4 1258 353 16 196 110 117 N W 226 7 3 210.000 A -Danny Heep 195 55 5 24 33 30 8 1313 338 25 144 149 153 N E 83 2 1 NA N -Dave Henderson 388 103 15 59 47 39 6 2174 555 80 285 274 186 A W 182 9 4 325.000 A -Donnie Hill 339 96 4 37 29 23 4 1064 290 11 123 108 55 A W 104 213 9 275.000 A -Dave Kingman 561 118 35 70 94 33 16 6677 1575 442 901 1210 608 A W 463 32 8 NA A -Davey Lopes 255 70 7 49 35 43 15 6311 1661 154 1019 608 820 N E 51 54 8 450.000 N -Don Mattingly 677 238 31 117 113 53 5 2223 737 93 349 401 171 A E 1377 100 6 1975.000 A -Darryl Motley 227 46 7 23 20 12 5 1325 324 44 156 158 67 A W 92 2 2 NA A -Dale Murphy 614 163 29 89 83 75 11 5017 1388 266 813 822 617 N W 303 6 6 1900.000 N -Dwayne Murphy 329 83 9 50 39 56 9 3828 948 145 575 528 635 A W 276 6 2 600.000 A -Dave Parker 637 174 31 89 116 56 14 6727 2024 247 978 1093 495 N W 278 9 9 1041.667 N -Dan Pasqua 280 82 16 44 45 47 2 428 113 25 61 70 63 A E 148 4 2 110.000 A -Darrell Porter 155 41 12 21 29 22 16 5409 1338 181 746 805 875 A W 165 9 1 260.000 A -Dick Schofield 458 114 13 67 57 48 4 1350 298 28 160 123 122 A W 246 389 18 475.000 A -Don Slaught 314 83 13 39 46 16 5 1457 405 28 156 159 76 A W 533 40 4 431.500 A -Darryl Strawberry 475 123 27 76 93 72 4 1810 471 108 292 343 267 N E 226 10 6 1220.000 N -Dale Sveum 317 78 7 35 35 32 1 317 78 7 35 35 32 A E 45 122 26 70.000 A -Danny Tartabull 511 138 25 76 96 61 3 592 164 28 87 110 71 A W 157 7 8 145.000 A -Dickie Thon 278 69 3 24 21 29 8 2079 565 32 258 192 162 N W 142 210 10 NA N -Denny Walling 382 119 13 54 58 36 12 2133 594 41 287 294 227 N W 59 156 9 595.000 N -Dave Winfield 565 148 24 90 104 77 14 7287 2083 305 1135 1234 791 A E 292 9 5 1861.460 A -Enos Cabell 277 71 2 27 29 14 15 5952 1647 60 753 596 259 N W 360 32 5 NA N -Eric Davis 415 115 27 97 71 68 3 711 184 45 156 119 99 N W 274 2 7 300.000 N -Eddie Milner 424 110 15 70 47 36 7 2130 544 38 335 174 258 N W 292 6 3 490.000 N -Eddie Murray 495 151 17 61 84 78 10 5624 1679 275 884 1015 709 A E 1045 88 13 2460.000 A -Ernest Riles 524 132 9 69 47 54 2 972 260 14 123 92 90 A E 212 327 20 NA A -Ed Romero 233 49 2 41 23 18 8 1350 336 7 166 122 106 A E 102 132 10 375.000 A -Ernie Whitt 395 106 16 48 56 35 10 2303 571 86 266 323 248 A E 709 41 7 NA A -Fred Lynn 397 114 23 67 67 53 13 5589 1632 241 906 926 716 A E 244 2 4 NA A -Floyd Rayford 210 37 8 15 19 15 6 994 244 36 107 114 53 A E 40 115 15 NA A -Franklin Stubbs 420 95 23 55 58 37 3 646 139 31 77 77 61 N W 206 10 7 NA N -Frank White 566 154 22 76 84 43 14 6100 1583 131 743 693 300 A W 316 439 10 750.000 A -George Bell 641 198 31 101 108 41 5 2129 610 92 297 319 117 A E 269 17 10 1175.000 A -Glenn Braggs 215 51 4 19 18 11 1 215 51 4 19 18 11 A E 116 5 12 70.000 A -George Brett 441 128 16 70 73 80 14 6675 2095 209 1072 1050 695 A W 97 218 16 1500.000 A -Greg Brock 325 76 16 33 52 37 5 1506 351 71 195 219 214 N W 726 87 3 385.000 A -Gary Carter 490 125 24 81 105 62 13 6063 1646 271 847 999 680 N E 869 62 8 1925.571 N -Glenn Davis 574 152 31 91 101 64 3 985 260 53 148 173 95 N W 1253 111 11 215.000 N -George Foster 284 64 14 30 42 24 18 7023 1925 348 986 1239 666 N E 96 4 4 NA N -Gary Gaetti 596 171 34 91 108 52 6 2862 728 107 361 401 224 A W 118 334 21 900.000 A -Greg Gagne 472 118 12 63 54 30 4 793 187 14 102 80 50 A W 228 377 26 155.000 A -George Hendrick 283 77 14 45 47 26 16 6840 1910 259 915 1067 546 A W 144 6 5 700.000 A -Glenn Hubbard 408 94 4 42 36 66 9 3573 866 59 429 365 410 N W 282 487 19 535.000 N -Garth Iorg 327 85 3 30 44 20 8 2140 568 16 216 208 93 A E 91 185 12 362.500 A -Gary Matthews 370 96 21 49 46 60 15 6986 1972 231 1070 955 921 N E 137 5 9 733.333 N -Graig Nettles 354 77 16 36 55 41 20 8716 2172 384 1172 1267 1057 N W 83 174 16 200.000 N -Gary Pettis 539 139 5 93 58 69 5 1469 369 12 247 126 198 A W 462 9 7 400.000 A -Gary Redus 340 84 11 62 33 47 5 1516 376 42 284 141 219 N E 185 8 4 400.000 A -Garry Templeton 510 126 2 42 44 35 11 5562 1578 44 703 519 256 N W 207 358 20 737.500 N -Gorman Thomas 315 59 16 45 36 58 13 4677 1051 268 681 782 697 A W 0 0 0 NA A -Greg Walker 282 78 13 37 51 29 5 1649 453 73 211 280 138 A W 670 57 5 500.000 A -Gary Ward 380 120 5 54 51 31 8 3118 900 92 444 419 240 A W 237 8 1 600.000 A -Glenn Wilson 584 158 15 70 84 42 5 2358 636 58 265 316 134 N E 331 20 4 662.500 N -Harold Baines 570 169 21 72 88 38 7 3754 1077 140 492 589 263 A W 295 15 5 950.000 A -Hubie Brooks 306 104 14 50 58 25 7 2954 822 55 313 377 187 N E 116 222 15 750.000 N -Howard Johnson 220 54 10 30 39 31 5 1185 299 40 145 154 128 N E 50 136 20 297.500 N -Hal McRae 278 70 7 22 37 18 18 7186 2081 190 935 1088 643 A W 0 0 0 325.000 A -Harold Reynolds 445 99 1 46 24 29 4 618 129 1 72 31 48 A W 278 415 16 87.500 A -Harry Spilman 143 39 5 18 30 15 9 639 151 16 80 97 61 N W 138 15 1 175.000 N -Herm Winningham 185 40 4 23 11 18 3 524 125 7 58 37 47 N E 97 2 2 90.000 N -Jesse Barfield 589 170 40 107 108 69 6 2325 634 128 371 376 238 A E 368 20 3 1237.500 A -Juan Beniquez 343 103 6 48 36 40 15 4338 1193 70 581 421 325 A E 211 56 13 430.000 A -Juan Bonilla 284 69 1 33 18 25 5 1407 361 6 139 98 111 A E 122 140 5 NA N -John Cangelosi 438 103 2 65 32 71 2 440 103 2 67 32 71 A W 276 7 9 100.000 N -Jose Canseco 600 144 33 85 117 65 2 696 173 38 101 130 69 A W 319 4 14 165.000 A -Joe Carter 663 200 29 108 121 32 4 1447 404 57 210 222 68 A E 241 8 6 250.000 A -Jack Clark 232 55 9 34 23 45 12 4405 1213 194 702 705 625 N E 623 35 3 1300.000 N -Jose Cruz 479 133 10 48 72 55 17 7472 2147 153 980 1032 854 N W 237 5 4 773.333 N -Julio Cruz 209 45 0 38 19 42 10 3859 916 23 557 279 478 A W 132 205 5 NA A -Jody Davis 528 132 21 61 74 41 6 2641 671 97 273 383 226 N E 885 105 8 1008.333 N -Jim Dwyer 160 39 8 18 31 22 14 2128 543 56 304 268 298 A E 33 3 0 275.000 A -Julio Franco 599 183 10 80 74 32 5 2482 715 27 330 326 158 A E 231 374 18 775.000 A -Jim Gantner 497 136 7 58 38 26 11 3871 1066 40 450 367 241 A E 304 347 10 850.000 A -Johnny Grubb 210 70 13 32 51 28 15 4040 1130 97 544 462 551 A E 0 0 0 365.000 A -Jerry Hairston 225 61 5 32 26 26 11 1568 408 25 202 185 257 A W 132 9 0 NA A -Jack Howell 151 41 4 26 21 19 2 288 68 9 45 39 35 A W 28 56 2 95.000 A -John Kruk 278 86 4 33 38 45 1 278 86 4 33 38 45 N W 102 4 2 110.000 N -Jeffrey Leonard 341 95 6 48 42 20 10 2964 808 81 379 428 221 N W 158 4 5 100.000 N -Jim Morrison 537 147 23 58 88 47 10 2744 730 97 302 351 174 N E 92 257 20 277.500 N -John Moses 399 102 3 56 34 34 5 670 167 4 89 48 54 A W 211 9 3 80.000 A -Jerry Mumphrey 309 94 5 37 32 26 13 4618 1330 57 616 522 436 N E 161 3 3 600.000 N -Joe Orsulak 401 100 2 60 19 28 4 876 238 2 126 44 55 N E 193 11 4 NA N -Jorge Orta 336 93 9 35 46 23 15 5779 1610 128 730 741 497 A W 0 0 0 NA A -Jim Presley 616 163 27 83 107 32 3 1437 377 65 181 227 82 A W 110 308 15 200.000 A -Jamie Quirk 219 47 8 24 26 17 12 1188 286 23 100 125 63 A W 260 58 4 NA A -Johnny Ray 579 174 7 67 78 58 6 3053 880 32 366 337 218 N E 280 479 5 657.000 N -Jeff Reed 165 39 2 13 9 16 3 196 44 2 18 10 18 A W 332 19 2 75.000 N -Jim Rice 618 200 20 98 110 62 13 7127 2163 351 1104 1289 564 A E 330 16 8 2412.500 A -Jerry Royster 257 66 5 31 26 32 14 3910 979 33 518 324 382 N W 87 166 14 250.000 A -John Russell 315 76 13 35 60 25 3 630 151 24 68 94 55 N E 498 39 13 155.000 N -Juan Samuel 591 157 16 90 78 26 4 2020 541 52 310 226 91 N E 290 440 25 640.000 N -John Shelby 404 92 11 54 49 18 6 1354 325 30 188 135 63 A E 222 5 5 300.000 A -Joel Skinner 315 73 5 23 37 16 4 450 108 6 38 46 28 A W 227 15 3 110.000 A -Jeff Stone 249 69 6 32 19 20 4 702 209 10 97 48 44 N E 103 8 2 NA N -Jim Sundberg 429 91 12 41 42 57 13 5590 1397 83 578 579 644 A W 686 46 4 825.000 N -Jim Traber 212 54 13 28 44 18 2 233 59 13 31 46 20 A E 243 23 5 NA A -Jose Uribe 453 101 3 46 43 61 3 948 218 6 96 72 91 N W 249 444 16 195.000 N -Jerry Willard 161 43 4 17 26 22 3 707 179 21 77 99 76 A W 300 12 2 NA A -Joel Youngblood 184 47 5 20 28 18 11 3327 890 74 419 382 304 N W 49 2 0 450.000 N -Kevin Bass 591 184 20 83 79 38 5 1689 462 40 219 195 82 N W 303 12 5 630.000 N -Kal Daniels 181 58 6 34 23 22 1 181 58 6 34 23 22 N W 88 0 3 86.500 N -Kirk Gibson 441 118 28 84 86 68 8 2723 750 126 433 420 309 A E 190 2 2 1300.000 A -Ken Griffey 490 150 21 69 58 35 14 6126 1839 121 983 707 600 A E 96 5 3 1000.000 N -Keith Hernandez 551 171 13 94 83 94 13 6090 1840 128 969 900 917 N E 1199 149 5 1800.000 N -Kent Hrbek 550 147 29 85 91 71 6 2816 815 117 405 474 319 A W 1218 104 10 1310.000 A -Ken Landreaux 283 74 4 34 29 22 10 3919 1062 85 505 456 283 N W 145 5 7 737.500 N -Kevin McReynolds 560 161 26 89 96 66 4 1789 470 65 233 260 155 N W 332 9 8 625.000 N -Kevin Mitchell 328 91 12 51 43 33 2 342 94 12 51 44 33 N E 145 59 8 125.000 N -Keith Moreland 586 159 12 72 79 53 9 3082 880 83 363 477 295 N E 181 13 4 1043.333 N -Ken Oberkfell 503 136 5 62 48 83 10 3423 970 20 408 303 414 N W 65 258 8 725.000 N -Ken Phelps 344 85 24 69 64 88 7 911 214 64 150 156 187 A W 0 0 0 300.000 A -Kirby Puckett 680 223 31 119 96 34 3 1928 587 35 262 201 91 A W 429 8 6 365.000 A -Kurt Stillwell 279 64 0 31 26 30 1 279 64 0 31 26 30 N W 107 205 16 75.000 N -Leon Durham 484 127 20 66 65 67 7 3006 844 116 436 458 377 N E 1231 80 7 1183.333 N -Len Dykstra 431 127 8 77 45 58 2 667 187 9 117 64 88 N E 283 8 3 202.500 N -Larry Herndon 283 70 8 33 37 27 12 4479 1222 94 557 483 307 A E 156 2 2 225.000 A -Lee Lacy 491 141 11 77 47 37 15 4291 1240 84 615 430 340 A E 239 8 2 525.000 A -Len Matuszek 199 52 9 26 28 21 6 805 191 30 113 119 87 N W 235 22 5 265.000 N -Lloyd Moseby 589 149 21 89 86 64 7 3558 928 102 513 471 351 A E 371 6 6 787.500 A -Lance Parrish 327 84 22 53 62 38 10 4273 1123 212 577 700 334 A E 483 48 6 800.000 N -Larry Parrish 464 128 28 67 94 52 13 5829 1552 210 740 840 452 A W 0 0 0 587.500 A -Luis Rivera 166 34 0 20 13 17 1 166 34 0 20 13 17 N E 64 119 9 NA N -Larry Sheets 338 92 18 42 60 21 3 682 185 36 88 112 50 A E 0 0 0 145.000 A -Lonnie Smith 508 146 8 80 44 46 9 3148 915 41 571 289 326 A W 245 5 9 NA A -Lou Whitaker 584 157 20 95 73 63 10 4704 1320 93 724 522 576 A E 276 421 11 420.000 A -Mike Aldrete 216 54 2 27 25 33 1 216 54 2 27 25 33 N W 317 36 1 75.000 N -Marty Barrett 625 179 4 94 60 65 5 1696 476 12 216 163 166 A E 303 450 14 575.000 A -Mike Brown 243 53 4 18 26 27 4 853 228 23 101 110 76 N E 107 3 3 NA N -Mike Davis 489 131 19 77 55 34 7 2051 549 62 300 263 153 A W 310 9 9 780.000 A -Mike Diaz 209 56 12 22 36 19 2 216 58 12 24 37 19 N E 201 6 3 90.000 N -Mariano Duncan 407 93 8 47 30 30 2 969 230 14 121 69 68 N W 172 317 25 150.000 N -Mike Easler 490 148 14 64 78 49 13 3400 1000 113 445 491 301 A E 0 0 0 700.000 N -Mike Fitzgerald 209 59 6 20 37 27 4 884 209 14 66 106 92 N E 415 35 3 NA N -Mel Hall 442 131 18 68 77 33 6 1416 398 47 210 203 136 A E 233 7 7 550.000 A -Mickey Hatcher 317 88 3 40 32 19 8 2543 715 28 269 270 118 A W 220 16 4 NA A -Mike Heath 288 65 8 30 36 27 9 2815 698 55 315 325 189 N E 259 30 10 650.000 A -Mike Kingery 209 54 3 25 14 12 1 209 54 3 25 14 12 A W 102 6 3 68.000 A -Mike LaValliere 303 71 3 18 30 36 3 344 76 3 20 36 45 N E 468 47 6 100.000 N -Mike Marshall 330 77 19 47 53 27 6 1928 516 90 247 288 161 N W 149 8 6 670.000 N -Mike Pagliarulo 504 120 28 71 71 54 3 1085 259 54 150 167 114 A E 103 283 19 175.000 A -Mark Salas 258 60 8 28 33 18 3 638 170 17 80 75 36 A W 358 32 8 137.000 A -Mike Schmidt 20 1 0 0 0 0 2 41 9 2 6 7 4 N E 78 220 6 2127.333 N -Mike Scioscia 374 94 5 36 26 62 7 1968 519 26 181 199 288 N W 756 64 15 875.000 N -Mickey Tettleton 211 43 10 26 35 39 3 498 116 14 59 55 78 A W 463 32 8 120.000 A -Milt Thompson 299 75 6 38 23 26 3 580 160 8 71 33 44 N E 212 1 2 140.000 N -Mitch Webster 576 167 8 89 49 57 4 822 232 19 132 83 79 N E 325 12 8 210.000 N -Mookie Wilson 381 110 9 61 45 32 7 3015 834 40 451 249 168 N E 228 7 5 800.000 N -Marvell Wynne 288 76 7 34 37 15 4 1644 408 16 198 120 113 N W 203 3 3 240.000 N -Mike Young 369 93 9 43 42 49 5 1258 323 54 181 177 157 A E 149 1 6 350.000 A -Nick Esasky 330 76 12 35 41 47 4 1367 326 55 167 198 167 N W 512 30 5 NA N -Ozzie Guillen 547 137 2 58 47 12 2 1038 271 3 129 80 24 A W 261 459 22 175.000 A -Oddibe McDowell 572 152 18 105 49 65 2 978 249 36 168 91 101 A W 325 13 3 200.000 A -Omar Moreno 359 84 4 46 27 21 12 4992 1257 37 699 386 387 N W 151 8 5 NA N -Ozzie Smith 514 144 0 67 54 79 9 4739 1169 13 583 374 528 N E 229 453 15 1940.000 N -Ozzie Virgil 359 80 15 45 48 63 7 1493 359 61 176 202 175 N W 682 93 13 700.000 N -Phil Bradley 526 163 12 88 50 77 4 1556 470 38 245 167 174 A W 250 11 1 750.000 A -Phil Garner 313 83 9 43 41 30 14 5885 1543 104 751 714 535 N W 58 141 23 450.000 N -Pete Incaviglia 540 135 30 82 88 55 1 540 135 30 82 88 55 A W 157 6 14 172.000 A -Paul Molitor 437 123 9 62 55 40 9 4139 1203 79 676 390 364 A E 82 170 15 1260.000 A -Pete O’Brien 551 160 23 86 90 87 5 2235 602 75 278 328 273 A W 1224 115 11 NA A -Pete Rose 237 52 0 15 25 30 24 14053 4256 160 2165 1314 1566 N W 523 43 6 750.000 N -Pat Sheridan 236 56 6 41 19 21 5 1257 329 24 166 125 105 A E 172 1 4 190.000 A -Pat Tabler 473 154 6 61 48 29 6 1966 566 29 250 252 178 A E 846 84 9 580.000 A -Rafael Belliard 309 72 0 33 31 26 5 354 82 0 41 32 26 N E 117 269 12 130.000 N -Rick Burleson 271 77 5 35 29 33 12 4933 1358 48 630 435 403 A W 62 90 3 450.000 A -Randy Bush 357 96 7 50 45 39 5 1394 344 43 178 192 136 A W 167 2 4 300.000 A -Rick Cerone 216 56 4 22 18 15 12 2796 665 43 266 304 198 A E 391 44 4 250.000 A -Ron Cey 256 70 13 42 36 44 16 7058 1845 312 965 1128 990 N E 41 118 8 1050.000 A -Rob Deer 466 108 33 75 86 72 3 652 142 44 102 109 102 A E 286 8 8 215.000 A -Rick Dempsey 327 68 13 42 29 45 18 3949 939 78 438 380 466 A E 659 53 7 400.000 A -Rich Gedman 462 119 16 49 65 37 7 2131 583 69 244 288 150 A E 866 65 6 NA A -Ron Hassey 341 110 9 45 49 46 9 2331 658 50 249 322 274 A E 251 9 4 560.000 A -Rickey Henderson 608 160 28 130 74 89 8 4071 1182 103 862 417 708 A E 426 4 6 1670.000 A -Reggie Jackson 419 101 18 65 58 92 20 9528 2510 548 1509 1659 1342 A W 0 0 0 487.500 A -Ricky Jones 33 6 0 2 4 7 1 33 6 0 2 4 7 A W 205 5 4 NA A -Ron Kittle 376 82 21 42 60 35 5 1770 408 115 238 299 157 A W 0 0 0 425.000 A -Ray Knight 486 145 11 51 76 40 11 3967 1102 67 410 497 284 N E 88 204 16 500.000 A -Randy Kutcher 186 44 7 28 16 11 1 186 44 7 28 16 11 N W 99 3 1 NA N -Rudy Law 307 80 1 42 36 29 7 2421 656 18 379 198 184 A W 145 2 2 NA A -Rick Leach 246 76 5 35 39 13 6 912 234 12 102 96 80 A E 44 0 1 250.000 A -Rick Manning 205 52 8 31 27 17 12 5134 1323 56 643 445 459 A E 155 3 2 400.000 A -Rance Mulliniks 348 90 11 50 45 43 10 2288 614 43 295 273 269 A E 60 176 6 450.000 A -Ron Oester 523 135 8 52 44 52 9 3368 895 39 377 284 296 N W 367 475 19 750.000 N -Rey Quinones 312 68 2 32 22 24 1 312 68 2 32 22 24 A E 86 150 15 70.000 A -Rafael Ramirez 496 119 8 57 33 21 7 3358 882 36 365 280 165 N W 155 371 29 875.000 N -Ronn Reynolds 126 27 3 8 10 5 4 239 49 3 16 13 14 N E 190 2 9 190.000 N -Ron Roenicke 275 68 5 42 42 61 6 961 238 16 128 104 172 N E 181 3 2 191.000 N -Ryne Sandberg 627 178 14 68 76 46 6 3146 902 74 494 345 242 N E 309 492 5 740.000 N -Rafael Santana 394 86 1 38 28 36 4 1089 267 3 94 71 76 N E 203 369 16 250.000 N -Rick Schu 208 57 8 32 25 18 3 653 170 17 98 54 62 N E 42 94 13 140.000 N -Ruben Sierra 382 101 16 50 55 22 1 382 101 16 50 55 22 A W 200 7 6 97.500 A -Roy Smalley 459 113 20 59 57 68 12 5348 1369 155 713 660 735 A W 0 0 0 740.000 A -Robby Thompson 549 149 7 73 47 42 1 549 149 7 73 47 42 N W 255 450 17 140.000 N -Rob Wilfong 288 63 3 25 33 16 10 2682 667 38 315 259 204 A W 135 257 7 341.667 A -Reggie Williams 303 84 4 35 32 23 2 312 87 4 39 32 23 N W 179 5 3 NA N -Robin Yount 522 163 9 82 46 62 13 7037 2019 153 1043 827 535 A E 352 9 1 1000.000 A -Steve Balboni 512 117 29 54 88 43 6 1750 412 100 204 276 155 A W 1236 98 18 100.000 A -Scott Bradley 220 66 5 20 28 13 3 290 80 5 27 31 15 A W 281 21 3 90.000 A -Sid Bream 522 140 16 73 77 60 4 730 185 22 93 106 86 N E 1320 166 17 200.000 N -Steve Buechele 461 112 18 54 54 35 2 680 160 24 76 75 49 A W 111 226 11 135.000 A -Shawon Dunston 581 145 17 66 68 21 2 831 210 21 106 86 40 N E 320 465 32 155.000 N -Scott Fletcher 530 159 3 82 50 47 6 1619 426 11 218 149 163 A W 196 354 15 475.000 A -Steve Garvey 557 142 21 58 81 23 18 8759 2583 271 1138 1299 478 N W 1160 53 7 1450.000 N -Steve Jeltz 439 96 0 44 36 65 4 711 148 1 68 56 99 N E 229 406 22 150.000 N -Steve Lombardozzi 453 103 8 53 33 52 2 507 123 8 63 39 58 A W 289 407 6 105.000 A -Spike Owen 528 122 1 67 45 51 4 1716 403 12 211 146 155 A W 209 372 17 350.000 A -Steve Sax 633 210 6 91 56 59 6 3070 872 19 420 230 274 N W 367 432 16 90.000 N -Tony Armas 16 2 0 1 0 0 2 28 4 0 1 0 0 A E 247 4 8 NA A -Tony Bernazard 562 169 17 88 73 53 8 3181 841 61 450 342 373 A E 351 442 17 530.000 A -Tom Brookens 281 76 3 42 25 20 8 2658 657 48 324 300 179 A E 106 144 7 341.667 A -Tom Brunansky 593 152 23 69 75 53 6 2765 686 133 369 384 321 A W 315 10 6 940.000 A -Tony Fernandez 687 213 10 91 65 27 4 1518 448 15 196 137 89 A E 294 445 13 350.000 A -Tim Flannery 368 103 3 48 28 54 8 1897 493 9 207 162 198 N W 209 246 3 326.667 N -Tom Foley 263 70 1 26 23 30 4 888 220 9 83 82 86 N E 81 147 4 250.000 N -Tony Gwynn 642 211 14 107 59 52 5 2364 770 27 352 230 193 N W 337 19 4 740.000 N -Terry Harper 265 68 8 26 30 29 7 1337 339 32 135 163 128 N W 92 5 3 425.000 A -Toby Harrah 289 63 7 36 41 44 17 7402 1954 195 1115 919 1153 A W 166 211 7 NA A -Tommy Herr 559 141 2 48 61 73 8 3162 874 16 421 349 359 N E 352 414 9 925.000 N -Tim Hulett 520 120 17 53 44 21 4 927 227 22 106 80 52 A W 70 144 11 185.000 A -Terry Kennedy 19 4 1 2 3 1 1 19 4 1 2 3 1 N W 692 70 8 920.000 A -Tito Landrum 205 43 2 24 17 20 7 854 219 12 105 99 71 N E 131 6 1 286.667 N -Tim Laudner 193 47 10 21 29 24 6 1136 256 42 129 139 106 A W 299 13 5 245.000 A -Tom O’Malley 181 46 1 19 18 17 5 937 238 9 88 95 104 A E 37 98 9 NA A -Tom Paciorek 213 61 4 17 22 3 17 4061 1145 83 488 491 244 A W 178 45 4 235.000 A -Tony Pena 510 147 10 56 52 53 7 2872 821 63 307 340 174 N E 810 99 18 1150.000 N -Terry Pendleton 578 138 1 56 59 34 3 1399 357 7 149 161 87 N E 133 371 20 160.000 N -Tony Perez 200 51 2 14 29 25 23 9778 2732 379 1272 1652 925 N W 398 29 7 NA N -Tony Phillips 441 113 5 76 52 76 5 1546 397 17 226 149 191 A W 160 290 11 425.000 A -Terry Puhl 172 42 3 17 14 15 10 4086 1150 57 579 363 406 N W 65 0 0 900.000 N -Tim Raines 580 194 9 91 62 78 8 3372 1028 48 604 314 469 N E 270 13 6 NA N -Ted Simmons 127 32 4 14 25 12 19 8396 2402 242 1048 1348 819 N W 167 18 6 500.000 N -Tim Teufel 279 69 4 35 31 32 4 1359 355 31 180 148 158 N E 133 173 9 277.500 N -Tim Wallach 480 112 18 50 71 44 7 3031 771 110 338 406 239 N E 94 270 16 750.000 N -Vince Coleman 600 139 0 94 29 60 2 1236 309 1 201 69 110 N E 300 12 9 160.000 N -Von Hayes 610 186 19 107 98 74 6 2728 753 69 399 366 286 N E 1182 96 13 1300.000 N -Vance Law 360 81 5 37 44 37 7 2268 566 41 279 257 246 N E 170 284 3 525.000 N -Wally Backman 387 124 1 67 27 36 7 1775 506 6 272 125 194 N E 186 290 17 550.000 N -Wade Boggs 580 207 8 107 71 105 5 2778 978 32 474 322 417 A E 121 267 19 1600.000 A -Will Clark 408 117 11 66 41 34 1 408 117 11 66 41 34 N W 942 72 11 120.000 N -Wally Joyner 593 172 22 82 100 57 1 593 172 22 82 100 57 A W 1222 139 15 165.000 A -Wayne Krenchicki 221 53 2 21 23 22 8 1063 283 15 107 124 106 N E 325 58 6 NA N -Willie McGee 497 127 7 65 48 37 5 2703 806 32 379 311 138 N E 325 9 3 700.000 N -Willie Randolph 492 136 5 76 50 94 12 5511 1511 39 897 451 875 A E 313 381 20 875.000 A -Wayne Tolleson 475 126 3 61 43 52 6 1700 433 7 217 93 146 A W 37 113 7 385.000 A -Willie Upshaw 573 144 9 85 60 78 8 3198 857 97 470 420 332 A E 1314 131 12 960.000 A -Willie Wilson 631 170 9 77 44 31 11 4908 1457 30 775 357 249 A W 408 4 3 1000.000 A 34.7.2 Heart数据 knitr::kable(Heart) Age Sex ChestPain RestBP Chol Fbs RestECG MaxHR ExAng Oldpeak Slope Ca Thal AHD 1 63 1 typical 145 233 1 2 150 0 2.3 3 0 fixed No 2 67 1 asymptomatic 160 286 0 2 108 1 1.5 2 3 normal Yes 3 67 1 asymptomatic 120 229 0 2 129 1 2.6 2 2 reversable Yes 4 37 1 nonanginal 130 250 0 0 187 0 3.5 3 0 normal No 5 41 0 nontypical 130 204 0 2 172 0 1.4 1 0 normal No 6 56 1 nontypical 120 236 0 0 178 0 0.8 1 0 normal No 7 62 0 asymptomatic 140 268 0 2 160 0 3.6 3 2 normal Yes 8 57 0 asymptomatic 120 354 0 0 163 1 0.6 1 0 normal No 9 63 1 asymptomatic 130 254 0 2 147 0 1.4 2 1 reversable Yes 10 53 1 asymptomatic 140 203 1 2 155 1 3.1 3 0 reversable Yes 11 57 1 asymptomatic 140 192 0 0 148 0 0.4 2 0 fixed No 12 56 0 nontypical 140 294 0 2 153 0 1.3 2 0 normal No 13 56 1 nonanginal 130 256 1 2 142 1 0.6 2 1 fixed Yes 14 44 1 nontypical 120 263 0 0 173 0 0.0 1 0 reversable No 15 52 1 nonanginal 172 199 1 0 162 0 0.5 1 0 reversable No 16 57 1 nonanginal 150 168 0 0 174 0 1.6 1 0 normal No 17 48 1 nontypical 110 229 0 0 168 0 1.0 3 0 reversable Yes 18 54 1 asymptomatic 140 239 0 0 160 0 1.2 1 0 normal No 19 48 0 nonanginal 130 275 0 0 139 0 0.2 1 0 normal No 20 49 1 nontypical 130 266 0 0 171 0 0.6 1 0 normal No 21 64 1 typical 110 211 0 2 144 1 1.8 2 0 normal No 22 58 0 typical 150 283 1 2 162 0 1.0 1 0 normal No 23 58 1 nontypical 120 284 0 2 160 0 1.8 2 0 normal Yes 24 58 1 nonanginal 132 224 0 2 173 0 3.2 1 2 reversable Yes 25 60 1 asymptomatic 130 206 0 2 132 1 2.4 2 2 reversable Yes 26 50 0 nonanginal 120 219 0 0 158 0 1.6 2 0 normal No 27 58 0 nonanginal 120 340 0 0 172 0 0.0 1 0 normal No 28 66 0 typical 150 226 0 0 114 0 2.6 3 0 normal No 29 43 1 asymptomatic 150 247 0 0 171 0 1.5 1 0 normal No 30 40 1 asymptomatic 110 167 0 2 114 1 2.0 2 0 reversable Yes 31 69 0 typical 140 239 0 0 151 0 1.8 1 2 normal No 32 60 1 asymptomatic 117 230 1 0 160 1 1.4 1 2 reversable Yes 33 64 1 nonanginal 140 335 0 0 158 0 0.0 1 0 normal Yes 34 59 1 asymptomatic 135 234 0 0 161 0 0.5 2 0 reversable No 35 44 1 nonanginal 130 233 0 0 179 1 0.4 1 0 normal No 36 42 1 asymptomatic 140 226 0 0 178 0 0.0 1 0 normal No 37 43 1 asymptomatic 120 177 0 2 120 1 2.5 2 0 reversable Yes 38 57 1 asymptomatic 150 276 0 2 112 1 0.6 2 1 fixed Yes 39 55 1 asymptomatic 132 353 0 0 132 1 1.2 2 1 reversable Yes 40 61 1 nonanginal 150 243 1 0 137 1 1.0 2 0 normal No 41 65 0 asymptomatic 150 225 0 2 114 0 1.0 2 3 reversable Yes 42 40 1 typical 140 199 0 0 178 1 1.4 1 0 reversable No 43 71 0 nontypical 160 302 0 0 162 0 0.4 1 2 normal No 44 59 1 nonanginal 150 212 1 0 157 0 1.6 1 0 normal No 45 61 0 asymptomatic 130 330 0 2 169 0 0.0 1 0 normal Yes 46 58 1 nonanginal 112 230 0 2 165 0 2.5 2 1 reversable Yes 47 51 1 nonanginal 110 175 0 0 123 0 0.6 1 0 normal No 48 50 1 asymptomatic 150 243 0 2 128 0 2.6 2 0 reversable Yes 49 65 0 nonanginal 140 417 1 2 157 0 0.8 1 1 normal No 50 53 1 nonanginal 130 197 1 2 152 0 1.2 3 0 normal No 51 41 0 nontypical 105 198 0 0 168 0 0.0 1 1 normal No 52 65 1 asymptomatic 120 177 0 0 140 0 0.4 1 0 reversable No 53 44 1 asymptomatic 112 290 0 2 153 0 0.0 1 1 normal Yes 54 44 1 nontypical 130 219 0 2 188 0 0.0 1 0 normal No 55 60 1 asymptomatic 130 253 0 0 144 1 1.4 1 1 reversable Yes 56 54 1 asymptomatic 124 266 0 2 109 1 2.2 2 1 reversable Yes 57 50 1 nonanginal 140 233 0 0 163 0 0.6 2 1 reversable Yes 58 41 1 asymptomatic 110 172 0 2 158 0 0.0 1 0 reversable Yes 59 54 1 nonanginal 125 273 0 2 152 0 0.5 3 1 normal No 60 51 1 typical 125 213 0 2 125 1 1.4 1 1 normal No 61 51 0 asymptomatic 130 305 0 0 142 1 1.2 2 0 reversable Yes 62 46 0 nonanginal 142 177 0 2 160 1 1.4 3 0 normal No 63 58 1 asymptomatic 128 216 0 2 131 1 2.2 2 3 reversable Yes 64 54 0 nonanginal 135 304 1 0 170 0 0.0 1 0 normal No 65 54 1 asymptomatic 120 188 0 0 113 0 1.4 2 1 reversable Yes 66 60 1 asymptomatic 145 282 0 2 142 1 2.8 2 2 reversable Yes 67 60 1 nonanginal 140 185 0 2 155 0 3.0 2 0 normal Yes 68 54 1 nonanginal 150 232 0 2 165 0 1.6 1 0 reversable No 69 59 1 asymptomatic 170 326 0 2 140 1 3.4 3 0 reversable Yes 70 46 1 nonanginal 150 231 0 0 147 0 3.6 2 0 normal Yes 71 65 0 nonanginal 155 269 0 0 148 0 0.8 1 0 normal No 72 67 1 asymptomatic 125 254 1 0 163 0 0.2 2 2 reversable Yes 73 62 1 asymptomatic 120 267 0 0 99 1 1.8 2 2 reversable Yes 74 65 1 asymptomatic 110 248 0 2 158 0 0.6 1 2 fixed Yes 75 44 1 asymptomatic 110 197 0 2 177 0 0.0 1 1 normal Yes 76 65 0 nonanginal 160 360 0 2 151 0 0.8 1 0 normal No 77 60 1 asymptomatic 125 258 0 2 141 1 2.8 2 1 reversable Yes 78 51 0 nonanginal 140 308 0 2 142 0 1.5 1 1 normal No 79 48 1 nontypical 130 245 0 2 180 0 0.2 2 0 normal No 80 58 1 asymptomatic 150 270 0 2 111 1 0.8 1 0 reversable Yes 81 45 1 asymptomatic 104 208 0 2 148 1 3.0 2 0 normal No 82 53 0 asymptomatic 130 264 0 2 143 0 0.4 2 0 normal No 83 39 1 nonanginal 140 321 0 2 182 0 0.0 1 0 normal No 84 68 1 nonanginal 180 274 1 2 150 1 1.6 2 0 reversable Yes 85 52 1 nontypical 120 325 0 0 172 0 0.2 1 0 normal No 86 44 1 nonanginal 140 235 0 2 180 0 0.0 1 0 normal No 87 47 1 nonanginal 138 257 0 2 156 0 0.0 1 0 normal No 89 53 0 asymptomatic 138 234 0 2 160 0 0.0 1 0 normal No 90 51 0 nonanginal 130 256 0 2 149 0 0.5 1 0 normal No 91 66 1 asymptomatic 120 302 0 2 151 0 0.4 2 0 normal No 92 62 0 asymptomatic 160 164 0 2 145 0 6.2 3 3 reversable Yes 93 62 1 nonanginal 130 231 0 0 146 0 1.8 2 3 reversable No 94 44 0 nonanginal 108 141 0 0 175 0 0.6 2 0 normal No 95 63 0 nonanginal 135 252 0 2 172 0 0.0 1 0 normal No 96 52 1 asymptomatic 128 255 0 0 161 1 0.0 1 1 reversable Yes 97 59 1 asymptomatic 110 239 0 2 142 1 1.2 2 1 reversable Yes 98 60 0 asymptomatic 150 258 0 2 157 0 2.6 2 2 reversable Yes 99 52 1 nontypical 134 201 0 0 158 0 0.8 1 1 normal No 100 48 1 asymptomatic 122 222 0 2 186 0 0.0 1 0 normal No 101 45 1 asymptomatic 115 260 0 2 185 0 0.0 1 0 normal No 102 34 1 typical 118 182 0 2 174 0 0.0 1 0 normal No 103 57 0 asymptomatic 128 303 0 2 159 0 0.0 1 1 normal No 104 71 0 nonanginal 110 265 1 2 130 0 0.0 1 1 normal No 105 49 1 nonanginal 120 188 0 0 139 0 2.0 2 3 reversable Yes 106 54 1 nontypical 108 309 0 0 156 0 0.0 1 0 reversable No 107 59 1 asymptomatic 140 177 0 0 162 1 0.0 1 1 reversable Yes 108 57 1 nonanginal 128 229 0 2 150 0 0.4 2 1 reversable Yes 109 61 1 asymptomatic 120 260 0 0 140 1 3.6 2 1 reversable Yes 110 39 1 asymptomatic 118 219 0 0 140 0 1.2 2 0 reversable Yes 111 61 0 asymptomatic 145 307 0 2 146 1 1.0 2 0 reversable Yes 112 56 1 asymptomatic 125 249 1 2 144 1 1.2 2 1 normal Yes 113 52 1 typical 118 186 0 2 190 0 0.0 2 0 fixed No 114 43 0 asymptomatic 132 341 1 2 136 1 3.0 2 0 reversable Yes 115 62 0 nonanginal 130 263 0 0 97 0 1.2 2 1 reversable Yes 116 41 1 nontypical 135 203 0 0 132 0 0.0 2 0 fixed No 117 58 1 nonanginal 140 211 1 2 165 0 0.0 1 0 normal No 118 35 0 asymptomatic 138 183 0 0 182 0 1.4 1 0 normal No 119 63 1 asymptomatic 130 330 1 2 132 1 1.8 1 3 reversable Yes 120 65 1 asymptomatic 135 254 0 2 127 0 2.8 2 1 reversable Yes 121 48 1 asymptomatic 130 256 1 2 150 1 0.0 1 2 reversable Yes 122 63 0 asymptomatic 150 407 0 2 154 0 4.0 2 3 reversable Yes 123 51 1 nonanginal 100 222 0 0 143 1 1.2 2 0 normal No 124 55 1 asymptomatic 140 217 0 0 111 1 5.6 3 0 reversable Yes 125 65 1 typical 138 282 1 2 174 0 1.4 2 1 normal Yes 126 45 0 nontypical 130 234 0 2 175 0 0.6 2 0 normal No 127 56 0 asymptomatic 200 288 1 2 133 1 4.0 3 2 reversable Yes 128 54 1 asymptomatic 110 239 0 0 126 1 2.8 2 1 reversable Yes 129 44 1 nontypical 120 220 0 0 170 0 0.0 1 0 normal No 130 62 0 asymptomatic 124 209 0 0 163 0 0.0 1 0 normal No 131 54 1 nonanginal 120 258 0 2 147 0 0.4 2 0 reversable No 132 51 1 nonanginal 94 227 0 0 154 1 0.0 1 1 reversable No 133 29 1 nontypical 130 204 0 2 202 0 0.0 1 0 normal No 134 51 1 asymptomatic 140 261 0 2 186 1 0.0 1 0 normal No 135 43 0 nonanginal 122 213 0 0 165 0 0.2 2 0 normal No 136 55 0 nontypical 135 250 0 2 161 0 1.4 2 0 normal No 137 70 1 asymptomatic 145 174 0 0 125 1 2.6 3 0 reversable Yes 138 62 1 nontypical 120 281 0 2 103 0 1.4 2 1 reversable Yes 139 35 1 asymptomatic 120 198 0 0 130 1 1.6 2 0 reversable Yes 140 51 1 nonanginal 125 245 1 2 166 0 2.4 2 0 normal No 141 59 1 nontypical 140 221 0 0 164 1 0.0 1 0 normal No 142 59 1 typical 170 288 0 2 159 0 0.2 2 0 reversable Yes 143 52 1 nontypical 128 205 1 0 184 0 0.0 1 0 normal No 144 64 1 nonanginal 125 309 0 0 131 1 1.8 2 0 reversable Yes 145 58 1 nonanginal 105 240 0 2 154 1 0.6 2 0 reversable No 146 47 1 nonanginal 108 243 0 0 152 0 0.0 1 0 normal Yes 147 57 1 asymptomatic 165 289 1 2 124 0 1.0 2 3 reversable Yes 148 41 1 nonanginal 112 250 0 0 179 0 0.0 1 0 normal No 149 45 1 nontypical 128 308 0 2 170 0 0.0 1 0 normal No 150 60 0 nonanginal 102 318 0 0 160 0 0.0 1 1 normal No 151 52 1 typical 152 298 1 0 178 0 1.2 2 0 reversable No 152 42 0 asymptomatic 102 265 0 2 122 0 0.6 2 0 normal No 153 67 0 nonanginal 115 564 0 2 160 0 1.6 2 0 reversable No 154 55 1 asymptomatic 160 289 0 2 145 1 0.8 2 1 reversable Yes 155 64 1 asymptomatic 120 246 0 2 96 1 2.2 3 1 normal Yes 156 70 1 asymptomatic 130 322 0 2 109 0 2.4 2 3 normal Yes 157 51 1 asymptomatic 140 299 0 0 173 1 1.6 1 0 reversable Yes 158 58 1 asymptomatic 125 300 0 2 171 0 0.0 1 2 reversable Yes 159 60 1 asymptomatic 140 293 0 2 170 0 1.2 2 2 reversable Yes 160 68 1 nonanginal 118 277 0 0 151 0 1.0 1 1 reversable No 161 46 1 nontypical 101 197 1 0 156 0 0.0 1 0 reversable No 162 77 1 asymptomatic 125 304 0 2 162 1 0.0 1 3 normal Yes 163 54 0 nonanginal 110 214 0 0 158 0 1.6 2 0 normal No 164 58 0 asymptomatic 100 248 0 2 122 0 1.0 2 0 normal No 165 48 1 nonanginal 124 255 1 0 175 0 0.0 1 2 normal No 166 57 1 asymptomatic 132 207 0 0 168 1 0.0 1 0 reversable No 168 54 0 nontypical 132 288 1 2 159 1 0.0 1 1 normal No 169 35 1 asymptomatic 126 282 0 2 156 1 0.0 1 0 reversable Yes 170 45 0 nontypical 112 160 0 0 138 0 0.0 2 0 normal No 171 70 1 nonanginal 160 269 0 0 112 1 2.9 2 1 reversable Yes 172 53 1 asymptomatic 142 226 0 2 111 1 0.0 1 0 reversable No 173 59 0 asymptomatic 174 249 0 0 143 1 0.0 2 0 normal Yes 174 62 0 asymptomatic 140 394 0 2 157 0 1.2 2 0 normal No 175 64 1 asymptomatic 145 212 0 2 132 0 2.0 2 2 fixed Yes 176 57 1 asymptomatic 152 274 0 0 88 1 1.2 2 1 reversable Yes 177 52 1 asymptomatic 108 233 1 0 147 0 0.1 1 3 reversable No 178 56 1 asymptomatic 132 184 0 2 105 1 2.1 2 1 fixed Yes 179 43 1 nonanginal 130 315 0 0 162 0 1.9 1 1 normal No 180 53 1 nonanginal 130 246 1 2 173 0 0.0 1 3 normal No 181 48 1 asymptomatic 124 274 0 2 166 0 0.5 2 0 reversable Yes 182 56 0 asymptomatic 134 409 0 2 150 1 1.9 2 2 reversable Yes 183 42 1 typical 148 244 0 2 178 0 0.8 1 2 normal No 184 59 1 typical 178 270 0 2 145 0 4.2 3 0 reversable No 185 60 0 asymptomatic 158 305 0 2 161 0 0.0 1 0 normal Yes 186 63 0 nontypical 140 195 0 0 179 0 0.0 1 2 normal No 187 42 1 nonanginal 120 240 1 0 194 0 0.8 3 0 reversable No 188 66 1 nontypical 160 246 0 0 120 1 0.0 2 3 fixed Yes 189 54 1 nontypical 192 283 0 2 195 0 0.0 1 1 reversable Yes 190 69 1 nonanginal 140 254 0 2 146 0 2.0 2 3 reversable Yes 191 50 1 nonanginal 129 196 0 0 163 0 0.0 1 0 normal No 192 51 1 asymptomatic 140 298 0 0 122 1 4.2 2 3 reversable Yes 194 62 0 asymptomatic 138 294 1 0 106 0 1.9 2 3 normal Yes 195 68 0 nonanginal 120 211 0 2 115 0 1.5 2 0 normal No 196 67 1 asymptomatic 100 299 0 2 125 1 0.9 2 2 normal Yes 197 69 1 typical 160 234 1 2 131 0 0.1 2 1 normal No 198 45 0 asymptomatic 138 236 0 2 152 1 0.2 2 0 normal No 199 50 0 nontypical 120 244 0 0 162 0 1.1 1 0 normal No 200 59 1 typical 160 273 0 2 125 0 0.0 1 0 normal Yes 201 50 0 asymptomatic 110 254 0 2 159 0 0.0 1 0 normal No 202 64 0 asymptomatic 180 325 0 0 154 1 0.0 1 0 normal No 203 57 1 nonanginal 150 126 1 0 173 0 0.2 1 1 reversable No 204 64 0 nonanginal 140 313 0 0 133 0 0.2 1 0 reversable No 205 43 1 asymptomatic 110 211 0 0 161 0 0.0 1 0 reversable No 206 45 1 asymptomatic 142 309 0 2 147 1 0.0 2 3 reversable Yes 207 58 1 asymptomatic 128 259 0 2 130 1 3.0 2 2 reversable Yes 208 50 1 asymptomatic 144 200 0 2 126 1 0.9 2 0 reversable Yes 209 55 1 nontypical 130 262 0 0 155 0 0.0 1 0 normal No 210 62 0 asymptomatic 150 244 0 0 154 1 1.4 2 0 normal Yes 211 37 0 nonanginal 120 215 0 0 170 0 0.0 1 0 normal No 212 38 1 typical 120 231 0 0 182 1 3.8 2 0 reversable Yes 213 41 1 nonanginal 130 214 0 2 168 0 2.0 2 0 normal No 214 66 0 asymptomatic 178 228 1 0 165 1 1.0 2 2 reversable Yes 215 52 1 asymptomatic 112 230 0 0 160 0 0.0 1 1 normal Yes 216 56 1 typical 120 193 0 2 162 0 1.9 2 0 reversable No 217 46 0 nontypical 105 204 0 0 172 0 0.0 1 0 normal No 218 46 0 asymptomatic 138 243 0 2 152 1 0.0 2 0 normal No 219 64 0 asymptomatic 130 303 0 0 122 0 2.0 2 2 normal No 220 59 1 asymptomatic 138 271 0 2 182 0 0.0 1 0 normal No 221 41 0 nonanginal 112 268 0 2 172 1 0.0 1 0 normal No 222 54 0 nonanginal 108 267 0 2 167 0 0.0 1 0 normal No 223 39 0 nonanginal 94 199 0 0 179 0 0.0 1 0 normal No 224 53 1 asymptomatic 123 282 0 0 95 1 2.0 2 2 reversable Yes 225 63 0 asymptomatic 108 269 0 0 169 1 1.8 2 2 normal Yes 226 34 0 nontypical 118 210 0 0 192 0 0.7 1 0 normal No 227 47 1 asymptomatic 112 204 0 0 143 0 0.1 1 0 normal No 228 67 0 nonanginal 152 277 0 0 172 0 0.0 1 1 normal No 229 54 1 asymptomatic 110 206 0 2 108 1 0.0 2 1 normal Yes 230 66 1 asymptomatic 112 212 0 2 132 1 0.1 1 1 normal Yes 231 52 0 nonanginal 136 196 0 2 169 0 0.1 2 0 normal No 232 55 0 asymptomatic 180 327 0 1 117 1 3.4 2 0 normal Yes 233 49 1 nonanginal 118 149 0 2 126 0 0.8 1 3 normal Yes 234 74 0 nontypical 120 269 0 2 121 1 0.2 1 1 normal No 235 54 0 nonanginal 160 201 0 0 163 0 0.0 1 1 normal No 236 54 1 asymptomatic 122 286 0 2 116 1 3.2 2 2 normal Yes 237 56 1 asymptomatic 130 283 1 2 103 1 1.6 3 0 reversable Yes 238 46 1 asymptomatic 120 249 0 2 144 0 0.8 1 0 reversable Yes 239 49 0 nontypical 134 271 0 0 162 0 0.0 2 0 normal No 240 42 1 nontypical 120 295 0 0 162 0 0.0 1 0 normal No 241 41 1 nontypical 110 235 0 0 153 0 0.0 1 0 normal No 242 41 0 nontypical 126 306 0 0 163 0 0.0 1 0 normal No 243 49 0 asymptomatic 130 269 0 0 163 0 0.0 1 0 normal No 244 61 1 typical 134 234 0 0 145 0 2.6 2 2 normal Yes 245 60 0 nonanginal 120 178 1 0 96 0 0.0 1 0 normal No 246 67 1 asymptomatic 120 237 0 0 71 0 1.0 2 0 normal Yes 247 58 1 asymptomatic 100 234 0 0 156 0 0.1 1 1 reversable Yes 248 47 1 asymptomatic 110 275 0 2 118 1 1.0 2 1 normal Yes 249 52 1 asymptomatic 125 212 0 0 168 0 1.0 1 2 reversable Yes 250 62 1 nontypical 128 208 1 2 140 0 0.0 1 0 normal No 251 57 1 asymptomatic 110 201 0 0 126 1 1.5 2 0 fixed No 252 58 1 asymptomatic 146 218 0 0 105 0 2.0 2 1 reversable Yes 253 64 1 asymptomatic 128 263 0 0 105 1 0.2 2 1 reversable No 254 51 0 nonanginal 120 295 0 2 157 0 0.6 1 0 normal No 255 43 1 asymptomatic 115 303 0 0 181 0 1.2 2 0 normal No 256 42 0 nonanginal 120 209 0 0 173 0 0.0 2 0 normal No 257 67 0 asymptomatic 106 223 0 0 142 0 0.3 1 2 normal No 258 76 0 nonanginal 140 197 0 1 116 0 1.1 2 0 normal No 259 70 1 nontypical 156 245 0 2 143 0 0.0 1 0 normal No 260 57 1 nontypical 124 261 0 0 141 0 0.3 1 0 reversable Yes 261 44 0 nonanginal 118 242 0 0 149 0 0.3 2 1 normal No 262 58 0 nontypical 136 319 1 2 152 0 0.0 1 2 normal Yes 263 60 0 typical 150 240 0 0 171 0 0.9 1 0 normal No 264 44 1 nonanginal 120 226 0 0 169 0 0.0 1 0 normal No 265 61 1 asymptomatic 138 166 0 2 125 1 3.6 2 1 normal Yes 266 42 1 asymptomatic 136 315 0 0 125 1 1.8 2 0 fixed Yes 268 59 1 nonanginal 126 218 1 0 134 0 2.2 2 1 fixed Yes 269 40 1 asymptomatic 152 223 0 0 181 0 0.0 1 0 reversable Yes 270 42 1 nonanginal 130 180 0 0 150 0 0.0 1 0 normal No 271 61 1 asymptomatic 140 207 0 2 138 1 1.9 1 1 reversable Yes 272 66 1 asymptomatic 160 228 0 2 138 0 2.3 1 0 fixed No 273 46 1 asymptomatic 140 311 0 0 120 1 1.8 2 2 reversable Yes 274 71 0 asymptomatic 112 149 0 0 125 0 1.6 2 0 normal No 275 59 1 typical 134 204 0 0 162 0 0.8 1 2 normal Yes 276 64 1 typical 170 227 0 2 155 0 0.6 2 0 reversable No 277 66 0 nonanginal 146 278 0 2 152 0 0.0 2 1 normal No 278 39 0 nonanginal 138 220 0 0 152 0 0.0 2 0 normal No 279 57 1 nontypical 154 232 0 2 164 0 0.0 1 1 normal Yes 280 58 0 asymptomatic 130 197 0 0 131 0 0.6 2 0 normal No 281 57 1 asymptomatic 110 335 0 0 143 1 3.0 2 1 reversable Yes 282 47 1 nonanginal 130 253 0 0 179 0 0.0 1 0 normal No 283 55 0 asymptomatic 128 205 0 1 130 1 2.0 2 1 reversable Yes 284 35 1 nontypical 122 192 0 0 174 0 0.0 1 0 normal No 285 61 1 asymptomatic 148 203 0 0 161 0 0.0 1 1 reversable Yes 286 58 1 asymptomatic 114 318 0 1 140 0 4.4 3 3 fixed Yes 287 58 0 asymptomatic 170 225 1 2 146 1 2.8 2 2 fixed Yes 289 56 1 nontypical 130 221 0 2 163 0 0.0 1 0 reversable No 290 56 1 nontypical 120 240 0 0 169 0 0.0 3 0 normal No 291 67 1 nonanginal 152 212 0 2 150 0 0.8 2 0 reversable Yes 292 55 0 nontypical 132 342 0 0 166 0 1.2 1 0 normal No 293 44 1 asymptomatic 120 169 0 0 144 1 2.8 3 0 fixed Yes 294 63 1 asymptomatic 140 187 0 2 144 1 4.0 1 2 reversable Yes 295 63 0 asymptomatic 124 197 0 0 136 1 0.0 2 0 normal Yes 296 41 1 nontypical 120 157 0 0 182 0 0.0 1 0 normal No 297 59 1 asymptomatic 164 176 1 2 90 0 1.0 2 2 fixed Yes 298 57 0 asymptomatic 140 241 0 0 123 1 0.2 2 0 reversable Yes 299 45 1 typical 110 264 0 0 132 0 1.2 2 0 reversable Yes 300 68 1 asymptomatic 144 193 1 0 141 0 3.4 2 2 reversable Yes 301 57 1 asymptomatic 130 131 0 0 115 1 1.2 2 1 reversable Yes 302 57 0 nontypical 130 236 0 2 174 0 0.0 2 1 normal Yes 34.7.3 CarSeats数据 knitr::kable(Carseats) Sales CompPrice Income Advertising Population Price ShelveLoc Age Education Urban US 9.50 138 73 11 276 120 Bad 42 17 Yes Yes 11.22 111 48 16 260 83 Good 65 10 Yes Yes 10.06 113 35 10 269 80 Medium 59 12 Yes Yes 7.40 117 100 4 466 97 Medium 55 14 Yes Yes 4.15 141 64 3 340 128 Bad 38 13 Yes No 10.81 124 113 13 501 72 Bad 78 16 No Yes 6.63 115 105 0 45 108 Medium 71 15 Yes No 11.85 136 81 15 425 120 Good 67 10 Yes Yes 6.54 132 110 0 108 124 Medium 76 10 No No 4.69 132 113 0 131 124 Medium 76 17 No Yes 9.01 121 78 9 150 100 Bad 26 10 No Yes 11.96 117 94 4 503 94 Good 50 13 Yes Yes 3.98 122 35 2 393 136 Medium 62 18 Yes No 10.96 115 28 11 29 86 Good 53 18 Yes Yes 11.17 107 117 11 148 118 Good 52 18 Yes Yes 8.71 149 95 5 400 144 Medium 76 18 No No 7.58 118 32 0 284 110 Good 63 13 Yes No 12.29 147 74 13 251 131 Good 52 10 Yes Yes 13.91 110 110 0 408 68 Good 46 17 No Yes 8.73 129 76 16 58 121 Medium 69 12 Yes Yes 6.41 125 90 2 367 131 Medium 35 18 Yes Yes 12.13 134 29 12 239 109 Good 62 18 No Yes 5.08 128 46 6 497 138 Medium 42 13 Yes No 5.87 121 31 0 292 109 Medium 79 10 Yes No 10.14 145 119 16 294 113 Bad 42 12 Yes Yes 14.90 139 32 0 176 82 Good 54 11 No No 8.33 107 115 11 496 131 Good 50 11 No Yes 5.27 98 118 0 19 107 Medium 64 17 Yes No 2.99 103 74 0 359 97 Bad 55 11 Yes Yes 7.81 104 99 15 226 102 Bad 58 17 Yes Yes 13.55 125 94 0 447 89 Good 30 12 Yes No 8.25 136 58 16 241 131 Medium 44 18 Yes Yes 6.20 107 32 12 236 137 Good 64 10 No Yes 8.77 114 38 13 317 128 Good 50 16 Yes Yes 2.67 115 54 0 406 128 Medium 42 17 Yes Yes 11.07 131 84 11 29 96 Medium 44 17 No Yes 8.89 122 76 0 270 100 Good 60 18 No No 4.95 121 41 5 412 110 Medium 54 10 Yes Yes 6.59 109 73 0 454 102 Medium 65 15 Yes No 3.24 130 60 0 144 138 Bad 38 10 No No 2.07 119 98 0 18 126 Bad 73 17 No No 7.96 157 53 0 403 124 Bad 58 16 Yes No 10.43 77 69 0 25 24 Medium 50 18 Yes No 4.12 123 42 11 16 134 Medium 59 13 Yes Yes 4.16 85 79 6 325 95 Medium 69 13 Yes Yes 4.56 141 63 0 168 135 Bad 44 12 Yes Yes 12.44 127 90 14 16 70 Medium 48 15 No Yes 4.38 126 98 0 173 108 Bad 55 16 Yes No 3.91 116 52 0 349 98 Bad 69 18 Yes No 10.61 157 93 0 51 149 Good 32 17 Yes No 1.42 99 32 18 341 108 Bad 80 16 Yes Yes 4.42 121 90 0 150 108 Bad 75 16 Yes No 7.91 153 40 3 112 129 Bad 39 18 Yes Yes 6.92 109 64 13 39 119 Medium 61 17 Yes Yes 4.90 134 103 13 25 144 Medium 76 17 No Yes 6.85 143 81 5 60 154 Medium 61 18 Yes Yes 11.91 133 82 0 54 84 Medium 50 17 Yes No 0.91 93 91 0 22 117 Bad 75 11 Yes No 5.42 103 93 15 188 103 Bad 74 16 Yes Yes 5.21 118 71 4 148 114 Medium 80 13 Yes No 8.32 122 102 19 469 123 Bad 29 13 Yes Yes 7.32 105 32 0 358 107 Medium 26 13 No No 1.82 139 45 0 146 133 Bad 77 17 Yes Yes 8.47 119 88 10 170 101 Medium 61 13 Yes Yes 7.80 100 67 12 184 104 Medium 32 16 No Yes 4.90 122 26 0 197 128 Medium 55 13 No No 8.85 127 92 0 508 91 Medium 56 18 Yes No 9.01 126 61 14 152 115 Medium 47 16 Yes Yes 13.39 149 69 20 366 134 Good 60 13 Yes Yes 7.99 127 59 0 339 99 Medium 65 12 Yes No 9.46 89 81 15 237 99 Good 74 12 Yes Yes 6.50 148 51 16 148 150 Medium 58 17 No Yes 5.52 115 45 0 432 116 Medium 25 15 Yes No 12.61 118 90 10 54 104 Good 31 11 No Yes 6.20 150 68 5 125 136 Medium 64 13 No Yes 8.55 88 111 23 480 92 Bad 36 16 No Yes 10.64 102 87 10 346 70 Medium 64 15 Yes Yes 7.70 118 71 12 44 89 Medium 67 18 No Yes 4.43 134 48 1 139 145 Medium 65 12 Yes Yes 9.14 134 67 0 286 90 Bad 41 13 Yes No 8.01 113 100 16 353 79 Bad 68 11 Yes Yes 7.52 116 72 0 237 128 Good 70 13 Yes No 11.62 151 83 4 325 139 Good 28 17 Yes Yes 4.42 109 36 7 468 94 Bad 56 11 Yes Yes 2.23 111 25 0 52 121 Bad 43 18 No No 8.47 125 103 0 304 112 Medium 49 13 No No 8.70 150 84 9 432 134 Medium 64 15 Yes No 11.70 131 67 7 272 126 Good 54 16 No Yes 6.56 117 42 7 144 111 Medium 62 10 Yes Yes 7.95 128 66 3 493 119 Medium 45 16 No No 5.33 115 22 0 491 103 Medium 64 11 No No 4.81 97 46 11 267 107 Medium 80 15 Yes Yes 4.53 114 113 0 97 125 Medium 29 12 Yes No 8.86 145 30 0 67 104 Medium 55 17 Yes No 8.39 115 97 5 134 84 Bad 55 11 Yes Yes 5.58 134 25 10 237 148 Medium 59 13 Yes Yes 9.48 147 42 10 407 132 Good 73 16 No Yes 7.45 161 82 5 287 129 Bad 33 16 Yes Yes 12.49 122 77 24 382 127 Good 36 16 No Yes 4.88 121 47 3 220 107 Bad 56 16 No Yes 4.11 113 69 11 94 106 Medium 76 12 No Yes 6.20 128 93 0 89 118 Medium 34 18 Yes No 5.30 113 22 0 57 97 Medium 65 16 No No 5.07 123 91 0 334 96 Bad 78 17 Yes Yes 4.62 121 96 0 472 138 Medium 51 12 Yes No 5.55 104 100 8 398 97 Medium 61 11 Yes Yes 0.16 102 33 0 217 139 Medium 70 18 No No 8.55 134 107 0 104 108 Medium 60 12 Yes No 3.47 107 79 2 488 103 Bad 65 16 Yes No 8.98 115 65 0 217 90 Medium 60 17 No No 9.00 128 62 7 125 116 Medium 43 14 Yes Yes 6.62 132 118 12 272 151 Medium 43 14 Yes Yes 6.67 116 99 5 298 125 Good 62 12 Yes Yes 6.01 131 29 11 335 127 Bad 33 12 Yes Yes 9.31 122 87 9 17 106 Medium 65 13 Yes Yes 8.54 139 35 0 95 129 Medium 42 13 Yes No 5.08 135 75 0 202 128 Medium 80 10 No No 8.80 145 53 0 507 119 Medium 41 12 Yes No 7.57 112 88 2 243 99 Medium 62 11 Yes Yes 7.37 130 94 8 137 128 Medium 64 12 Yes Yes 6.87 128 105 11 249 131 Medium 63 13 Yes Yes 11.67 125 89 10 380 87 Bad 28 10 Yes Yes 6.88 119 100 5 45 108 Medium 75 10 Yes Yes 8.19 127 103 0 125 155 Good 29 15 No Yes 8.87 131 113 0 181 120 Good 63 14 Yes No 9.34 89 78 0 181 49 Medium 43 15 No No 11.27 153 68 2 60 133 Good 59 16 Yes Yes 6.52 125 48 3 192 116 Medium 51 14 Yes Yes 4.96 133 100 3 350 126 Bad 55 13 Yes Yes 4.47 143 120 7 279 147 Bad 40 10 No Yes 8.41 94 84 13 497 77 Medium 51 12 Yes Yes 6.50 108 69 3 208 94 Medium 77 16 Yes No 9.54 125 87 9 232 136 Good 72 10 Yes Yes 7.62 132 98 2 265 97 Bad 62 12 Yes Yes 3.67 132 31 0 327 131 Medium 76 16 Yes No 6.44 96 94 14 384 120 Medium 36 18 No Yes 5.17 131 75 0 10 120 Bad 31 18 No No 6.52 128 42 0 436 118 Medium 80 11 Yes No 10.27 125 103 12 371 109 Medium 44 10 Yes Yes 12.30 146 62 10 310 94 Medium 30 13 No Yes 6.03 133 60 10 277 129 Medium 45 18 Yes Yes 6.53 140 42 0 331 131 Bad 28 15 Yes No 7.44 124 84 0 300 104 Medium 77 15 Yes No 0.53 122 88 7 36 159 Bad 28 17 Yes Yes 9.09 132 68 0 264 123 Good 34 11 No No 8.77 144 63 11 27 117 Medium 47 17 Yes Yes 3.90 114 83 0 412 131 Bad 39 14 Yes No 10.51 140 54 9 402 119 Good 41 16 No Yes 7.56 110 119 0 384 97 Medium 72 14 No Yes 11.48 121 120 13 140 87 Medium 56 11 Yes Yes 10.49 122 84 8 176 114 Good 57 10 No Yes 10.77 111 58 17 407 103 Good 75 17 No Yes 7.64 128 78 0 341 128 Good 45 13 No No 5.93 150 36 7 488 150 Medium 25 17 No Yes 6.89 129 69 10 289 110 Medium 50 16 No Yes 7.71 98 72 0 59 69 Medium 65 16 Yes No 7.49 146 34 0 220 157 Good 51 16 Yes No 10.21 121 58 8 249 90 Medium 48 13 No Yes 12.53 142 90 1 189 112 Good 39 10 No Yes 9.32 119 60 0 372 70 Bad 30 18 No No 4.67 111 28 0 486 111 Medium 29 12 No No 2.93 143 21 5 81 160 Medium 67 12 No Yes 3.63 122 74 0 424 149 Medium 51 13 Yes No 5.68 130 64 0 40 106 Bad 39 17 No No 8.22 148 64 0 58 141 Medium 27 13 No Yes 0.37 147 58 7 100 191 Bad 27 15 Yes Yes 6.71 119 67 17 151 137 Medium 55 11 Yes Yes 6.71 106 73 0 216 93 Medium 60 13 Yes No 7.30 129 89 0 425 117 Medium 45 10 Yes No 11.48 104 41 15 492 77 Good 73 18 Yes Yes 8.01 128 39 12 356 118 Medium 71 10 Yes Yes 12.49 93 106 12 416 55 Medium 75 15 Yes Yes 9.03 104 102 13 123 110 Good 35 16 Yes Yes 6.38 135 91 5 207 128 Medium 66 18 Yes Yes 0.00 139 24 0 358 185 Medium 79 15 No No 7.54 115 89 0 38 122 Medium 25 12 Yes No 5.61 138 107 9 480 154 Medium 47 11 No Yes 10.48 138 72 0 148 94 Medium 27 17 Yes Yes 10.66 104 71 14 89 81 Medium 25 14 No Yes 7.78 144 25 3 70 116 Medium 77 18 Yes Yes 4.94 137 112 15 434 149 Bad 66 13 Yes Yes 7.43 121 83 0 79 91 Medium 68 11 Yes No 4.74 137 60 4 230 140 Bad 25 13 Yes No 5.32 118 74 6 426 102 Medium 80 18 Yes Yes 9.95 132 33 7 35 97 Medium 60 11 No Yes 10.07 130 100 11 449 107 Medium 64 10 Yes Yes 8.68 120 51 0 93 86 Medium 46 17 No No 6.03 117 32 0 142 96 Bad 62 17 Yes No 8.07 116 37 0 426 90 Medium 76 15 Yes No 12.11 118 117 18 509 104 Medium 26 15 No Yes 8.79 130 37 13 297 101 Medium 37 13 No Yes 6.67 156 42 13 170 173 Good 74 14 Yes Yes 7.56 108 26 0 408 93 Medium 56 14 No No 13.28 139 70 7 71 96 Good 61 10 Yes Yes 7.23 112 98 18 481 128 Medium 45 11 Yes Yes 4.19 117 93 4 420 112 Bad 66 11 Yes Yes 4.10 130 28 6 410 133 Bad 72 16 Yes Yes 2.52 124 61 0 333 138 Medium 76 16 Yes No 3.62 112 80 5 500 128 Medium 69 10 Yes Yes 6.42 122 88 5 335 126 Medium 64 14 Yes Yes 5.56 144 92 0 349 146 Medium 62 12 No No 5.94 138 83 0 139 134 Medium 54 18 Yes No 4.10 121 78 4 413 130 Bad 46 10 No Yes 2.05 131 82 0 132 157 Bad 25 14 Yes No 8.74 155 80 0 237 124 Medium 37 14 Yes No 5.68 113 22 1 317 132 Medium 28 12 Yes No 4.97 162 67 0 27 160 Medium 77 17 Yes Yes 8.19 111 105 0 466 97 Bad 61 10 No No 7.78 86 54 0 497 64 Bad 33 12 Yes No 3.02 98 21 11 326 90 Bad 76 11 No Yes 4.36 125 41 2 357 123 Bad 47 14 No Yes 9.39 117 118 14 445 120 Medium 32 15 Yes Yes 12.04 145 69 19 501 105 Medium 45 11 Yes Yes 8.23 149 84 5 220 139 Medium 33 10 Yes Yes 4.83 115 115 3 48 107 Medium 73 18 Yes Yes 2.34 116 83 15 170 144 Bad 71 11 Yes Yes 5.73 141 33 0 243 144 Medium 34 17 Yes No 4.34 106 44 0 481 111 Medium 70 14 No No 9.70 138 61 12 156 120 Medium 25 14 Yes Yes 10.62 116 79 19 359 116 Good 58 17 Yes Yes 10.59 131 120 15 262 124 Medium 30 10 Yes Yes 6.43 124 44 0 125 107 Medium 80 11 Yes No 7.49 136 119 6 178 145 Medium 35 13 Yes Yes 3.45 110 45 9 276 125 Medium 62 14 Yes Yes 4.10 134 82 0 464 141 Medium 48 13 No No 6.68 107 25 0 412 82 Bad 36 14 Yes No 7.80 119 33 0 245 122 Good 56 14 Yes No 8.69 113 64 10 68 101 Medium 57 16 Yes Yes 5.40 149 73 13 381 163 Bad 26 11 No Yes 11.19 98 104 0 404 72 Medium 27 18 No No 5.16 115 60 0 119 114 Bad 38 14 No No 8.09 132 69 0 123 122 Medium 27 11 No No 13.14 137 80 10 24 105 Good 61 15 Yes Yes 8.65 123 76 18 218 120 Medium 29 14 No Yes 9.43 115 62 11 289 129 Good 56 16 No Yes 5.53 126 32 8 95 132 Medium 50 17 Yes Yes 9.32 141 34 16 361 108 Medium 69 10 Yes Yes 9.62 151 28 8 499 135 Medium 48 10 Yes Yes 7.36 121 24 0 200 133 Good 73 13 Yes No 3.89 123 105 0 149 118 Bad 62 16 Yes Yes 10.31 159 80 0 362 121 Medium 26 18 Yes No 12.01 136 63 0 160 94 Medium 38 12 Yes No 4.68 124 46 0 199 135 Medium 52 14 No No 7.82 124 25 13 87 110 Medium 57 10 Yes Yes 8.78 130 30 0 391 100 Medium 26 18 Yes No 10.00 114 43 0 199 88 Good 57 10 No Yes 6.90 120 56 20 266 90 Bad 78 18 Yes Yes 5.04 123 114 0 298 151 Bad 34 16 Yes No 5.36 111 52 0 12 101 Medium 61 11 Yes Yes 5.05 125 67 0 86 117 Bad 65 11 Yes No 9.16 137 105 10 435 156 Good 72 14 Yes Yes 3.72 139 111 5 310 132 Bad 62 13 Yes Yes 8.31 133 97 0 70 117 Medium 32 16 Yes No 5.64 124 24 5 288 122 Medium 57 12 No Yes 9.58 108 104 23 353 129 Good 37 17 Yes Yes 7.71 123 81 8 198 81 Bad 80 15 Yes Yes 4.20 147 40 0 277 144 Medium 73 10 Yes No 8.67 125 62 14 477 112 Medium 80 13 Yes Yes 3.47 108 38 0 251 81 Bad 72 14 No No 5.12 123 36 10 467 100 Bad 74 11 No Yes 7.67 129 117 8 400 101 Bad 36 10 Yes Yes 5.71 121 42 4 188 118 Medium 54 15 Yes Yes 6.37 120 77 15 86 132 Medium 48 18 Yes Yes 7.77 116 26 6 434 115 Medium 25 17 Yes Yes 6.95 128 29 5 324 159 Good 31 15 Yes Yes 5.31 130 35 10 402 129 Bad 39 17 Yes Yes 9.10 128 93 12 343 112 Good 73 17 No Yes 5.83 134 82 7 473 112 Bad 51 12 No Yes 6.53 123 57 0 66 105 Medium 39 11 Yes No 5.01 159 69 0 438 166 Medium 46 17 Yes No 11.99 119 26 0 284 89 Good 26 10 Yes No 4.55 111 56 0 504 110 Medium 62 16 Yes No 12.98 113 33 0 14 63 Good 38 12 Yes No 10.04 116 106 8 244 86 Medium 58 12 Yes Yes 7.22 135 93 2 67 119 Medium 34 11 Yes Yes 6.67 107 119 11 210 132 Medium 53 11 Yes Yes 6.93 135 69 14 296 130 Medium 73 15 Yes Yes 7.80 136 48 12 326 125 Medium 36 16 Yes Yes 7.22 114 113 2 129 151 Good 40 15 No Yes 3.42 141 57 13 376 158 Medium 64 18 Yes Yes 2.86 121 86 10 496 145 Bad 51 10 Yes Yes 11.19 122 69 7 303 105 Good 45 16 No Yes 7.74 150 96 0 80 154 Good 61 11 Yes No 5.36 135 110 0 112 117 Medium 80 16 No No 6.97 106 46 11 414 96 Bad 79 17 No No 7.60 146 26 11 261 131 Medium 39 10 Yes Yes 7.53 117 118 11 429 113 Medium 67 18 No Yes 6.88 95 44 4 208 72 Bad 44 17 Yes Yes 6.98 116 40 0 74 97 Medium 76 15 No No 8.75 143 77 25 448 156 Medium 43 17 Yes Yes 9.49 107 111 14 400 103 Medium 41 11 No Yes 6.64 118 70 0 106 89 Bad 39 17 Yes No 11.82 113 66 16 322 74 Good 76 15 Yes Yes 11.28 123 84 0 74 89 Good 59 10 Yes No 12.66 148 76 3 126 99 Good 60 11 Yes Yes 4.21 118 35 14 502 137 Medium 79 10 No Yes 8.21 127 44 13 160 123 Good 63 18 Yes Yes 3.07 118 83 13 276 104 Bad 75 10 Yes Yes 10.98 148 63 0 312 130 Good 63 15 Yes No 9.40 135 40 17 497 96 Medium 54 17 No Yes 8.57 116 78 1 158 99 Medium 45 11 Yes Yes 7.41 99 93 0 198 87 Medium 57 16 Yes Yes 5.28 108 77 13 388 110 Bad 74 14 Yes Yes 10.01 133 52 16 290 99 Medium 43 11 Yes Yes 11.93 123 98 12 408 134 Good 29 10 Yes Yes 8.03 115 29 26 394 132 Medium 33 13 Yes Yes 4.78 131 32 1 85 133 Medium 48 12 Yes Yes 5.90 138 92 0 13 120 Bad 61 12 Yes No 9.24 126 80 19 436 126 Medium 52 10 Yes Yes 11.18 131 111 13 33 80 Bad 68 18 Yes Yes 9.53 175 65 29 419 166 Medium 53 12 Yes Yes 6.15 146 68 12 328 132 Bad 51 14 Yes Yes 6.80 137 117 5 337 135 Bad 38 10 Yes Yes 9.33 103 81 3 491 54 Medium 66 13 Yes No 7.72 133 33 10 333 129 Good 71 14 Yes Yes 6.39 131 21 8 220 171 Good 29 14 Yes Yes 15.63 122 36 5 369 72 Good 35 10 Yes Yes 6.41 142 30 0 472 136 Good 80 15 No No 10.08 116 72 10 456 130 Good 41 14 No Yes 6.97 127 45 19 459 129 Medium 57 11 No Yes 5.86 136 70 12 171 152 Medium 44 18 Yes Yes 7.52 123 39 5 499 98 Medium 34 15 Yes No 9.16 140 50 10 300 139 Good 60 15 Yes Yes 10.36 107 105 18 428 103 Medium 34 12 Yes Yes 2.66 136 65 4 133 150 Bad 53 13 Yes Yes 11.70 144 69 11 131 104 Medium 47 11 Yes Yes 4.69 133 30 0 152 122 Medium 53 17 Yes No 6.23 112 38 17 316 104 Medium 80 16 Yes Yes 3.15 117 66 1 65 111 Bad 55 11 Yes Yes 11.27 100 54 9 433 89 Good 45 12 Yes Yes 4.99 122 59 0 501 112 Bad 32 14 No No 10.10 135 63 15 213 134 Medium 32 10 Yes Yes 5.74 106 33 20 354 104 Medium 61 12 Yes Yes 5.87 136 60 7 303 147 Medium 41 10 Yes Yes 7.63 93 117 9 489 83 Bad 42 13 Yes Yes 6.18 120 70 15 464 110 Medium 72 15 Yes Yes 5.17 138 35 6 60 143 Bad 28 18 Yes No 8.61 130 38 0 283 102 Medium 80 15 Yes No 5.97 112 24 0 164 101 Medium 45 11 Yes No 11.54 134 44 4 219 126 Good 44 15 Yes Yes 7.50 140 29 0 105 91 Bad 43 16 Yes No 7.38 98 120 0 268 93 Medium 72 10 No No 7.81 137 102 13 422 118 Medium 71 10 No Yes 5.99 117 42 10 371 121 Bad 26 14 Yes Yes 8.43 138 80 0 108 126 Good 70 13 No Yes 4.81 121 68 0 279 149 Good 79 12 Yes No 8.97 132 107 0 144 125 Medium 33 13 No No 6.88 96 39 0 161 112 Good 27 14 No No 12.57 132 102 20 459 107 Good 49 11 Yes Yes 9.32 134 27 18 467 96 Medium 49 14 No Yes 8.64 111 101 17 266 91 Medium 63 17 No Yes 10.44 124 115 16 458 105 Medium 62 16 No Yes 13.44 133 103 14 288 122 Good 61 17 Yes Yes 9.45 107 67 12 430 92 Medium 35 12 No Yes 5.30 133 31 1 80 145 Medium 42 18 Yes Yes 7.02 130 100 0 306 146 Good 42 11 Yes No 3.58 142 109 0 111 164 Good 72 12 Yes No 13.36 103 73 3 276 72 Medium 34 15 Yes Yes 4.17 123 96 10 71 118 Bad 69 11 Yes Yes 3.13 130 62 11 396 130 Bad 66 14 Yes Yes 8.77 118 86 7 265 114 Good 52 15 No Yes 8.68 131 25 10 183 104 Medium 56 15 No Yes 5.25 131 55 0 26 110 Bad 79 12 Yes Yes 10.26 111 75 1 377 108 Good 25 12 Yes No 10.50 122 21 16 488 131 Good 30 14 Yes Yes 6.53 154 30 0 122 162 Medium 57 17 No No 5.98 124 56 11 447 134 Medium 53 12 No Yes 14.37 95 106 0 256 53 Good 52 17 Yes No 10.71 109 22 10 348 79 Good 74 14 No Yes 10.26 135 100 22 463 122 Medium 36 14 Yes Yes 7.68 126 41 22 403 119 Bad 42 12 Yes Yes 9.08 152 81 0 191 126 Medium 54 16 Yes No 7.80 121 50 0 508 98 Medium 65 11 No No 5.58 137 71 0 402 116 Medium 78 17 Yes No 9.44 131 47 7 90 118 Medium 47 12 Yes Yes 7.90 132 46 4 206 124 Medium 73 11 Yes No 16.27 141 60 19 319 92 Good 44 11 Yes Yes 6.81 132 61 0 263 125 Medium 41 12 No No 6.11 133 88 3 105 119 Medium 79 12 Yes Yes 5.81 125 111 0 404 107 Bad 54 15 Yes No 9.64 106 64 10 17 89 Medium 68 17 Yes Yes 3.90 124 65 21 496 151 Bad 77 13 Yes Yes 4.95 121 28 19 315 121 Medium 66 14 Yes Yes 9.35 98 117 0 76 68 Medium 63 10 Yes No 12.85 123 37 15 348 112 Good 28 12 Yes Yes 5.87 131 73 13 455 132 Medium 62 17 Yes Yes 5.32 152 116 0 170 160 Medium 39 16 Yes No 8.67 142 73 14 238 115 Medium 73 14 No Yes 8.14 135 89 11 245 78 Bad 79 16 Yes Yes 8.44 128 42 8 328 107 Medium 35 12 Yes Yes 5.47 108 75 9 61 111 Medium 67 12 Yes Yes 6.10 153 63 0 49 124 Bad 56 16 Yes No 4.53 129 42 13 315 130 Bad 34 13 Yes Yes 5.57 109 51 10 26 120 Medium 30 17 No Yes 5.35 130 58 19 366 139 Bad 33 16 Yes Yes 12.57 138 108 17 203 128 Good 33 14 Yes Yes 6.14 139 23 3 37 120 Medium 55 11 No Yes 7.41 162 26 12 368 159 Medium 40 18 Yes Yes 5.94 100 79 7 284 95 Bad 50 12 Yes Yes 9.71 134 37 0 27 120 Good 49 16 Yes Yes 34.7.4 Boston数据 knitr::kable(Boston) crim zn indus chas nox rm age dis rad tax ptratio black lstat medv 0.00632 18.0 2.31 0 0.5380 6.575 65.2 4.0900 1 296 15.3 396.90 4.98 24.0 0.02731 0.0 7.07 0 0.4690 6.421 78.9 4.9671 2 242 17.8 396.90 9.14 21.6 0.02729 0.0 7.07 0 0.4690 7.185 61.1 4.9671 2 242 17.8 392.83 4.03 34.7 0.03237 0.0 2.18 0 0.4580 6.998 45.8 6.0622 3 222 18.7 394.63 2.94 33.4 0.06905 0.0 2.18 0 0.4580 7.147 54.2 6.0622 3 222 18.7 396.90 5.33 36.2 0.02985 0.0 2.18 0 0.4580 6.430 58.7 6.0622 3 222 18.7 394.12 5.21 28.7 0.08829 12.5 7.87 0 0.5240 6.012 66.6 5.5605 5 311 15.2 395.60 12.43 22.9 0.14455 12.5 7.87 0 0.5240 6.172 96.1 5.9505 5 311 15.2 396.90 19.15 27.1 0.21124 12.5 7.87 0 0.5240 5.631 100.0 6.0821 5 311 15.2 386.63 29.93 16.5 0.17004 12.5 7.87 0 0.5240 6.004 85.9 6.5921 5 311 15.2 386.71 17.10 18.9 0.22489 12.5 7.87 0 0.5240 6.377 94.3 6.3467 5 311 15.2 392.52 20.45 15.0 0.11747 12.5 7.87 0 0.5240 6.009 82.9 6.2267 5 311 15.2 396.90 13.27 18.9 0.09378 12.5 7.87 0 0.5240 5.889 39.0 5.4509 5 311 15.2 390.50 15.71 21.7 0.62976 0.0 8.14 0 0.5380 5.949 61.8 4.7075 4 307 21.0 396.90 8.26 20.4 0.63796 0.0 8.14 0 0.5380 6.096 84.5 4.4619 4 307 21.0 380.02 10.26 18.2 0.62739 0.0 8.14 0 0.5380 5.834 56.5 4.4986 4 307 21.0 395.62 8.47 19.9 1.05393 0.0 8.14 0 0.5380 5.935 29.3 4.4986 4 307 21.0 386.85 6.58 23.1 0.78420 0.0 8.14 0 0.5380 5.990 81.7 4.2579 4 307 21.0 386.75 14.67 17.5 0.80271 0.0 8.14 0 0.5380 5.456 36.6 3.7965 4 307 21.0 288.99 11.69 20.2 0.72580 0.0 8.14 0 0.5380 5.727 69.5 3.7965 4 307 21.0 390.95 11.28 18.2 1.25179 0.0 8.14 0 0.5380 5.570 98.1 3.7979 4 307 21.0 376.57 21.02 13.6 0.85204 0.0 8.14 0 0.5380 5.965 89.2 4.0123 4 307 21.0 392.53 13.83 19.6 1.23247 0.0 8.14 0 0.5380 6.142 91.7 3.9769 4 307 21.0 396.90 18.72 15.2 0.98843 0.0 8.14 0 0.5380 5.813 100.0 4.0952 4 307 21.0 394.54 19.88 14.5 0.75026 0.0 8.14 0 0.5380 5.924 94.1 4.3996 4 307 21.0 394.33 16.30 15.6 0.84054 0.0 8.14 0 0.5380 5.599 85.7 4.4546 4 307 21.0 303.42 16.51 13.9 0.67191 0.0 8.14 0 0.5380 5.813 90.3 4.6820 4 307 21.0 376.88 14.81 16.6 0.95577 0.0 8.14 0 0.5380 6.047 88.8 4.4534 4 307 21.0 306.38 17.28 14.8 0.77299 0.0 8.14 0 0.5380 6.495 94.4 4.4547 4 307 21.0 387.94 12.80 18.4 1.00245 0.0 8.14 0 0.5380 6.674 87.3 4.2390 4 307 21.0 380.23 11.98 21.0 1.13081 0.0 8.14 0 0.5380 5.713 94.1 4.2330 4 307 21.0 360.17 22.60 12.7 1.35472 0.0 8.14 0 0.5380 6.072 100.0 4.1750 4 307 21.0 376.73 13.04 14.5 1.38799 0.0 8.14 0 0.5380 5.950 82.0 3.9900 4 307 21.0 232.60 27.71 13.2 1.15172 0.0 8.14 0 0.5380 5.701 95.0 3.7872 4 307 21.0 358.77 18.35 13.1 1.61282 0.0 8.14 0 0.5380 6.096 96.9 3.7598 4 307 21.0 248.31 20.34 13.5 0.06417 0.0 5.96 0 0.4990 5.933 68.2 3.3603 5 279 19.2 396.90 9.68 18.9 0.09744 0.0 5.96 0 0.4990 5.841 61.4 3.3779 5 279 19.2 377.56 11.41 20.0 0.08014 0.0 5.96 0 0.4990 5.850 41.5 3.9342 5 279 19.2 396.90 8.77 21.0 0.17505 0.0 5.96 0 0.4990 5.966 30.2 3.8473 5 279 19.2 393.43 10.13 24.7 0.02763 75.0 2.95 0 0.4280 6.595 21.8 5.4011 3 252 18.3 395.63 4.32 30.8 0.03359 75.0 2.95 0 0.4280 7.024 15.8 5.4011 3 252 18.3 395.62 1.98 34.9 0.12744 0.0 6.91 0 0.4480 6.770 2.9 5.7209 3 233 17.9 385.41 4.84 26.6 0.14150 0.0 6.91 0 0.4480 6.169 6.6 5.7209 3 233 17.9 383.37 5.81 25.3 0.15936 0.0 6.91 0 0.4480 6.211 6.5 5.7209 3 233 17.9 394.46 7.44 24.7 0.12269 0.0 6.91 0 0.4480 6.069 40.0 5.7209 3 233 17.9 389.39 9.55 21.2 0.17142 0.0 6.91 0 0.4480 5.682 33.8 5.1004 3 233 17.9 396.90 10.21 19.3 0.18836 0.0 6.91 0 0.4480 5.786 33.3 5.1004 3 233 17.9 396.90 14.15 20.0 0.22927 0.0 6.91 0 0.4480 6.030 85.5 5.6894 3 233 17.9 392.74 18.80 16.6 0.25387 0.0 6.91 0 0.4480 5.399 95.3 5.8700 3 233 17.9 396.90 30.81 14.4 0.21977 0.0 6.91 0 0.4480 5.602 62.0 6.0877 3 233 17.9 396.90 16.20 19.4 0.08873 21.0 5.64 0 0.4390 5.963 45.7 6.8147 4 243 16.8 395.56 13.45 19.7 0.04337 21.0 5.64 0 0.4390 6.115 63.0 6.8147 4 243 16.8 393.97 9.43 20.5 0.05360 21.0 5.64 0 0.4390 6.511 21.1 6.8147 4 243 16.8 396.90 5.28 25.0 0.04981 21.0 5.64 0 0.4390 5.998 21.4 6.8147 4 243 16.8 396.90 8.43 23.4 0.01360 75.0 4.00 0 0.4100 5.888 47.6 7.3197 3 469 21.1 396.90 14.80 18.9 0.01311 90.0 1.22 0 0.4030 7.249 21.9 8.6966 5 226 17.9 395.93 4.81 35.4 0.02055 85.0 0.74 0 0.4100 6.383 35.7 9.1876 2 313 17.3 396.90 5.77 24.7 0.01432 100.0 1.32 0 0.4110 6.816 40.5 8.3248 5 256 15.1 392.90 3.95 31.6 0.15445 25.0 5.13 0 0.4530 6.145 29.2 7.8148 8 284 19.7 390.68 6.86 23.3 0.10328 25.0 5.13 0 0.4530 5.927 47.2 6.9320 8 284 19.7 396.90 9.22 19.6 0.14932 25.0 5.13 0 0.4530 5.741 66.2 7.2254 8 284 19.7 395.11 13.15 18.7 0.17171 25.0 5.13 0 0.4530 5.966 93.4 6.8185 8 284 19.7 378.08 14.44 16.0 0.11027 25.0 5.13 0 0.4530 6.456 67.8 7.2255 8 284 19.7 396.90 6.73 22.2 0.12650 25.0 5.13 0 0.4530 6.762 43.4 7.9809 8 284 19.7 395.58 9.50 25.0 0.01951 17.5 1.38 0 0.4161 7.104 59.5 9.2229 3 216 18.6 393.24 8.05 33.0 0.03584 80.0 3.37 0 0.3980 6.290 17.8 6.6115 4 337 16.1 396.90 4.67 23.5 0.04379 80.0 3.37 0 0.3980 5.787 31.1 6.6115 4 337 16.1 396.90 10.24 19.4 0.05789 12.5 6.07 0 0.4090 5.878 21.4 6.4980 4 345 18.9 396.21 8.10 22.0 0.13554 12.5 6.07 0 0.4090 5.594 36.8 6.4980 4 345 18.9 396.90 13.09 17.4 0.12816 12.5 6.07 0 0.4090 5.885 33.0 6.4980 4 345 18.9 396.90 8.79 20.9 0.08826 0.0 10.81 0 0.4130 6.417 6.6 5.2873 4 305 19.2 383.73 6.72 24.2 0.15876 0.0 10.81 0 0.4130 5.961 17.5 5.2873 4 305 19.2 376.94 9.88 21.7 0.09164 0.0 10.81 0 0.4130 6.065 7.8 5.2873 4 305 19.2 390.91 5.52 22.8 0.19539 0.0 10.81 0 0.4130 6.245 6.2 5.2873 4 305 19.2 377.17 7.54 23.4 0.07896 0.0 12.83 0 0.4370 6.273 6.0 4.2515 5 398 18.7 394.92 6.78 24.1 0.09512 0.0 12.83 0 0.4370 6.286 45.0 4.5026 5 398 18.7 383.23 8.94 21.4 0.10153 0.0 12.83 0 0.4370 6.279 74.5 4.0522 5 398 18.7 373.66 11.97 20.0 0.08707 0.0 12.83 0 0.4370 6.140 45.8 4.0905 5 398 18.7 386.96 10.27 20.8 0.05646 0.0 12.83 0 0.4370 6.232 53.7 5.0141 5 398 18.7 386.40 12.34 21.2 0.08387 0.0 12.83 0 0.4370 5.874 36.6 4.5026 5 398 18.7 396.06 9.10 20.3 0.04113 25.0 4.86 0 0.4260 6.727 33.5 5.4007 4 281 19.0 396.90 5.29 28.0 0.04462 25.0 4.86 0 0.4260 6.619 70.4 5.4007 4 281 19.0 395.63 7.22 23.9 0.03659 25.0 4.86 0 0.4260 6.302 32.2 5.4007 4 281 19.0 396.90 6.72 24.8 0.03551 25.0 4.86 0 0.4260 6.167 46.7 5.4007 4 281 19.0 390.64 7.51 22.9 0.05059 0.0 4.49 0 0.4490 6.389 48.0 4.7794 3 247 18.5 396.90 9.62 23.9 0.05735 0.0 4.49 0 0.4490 6.630 56.1 4.4377 3 247 18.5 392.30 6.53 26.6 0.05188 0.0 4.49 0 0.4490 6.015 45.1 4.4272 3 247 18.5 395.99 12.86 22.5 0.07151 0.0 4.49 0 0.4490 6.121 56.8 3.7476 3 247 18.5 395.15 8.44 22.2 0.05660 0.0 3.41 0 0.4890 7.007 86.3 3.4217 2 270 17.8 396.90 5.50 23.6 0.05302 0.0 3.41 0 0.4890 7.079 63.1 3.4145 2 270 17.8 396.06 5.70 28.7 0.04684 0.0 3.41 0 0.4890 6.417 66.1 3.0923 2 270 17.8 392.18 8.81 22.6 0.03932 0.0 3.41 0 0.4890 6.405 73.9 3.0921 2 270 17.8 393.55 8.20 22.0 0.04203 28.0 15.04 0 0.4640 6.442 53.6 3.6659 4 270 18.2 395.01 8.16 22.9 0.02875 28.0 15.04 0 0.4640 6.211 28.9 3.6659 4 270 18.2 396.33 6.21 25.0 0.04294 28.0 15.04 0 0.4640 6.249 77.3 3.6150 4 270 18.2 396.90 10.59 20.6 0.12204 0.0 2.89 0 0.4450 6.625 57.8 3.4952 2 276 18.0 357.98 6.65 28.4 0.11504 0.0 2.89 0 0.4450 6.163 69.6 3.4952 2 276 18.0 391.83 11.34 21.4 0.12083 0.0 2.89 0 0.4450 8.069 76.0 3.4952 2 276 18.0 396.90 4.21 38.7 0.08187 0.0 2.89 0 0.4450 7.820 36.9 3.4952 2 276 18.0 393.53 3.57 43.8 0.06860 0.0 2.89 0 0.4450 7.416 62.5 3.4952 2 276 18.0 396.90 6.19 33.2 0.14866 0.0 8.56 0 0.5200 6.727 79.9 2.7778 5 384 20.9 394.76 9.42 27.5 0.11432 0.0 8.56 0 0.5200 6.781 71.3 2.8561 5 384 20.9 395.58 7.67 26.5 0.22876 0.0 8.56 0 0.5200 6.405 85.4 2.7147 5 384 20.9 70.80 10.63 18.6 0.21161 0.0 8.56 0 0.5200 6.137 87.4 2.7147 5 384 20.9 394.47 13.44 19.3 0.13960 0.0 8.56 0 0.5200 6.167 90.0 2.4210 5 384 20.9 392.69 12.33 20.1 0.13262 0.0 8.56 0 0.5200 5.851 96.7 2.1069 5 384 20.9 394.05 16.47 19.5 0.17120 0.0 8.56 0 0.5200 5.836 91.9 2.2110 5 384 20.9 395.67 18.66 19.5 0.13117 0.0 8.56 0 0.5200 6.127 85.2 2.1224 5 384 20.9 387.69 14.09 20.4 0.12802 0.0 8.56 0 0.5200 6.474 97.1 2.4329 5 384 20.9 395.24 12.27 19.8 0.26363 0.0 8.56 0 0.5200 6.229 91.2 2.5451 5 384 20.9 391.23 15.55 19.4 0.10793 0.0 8.56 0 0.5200 6.195 54.4 2.7778 5 384 20.9 393.49 13.00 21.7 0.10084 0.0 10.01 0 0.5470 6.715 81.6 2.6775 6 432 17.8 395.59 10.16 22.8 0.12329 0.0 10.01 0 0.5470 5.913 92.9 2.3534 6 432 17.8 394.95 16.21 18.8 0.22212 0.0 10.01 0 0.5470 6.092 95.4 2.5480 6 432 17.8 396.90 17.09 18.7 0.14231 0.0 10.01 0 0.5470 6.254 84.2 2.2565 6 432 17.8 388.74 10.45 18.5 0.17134 0.0 10.01 0 0.5470 5.928 88.2 2.4631 6 432 17.8 344.91 15.76 18.3 0.13158 0.0 10.01 0 0.5470 6.176 72.5 2.7301 6 432 17.8 393.30 12.04 21.2 0.15098 0.0 10.01 0 0.5470 6.021 82.6 2.7474 6 432 17.8 394.51 10.30 19.2 0.13058 0.0 10.01 0 0.5470 5.872 73.1 2.4775 6 432 17.8 338.63 15.37 20.4 0.14476 0.0 10.01 0 0.5470 5.731 65.2 2.7592 6 432 17.8 391.50 13.61 19.3 0.06899 0.0 25.65 0 0.5810 5.870 69.7 2.2577 2 188 19.1 389.15 14.37 22.0 0.07165 0.0 25.65 0 0.5810 6.004 84.1 2.1974 2 188 19.1 377.67 14.27 20.3 0.09299 0.0 25.65 0 0.5810 5.961 92.9 2.0869 2 188 19.1 378.09 17.93 20.5 0.15038 0.0 25.65 0 0.5810 5.856 97.0 1.9444 2 188 19.1 370.31 25.41 17.3 0.09849 0.0 25.65 0 0.5810 5.879 95.8 2.0063 2 188 19.1 379.38 17.58 18.8 0.16902 0.0 25.65 0 0.5810 5.986 88.4 1.9929 2 188 19.1 385.02 14.81 21.4 0.38735 0.0 25.65 0 0.5810 5.613 95.6 1.7572 2 188 19.1 359.29 27.26 15.7 0.25915 0.0 21.89 0 0.6240 5.693 96.0 1.7883 4 437 21.2 392.11 17.19 16.2 0.32543 0.0 21.89 0 0.6240 6.431 98.8 1.8125 4 437 21.2 396.90 15.39 18.0 0.88125 0.0 21.89 0 0.6240 5.637 94.7 1.9799 4 437 21.2 396.90 18.34 14.3 0.34006 0.0 21.89 0 0.6240 6.458 98.9 2.1185 4 437 21.2 395.04 12.60 19.2 1.19294 0.0 21.89 0 0.6240 6.326 97.7 2.2710 4 437 21.2 396.90 12.26 19.6 0.59005 0.0 21.89 0 0.6240 6.372 97.9 2.3274 4 437 21.2 385.76 11.12 23.0 0.32982 0.0 21.89 0 0.6240 5.822 95.4 2.4699 4 437 21.2 388.69 15.03 18.4 0.97617 0.0 21.89 0 0.6240 5.757 98.4 2.3460 4 437 21.2 262.76 17.31 15.6 0.55778 0.0 21.89 0 0.6240 6.335 98.2 2.1107 4 437 21.2 394.67 16.96 18.1 0.32264 0.0 21.89 0 0.6240 5.942 93.5 1.9669 4 437 21.2 378.25 16.90 17.4 0.35233 0.0 21.89 0 0.6240 6.454 98.4 1.8498 4 437 21.2 394.08 14.59 17.1 0.24980 0.0 21.89 0 0.6240 5.857 98.2 1.6686 4 437 21.2 392.04 21.32 13.3 0.54452 0.0 21.89 0 0.6240 6.151 97.9 1.6687 4 437 21.2 396.90 18.46 17.8 0.29090 0.0 21.89 0 0.6240 6.174 93.6 1.6119 4 437 21.2 388.08 24.16 14.0 1.62864 0.0 21.89 0 0.6240 5.019 100.0 1.4394 4 437 21.2 396.90 34.41 14.4 3.32105 0.0 19.58 1 0.8710 5.403 100.0 1.3216 5 403 14.7 396.90 26.82 13.4 4.09740 0.0 19.58 0 0.8710 5.468 100.0 1.4118 5 403 14.7 396.90 26.42 15.6 2.77974 0.0 19.58 0 0.8710 4.903 97.8 1.3459 5 403 14.7 396.90 29.29 11.8 2.37934 0.0 19.58 0 0.8710 6.130 100.0 1.4191 5 403 14.7 172.91 27.80 13.8 2.15505 0.0 19.58 0 0.8710 5.628 100.0 1.5166 5 403 14.7 169.27 16.65 15.6 2.36862 0.0 19.58 0 0.8710 4.926 95.7 1.4608 5 403 14.7 391.71 29.53 14.6 2.33099 0.0 19.58 0 0.8710 5.186 93.8 1.5296 5 403 14.7 356.99 28.32 17.8 2.73397 0.0 19.58 0 0.8710 5.597 94.9 1.5257 5 403 14.7 351.85 21.45 15.4 1.65660 0.0 19.58 0 0.8710 6.122 97.3 1.6180 5 403 14.7 372.80 14.10 21.5 1.49632 0.0 19.58 0 0.8710 5.404 100.0 1.5916 5 403 14.7 341.60 13.28 19.6 1.12658 0.0 19.58 1 0.8710 5.012 88.0 1.6102 5 403 14.7 343.28 12.12 15.3 2.14918 0.0 19.58 0 0.8710 5.709 98.5 1.6232 5 403 14.7 261.95 15.79 19.4 1.41385 0.0 19.58 1 0.8710 6.129 96.0 1.7494 5 403 14.7 321.02 15.12 17.0 3.53501 0.0 19.58 1 0.8710 6.152 82.6 1.7455 5 403 14.7 88.01 15.02 15.6 2.44668 0.0 19.58 0 0.8710 5.272 94.0 1.7364 5 403 14.7 88.63 16.14 13.1 1.22358 0.0 19.58 0 0.6050 6.943 97.4 1.8773 5 403 14.7 363.43 4.59 41.3 1.34284 0.0 19.58 0 0.6050 6.066 100.0 1.7573 5 403 14.7 353.89 6.43 24.3 1.42502 0.0 19.58 0 0.8710 6.510 100.0 1.7659 5 403 14.7 364.31 7.39 23.3 1.27346 0.0 19.58 1 0.6050 6.250 92.6 1.7984 5 403 14.7 338.92 5.50 27.0 1.46336 0.0 19.58 0 0.6050 7.489 90.8 1.9709 5 403 14.7 374.43 1.73 50.0 1.83377 0.0 19.58 1 0.6050 7.802 98.2 2.0407 5 403 14.7 389.61 1.92 50.0 1.51902 0.0 19.58 1 0.6050 8.375 93.9 2.1620 5 403 14.7 388.45 3.32 50.0 2.24236 0.0 19.58 0 0.6050 5.854 91.8 2.4220 5 403 14.7 395.11 11.64 22.7 2.92400 0.0 19.58 0 0.6050 6.101 93.0 2.2834 5 403 14.7 240.16 9.81 25.0 2.01019 0.0 19.58 0 0.6050 7.929 96.2 2.0459 5 403 14.7 369.30 3.70 50.0 1.80028 0.0 19.58 0 0.6050 5.877 79.2 2.4259 5 403 14.7 227.61 12.14 23.8 2.30040 0.0 19.58 0 0.6050 6.319 96.1 2.1000 5 403 14.7 297.09 11.10 23.8 2.44953 0.0 19.58 0 0.6050 6.402 95.2 2.2625 5 403 14.7 330.04 11.32 22.3 1.20742 0.0 19.58 0 0.6050 5.875 94.6 2.4259 5 403 14.7 292.29 14.43 17.4 2.31390 0.0 19.58 0 0.6050 5.880 97.3 2.3887 5 403 14.7 348.13 12.03 19.1 0.13914 0.0 4.05 0 0.5100 5.572 88.5 2.5961 5 296 16.6 396.90 14.69 23.1 0.09178 0.0 4.05 0 0.5100 6.416 84.1 2.6463 5 296 16.6 395.50 9.04 23.6 0.08447 0.0 4.05 0 0.5100 5.859 68.7 2.7019 5 296 16.6 393.23 9.64 22.6 0.06664 0.0 4.05 0 0.5100 6.546 33.1 3.1323 5 296 16.6 390.96 5.33 29.4 0.07022 0.0 4.05 0 0.5100 6.020 47.2 3.5549 5 296 16.6 393.23 10.11 23.2 0.05425 0.0 4.05 0 0.5100 6.315 73.4 3.3175 5 296 16.6 395.60 6.29 24.6 0.06642 0.0 4.05 0 0.5100 6.860 74.4 2.9153 5 296 16.6 391.27 6.92 29.9 0.05780 0.0 2.46 0 0.4880 6.980 58.4 2.8290 3 193 17.8 396.90 5.04 37.2 0.06588 0.0 2.46 0 0.4880 7.765 83.3 2.7410 3 193 17.8 395.56 7.56 39.8 0.06888 0.0 2.46 0 0.4880 6.144 62.2 2.5979 3 193 17.8 396.90 9.45 36.2 0.09103 0.0 2.46 0 0.4880 7.155 92.2 2.7006 3 193 17.8 394.12 4.82 37.9 0.10008 0.0 2.46 0 0.4880 6.563 95.6 2.8470 3 193 17.8 396.90 5.68 32.5 0.08308 0.0 2.46 0 0.4880 5.604 89.8 2.9879 3 193 17.8 391.00 13.98 26.4 0.06047 0.0 2.46 0 0.4880 6.153 68.8 3.2797 3 193 17.8 387.11 13.15 29.6 0.05602 0.0 2.46 0 0.4880 7.831 53.6 3.1992 3 193 17.8 392.63 4.45 50.0 0.07875 45.0 3.44 0 0.4370 6.782 41.1 3.7886 5 398 15.2 393.87 6.68 32.0 0.12579 45.0 3.44 0 0.4370 6.556 29.1 4.5667 5 398 15.2 382.84 4.56 29.8 0.08370 45.0 3.44 0 0.4370 7.185 38.9 4.5667 5 398 15.2 396.90 5.39 34.9 0.09068 45.0 3.44 0 0.4370 6.951 21.5 6.4798 5 398 15.2 377.68 5.10 37.0 0.06911 45.0 3.44 0 0.4370 6.739 30.8 6.4798 5 398 15.2 389.71 4.69 30.5 0.08664 45.0 3.44 0 0.4370 7.178 26.3 6.4798 5 398 15.2 390.49 2.87 36.4 0.02187 60.0 2.93 0 0.4010 6.800 9.9 6.2196 1 265 15.6 393.37 5.03 31.1 0.01439 60.0 2.93 0 0.4010 6.604 18.8 6.2196 1 265 15.6 376.70 4.38 29.1 0.01381 80.0 0.46 0 0.4220 7.875 32.0 5.6484 4 255 14.4 394.23 2.97 50.0 0.04011 80.0 1.52 0 0.4040 7.287 34.1 7.3090 2 329 12.6 396.90 4.08 33.3 0.04666 80.0 1.52 0 0.4040 7.107 36.6 7.3090 2 329 12.6 354.31 8.61 30.3 0.03768 80.0 1.52 0 0.4040 7.274 38.3 7.3090 2 329 12.6 392.20 6.62 34.6 0.03150 95.0 1.47 0 0.4030 6.975 15.3 7.6534 3 402 17.0 396.90 4.56 34.9 0.01778 95.0 1.47 0 0.4030 7.135 13.9 7.6534 3 402 17.0 384.30 4.45 32.9 0.03445 82.5 2.03 0 0.4150 6.162 38.4 6.2700 2 348 14.7 393.77 7.43 24.1 0.02177 82.5 2.03 0 0.4150 7.610 15.7 6.2700 2 348 14.7 395.38 3.11 42.3 0.03510 95.0 2.68 0 0.4161 7.853 33.2 5.1180 4 224 14.7 392.78 3.81 48.5 0.02009 95.0 2.68 0 0.4161 8.034 31.9 5.1180 4 224 14.7 390.55 2.88 50.0 0.13642 0.0 10.59 0 0.4890 5.891 22.3 3.9454 4 277 18.6 396.90 10.87 22.6 0.22969 0.0 10.59 0 0.4890 6.326 52.5 4.3549 4 277 18.6 394.87 10.97 24.4 0.25199 0.0 10.59 0 0.4890 5.783 72.7 4.3549 4 277 18.6 389.43 18.06 22.5 0.13587 0.0 10.59 1 0.4890 6.064 59.1 4.2392 4 277 18.6 381.32 14.66 24.4 0.43571 0.0 10.59 1 0.4890 5.344 100.0 3.8750 4 277 18.6 396.90 23.09 20.0 0.17446 0.0 10.59 1 0.4890 5.960 92.1 3.8771 4 277 18.6 393.25 17.27 21.7 0.37578 0.0 10.59 1 0.4890 5.404 88.6 3.6650 4 277 18.6 395.24 23.98 19.3 0.21719 0.0 10.59 1 0.4890 5.807 53.8 3.6526 4 277 18.6 390.94 16.03 22.4 0.14052 0.0 10.59 0 0.4890 6.375 32.3 3.9454 4 277 18.6 385.81 9.38 28.1 0.28955 0.0 10.59 0 0.4890 5.412 9.8 3.5875 4 277 18.6 348.93 29.55 23.7 0.19802 0.0 10.59 0 0.4890 6.182 42.4 3.9454 4 277 18.6 393.63 9.47 25.0 0.04560 0.0 13.89 1 0.5500 5.888 56.0 3.1121 5 276 16.4 392.80 13.51 23.3 0.07013 0.0 13.89 0 0.5500 6.642 85.1 3.4211 5 276 16.4 392.78 9.69 28.7 0.11069 0.0 13.89 1 0.5500 5.951 93.8 2.8893 5 276 16.4 396.90 17.92 21.5 0.11425 0.0 13.89 1 0.5500 6.373 92.4 3.3633 5 276 16.4 393.74 10.50 23.0 0.35809 0.0 6.20 1 0.5070 6.951 88.5 2.8617 8 307 17.4 391.70 9.71 26.7 0.40771 0.0 6.20 1 0.5070 6.164 91.3 3.0480 8 307 17.4 395.24 21.46 21.7 0.62356 0.0 6.20 1 0.5070 6.879 77.7 3.2721 8 307 17.4 390.39 9.93 27.5 0.61470 0.0 6.20 0 0.5070 6.618 80.8 3.2721 8 307 17.4 396.90 7.60 30.1 0.31533 0.0 6.20 0 0.5040 8.266 78.3 2.8944 8 307 17.4 385.05 4.14 44.8 0.52693 0.0 6.20 0 0.5040 8.725 83.0 2.8944 8 307 17.4 382.00 4.63 50.0 0.38214 0.0 6.20 0 0.5040 8.040 86.5 3.2157 8 307 17.4 387.38 3.13 37.6 0.41238 0.0 6.20 0 0.5040 7.163 79.9 3.2157 8 307 17.4 372.08 6.36 31.6 0.29819 0.0 6.20 0 0.5040 7.686 17.0 3.3751 8 307 17.4 377.51 3.92 46.7 0.44178 0.0 6.20 0 0.5040 6.552 21.4 3.3751 8 307 17.4 380.34 3.76 31.5 0.53700 0.0 6.20 0 0.5040 5.981 68.1 3.6715 8 307 17.4 378.35 11.65 24.3 0.46296 0.0 6.20 0 0.5040 7.412 76.9 3.6715 8 307 17.4 376.14 5.25 31.7 0.57529 0.0 6.20 0 0.5070 8.337 73.3 3.8384 8 307 17.4 385.91 2.47 41.7 0.33147 0.0 6.20 0 0.5070 8.247 70.4 3.6519 8 307 17.4 378.95 3.95 48.3 0.44791 0.0 6.20 1 0.5070 6.726 66.5 3.6519 8 307 17.4 360.20 8.05 29.0 0.33045 0.0 6.20 0 0.5070 6.086 61.5 3.6519 8 307 17.4 376.75 10.88 24.0 0.52058 0.0 6.20 1 0.5070 6.631 76.5 4.1480 8 307 17.4 388.45 9.54 25.1 0.51183 0.0 6.20 0 0.5070 7.358 71.6 4.1480 8 307 17.4 390.07 4.73 31.5 0.08244 30.0 4.93 0 0.4280 6.481 18.5 6.1899 6 300 16.6 379.41 6.36 23.7 0.09252 30.0 4.93 0 0.4280 6.606 42.2 6.1899 6 300 16.6 383.78 7.37 23.3 0.11329 30.0 4.93 0 0.4280 6.897 54.3 6.3361 6 300 16.6 391.25 11.38 22.0 0.10612 30.0 4.93 0 0.4280 6.095 65.1 6.3361 6 300 16.6 394.62 12.40 20.1 0.10290 30.0 4.93 0 0.4280 6.358 52.9 7.0355 6 300 16.6 372.75 11.22 22.2 0.12757 30.0 4.93 0 0.4280 6.393 7.8 7.0355 6 300 16.6 374.71 5.19 23.7 0.20608 22.0 5.86 0 0.4310 5.593 76.5 7.9549 7 330 19.1 372.49 12.50 17.6 0.19133 22.0 5.86 0 0.4310 5.605 70.2 7.9549 7 330 19.1 389.13 18.46 18.5 0.33983 22.0 5.86 0 0.4310 6.108 34.9 8.0555 7 330 19.1 390.18 9.16 24.3 0.19657 22.0 5.86 0 0.4310 6.226 79.2 8.0555 7 330 19.1 376.14 10.15 20.5 0.16439 22.0 5.86 0 0.4310 6.433 49.1 7.8265 7 330 19.1 374.71 9.52 24.5 0.19073 22.0 5.86 0 0.4310 6.718 17.5 7.8265 7 330 19.1 393.74 6.56 26.2 0.14030 22.0 5.86 0 0.4310 6.487 13.0 7.3967 7 330 19.1 396.28 5.90 24.4 0.21409 22.0 5.86 0 0.4310 6.438 8.9 7.3967 7 330 19.1 377.07 3.59 24.8 0.08221 22.0 5.86 0 0.4310 6.957 6.8 8.9067 7 330 19.1 386.09 3.53 29.6 0.36894 22.0 5.86 0 0.4310 8.259 8.4 8.9067 7 330 19.1 396.90 3.54 42.8 0.04819 80.0 3.64 0 0.3920 6.108 32.0 9.2203 1 315 16.4 392.89 6.57 21.9 0.03548 80.0 3.64 0 0.3920 5.876 19.1 9.2203 1 315 16.4 395.18 9.25 20.9 0.01538 90.0 3.75 0 0.3940 7.454 34.2 6.3361 3 244 15.9 386.34 3.11 44.0 0.61154 20.0 3.97 0 0.6470 8.704 86.9 1.8010 5 264 13.0 389.70 5.12 50.0 0.66351 20.0 3.97 0 0.6470 7.333 100.0 1.8946 5 264 13.0 383.29 7.79 36.0 0.65665 20.0 3.97 0 0.6470 6.842 100.0 2.0107 5 264 13.0 391.93 6.90 30.1 0.54011 20.0 3.97 0 0.6470 7.203 81.8 2.1121 5 264 13.0 392.80 9.59 33.8 0.53412 20.0 3.97 0 0.6470 7.520 89.4 2.1398 5 264 13.0 388.37 7.26 43.1 0.52014 20.0 3.97 0 0.6470 8.398 91.5 2.2885 5 264 13.0 386.86 5.91 48.8 0.82526 20.0 3.97 0 0.6470 7.327 94.5 2.0788 5 264 13.0 393.42 11.25 31.0 0.55007 20.0 3.97 0 0.6470 7.206 91.6 1.9301 5 264 13.0 387.89 8.10 36.5 0.76162 20.0 3.97 0 0.6470 5.560 62.8 1.9865 5 264 13.0 392.40 10.45 22.8 0.78570 20.0 3.97 0 0.6470 7.014 84.6 2.1329 5 264 13.0 384.07 14.79 30.7 0.57834 20.0 3.97 0 0.5750 8.297 67.0 2.4216 5 264 13.0 384.54 7.44 50.0 0.54050 20.0 3.97 0 0.5750 7.470 52.6 2.8720 5 264 13.0 390.30 3.16 43.5 0.09065 20.0 6.96 1 0.4640 5.920 61.5 3.9175 3 223 18.6 391.34 13.65 20.7 0.29916 20.0 6.96 0 0.4640 5.856 42.1 4.4290 3 223 18.6 388.65 13.00 21.1 0.16211 20.0 6.96 0 0.4640 6.240 16.3 4.4290 3 223 18.6 396.90 6.59 25.2 0.11460 20.0 6.96 0 0.4640 6.538 58.7 3.9175 3 223 18.6 394.96 7.73 24.4 0.22188 20.0 6.96 1 0.4640 7.691 51.8 4.3665 3 223 18.6 390.77 6.58 35.2 0.05644 40.0 6.41 1 0.4470 6.758 32.9 4.0776 4 254 17.6 396.90 3.53 32.4 0.09604 40.0 6.41 0 0.4470 6.854 42.8 4.2673 4 254 17.6 396.90 2.98 32.0 0.10469 40.0 6.41 1 0.4470 7.267 49.0 4.7872 4 254 17.6 389.25 6.05 33.2 0.06127 40.0 6.41 1 0.4470 6.826 27.6 4.8628 4 254 17.6 393.45 4.16 33.1 0.07978 40.0 6.41 0 0.4470 6.482 32.1 4.1403 4 254 17.6 396.90 7.19 29.1 0.21038 20.0 3.33 0 0.4429 6.812 32.2 4.1007 5 216 14.9 396.90 4.85 35.1 0.03578 20.0 3.33 0 0.4429 7.820 64.5 4.6947 5 216 14.9 387.31 3.76 45.4 0.03705 20.0 3.33 0 0.4429 6.968 37.2 5.2447 5 216 14.9 392.23 4.59 35.4 0.06129 20.0 3.33 1 0.4429 7.645 49.7 5.2119 5 216 14.9 377.07 3.01 46.0 0.01501 90.0 1.21 1 0.4010 7.923 24.8 5.8850 1 198 13.6 395.52 3.16 50.0 0.00906 90.0 2.97 0 0.4000 7.088 20.8 7.3073 1 285 15.3 394.72 7.85 32.2 0.01096 55.0 2.25 0 0.3890 6.453 31.9 7.3073 1 300 15.3 394.72 8.23 22.0 0.01965 80.0 1.76 0 0.3850 6.230 31.5 9.0892 1 241 18.2 341.60 12.93 20.1 0.03871 52.5 5.32 0 0.4050 6.209 31.3 7.3172 6 293 16.6 396.90 7.14 23.2 0.04590 52.5 5.32 0 0.4050 6.315 45.6 7.3172 6 293 16.6 396.90 7.60 22.3 0.04297 52.5 5.32 0 0.4050 6.565 22.9 7.3172 6 293 16.6 371.72 9.51 24.8 0.03502 80.0 4.95 0 0.4110 6.861 27.9 5.1167 4 245 19.2 396.90 3.33 28.5 0.07886 80.0 4.95 0 0.4110 7.148 27.7 5.1167 4 245 19.2 396.90 3.56 37.3 0.03615 80.0 4.95 0 0.4110 6.630 23.4 5.1167 4 245 19.2 396.90 4.70 27.9 0.08265 0.0 13.92 0 0.4370 6.127 18.4 5.5027 4 289 16.0 396.90 8.58 23.9 0.08199 0.0 13.92 0 0.4370 6.009 42.3 5.5027 4 289 16.0 396.90 10.40 21.7 0.12932 0.0 13.92 0 0.4370 6.678 31.1 5.9604 4 289 16.0 396.90 6.27 28.6 0.05372 0.0 13.92 0 0.4370 6.549 51.0 5.9604 4 289 16.0 392.85 7.39 27.1 0.14103 0.0 13.92 0 0.4370 5.790 58.0 6.3200 4 289 16.0 396.90 15.84 20.3 0.06466 70.0 2.24 0 0.4000 6.345 20.1 7.8278 5 358 14.8 368.24 4.97 22.5 0.05561 70.0 2.24 0 0.4000 7.041 10.0 7.8278 5 358 14.8 371.58 4.74 29.0 0.04417 70.0 2.24 0 0.4000 6.871 47.4 7.8278 5 358 14.8 390.86 6.07 24.8 0.03537 34.0 6.09 0 0.4330 6.590 40.4 5.4917 7 329 16.1 395.75 9.50 22.0 0.09266 34.0 6.09 0 0.4330 6.495 18.4 5.4917 7 329 16.1 383.61 8.67 26.4 0.10000 34.0 6.09 0 0.4330 6.982 17.7 5.4917 7 329 16.1 390.43 4.86 33.1 0.05515 33.0 2.18 0 0.4720 7.236 41.1 4.0220 7 222 18.4 393.68 6.93 36.1 0.05479 33.0 2.18 0 0.4720 6.616 58.1 3.3700 7 222 18.4 393.36 8.93 28.4 0.07503 33.0 2.18 0 0.4720 7.420 71.9 3.0992 7 222 18.4 396.90 6.47 33.4 0.04932 33.0 2.18 0 0.4720 6.849 70.3 3.1827 7 222 18.4 396.90 7.53 28.2 0.49298 0.0 9.90 0 0.5440 6.635 82.5 3.3175 4 304 18.4 396.90 4.54 22.8 0.34940 0.0 9.90 0 0.5440 5.972 76.7 3.1025 4 304 18.4 396.24 9.97 20.3 2.63548 0.0 9.90 0 0.5440 4.973 37.8 2.5194 4 304 18.4 350.45 12.64 16.1 0.79041 0.0 9.90 0 0.5440 6.122 52.8 2.6403 4 304 18.4 396.90 5.98 22.1 0.26169 0.0 9.90 0 0.5440 6.023 90.4 2.8340 4 304 18.4 396.30 11.72 19.4 0.26938 0.0 9.90 0 0.5440 6.266 82.8 3.2628 4 304 18.4 393.39 7.90 21.6 0.36920 0.0 9.90 0 0.5440 6.567 87.3 3.6023 4 304 18.4 395.69 9.28 23.8 0.25356 0.0 9.90 0 0.5440 5.705 77.7 3.9450 4 304 18.4 396.42 11.50 16.2 0.31827 0.0 9.90 0 0.5440 5.914 83.2 3.9986 4 304 18.4 390.70 18.33 17.8 0.24522 0.0 9.90 0 0.5440 5.782 71.7 4.0317 4 304 18.4 396.90 15.94 19.8 0.40202 0.0 9.90 0 0.5440 6.382 67.2 3.5325 4 304 18.4 395.21 10.36 23.1 0.47547 0.0 9.90 0 0.5440 6.113 58.8 4.0019 4 304 18.4 396.23 12.73 21.0 0.16760 0.0 7.38 0 0.4930 6.426 52.3 4.5404 5 287 19.6 396.90 7.20 23.8 0.18159 0.0 7.38 0 0.4930 6.376 54.3 4.5404 5 287 19.6 396.90 6.87 23.1 0.35114 0.0 7.38 0 0.4930 6.041 49.9 4.7211 5 287 19.6 396.90 7.70 20.4 0.28392 0.0 7.38 0 0.4930 5.708 74.3 4.7211 5 287 19.6 391.13 11.74 18.5 0.34109 0.0 7.38 0 0.4930 6.415 40.1 4.7211 5 287 19.6 396.90 6.12 25.0 0.19186 0.0 7.38 0 0.4930 6.431 14.7 5.4159 5 287 19.6 393.68 5.08 24.6 0.30347 0.0 7.38 0 0.4930 6.312 28.9 5.4159 5 287 19.6 396.90 6.15 23.0 0.24103 0.0 7.38 0 0.4930 6.083 43.7 5.4159 5 287 19.6 396.90 12.79 22.2 0.06617 0.0 3.24 0 0.4600 5.868 25.8 5.2146 4 430 16.9 382.44 9.97 19.3 0.06724 0.0 3.24 0 0.4600 6.333 17.2 5.2146 4 430 16.9 375.21 7.34 22.6 0.04544 0.0 3.24 0 0.4600 6.144 32.2 5.8736 4 430 16.9 368.57 9.09 19.8 0.05023 35.0 6.06 0 0.4379 5.706 28.4 6.6407 1 304 16.9 394.02 12.43 17.1 0.03466 35.0 6.06 0 0.4379 6.031 23.3 6.6407 1 304 16.9 362.25 7.83 19.4 0.05083 0.0 5.19 0 0.5150 6.316 38.1 6.4584 5 224 20.2 389.71 5.68 22.2 0.03738 0.0 5.19 0 0.5150 6.310 38.5 6.4584 5 224 20.2 389.40 6.75 20.7 0.03961 0.0 5.19 0 0.5150 6.037 34.5 5.9853 5 224 20.2 396.90 8.01 21.1 0.03427 0.0 5.19 0 0.5150 5.869 46.3 5.2311 5 224 20.2 396.90 9.80 19.5 0.03041 0.0 5.19 0 0.5150 5.895 59.6 5.6150 5 224 20.2 394.81 10.56 18.5 0.03306 0.0 5.19 0 0.5150 6.059 37.3 4.8122 5 224 20.2 396.14 8.51 20.6 0.05497 0.0 5.19 0 0.5150 5.985 45.4 4.8122 5 224 20.2 396.90 9.74 19.0 0.06151 0.0 5.19 0 0.5150 5.968 58.5 4.8122 5 224 20.2 396.90 9.29 18.7 0.01301 35.0 1.52 0 0.4420 7.241 49.3 7.0379 1 284 15.5 394.74 5.49 32.7 0.02498 0.0 1.89 0 0.5180 6.540 59.7 6.2669 1 422 15.9 389.96 8.65 16.5 0.02543 55.0 3.78 0 0.4840 6.696 56.4 5.7321 5 370 17.6 396.90 7.18 23.9 0.03049 55.0 3.78 0 0.4840 6.874 28.1 6.4654 5 370 17.6 387.97 4.61 31.2 0.03113 0.0 4.39 0 0.4420 6.014 48.5 8.0136 3 352 18.8 385.64 10.53 17.5 0.06162 0.0 4.39 0 0.4420 5.898 52.3 8.0136 3 352 18.8 364.61 12.67 17.2 0.01870 85.0 4.15 0 0.4290 6.516 27.7 8.5353 4 351 17.9 392.43 6.36 23.1 0.01501 80.0 2.01 0 0.4350 6.635 29.7 8.3440 4 280 17.0 390.94 5.99 24.5 0.02899 40.0 1.25 0 0.4290 6.939 34.5 8.7921 1 335 19.7 389.85 5.89 26.6 0.06211 40.0 1.25 0 0.4290 6.490 44.4 8.7921 1 335 19.7 396.90 5.98 22.9 0.07950 60.0 1.69 0 0.4110 6.579 35.9 10.7103 4 411 18.3 370.78 5.49 24.1 0.07244 60.0 1.69 0 0.4110 5.884 18.5 10.7103 4 411 18.3 392.33 7.79 18.6 0.01709 90.0 2.02 0 0.4100 6.728 36.1 12.1265 5 187 17.0 384.46 4.50 30.1 0.04301 80.0 1.91 0 0.4130 5.663 21.9 10.5857 4 334 22.0 382.80 8.05 18.2 0.10659 80.0 1.91 0 0.4130 5.936 19.5 10.5857 4 334 22.0 376.04 5.57 20.6 8.98296 0.0 18.10 1 0.7700 6.212 97.4 2.1222 24 666 20.2 377.73 17.60 17.8 3.84970 0.0 18.10 1 0.7700 6.395 91.0 2.5052 24 666 20.2 391.34 13.27 21.7 5.20177 0.0 18.10 1 0.7700 6.127 83.4 2.7227 24 666 20.2 395.43 11.48 22.7 4.26131 0.0 18.10 0 0.7700 6.112 81.3 2.5091 24 666 20.2 390.74 12.67 22.6 4.54192 0.0 18.10 0 0.7700 6.398 88.0 2.5182 24 666 20.2 374.56 7.79 25.0 3.83684 0.0 18.10 0 0.7700 6.251 91.1 2.2955 24 666 20.2 350.65 14.19 19.9 3.67822 0.0 18.10 0 0.7700 5.362 96.2 2.1036 24 666 20.2 380.79 10.19 20.8 4.22239 0.0 18.10 1 0.7700 5.803 89.0 1.9047 24 666 20.2 353.04 14.64 16.8 3.47428 0.0 18.10 1 0.7180 8.780 82.9 1.9047 24 666 20.2 354.55 5.29 21.9 4.55587 0.0 18.10 0 0.7180 3.561 87.9 1.6132 24 666 20.2 354.70 7.12 27.5 3.69695 0.0 18.10 0 0.7180 4.963 91.4 1.7523 24 666 20.2 316.03 14.00 21.9 13.52220 0.0 18.10 0 0.6310 3.863 100.0 1.5106 24 666 20.2 131.42 13.33 23.1 4.89822 0.0 18.10 0 0.6310 4.970 100.0 1.3325 24 666 20.2 375.52 3.26 50.0 5.66998 0.0 18.10 1 0.6310 6.683 96.8 1.3567 24 666 20.2 375.33 3.73 50.0 6.53876 0.0 18.10 1 0.6310 7.016 97.5 1.2024 24 666 20.2 392.05 2.96 50.0 9.23230 0.0 18.10 0 0.6310 6.216 100.0 1.1691 24 666 20.2 366.15 9.53 50.0 8.26725 0.0 18.10 1 0.6680 5.875 89.6 1.1296 24 666 20.2 347.88 8.88 50.0 11.10810 0.0 18.10 0 0.6680 4.906 100.0 1.1742 24 666 20.2 396.90 34.77 13.8 18.49820 0.0 18.10 0 0.6680 4.138 100.0 1.1370 24 666 20.2 396.90 37.97 13.8 19.60910 0.0 18.10 0 0.6710 7.313 97.9 1.3163 24 666 20.2 396.90 13.44 15.0 15.28800 0.0 18.10 0 0.6710 6.649 93.3 1.3449 24 666 20.2 363.02 23.24 13.9 9.82349 0.0 18.10 0 0.6710 6.794 98.8 1.3580 24 666 20.2 396.90 21.24 13.3 23.64820 0.0 18.10 0 0.6710 6.380 96.2 1.3861 24 666 20.2 396.90 23.69 13.1 17.86670 0.0 18.10 0 0.6710 6.223 100.0 1.3861 24 666 20.2 393.74 21.78 10.2 88.97620 0.0 18.10 0 0.6710 6.968 91.9 1.4165 24 666 20.2 396.90 17.21 10.4 15.87440 0.0 18.10 0 0.6710 6.545 99.1 1.5192 24 666 20.2 396.90 21.08 10.9 9.18702 0.0 18.10 0 0.7000 5.536 100.0 1.5804 24 666 20.2 396.90 23.60 11.3 7.99248 0.0 18.10 0 0.7000 5.520 100.0 1.5331 24 666 20.2 396.90 24.56 12.3 20.08490 0.0 18.10 0 0.7000 4.368 91.2 1.4395 24 666 20.2 285.83 30.63 8.8 16.81180 0.0 18.10 0 0.7000 5.277 98.1 1.4261 24 666 20.2 396.90 30.81 7.2 24.39380 0.0 18.10 0 0.7000 4.652 100.0 1.4672 24 666 20.2 396.90 28.28 10.5 22.59710 0.0 18.10 0 0.7000 5.000 89.5 1.5184 24 666 20.2 396.90 31.99 7.4 14.33370 0.0 18.10 0 0.7000 4.880 100.0 1.5895 24 666 20.2 372.92 30.62 10.2 8.15174 0.0 18.10 0 0.7000 5.390 98.9 1.7281 24 666 20.2 396.90 20.85 11.5 6.96215 0.0 18.10 0 0.7000 5.713 97.0 1.9265 24 666 20.2 394.43 17.11 15.1 5.29305 0.0 18.10 0 0.7000 6.051 82.5 2.1678 24 666 20.2 378.38 18.76 23.2 11.57790 0.0 18.10 0 0.7000 5.036 97.0 1.7700 24 666 20.2 396.90 25.68 9.7 8.64476 0.0 18.10 0 0.6930 6.193 92.6 1.7912 24 666 20.2 396.90 15.17 13.8 13.35980 0.0 18.10 0 0.6930 5.887 94.7 1.7821 24 666 20.2 396.90 16.35 12.7 8.71675 0.0 18.10 0 0.6930 6.471 98.8 1.7257 24 666 20.2 391.98 17.12 13.1 5.87205 0.0 18.10 0 0.6930 6.405 96.0 1.6768 24 666 20.2 396.90 19.37 12.5 7.67202 0.0 18.10 0 0.6930 5.747 98.9 1.6334 24 666 20.2 393.10 19.92 8.5 38.35180 0.0 18.10 0 0.6930 5.453 100.0 1.4896 24 666 20.2 396.90 30.59 5.0 9.91655 0.0 18.10 0 0.6930 5.852 77.8 1.5004 24 666 20.2 338.16 29.97 6.3 25.04610 0.0 18.10 0 0.6930 5.987 100.0 1.5888 24 666 20.2 396.90 26.77 5.6 14.23620 0.0 18.10 0 0.6930 6.343 100.0 1.5741 24 666 20.2 396.90 20.32 7.2 9.59571 0.0 18.10 0 0.6930 6.404 100.0 1.6390 24 666 20.2 376.11 20.31 12.1 24.80170 0.0 18.10 0 0.6930 5.349 96.0 1.7028 24 666 20.2 396.90 19.77 8.3 41.52920 0.0 18.10 0 0.6930 5.531 85.4 1.6074 24 666 20.2 329.46 27.38 8.5 67.92080 0.0 18.10 0 0.6930 5.683 100.0 1.4254 24 666 20.2 384.97 22.98 5.0 20.71620 0.0 18.10 0 0.6590 4.138 100.0 1.1781 24 666 20.2 370.22 23.34 11.9 11.95110 0.0 18.10 0 0.6590 5.608 100.0 1.2852 24 666 20.2 332.09 12.13 27.9 7.40389 0.0 18.10 0 0.5970 5.617 97.9 1.4547 24 666 20.2 314.64 26.40 17.2 14.43830 0.0 18.10 0 0.5970 6.852 100.0 1.4655 24 666 20.2 179.36 19.78 27.5 51.13580 0.0 18.10 0 0.5970 5.757 100.0 1.4130 24 666 20.2 2.60 10.11 15.0 14.05070 0.0 18.10 0 0.5970 6.657 100.0 1.5275 24 666 20.2 35.05 21.22 17.2 18.81100 0.0 18.10 0 0.5970 4.628 100.0 1.5539 24 666 20.2 28.79 34.37 17.9 28.65580 0.0 18.10 0 0.5970 5.155 100.0 1.5894 24 666 20.2 210.97 20.08 16.3 45.74610 0.0 18.10 0 0.6930 4.519 100.0 1.6582 24 666 20.2 88.27 36.98 7.0 18.08460 0.0 18.10 0 0.6790 6.434 100.0 1.8347 24 666 20.2 27.25 29.05 7.2 10.83420 0.0 18.10 0 0.6790 6.782 90.8 1.8195 24 666 20.2 21.57 25.79 7.5 25.94060 0.0 18.10 0 0.6790 5.304 89.1 1.6475 24 666 20.2 127.36 26.64 10.4 73.53410 0.0 18.10 0 0.6790 5.957 100.0 1.8026 24 666 20.2 16.45 20.62 8.8 11.81230 0.0 18.10 0 0.7180 6.824 76.5 1.7940 24 666 20.2 48.45 22.74 8.4 11.08740 0.0 18.10 0 0.7180 6.411 100.0 1.8589 24 666 20.2 318.75 15.02 16.7 7.02259 0.0 18.10 0 0.7180 6.006 95.3 1.8746 24 666 20.2 319.98 15.70 14.2 12.04820 0.0 18.10 0 0.6140 5.648 87.6 1.9512 24 666 20.2 291.55 14.10 20.8 7.05042 0.0 18.10 0 0.6140 6.103 85.1 2.0218 24 666 20.2 2.52 23.29 13.4 8.79212 0.0 18.10 0 0.5840 5.565 70.6 2.0635 24 666 20.2 3.65 17.16 11.7 15.86030 0.0 18.10 0 0.6790 5.896 95.4 1.9096 24 666 20.2 7.68 24.39 8.3 12.24720 0.0 18.10 0 0.5840 5.837 59.7 1.9976 24 666 20.2 24.65 15.69 10.2 37.66190 0.0 18.10 0 0.6790 6.202 78.7 1.8629 24 666 20.2 18.82 14.52 10.9 7.36711 0.0 18.10 0 0.6790 6.193 78.1 1.9356 24 666 20.2 96.73 21.52 11.0 9.33889 0.0 18.10 0 0.6790 6.380 95.6 1.9682 24 666 20.2 60.72 24.08 9.5 8.49213 0.0 18.10 0 0.5840 6.348 86.1 2.0527 24 666 20.2 83.45 17.64 14.5 10.06230 0.0 18.10 0 0.5840 6.833 94.3 2.0882 24 666 20.2 81.33 19.69 14.1 6.44405 0.0 18.10 0 0.5840 6.425 74.8 2.2004 24 666 20.2 97.95 12.03 16.1 5.58107 0.0 18.10 0 0.7130 6.436 87.9 2.3158 24 666 20.2 100.19 16.22 14.3 13.91340 0.0 18.10 0 0.7130 6.208 95.0 2.2222 24 666 20.2 100.63 15.17 11.7 11.16040 0.0 18.10 0 0.7400 6.629 94.6 2.1247 24 666 20.2 109.85 23.27 13.4 14.42080 0.0 18.10 0 0.7400 6.461 93.3 2.0026 24 666 20.2 27.49 18.05 9.6 15.17720 0.0 18.10 0 0.7400 6.152 100.0 1.9142 24 666 20.2 9.32 26.45 8.7 13.67810 0.0 18.10 0 0.7400 5.935 87.9 1.8206 24 666 20.2 68.95 34.02 8.4 9.39063 0.0 18.10 0 0.7400 5.627 93.9 1.8172 24 666 20.2 396.90 22.88 12.8 22.05110 0.0 18.10 0 0.7400 5.818 92.4 1.8662 24 666 20.2 391.45 22.11 10.5 9.72418 0.0 18.10 0 0.7400 6.406 97.2 2.0651 24 666 20.2 385.96 19.52 17.1 5.66637 0.0 18.10 0 0.7400 6.219 100.0 2.0048 24 666 20.2 395.69 16.59 18.4 9.96654 0.0 18.10 0 0.7400 6.485 100.0 1.9784 24 666 20.2 386.73 18.85 15.4 12.80230 0.0 18.10 0 0.7400 5.854 96.6 1.8956 24 666 20.2 240.52 23.79 10.8 10.67180 0.0 18.10 0 0.7400 6.459 94.8 1.9879 24 666 20.2 43.06 23.98 11.8 6.28807 0.0 18.10 0 0.7400 6.341 96.4 2.0720 24 666 20.2 318.01 17.79 14.9 9.92485 0.0 18.10 0 0.7400 6.251 96.6 2.1980 24 666 20.2 388.52 16.44 12.6 9.32909 0.0 18.10 0 0.7130 6.185 98.7 2.2616 24 666 20.2 396.90 18.13 14.1 7.52601 0.0 18.10 0 0.7130 6.417 98.3 2.1850 24 666 20.2 304.21 19.31 13.0 6.71772 0.0 18.10 0 0.7130 6.749 92.6 2.3236 24 666 20.2 0.32 17.44 13.4 5.44114 0.0 18.10 0 0.7130 6.655 98.2 2.3552 24 666 20.2 355.29 17.73 15.2 5.09017 0.0 18.10 0 0.7130 6.297 91.8 2.3682 24 666 20.2 385.09 17.27 16.1 8.24809 0.0 18.10 0 0.7130 7.393 99.3 2.4527 24 666 20.2 375.87 16.74 17.8 9.51363 0.0 18.10 0 0.7130 6.728 94.1 2.4961 24 666 20.2 6.68 18.71 14.9 4.75237 0.0 18.10 0 0.7130 6.525 86.5 2.4358 24 666 20.2 50.92 18.13 14.1 4.66883 0.0 18.10 0 0.7130 5.976 87.9 2.5806 24 666 20.2 10.48 19.01 12.7 8.20058 0.0 18.10 0 0.7130 5.936 80.3 2.7792 24 666 20.2 3.50 16.94 13.5 7.75223 0.0 18.10 0 0.7130 6.301 83.7 2.7831 24 666 20.2 272.21 16.23 14.9 6.80117 0.0 18.10 0 0.7130 6.081 84.4 2.7175 24 666 20.2 396.90 14.70 20.0 4.81213 0.0 18.10 0 0.7130 6.701 90.0 2.5975 24 666 20.2 255.23 16.42 16.4 3.69311 0.0 18.10 0 0.7130 6.376 88.4 2.5671 24 666 20.2 391.43 14.65 17.7 6.65492 0.0 18.10 0 0.7130 6.317 83.0 2.7344 24 666 20.2 396.90 13.99 19.5 5.82115 0.0 18.10 0 0.7130 6.513 89.9 2.8016 24 666 20.2 393.82 10.29 20.2 7.83932 0.0 18.10 0 0.6550 6.209 65.4 2.9634 24 666 20.2 396.90 13.22 21.4 3.16360 0.0 18.10 0 0.6550 5.759 48.2 3.0665 24 666 20.2 334.40 14.13 19.9 3.77498 0.0 18.10 0 0.6550 5.952 84.7 2.8715 24 666 20.2 22.01 17.15 19.0 4.42228 0.0 18.10 0 0.5840 6.003 94.5 2.5403 24 666 20.2 331.29 21.32 19.1 15.57570 0.0 18.10 0 0.5800 5.926 71.0 2.9084 24 666 20.2 368.74 18.13 19.1 13.07510 0.0 18.10 0 0.5800 5.713 56.7 2.8237 24 666 20.2 396.90 14.76 20.1 4.34879 0.0 18.10 0 0.5800 6.167 84.0 3.0334 24 666 20.2 396.90 16.29 19.9 4.03841 0.0 18.10 0 0.5320 6.229 90.7 3.0993 24 666 20.2 395.33 12.87 19.6 3.56868 0.0 18.10 0 0.5800 6.437 75.0 2.8965 24 666 20.2 393.37 14.36 23.2 4.64689 0.0 18.10 0 0.6140 6.980 67.6 2.5329 24 666 20.2 374.68 11.66 29.8 8.05579 0.0 18.10 0 0.5840 5.427 95.4 2.4298 24 666 20.2 352.58 18.14 13.8 6.39312 0.0 18.10 0 0.5840 6.162 97.4 2.2060 24 666 20.2 302.76 24.10 13.3 4.87141 0.0 18.10 0 0.6140 6.484 93.6 2.3053 24 666 20.2 396.21 18.68 16.7 15.02340 0.0 18.10 0 0.6140 5.304 97.3 2.1007 24 666 20.2 349.48 24.91 12.0 10.23300 0.0 18.10 0 0.6140 6.185 96.7 2.1705 24 666 20.2 379.70 18.03 14.6 14.33370 0.0 18.10 0 0.6140 6.229 88.0 1.9512 24 666 20.2 383.32 13.11 21.4 5.82401 0.0 18.10 0 0.5320 6.242 64.7 3.4242 24 666 20.2 396.90 10.74 23.0 5.70818 0.0 18.10 0 0.5320 6.750 74.9 3.3317 24 666 20.2 393.07 7.74 23.7 5.73116 0.0 18.10 0 0.5320 7.061 77.0 3.4106 24 666 20.2 395.28 7.01 25.0 2.81838 0.0 18.10 0 0.5320 5.762 40.3 4.0983 24 666 20.2 392.92 10.42 21.8 2.37857 0.0 18.10 0 0.5830 5.871 41.9 3.7240 24 666 20.2 370.73 13.34 20.6 3.67367 0.0 18.10 0 0.5830 6.312 51.9 3.9917 24 666 20.2 388.62 10.58 21.2 5.69175 0.0 18.10 0 0.5830 6.114 79.8 3.5459 24 666 20.2 392.68 14.98 19.1 4.83567 0.0 18.10 0 0.5830 5.905 53.2 3.1523 24 666 20.2 388.22 11.45 20.6 0.15086 0.0 27.74 0 0.6090 5.454 92.7 1.8209 4 711 20.1 395.09 18.06 15.2 0.18337 0.0 27.74 0 0.6090 5.414 98.3 1.7554 4 711 20.1 344.05 23.97 7.0 0.20746 0.0 27.74 0 0.6090 5.093 98.0 1.8226 4 711 20.1 318.43 29.68 8.1 0.10574 0.0 27.74 0 0.6090 5.983 98.8 1.8681 4 711 20.1 390.11 18.07 13.6 0.11132 0.0 27.74 0 0.6090 5.983 83.5 2.1099 4 711 20.1 396.90 13.35 20.1 0.17331 0.0 9.69 0 0.5850 5.707 54.0 2.3817 6 391 19.2 396.90 12.01 21.8 0.27957 0.0 9.69 0 0.5850 5.926 42.6 2.3817 6 391 19.2 396.90 13.59 24.5 0.17899 0.0 9.69 0 0.5850 5.670 28.8 2.7986 6 391 19.2 393.29 17.60 23.1 0.28960 0.0 9.69 0 0.5850 5.390 72.9 2.7986 6 391 19.2 396.90 21.14 19.7 0.26838 0.0 9.69 0 0.5850 5.794 70.6 2.8927 6 391 19.2 396.90 14.10 18.3 0.23912 0.0 9.69 0 0.5850 6.019 65.3 2.4091 6 391 19.2 396.90 12.92 21.2 0.17783 0.0 9.69 0 0.5850 5.569 73.5 2.3999 6 391 19.2 395.77 15.10 17.5 0.22438 0.0 9.69 0 0.5850 6.027 79.7 2.4982 6 391 19.2 396.90 14.33 16.8 0.06263 0.0 11.93 0 0.5730 6.593 69.1 2.4786 1 273 21.0 391.99 9.67 22.4 0.04527 0.0 11.93 0 0.5730 6.120 76.7 2.2875 1 273 21.0 396.90 9.08 20.6 0.06076 0.0 11.93 0 0.5730 6.976 91.0 2.1675 1 273 21.0 396.90 5.64 23.9 0.10959 0.0 11.93 0 0.5730 6.794 89.3 2.3889 1 273 21.0 393.45 6.48 22.0 0.04741 0.0 11.93 0 0.5730 6.030 80.8 2.5050 1 273 21.0 396.90 7.88 11.9 References "],["simulation.html", "35 随机模拟 35.1 随机数 35.2 sample()函数 35.3 随机模拟示例", " 35 随机模拟 35.1 随机数 随机模拟是统计研究的重要方法， 另外许多现代统计计算方法（如MCMC）也是基于随机模拟的。 R中提供了多种不同概率分布的随机数函数， 可以批量地产生随机数。 一些R扩展包利用了随机模拟方法，如boot包进行bootstrap估计。 所谓随机数，实际是“伪随机数”， 是从一组起始值（称为种子）， 按照某种递推算法向前递推得到的。 所以，从同一种子出发，得到的随机数序列是相同的。 为了得到可重现的结果， 随机模拟应该从固定不变的种子开始模拟。 用set.seed(k)指定一个编号为k的种子， 这样每次从编号k种子运行相同的模拟程序可以得到相同的结果。 还可以用set.seed()加选项kind=指定后续程序要使用的随机数发生器名称， 用normal.kind=指定要使用的正态分布随机数发生器名称。 R提供了多种分布的随机数函数，如runif(n)产生n个标准均匀分布随机数， rnorm(n)产生n个标准正态分布随机数。 例如： round(runif(5), 2) ## [1] 0.44 0.56 0.93 0.23 0.22 round(rnorm(5), 2) ## [1] -0.20 1.10 -0.02 0.16 2.02 注意因为没有指定种子，每次运行会得到不同的结果。 在R命令行运行 ?Distributions 可以查看R中提供的不同概率分布。 35.2 sample()函数 sample()函数从一个有限集合中无放回或有放回地随机抽取， 产生随机结果。 例如，为了设随机变量\\(X\\)取值于\\(\\{\\text{正面}, \\text{反面} \\}\\), 且\\(P(X=\\text{正面}) = 0.7 = 1 - P(X = \\text{反面})\\), 如下程序产生\\(X\\)的10个随机抽样值: sample(c(&#39;正面&#39;, &#39;反面&#39;), size=10, prob=c(0.7, 0.3), replace=TRUE) ## [1] &quot;反面&quot; &quot;反面&quot; &quot;反面&quot; &quot;反面&quot; &quot;正面&quot; ## [6] &quot;正面&quot; &quot;正面&quot; &quot;正面&quot; &quot;反面&quot; &quot;反面&quot; sample()的选项size指定抽样个数， prob指定每个值的概率， replace=TRUE说明是有放回抽样。 如果要做无放回等概率的随机抽样， 可以不指定prob和replace(缺省是FALSE)。 比如，下面的程序从1:10随机抽取4个: sample(1:10, size=4) ## [1] 1 5 8 10 如果要从\\(1:n\\)中等概率无放回随机抽样直到每一个都被抽过，只要用如： sample(10) ## [1] 3 5 9 2 10 7 4 1 6 8 这实际上返回了\\(1:10\\)的一个重排。 dplyr包的sample_n()函数与sample()类似， 但输入为数据框， 输出为随机抽取的数据框行子集。 35.3 随机模拟示例 35.3.1 估计期望值 设随机变量或随机向量\\(X\\)有复杂的分布， 使得期望\\(\\theta = E h(X)\\)很难计算。 如果可以得到\\(X\\)的\\(N\\)个独立同分布抽样值\\(X_1, X_2, \\dots, X_N\\)， 则可估计\\(\\theta\\)为： \\[ \\hat\\theta = \\frac{1}{N} \\sum_{i=1}^N h(X_i) \\] 这时\\(E \\hat\\theta = \\theta\\)， 估计无偏； 均方误差为 \\[\\begin{aligned} \\text{MSE} =&amp; E|\\hat\\theta - \\theta|^2 = \\text{Var}(\\hat\\theta) = \\text{SE}^2 \\\\ =&amp; \\frac{\\text{Var}(X)}{N} \\approx \\frac{S_N^2}{N} \\end{aligned}\\] 其中 \\[ S_N^2 = \\frac{1}{N-1} \\sum_{i=1}^N (h(X_i) - \\hat\\theta)^2 \\] 是样本方差。 由强大数律可知\\(N\\to\\infty\\)时\\(\\hat\\theta\\)依概率1收敛到\\(\\theta\\)， 由中心极限定理可知\\(N\\)充分大时\\(\\hat\\theta\\)有近似正态分布 \\[ \\text{N}(\\theta, \\text{SE}^2) . \\] 例如，考虑正方形区域\\(\\Omega = \\{(x,y): x \\in [0,1], y \\in [0,1] \\}\\)， 以及其中的四分之一扇形\\(A = \\{(x,y): (x,y) \\in \\Omega, x^2 + y^2 \\leq 1 \\}\\)。 设\\(\\boldsymbol X\\)服从\\(\\Omega\\)上的均匀分布， 令 \\[ Y = \\begin{cases} 1, &amp; \\text{当} \\boldsymbol X \\in A, \\\\ 0, &amp; \\text{其它} \\end{cases} \\] 则\\(Y\\)服从两点分布， 概率为 \\[ p = E Y = \\frac{\\frac{1}{4} \\pi 1^2}{1^2} = \\frac{\\pi}{4} \\] 在\\(\\Omega\\)中投入\\(N=10000\\)个点， 得到\\(N\\)个\\(Y_i, i=1,2,\\dots,N\\)的值，估计\\(\\pi\\)为 \\[ \\hat\\pi = 4 \\bar Y = \\frac{4}{N} \\sum_{i=1}^N Y_i \\] \\(E \\hat\\pi = \\pi\\), 估计的根均方误差可估计为 \\[ \\text{RMSE} = \\sqrt{E | \\hat\\pi - \\pi |^2} = 4 \\frac{\\sqrt{\\text{Var}(Y)}}{\\sqrt{N}} \\approx 4 \\frac{S_N}{\\sqrt{N}} . \\] 程序如下： est_pi &lt;- function(N){ set.seed(101) x1 &lt;- runif(N, 0, 1) x2 &lt;- runif(N, 0, 1) y &lt;- as.numeric(x1^2 + x2^2 &lt;= 1) hat_pi &lt;- 4*mean(y) se &lt;- 4 * sd(y) / sqrt(N) cat(&quot;N = &quot;, N, &quot; pi估计值 =&quot;, hat_pi, &quot; SE =&quot;, se, &quot;\\n&quot;) invisible(list(N=N, hat_pi = hat_pi, SE = se)) } est_pi(1E4) ## N = 10000 pi估计值 = 3.14 SE = 0.01643372 估计的标准误差(SE)还是比较大， 提高到\\(N=10^6\\)，精度可以增加一位小数： est_pi(1E6) ## N = 1e+06 pi估计值 = 3.145576 SE = 0.001639408 35.3.2 线性回归模拟 考虑如下线性回归模型 \\[\\begin{aligned} y = 10 + 2 x + \\varepsilon, \\ \\varepsilon \\sim \\text{N}(0, 0.5^2) . \\end{aligned}\\] 假设有样本量\\(n=10\\)的一组样本， R函数lm()可以 可以得到截距\\(a\\), 斜率\\(b\\)的估计\\(\\hat a, \\hat b\\), 以及相应的标准误差\\(\\text{SE}(\\hat a)\\), \\(\\text{SE}(\\hat b)\\)。 样本可以模拟产生。 模型中的自变量\\(x\\)可以用随机数产生， 比如，用sample()函数从\\(1:10\\)中随机有放回地抽取\\(n\\)个。 模型中的随机误差项\\(\\varepsilon\\)可以用rnorm()产生。 产生一组样本的程序如: n &lt;- 10; a &lt;- 10; b &lt;- 2 x &lt;- sample(1:10, size=n, replace=TRUE) eps &lt;- rnorm(n, 0, 0.5) y &lt;- a + b * x + eps 如下程序计算线性回归: lm(y ~ x) ## ## Call: ## lm(formula = y ~ x) ## ## Coefficients: ## (Intercept) x ## 10.080 1.995 如下程序计算线性回归的多种统计量: summary(lm(y ~ x)) ## ## Call: ## lm(formula = y ~ x) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.76774 -0.14896 0.02445 0.33051 0.49779 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 10.08026 0.22313 45.18 6.37e-11 *** ## x 1.99518 0.04545 43.90 8.00e-11 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.4286 on 8 degrees of freedom ## Multiple R-squared: 0.9959, Adjusted R-squared: 0.9953 ## F-statistic: 1927 on 1 and 8 DF, p-value: 8.004e-11 如下程序返回一个矩阵， 包括\\(a, b\\)的估计值、标准误差、t检验统计量、检验p值: summary(lm(y ~ x))$coefficients ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 10.080258 0.22313107 45.17640 6.365149e-11 ## x 1.995183 0.04545185 43.89664 8.003683e-11 如下程序把上述矩阵的前两列拉直成一个向量返回： c(summary(lm(y ~ x))$coefficients[,1:2]) ## [1] 10.08025775 1.99518338 0.22313107 0.04545185 这样得到 \\(\\hat a, \\hat b, \\text{SE}(\\hat a), \\text{SE}(\\hat b)\\)这四个值。 用replicate(, 复合语句)执行多次模拟， 返回向量或矩阵结果， 返回矩阵时，每列是一次模拟的结果。 下面是线性回归整个模拟程序，写成了一个函数。 reg.sim &lt;- function( a=10, b=2, sigma=0.5, n=10, B=1000){ set.seed(1) resm &lt;- replicate(B, { x &lt;- sample(1:10, size=n, replace=TRUE) eps &lt;- rnorm(n, 0, 0.5) y &lt;- a + b * x + eps c(summary(lm(y ~ x))$coefficients[,1:2]) }) resm &lt;- t(resm) colnames(resm) &lt;- c(&#39;a&#39;, &#39;b&#39;, &#39;SE.a&#39;, &#39;SE.b&#39;) cat(B, &#39;次模拟的平均值:\\n&#39;) print( apply(resm, 2, mean) ) cat(B, &#39;次模拟的标准差:\\n&#39;) print( apply(resm, 2, sd) ) } 运行测试： set.seed(1) reg.sim() ## 1000 次模拟的平均值: ## a b SE.a SE.b ## 9.9970476 1.9994490 0.3639505 0.0592510 ## 1000 次模拟的标准差: ## a b SE.a SE.b ## 0.37974881 0.06297733 0.11992515 0.01795926 可以看出，标准误差作为\\(\\hat a, \\hat b\\)的标准差估计， 与多次模拟得到多个\\(\\hat a, \\hat b\\)样本计算得到的标准差估计是比较接近的。 结果中\\(\\text{SE}(\\hat a)\\)的平均值为0.363, 1000次模拟的\\(\\hat a\\)的样本标准差为0.393，比较接近； \\(\\text{SE}(\\hat b)\\)的平均值为0.0594, 1000次模拟的\\(\\hat b\\)的样本标准差为0.0637，比较接近。 35.3.3 核密度的bootstrap置信区间 R自带的数据框faithful内保存了美国黄石国家公园Faithful火山的272次爆发持续时间和间歇时间。 为估计爆发持续时间的密度，可以用核密度估计方法， R函数density可以执行此估计， 返回\\(N\\)个格子点上的密度曲线坐标: x &lt;- faithful$eruptions est0 &lt;- density(x) plot(est0) 这个密度估计明显呈现出双峰形态。 核密度估计是统计估计， 为了得到其置信区间（给定每个\\(x\\)坐标，真实密度\\(f(x)\\)的单点的置信区间）， 采用如下非参数bootstrap方法： 重复\\(B=10000\\)次， 每次从原始样本中有重复地抽取与原来大小相同的一组样本， 对这组样本计算核密度估计， 结果为\\((x_i, y_i^{(j)}), i=1,2,\\dots,N, j=1,2,\\dots, B\\)， 每组样本估计\\(N\\)个格子点的密度曲线坐标, 横坐标不随样本改变。 对每个横坐标\\(x_i\\)， 取bootstrap得到的\\(B\\)个\\(y_i^{(j)}, j=1,2,\\dots,B\\)的0.025和0.975样本分位数， 作为真实密度\\(f(x_i)\\)的bootstrap置信区间。 在R中利用replicate()函数实现： set.seed(1) resm &lt;- replicate(10000, { x1 &lt;- sample(x, replace=TRUE) density(x1, from=min(est0$x), to=max(est0$x))$y }) CI &lt;- apply(resm, 1, quantile, c(0.025, 0.975)) plot(est0, ylim=range(CI), type=&#39;n&#39;) polygon(c(est0$x, rev(est0$x)), c(CI[1,], rev(CI[2,])), col=&#39;grey&#39;, border=FALSE) lines(est0, lwd=2) 程序中用set.seed(1)保证每次运行得到的结果是不变的， replicate()函数第一参数是重复模拟次数， 第二参数是复合语句， 这些语句是每次模拟要执行的计算。 在每次模拟中， 用带有replace=TRUE选项的sample()函数从样本中有放回地抽样得到一组bootstrap样本， 每次模拟的结果是在指定格子点上计算的核密度估计的纵坐标。 replicate()的结果为一个矩阵， 每一列是一次模拟得到的纵坐标集合。 对每个横坐标格子点，用quantile()函数计算\\(B\\)个bootstrap样本的2.5%和97.5%分位数， 循环用apply()函数表示。 polygon()函数指定一个多边形的顺序的顶点坐标用col=指定的颜色填充， 本程序中实现了置信下限与置信上限两条曲线之间的颜色填充。 lines()函数绘制了与原始样本对应的核密度估计曲线。 "],["text.html", "36 R语言的文本处理 36.1 简单的文本处理 36.2 文本文件读写 36.3 正则表达式 36.4 stringr包的正则表达式函数 36.5 利用基本R函数进行正则表达式处理 36.6 正则表达式应用例子 36.7 网站数据获取 36.8 中文分词与词频", " 36 R语言的文本处理 36.1 简单的文本处理 在信息爆炸性增长的今天， 大量的信息是文本型的， 如互联网上的大多数资源。 R具有基本的文本数据处理能力， 而且因为R的向量语言特点和强大的统计计算和图形功能， 用R处理文本数据是可行的。 36.1.1 字符型常量与字符型向量 字符串常量写在两个双撇号或者两个单撇号中间， 建议仅使用双撇号， 因为这是大多数常见程序语言的做法。 如果内容中有单撇号或者双撇号， 可以在前面加反斜杠\\。 为了在字符串中写一个反斜杠， 需要写成两个， 比如路径C:\\work写成R字符串， 要写成\"C:\\\\work\"。 注意， 这些规定都是针对程序中的字符串常量， 数据中的文本类型数据是不需要遵照这些规定的。 在用print()显示字符串变量时， 也会按照上述的办法显示， 比如字符串内的双撇号会被自动加上前导反斜杠， 但保存的实际内容中并没有反斜杠。 字符串中可以有一些特殊字符， 如\"\\n\"表示换行符， \"\\t\"表示制表符， \"\\r\"表示回车符，等等。 R的字符型向量每个元素是一个字符串， 如： s &lt;- c(&quot;123&quot;, &quot;abc&quot;, &quot;张三李四&quot;, &quot;@#$%^&amp;&quot;) s ## [1] &quot;123&quot; &quot;abc&quot; &quot;张三李四&quot; &quot;@#$%^&amp;&quot; R中处理文本型数据的函数有文件访问函数以及readLines，nchar, paste，sprintf， format，formatC， substring等函数。 R支持正则表达式， 函数grep, grepl, sub, gsub, regexpr, gregexpr, strsplit与正则表达式有关。 字符型函数一般都是向量化的， 对输入的一个字符型向量的每个元素操作。 R扩展包stringr和stringi提供了更方便、功能更强的字符串功能， 包括正则表达式功能。 其中stringr是常用功能， stringi是更基本、更灵活的功能， 一般使用stringr就足够了。 stringr包的函数名大多都以str_开头。 下面先介绍常用的较简单的字符串函数， 包括stringr包的函数与基本R函数。 library(stringr) 36.1.2 字符串连接、重复 stringr::str_c()用来把多个输入自变量按照元素对应组合为一个字符型向量， 用sep指定分隔符，默认为不分隔。 类似于R中向量间运算的一般规则， 各自变量长度不同时短的自动循环使用。 非字符串类型自动转换为字符型。 如 str_c(c(&quot;x&quot;, &quot;y&quot;), c(&quot;a&quot;, &quot;b&quot;), sep=&quot;*&quot;) ## [1] &quot;x*a&quot; &quot;y*b&quot; str_c(&quot;data&quot;, 1:3, &quot;.txt&quot;) ## [1] &quot;data1.txt&quot; &quot;data2.txt&quot; &quot;data3.txt&quot; 字符型缺失值参与连接时， 结果变成缺失值； 可以用str_replace_na()函数将待连接的字符型向量中的缺失值转换成字符串\"NA\"再连接。 用collapse选项要求将连接后的字符型向量的所有元素连接在一起， collapse的值为将多个元素合并时的分隔符。 如 str_c(c(&quot;a&quot;, &quot;bc&quot;, &quot;def&quot;), collapse=&quot;---&quot;) ## [1] &quot;a---bc---def&quot; 在使用了collapse时如果有多个要连接的部分， str_c()函数先将各部分连接成为一个字符型向量， 然后再把结果的各个向量元素连接起来。 如 str_c(&quot;data&quot;, 1:3, &quot;.txt&quot;, sep=&quot;&quot;, collapse=&quot;;&quot;) ## [1] &quot;data1.txt;data2.txt;data3.txt&quot; stringr::str_flatten()类似于stringr::str_c()仅有collapse参数作用一样， 仅将一个字符型向量的各个元素按照collapse参数指定的分隔符连接成一个长字符串， collapse默认值是空字符串，如： str_flatten(c(&quot;a&quot;, &quot;bc&quot;, &quot;def&quot;), collapse=&quot;---&quot;) ## [1] &quot;a---bc---def&quot; str_flatten(c(&quot;a&quot;, &quot;bc&quot;, &quot;def&quot;)) ## [1] &quot;abcdef&quot; 基本R的paste()函数与stringr::str_c()函数有类似的用法， 但是参数sep的默认值是空格。 基本R的paste0()函数相当于stringr::str_c()函数固定sep参数为空字符串。 如： paste(c(&quot;x&quot;, &quot;y&quot;), c(&quot;a&quot;, &quot;b&quot;), sep=&quot;*&quot;) ## [1] &quot;x*a&quot; &quot;y*b&quot; paste(&quot;data&quot;, 1:3, &quot;.txt&quot;, sep=&quot;&quot;) ## [1] &quot;data1.txt&quot; &quot;data2.txt&quot; &quot;data3.txt&quot; paste0(&quot;data&quot;, 1:3, &quot;.txt&quot;) ## [1] &quot;data1.txt&quot; &quot;data2.txt&quot; &quot;data3.txt&quot; paste(c(&quot;a&quot;, &quot;bc&quot;, &quot;def&quot;), collapse=&quot;---&quot;) ## [1] &quot;a---bc---def&quot; paste(&quot;data&quot;, 1:3, &quot;.txt&quot;, sep=&quot;&quot;, collapse=&quot;;&quot;) ## [1] &quot;data1.txt;data2.txt;data3.txt&quot; stringr::str_dup(string, times)类似于rep()函数， 可以将字符型向量的元素按照times指定的次数在同一字符串内重复，如： str_dup(c(&quot;abc&quot;, &quot;长江&quot;), 3) ## [1] &quot;abcabcabc&quot; &quot;长江长江长江&quot; 也可以针对每个元素指定不同重复次数，如 str_dup(c(&quot;abc&quot;, &quot;长江&quot;), c(3, 2)) ## [1] &quot;abcabcabc&quot; &quot;长江长江&quot; 36.1.3 格式化输出 36.1.3.1 format()函数 format()函数可以将一个数值型向量的各个元素按照统一格式转换为字符型， 如： as.character(1.000) ## [1] &quot;1&quot; as.character(1.2) ## [1] &quot;1.2&quot; as.character(1.23) ## [1] &quot;1.23&quot; format(c(1.000, 1.2, 1.23)) ## [1] &quot;1.00&quot; &quot;1.20&quot; &quot;1.23&quot; 选项digits与nsmall共同控制输出的精度， nsmall控制非科学记数法显示时小数点后的至少要有的位数， digits控制至少要有的有效位数。 这使得输出的宽度是不可控的， 如： format(c(pi, pi*10000), digits=8, nsmall=4) ## [1] &quot; 3.1415927&quot; &quot;31415.9265359&quot; width参数指定至少要有的输出宽度， 不足时默认在左侧用空格填充，如： format(1.000, width=6, nsmall=2) ## [1] &quot; 1.00&quot; format()还有许多选项， 详见函数的帮助。 36.1.3.2 sprintf()函数 format()函数无法精确控制输出长度和格式。 sprintf是C语言中sprintf的向量化版本， 可以把一个元素或一个向量的各个元素按照C语言输出格式转换为字符型向量。 第一个自变量是C语言格式的输出格式字符串， 其中%d表示输出整数，%f表示输出实数， %02d表示输出宽度为2、不够左填0的整数， %6.2f表示输出宽度为6、宽度不足时左填空格、含两位小数的实数， 等等。 比如，标量转换 sprintf(&quot;%6.2f&quot;, pi) ## [1] &quot; 3.14&quot; 又如，向量转换： sprintf(&quot;tour%03d.jpg&quot;, c(1, 5, 10, 15, 100)) ## [1] &quot;tour001.jpg&quot; &quot;tour005.jpg&quot; &quot;tour010.jpg&quot; &quot;tour015.jpg&quot; &quot;tour100.jpg&quot; 还可以支持多个向量同时转换，如： sprintf(&quot;%1dx%1d=%2d&quot;, 1:5, 5:1, (1:5)*(5:1)) ## [1] &quot;1x5= 5&quot; &quot;2x4= 8&quot; &quot;3x3= 9&quot; &quot;4x2= 8&quot; &quot;5x1= 5&quot; 36.1.3.3 字符串插值函数 许多脚本型程序设计语言都有在字符串的内容中插入变量值的功能， R本身不具有这样的功能， sprintf()函数有类似作用但只是一个不方便使用的副作用。 stringr::str_glue()和stringr::str_glue_data()提供了字符串插值的功能。 只要在字符串内用大括号写变量名， 则函数可以将字符串内容中的变量名替换成变量值，如： name &lt;- &quot;李明&quot; tele &lt;- &quot;13512345678&quot; str_glue(&quot;姓名: {name}\\n电话号码: {tele}\\n&quot;) ## 姓名: 李明 ## 电话号码: 13512345678 上面的例子直接用了换行符\"\\n\"来分开不同内容。 也可以输入多个字符串作为自变量， 内容自动连接在一起，可以用参数.sep指定分隔符： name &lt;- &quot;李明&quot; tele &lt;- &quot;13512345678&quot; str_glue(&quot;姓名: {name}, &quot;, &quot;电话号码: {tele}&quot;) ## 姓名: 李明, 电话号码: 13512345678 str_glue(&quot;姓名: {name}&quot;, &quot;电话号码: {tele}&quot;, .sep=&quot;; &quot;) ## 姓名: 李明; 电话号码: 13512345678 也可以直接在str_glue()中指定变量值，如： str_glue(&quot;姓名: {name}&quot;, &quot;电话号码: {tele}&quot;, .sep=&quot;; &quot;, name = &quot;张三&quot;, tele = &quot;13588888888&quot;) ## 姓名: 张三; 电话号码: 13588888888 stringr::str_glue_data()则以一个包含变量定义的对象.x为第一自变量， 类型可以是环境、列表、数据框等。如： str_glue_data(list(name = &quot;王五&quot;, tele = &quot;13500000000&quot;), &quot;姓名: {name}&quot;, &quot;电话号码: {tele}&quot;, .sep=&quot;; &quot;) ## 姓名: 王五; 电话号码: 13500000000 36.1.4 字符串长度 stringr::str_length(string)求字符型向量string每个元素的长度。 一个汉字长度为1。 str_length(c(&quot;a&quot;, &quot;bc&quot;, &quot;def&quot;, &quot;北京&quot;)) ## [1] 1 2 3 2 函数nchar(text)计算字符串长度，默认按照字符个数计算而不是按字节数计算， 如 nchar(c(&quot;a&quot;, &quot;bc&quot;, &quot;def&quot;, &quot;北京&quot;)) ## [1] 1 2 3 2 注意函数对输入的字符型向量每个元素计算长度。 nchar()加选项type=\"bytes\"可用按字符串占用的字节数计算， 这时一个汉字占用多个字节（具体占用多少与编码有关）。 如 nchar(c(&quot;a&quot;, &quot;bc&quot;, &quot;def&quot;, &quot;北京&quot;), type=&quot;bytes&quot;) ## [1] 1 2 3 4 36.1.5 取子串 stringr::str_sub(string, start, end)字符串字串， 用开始字符位置start和结束字符位置end设定字串位置。 用负数表示倒数位置。 默认开始位置为1， 默认结束位置为最后一个字符。 如： str_sub(&quot;term2017&quot;, 5, 8) ## [1] &quot;2017&quot; str_sub(c(&quot;term2017&quot;, &quot;term2018&quot;), 5, 8) ## [1] &quot;2017&quot; &quot;2018&quot; str_sub(&quot;term2017&quot;, 5) ## [1] &quot;2017&quot; str_sub(&quot;term2017&quot;, -4, -1) ## [1] &quot;2017&quot; str_sub(&quot;term2017&quot;, end=4) ## [1] &quot;term&quot; 取子串时，一般按照字符个数计算位置，如 str_sub(&quot;北京市海淀区颐和园路5号&quot;, 4, 6) ## [1] &quot;海淀区&quot; 当起始位置超过总长度或结束位置超过第一个字符时返回空字符串； 当起始位置超过结束位置是返回空字符串。 如： str_sub(&quot;term2017&quot;, 9) ## [1] &quot;&quot; str_sub(&quot;term2017&quot;, 1, -9) ## [1] &quot;&quot; str_sub(&quot;term2017&quot;, 8, 5) ## [1] &quot;&quot; 可以对str_sub()结果赋值，表示修改子串内容，如： s &lt;- &quot;term2017&quot; str_sub(s, 5, 8) &lt;- &quot;18&quot; s ## [1] &quot;term18&quot; 字符串替换一般还是应该使用专用的替换函数如stringr::str_replace_all()， gsub()。 基本R的substring(text, first, last)函数与stringr::str_sub()功能相同， 但first和last参数不允许用负数, last的默认值是一个很大的数，所以省略last时会取到字符串末尾。 substring()对三个参数text, first, last都是向量化的， 长度不一致时按照一般的不等长向量间运算规则处理。如： substring(c(&quot;term2017&quot;, &quot;term2018&quot;), first=c(1, 5), last=c(4, 8)) ## [1] &quot;term&quot; &quot;2018&quot; substring(&quot;term2017&quot;, first=c(1, 5), last=c(4, 8)) ## [1] &quot;term&quot; &quot;2017&quot; substring()也允许修改某个字符串的指定子串的内容，如 s &lt;- &quot;123456789&quot; substring(s, 3, 5) &lt;- &quot;abc&quot; s ## [1] &quot;12abc6789&quot; R的substr(x, start, stop)作用类似， 但是仅支持x为字符型向量， start和stop是标量。 36.1.6 字符串变换 36.1.6.1 大小写 stringr::str_to_upper(string)将字符型向量string中的英文字母都转换为大写。 类似函数有stringr::str_to_lower(string)转换为小写， stringr::str_to_title(string)转换为标题需要的大小写， stringr::str_to_scentence(string)转换为句子需要的大小写。 这都是针对英文的， 选项locale用来选语言，locale=\"en\"为默认值。 基本R的toupper()将字符型向量的每个元素中的小写字母转换为大写, tolower()转小写。 36.1.6.2 字符变换表 基本R的chartr(old, new, x)函数指定一个字符对应关系， 旧字符在old中，新字符在new中，x是一个要进行替换的字符型向量。 比如，下面的例子把所有!替换成.，把所有;替换成,： chartr(&quot;!;&quot;, &quot;.,&quot;, c(&quot;Hi; boy!&quot;, &quot;How do you do!&quot;)) ## [1] &quot;Hi, boy.&quot; &quot;How do you do.&quot; chartr(&quot;。，；县&quot;, &quot;.,;区&quot;, &quot;昌平县，大兴县；固安县。&quot;) ## [1] &quot;昌平区,大兴区;固安区.&quot; 第二个例子中被替换的标点是中文标点，替换成了相应的英文标点。 36.1.6.3 空白处理 stringr::str_trim(string, side)返回删去字符型向量string每个元素的首尾空格的结果， 可以用side指定删除首尾空格（\"both\"）、开头空格（\"left\"）、末尾空格（\"right\"）。 如： str_trim(c(&quot; 李明&quot;, &quot;李明 &quot;, &quot; 李明 &quot;, &quot;李 明&quot;)) ## [1] &quot;李明&quot; &quot;李明&quot; &quot;李明&quot; &quot;李 明&quot; str_trim(c(&quot; 李明&quot;, &quot;李明 &quot;, &quot; 李明 &quot;, &quot;李 明&quot;), side=&quot;left&quot;) ## [1] &quot;李明&quot; &quot;李明 &quot; &quot;李明 &quot; &quot;李 明&quot; str_trim(c(&quot; 李明&quot;, &quot;李明 &quot;, &quot; 李明 &quot;, &quot;李 明&quot;), side=&quot;right&quot;) ## [1] &quot; 李明&quot; &quot;李明&quot; &quot; 李明&quot; &quot;李 明&quot; stringr::str_squish(string)对字符型向量string每个元素， 删去首尾空格，将重复空格变成单个，返回变换后的结果。如： str_squish(c(&quot; 李明&quot;, &quot;李明 &quot;, &quot; 李明 &quot;, &quot;李 明&quot;)) ## [1] &quot;李明&quot; &quot;李明&quot; &quot;李明&quot; &quot;李 明&quot; 基本R函数trimws(x, which)与str_trim()作用类似， 选项which=\"left\"可以仅删去开头的空格， 选项which=\"right\"可以仅删去结尾的空格。 trimws(c(&quot; 李明&quot;, &quot;李明 &quot;, &quot; 李明 &quot;, &quot;李 明&quot;)) ## [1] &quot;李明&quot; &quot;李明&quot; &quot;李明&quot; &quot;李 明&quot; trimws(c(&quot; 李明&quot;, &quot;李明 &quot;, &quot; 李明 &quot;, &quot;李 明&quot;), which=&quot;left&quot;) ## [1] &quot;李明&quot; &quot;李明 &quot; &quot;李明 &quot; &quot;李 明&quot; trimws(c(&quot; 李明&quot;, &quot;李明 &quot;, &quot; 李明 &quot;, &quot;李 明&quot;), which=&quot;right&quot;) ## [1] &quot; 李明&quot; &quot;李明&quot; &quot; 李明&quot; &quot;李 明&quot; 为了去掉输入字符串中所有空格，可以用gsub()替换功能，如： gsub(&quot; &quot;, &quot;&quot;, c(&quot; 李明&quot;, &quot;李明 &quot;, &quot; 李明 &quot;, &quot;李 明&quot;), fixed=TRUE) ## [1] &quot;李明&quot; &quot;李明&quot; &quot;李明&quot; &quot;李明&quot; stringr::str_pad(string, width)可以将字符型向量string的每个元素加长到width个字符， 不足时左补空格，已经达到或超过width的则不变，如： str_pad(c(&quot;12&quot;, &quot;1234&quot;), 3) ## [1] &quot; 12&quot; &quot;1234&quot; 可以用选项side选择在哪里填补空格， 默认为\"left\"， 还可选\"right\"，\"both\"。 stringr::str_wrap()可以将作为字符型向量的长字符串拆分成近似等长的行， 行之间用换行符分隔。 36.1.6.4 排序 基本R函数sort()可以用来对字符型向量的各个元素按照字典序排序， 但是字符的先后顺序是按照操作系统的当前编码值次序， 见关于locales的帮助。 str_sort(x)对字符型向量x排序。 可以用locale选项指定所依据的locale， 不同的locale下次序不同。 默认为\"en\"即英语， 中国大陆的GB编码(包括GBK和GB18030)对应的locale是\"zh\"。 str_order(x)返回将x的各个元素从小到大排序的下标序列。 36.1.7 简单匹配与查找 36.1.7.1 开头和结尾匹配 基本R的startsWith(x, prefix)可以判断字符型向量x的每个元素是否以prefix开头， 结果为一个与x长度相同的逻辑型向量。如 startsWith(c(&quot;xyz123&quot;, &quot;tu004&quot;), &quot;tu&quot;) ## [1] FALSE TRUE endsWith(x, suffix)可以判断字符型向量x的每个元素是否以suffix结尾， 如 endsWith(c(&quot;xyz123&quot;, &quot;tu004&quot;), &quot;123&quot;) ## [1] TRUE FALSE stringr包的str_starts(string, pattern)判断string的每个元素是否以模式pattern开头， 加选项negate=TRUE表示输出反面结果。 pattern是正则表达式， 如果需要用非正则表达式，可以用fixed()或者coll()保护，如： str_starts(c(&quot;xyz123&quot;, &quot;tu004&quot;), fixed(&quot;tu&quot;)) ## [1] FALSE TRUE str_starts(c(&quot;xyz123&quot;, &quot;tu004&quot;), coll(&quot;tu&quot;)) ## [1] FALSE TRUE stringr包的str_ends(string, pattern)判断是否以给定模式结尾。 36.1.7.2 中间匹配 函数grep(), grepl()等可以用于查找子字符串， 位置不限于开头和结尾， 详见“正则表达式”章节。 在grepl()函数中加fixed=TRUE选项表示查找一般文本内容（非正则表达式）。 比如，查找字符串中是否含有our: grepl(&quot;our&quot;, c(&quot;flavor&quot;, &quot;tournament&quot;), fixed=TRUE) ## [1] FALSE TRUE 36.1.8 字符串替换 用gsub(pattern, replacement, x, fixed=TRUE) 把字符型向量x中每个元素中出现的子串 pattern都替换为replacement。 如 gsub(&quot;the&quot;, &quot;**&quot;, c(&quot;New theme&quot;, &quot;Old times&quot;, &quot;In the present theme&quot;), fixed=TRUE) ## [1] &quot;New **me&quot; &quot;Old times&quot; &quot;In ** present **me&quot; 设有些应用程序的输入要求使用逗号“,”分隔， 但是用户可能输入了中文逗号“，”， 就可以用gsub()来替换： x &lt;- c(&quot;15.34,14.11&quot;, &quot;13.25，16.92&quot;) x &lt;- gsub(&quot;，&quot;, &quot;,&quot;, x, fixed=TRUE); x ## [1] &quot;15.34,14.11&quot; &quot;13.25,16.92&quot; 例子中x的第二个元素中的逗号是中文逗号。 函数sub()与gsub()类似，但是仅替换第一次出现的pattern。 36.1.9 字符串拆分 stringr::str_split(string, pattern)对字符型向量string的每一个元素按分隔符pattern进行拆分， 每个元素拆分为一个字符型向量，结果是一个列表，列表元素为字符型向量。 其中pattern是正则表达式， 为了按照固定模式拆分，用fixed()进行保护。如 x &lt;- c(&quot;11,12&quot;, &quot;21,22,23&quot;, &quot;31,32,33,34&quot;) res1 &lt;- str_split(x, fixed(&quot;,&quot;)) res1 ## [[1]] ## [1] &quot;11&quot; &quot;12&quot; ## ## [[2]] ## [1] &quot;21&quot; &quot;22&quot; &quot;23&quot; ## ## [[3]] ## [1] &quot;31&quot; &quot;32&quot; &quot;33&quot; &quot;34&quot; str_split()可以用选项n指定仅拆分出成几项，最后一项合并不拆分，如： x &lt;- c(&quot;11,12&quot;, &quot;21,22,23&quot;, &quot;31,32,33,34&quot;) res2 &lt;- str_split(x, fixed(&quot;,&quot;), n=2) res2 ## [[1]] ## [1] &quot;11&quot; &quot;12&quot; ## ## [[2]] ## [1] &quot;21&quot; &quot;22,23&quot; ## ## [[3]] ## [1] &quot;31&quot; &quot;32,33,34&quot; 拆分的结果可以用lapply(), sapply()，vapply()等函数处理。 例如， 将每个元素的拆分结果转换成数值型： lapply(res1, as.numeric) ## [[1]] ## [1] 11 12 ## ## [[2]] ## [1] 21 22 23 ## ## [[3]] ## [1] 31 32 33 34 可以用unlist()函数将列表中的各个向量连接成一个长向量，如： unlist(res1) ## [1] &quot;11&quot; &quot;12&quot; &quot;21&quot; &quot;22&quot; &quot;23&quot; &quot;31&quot; &quot;32&quot; &quot;33&quot; &quot;34&quot; 注意，即使输入只有一个字符串，str_split()的结果也是列表， 所以输入只有一个字符串时我们应该取出结果列表的第一个元素，如 strsplit(&quot;31,32,33,34&quot;, split=&quot;,&quot;, fixed=TRUE)[[1]] ## [1] &quot;31&quot; &quot;32&quot; &quot;33&quot; &quot;34&quot; 如果确知每个字符串拆分出来的字符串个数都相同， 可以用stringr::str_split_fixed()， 用参数n指定拆出来的项数， 这时结果为一个字符型矩阵， 原来的每个元素变成结果中的一行： x &lt;- c(&quot;11,12&quot;, &quot;21,22&quot;, &quot;31,32&quot;) res3 &lt;- str_split_fixed(x, fixed(&quot;,&quot;), n=2) res3 ## [,1] [,2] ## [1,] &quot;11&quot; &quot;12&quot; ## [2,] &quot;21&quot; &quot;22&quot; ## [3,] &quot;31&quot; &quot;32&quot; 基本R的strsplit(x,split,fixed=TRUE) 可以把字符型向量x的每一个元素按分隔符split拆分为一个字符型向量， strsplit的结果为一个列表， 每个列表元素对应于x的每个元素。 如 x &lt;- c(&quot;11,12&quot;, &quot;21,22,23&quot;, &quot;31,32,33,34&quot;) res4 &lt;- strsplit(x, split=&quot;,&quot;, fixed=TRUE) res4 ## [[1]] ## [1] &quot;11&quot; &quot;12&quot; ## ## [[2]] ## [1] &quot;21&quot; &quot;22&quot; &quot;23&quot; ## ## [[3]] ## [1] &quot;31&quot; &quot;32&quot; &quot;33&quot; &quot;34&quot; 36.2 文本文件读写 文本文件是内容为普通文字、用换行分隔成多行的文件， 与二进制文件有区别， 二进制文件中换行符没有特殊含义， 而且二进制文件的内容往往也不是文字内容。 二进制文件的代表有图片、声音， 以及各种专用软件的的私有格式文件， 如Word文件、Excel文件。 对于文本文件，可以用readLines()函数将其各行的内容读入为一个字符型数组， 字符型数组的每一个元素对应于文件中的一行， 读入的字符型数组元素不包含分隔行用的换行符。 最简单的用法是读入一个本地的文本文件， 一次性读入所有内容，用如 lines &lt;- readLines(&quot;filename.ext&quot;) 其中filename.ext是文件名， 也可以用全路径名或相对路径名。 当文本文件很大的时候， 整体读入有时存不下， 即使能存下处理速度也很慢， 可以一次读入部分行，逐批读入并且逐批处理，这样程序效率更高。 这样的程序要复杂一些，例如 infcon &lt;- file(&quot;filename.ext&quot;, open=&quot;rt&quot;) batch &lt;- 1000 repeat{ lines &lt;- readLines(infcon, n=batch) if(length(lines)==0) break ## 处理读入的这些行 } close(infcon) 以上程序先打开一个文件，inffcon是打开的文件的读写入口（称为一个“连接对象”）。 每次读入指定的行并处理读入的行，直到读入了0行为止， 最后关闭infcon连接。 对文本文件的典型处理是读入后作一些修改， 另外保存。 函数writeLines(lines, con=\"outfilename.txt\")可以将字符型向量lines的各个元素变成输出文件的各行保存起来， 自动添加分隔行的换行符。 如果是分批读入分批处理的， 则写入也需要分批写入， 以上的分批处理程序变成： infcon &lt;- file(&quot;filename.ext&quot;, open=&quot;rt&quot;) outfcon &lt;- file(&quot;outfilename.txt&quot;, open=&quot;wt&quot;) batch &lt;- 1000 while(TRUE){ lines &lt;- readLines(infcon, n=batch) if(length(lines)==0) break ## 处理读入的这些行, 变换成outlines writeLines(outlines, con=outfcon) } close(outfcon) close(infcon) readLines()也可以直接读取网站的网页文件， 如 lines &lt;- readLines(url(&quot;https://www.r-project.org/&quot;)) length(lines) ## [1] 116 head(lines) ## [1] &quot;&lt;!DOCTYPE html&gt;&quot; ## [2] &quot;&lt;html lang=\\&quot;en\\&quot;&gt;&quot; ## [3] &quot; &lt;head&gt;&quot; ## [4] &quot; &lt;meta charset=\\&quot;utf-8\\&quot;&gt;&quot; ## [5] &quot; &lt;meta http-equiv=\\&quot;X-UA-Compatible\\&quot; content=\\&quot;IE=edge\\&quot;&gt;&quot; ## [6] &quot; &lt;meta name=\\&quot;viewport\\&quot; content=\\&quot;width=device-width, initial-scale=1\\&quot;&gt;&quot; readr包的read_lines()和write_lines()函数起到与基本R中 readLines()和writeLines()类似的作用， read_file()和read_file_raw()可以将整个文件读入为一个字符串。 关于读写文件时的编码问题， 详见15.5。 36.3 正则表达式 在对字符串进行查找或替换时， 有时要查找替换的不是固定的子串而是某种模式。 比如，要查找或替换连续的三个数字，正文中的电子邮件地址， 网址，电话号码，等等。 正则表达式(regular expressions)用于表示各种复杂模式。 基本R中的正则表达式规则可以用POSIX 1003.2标准或者Perl规则。 建议使用perl语言的正则表达式， 在基本R的有关函数中规定参数perl=TRUE。 stringr包提供了更方便的正则表达式功能， 其正则表达式规则是ICU正则表达式规则， 针对UTF-8编码的文本数据， 基本与perl规则兼容。 在正则表达式的模式(pattern)中， .*+?{}\\[]^$() 等字符是特殊字符，有特殊的解释。 除了\\之外的其它12个都称为“元字符”（meta characters）。 在R语言中使用正则表达式时， 需要注意R字符型常量中一个\\要写成两个。 36.3.1 字面匹配与匹配显示 如果模式中不含特殊字符，匹配为原样的子串。也叫做字面(literal)匹配。 stringr包提供了定义正则表达式、匹配正则表达式、按正则表达式替换、抽取匹配结果、用富文本显示匹配结果等强大功能， 其中str_view()函数可以在HTML输出中或者在RStudio软件中用富文本显示匹配结果， 在源数据中加亮显示匹配。 注意， 如果你现在看的是PDF文件， 结果可能无法显示。 在使用rmarkdown、bookdown创作文章和书籍时， 因为同一源文件需要能同时支持HTML、LaTeX转换PDF， 但str_view()等函数仅支持HTML， 所以需要进行设置。 可以在Rmd源文件开头运行命令： is_html &lt;- knitr::opts_knit$get(&quot;rmarkdown.pandoc.to&quot;) == &quot;html&quot; 这可以定义一个变量is_html， 仅在输出格式为HTML时才为TRUE， 然后在包含特殊HTML显示的代码段选项中， 加选项eval = is_html。 下面的程序在字符型向量x的三个字符串元素中原因查找子字符串\"the\"并加亮显示： x &lt;- c(&quot;New theme&quot;, &quot;Old times&quot;, &quot;In the present theme&quot;) str_view(x, &quot;the&quot;) 在RStudio中会在Viewer窗格显示匹配结果， 匹配内容被高亮显示。 源数据中的第三项实际上有两处\"the\"出现但结果只显示了第一处。 用str_view_all()查看所有匹配，如： x &lt;- c(&quot;New theme&quot;, &quot;Old times&quot;, &quot;In the present theme&quot;) str_view_all(x, &quot;the&quot;) 36.3.2 不区分大小写匹配和regex函数 str_view(string, pattern)中的pattern应该为正则表达式类型， 如果输入了字符串， 会自动被函数regex()转换成正则表达式类型。 正则表达式的模式一般是区分大小写的， 通过在regex()函数中加选项ignore_case=TRUE可以进行不区分大小写的匹配； 在模式前面附加(?i)前缀式选项也可以实现不区分大小写匹配。 如 str_view_all(c(&quot;Dr. Wang&quot;, &quot;DR. WANG&quot;, &quot;dR. W.R.&quot;), &quot;Dr&quot;) str_view_all(c(&quot;Dr. Wang&quot;, &quot;DR. WANG&quot;, &quot;dR. W.R.&quot;), regex(&quot;Dr&quot;, ignore_case=TRUE)) str_view_all(c(&quot;Dr. Wang&quot;, &quot;DR. WANG&quot;, &quot;dR. W.R.&quot;), &quot;(?i)Dr&quot;) 36.3.3 用句点匹配单个字符 在模式中用“.”匹配任意一个字符（除了换行符\"\\n\"，能否匹配此字符与选项有关）。 如 s &lt;- c(&quot;abc&quot;, &quot;cabs&quot;, &quot;lab&quot;) str_view_all(s, &quot;ab.&quot;) 像句点这样的字符称为元字符（meta characters）， 在正则表达式中有特殊作用。 如果需要匹配句点本身，用“[.]”或者“\\.”表示。 比如，要匹配a.txt这个文件名，如下做法有错误： str_view_all(c(&quot;a.txt&quot;, &quot;a0txt&quot;), &quot;a.txt&quot;) 结果连a0txt也匹配了。用“[.]”表示句点则将句点不做特殊解释： str_view_all(c(&quot;a.txt&quot;, &quot;a0txt&quot;), &quot;a[.]txt&quot;) str_view_all(c(&quot;a.txt&quot;, &quot;a0txt&quot;), &quot;a\\\\.txt&quot;) 注意在R语言字符型常量中一个\\需要写成两个。 如果仅需按照原样进行查找， 也可以将pattern的字符串用fixed()函数保护，如： 如 str_view_all(c(&quot;a.txt&quot;, &quot;a0txt&quot;), fixed(&quot;a.txt&quot;)) 36.3.4 匹配一组字符中的某一个 模式中使用方括号给定一个字符类， 单个字符与字符类中任何一个字符相同都算是匹配成功。 比如，模式“[ns]a.[.]xls” 表示匹配的第一个字符是n或s， 第二个字符是a，第三个字符任意，第四个字符是句点， 然后是xls。 测试： str_view_all(c(&quot;sa1.xls&quot;, &quot;dna2.xlss&quot;, &quot;nat.xls&quot;), &quot;[ns]a.[.]xls&quot;) 注意匹配并不需要从开头匹配到结尾， 中间匹配是允许的，类似于搜索符合某种规律的子串。 在上例中第二个元素是从第二个字符开始匹配的，也没有匹配到末尾。 例：模式[Rr]eg[Ee]x可以匹配RegEx或Regex或 regex或regEx。 如果希望完全忽略大小写进行匹配， 可以使用在regex()等函数中指定ignore_case=TRUE选项， 或在模式字符串的最前面添加(?i)选项。 在“[]”中允许用-表示一个范围。 如[a-z]匹配小写英文字母, [A-Z]匹配大写英文字母, [a-zA-Z]匹配大小写的英文字母, [a-zA-Z0-9]匹配大小写的英文字母和数字。 为了匹配一个16进制数字， 可以用[0-9A-Fa-f]。 例：模式“[ns]a[0-9][.]xls”要求匹配的第三个字符为数字。 str_view_all(c(&quot;sa1.xls&quot;, &quot;dna2.xlss&quot;, &quot;nat.xls&quot;), &quot;[ns]a[0-9][.]xls&quot;) 在方括号内第一个位置的^表示对指定的范围取余集。 例如，模式[ns]a[^0-9][.]xls要求匹配的第三个字符不能为数字: str_view_all(c(&quot;sa1.xls&quot;, &quot;dna2.xlss&quot;, &quot;nat.xls&quot;), &quot;[ns]a[^0-9][.]xls&quot;) 36.3.5 原样匹配元字符 元字符(meta characters)是在正则表达式中有特殊含义的字符。 比如句点可以匹配任意一个字符, 左方括号代表字符集合的开始。 所以元字符不能直接匹配自身， 可以用“[.]”匹配一个句点。 为匹配左方括号，在前面加上转义字符\\变成\\[， 但是在R字符串中一个\\必须用\\\\表示， 所以模式“\\[”在R中写成字符串常量， 必须写成\"\\\\[\"。 其它的元字符如果要原样匹配也可以在前面加上转义字符\\， 比如匹配\\本身可以用\\\\，但是在R字符型常量中需要写成\"\\\\\\\\\"。 例，匹配x[5]，因为[是元字符，需要写成： str_view_all(c(&quot;int x;&quot;, &quot;int x[5]&quot;), &quot;int x\\\\[5\\\\]&quot;) Perl中允许用“[[]”表示“[”， 用“[]]”表示“]”， 但stringr包不支持这种做法。 36.3.6 匹配空白 表示空白的元字符有: \\f 换页符 \\n 换行符 \\r 回车符 \\t 制表符 \\v 垂直制表符 不同操作系统的文本文件的行分隔符不同， 为了匹配Windows格式的文本文件中的空行， 用“\\r\\n\\r\\n”； 为了匹配Unix格式的文本文件中的空行则用“\\r\\r”。 写成R的字符型常量时， 这些表示本身也是R的相应字符的表示， 所以在R字符型常量中这些字符不需要用两个\\表示一个\\。 匹配任意一个空白字符用“\\s”， 这等价于“[ \\f\\n\\r\\t\\v]”。 大写的“\\S”则匹配任意一个非空白的字符。 36.3.7 匹配数字 用\\d匹配一个数字，相当于[0-9]。 用\\D匹配一个非数字。 如 str_view_all(c(&quot;n1.xls&quot;, &quot;na.xls&quot;), &quot;n\\\\d[.]xls&quot;) 36.3.8 匹配字母、数字、下划线 匹配字母、数字、下划线字符用\\w（小写）， 等价于[a-zA-Z0-9_]。 \\W（大写）匹配这些字符以外的字符。 如 str_view_all(c(&quot;file-s1.xls&quot;, &quot;s#.xls&quot;), &quot;s\\\\w[.]&quot;) 可以看出，模式匹配了s1.而没有匹配s#.。 36.3.9 十六进制和八进制数 在模式中可以用十六进制数和八进制数表示特殊的字符。 十六进制数用\\X引入， 比如\\X0A对应\\n字符。 八进制数用\\0引入， 比如\\011表示\\t字符。 例如，str_view_all(\"abc\\nefg\\n\", \"\\\\x0A\")可以匹配两个换行符。 36.3.10 POSIX字符类 \\d, \\w这样的字符类不方便用在方括号中组成字符集合， 而且也不容易记忆和认读。 在模式中方括号内可以用[:alpha:] 表示任意一个字母。 比如，[[:alpha:]]匹配任意一个字母（外层的方括号表示字符集合， 内层的方括号是POSIX字符类的固有界定符）。 这样的POSIX字符类有： [:alpha:]表示任意一个字母； [:lower:]为小写字母； [:upper:]为大写字母； [:digit:]为数字； [:xdigit:]为十六进制数字。 [:alnum:]为字母数字(不包括下划线)； [:blank:]为空格或制表符； [:space:]为任何一种空白字符，包括空格、制表符、换页符、换行符、回车符； [:print:]为可打印字符； [:graph:]和[:print:]一样但不包括空格； [:punct:]为[:print:]中除[:alnum:]和空白以外的所有字符； 例如： str_view_all(c(&quot;x1&quot;, &quot;_x&quot;, &quot;.x&quot;, &quot;.1&quot;), &quot;[[:alpha:]_.][[:alnum:]_.]&quot;) 模式匹配长度为2的字符串， 第一个字符是字母、下划线或者小数点， 第二个字符是字母、数字、下划线或者小数点。 这个模式试图匹配由两个字符组成的合法R变量名， 但是最后一个非变量名.1也被匹配了。 解决这样的问题可以采用后面讲到的|备择模式。 36.3.11 匹配开头和末尾 模式匹配相当于在字符串内部搜索某种模式， 如果要从字符串开头匹配， 在模式中取第一个模式规定为^或\\A。 如果模式中最后一个字符是$或\\Z， 则需要匹配到字符串末尾。 用\\Z匹配字符串末尾时如果末尾有一个换行符则匹配到换行符之前。 如 str_view_all(c(&quot;n1.xls&quot;, &quot;na.xls&quot;, &quot;cn1.xls&quot;, &quot;n1.xlsx&quot;), &quot;^n\\\\d[.]xls$&quot;) str_view_all(c(&quot;n1.xls&quot;, &quot;na.xls&quot;, &quot;cn1.xls&quot;, &quot;n1.xlsx&quot;), &quot;\\\\An\\\\d[.]xls\\\\Z&quot;) 只匹配了第一个输入字符串。 有时候源文本的每个字符串保存了一个文本文件内容， 各行用\\n分隔， 后面将给出匹配每行的行首与行尾的方法。 36.3.12 单词边界 用\\b匹配单词边界， 这样可以查找作为单词而不是单词的一部分存在的内容。 \\B匹配非单词边界。 如 str_view_all(c(&quot;a cat meaos&quot;, &quot;the category&quot;), &quot;\\\\bcat\\\\b&quot;) 36.3.13 重复匹配 36.3.13.1 加号重复匹配 模式中在一个字符或字符集合后加后缀+表示一个或多个前一字符。 比如 str_view_all(c(&quot;sa1&quot;, &quot;dsa123&quot;), &quot;sa[[:digit:]]+&quot;) 例如，匹配电子邮件地址： str_view_all(&quot;abc123@efg.com&quot;, &quot;^[[:alnum:]_]+@[[:alnum:]_]+[.][[:alnum:]_]+$&quot;) 匹配的电子邮件地址在@前面可以使用任意多个字母、数字、下划线， 在@后面由小数点分成两段， 每段可以使用任意多个字母、数字、下划线。 这里用了^和$表示全字符串匹配。 36.3.13.2 星号和问号重复匹配 在一个字符或字符集合后加后缀*表示零个或多个前一字符， 后缀?表示零个或一个前一字符。 比如， ^https?://[[:alnum:]./]+$可以匹配http或https开始的网址。 如 str_view_all(c(&quot;http://www.163.net&quot;, &quot;https://123.456.&quot;), &quot;^https?://[[:alnum:]_./]+$&quot;) (注意第二个字符串不是合法网址但是按这个正则表达式也能匹配) x[[:digit:]]*能匹配“x”, “x1”, “x123”这样的变量名，如： str_view_all(c(&quot;x&quot;, &quot;x1&quot;, &quot;x123&quot;), &quot;x[[:digit:]]*&quot;) str_view_all(c(&quot;x&quot;, &quot;x1&quot;, &quot;x123&quot;), &quot;x\\\\d*&quot;) 36.3.13.3 计数重复 问号可以表示零个或一个， 而加号、星号重复不能控制重复次数。 在后缀大括号中写一个整数表示精确的重复次数。 如 str_view_all(c(&quot;1&quot;, &quot;12&quot;, &quot;123&quot;, &quot;1234&quot;), &quot;[[:digit:]]{3}&quot;) 模式匹配的是三位的数字。 因为没有要求从开头一直匹配到末尾， 所以三位以上数字也能匹配其中开始的三位。 可以在后缀大括号中指定重复的最小和最大次数， 中间用逗号分隔。 比如， 月日年的日期格式可以用 [[:digit:]]{1,2}[-/][[:digit:]]{1,2}[-/][[:digit:]]{2,4} 来匹配。 如 (注意这个模式还会匹配非日期) pat &lt;- paste0( &quot;[[:digit:]]{1,2}[-/]&quot;, &quot;[[:digit:]]{1,2}[-/]&quot;, &quot;[[:digit:]]{2,4}&quot;) str_view_all(c(&quot;2/4/1998&quot;, &quot;13/15/198&quot;), pat) 重复数允许指定为0。 重复数的逗号后面空置表示重复数没有上限。 例如，后缀{3,}表示前一模式必须至少重复3次。 36.3.14 贪婪匹配和懒惰匹配 无上限的重复匹配如*, +, {3,}等缺省是贪婪型的， 重复直到文本中能匹配的最长范围。 比如我们希望找出圆括号这样的结构， 很容易想到用\\(.+\\)这样的模式（注意圆括号是元字符，需要用反斜杠保护）， 但是这不会恰好匹配一次， 模式会一直搜索到最后一个)为止。 例如： str_view_all(&quot;(1st) other (2nd)&quot;, &quot;\\\\(.+\\\\)&quot;) 我们本来期望的是提取两个“(1st)”和“(2nd)”组合， 不料整个地提取了“(1st) other (2nd)”。 这就是因为.+的贪婪匹配。 如果要求尽可能短的匹配， 使用*?, +?, {3,}?等“懒惰型”重复模式。 在无上限重复标志后面加问号表示懒惰性重复。 比如，上例中模式修改后得到了期望的结果： str_view_all(&quot;(1st) other (2nd)&quot;, &quot;\\\\(.+?\\\\)&quot;) 懒惰匹配会造成搜索效率降低， 应仅在需要的时候使用。 36.3.15 句点全匹配与多行模式 句点通配符一般不能匹配换行，如 str_view_all(&quot;(1,\\n2)&quot;, &quot;\\\\(.+?\\\\)&quot;) 跨行匹配失败。 一种办法是预先用str_replace_all()或gsub()把所有换行符替换为空格。 但是这只能解决部分问题。 解决方法是在将模式用regex()保护并加选项dotall=TRUE， 或者在Perl正则表达式开头添加(?s)选项， 这样使得句点通配符可以匹配换行符， 称为句点全匹配模式。 如 str_view_all(&quot;(1,\\n2)&quot;, regex(&quot;\\\\(.+?\\\\)&quot;, dotall=TRUE)) str_view_all(&quot;(1,\\n2)&quot;, &quot;(?s)\\\\(.+?\\\\)&quot;) 在regex()函数中加选项multiline=TRUE， 或者在正则表达式开头用(?m)表示把整个输入字符串看成用换行符分开的多行。 这时^和$匹配每行的开头和结尾， “每行”是指字符串中用换行符分开的各个字符子串。 (?s)与(?m)可以同时使用。 例： str_view_all(&quot;(1,2)\\n(3,4)\\n&quot;, &quot;^\\\\(.+?\\\\)$&quot;) 元数据中包含两行内容， 结果没有能够匹配， 这是因为模式要求从整个字符串开头一直匹配到末尾。 增加multiline=TRUE或者(?m)选项则可以匹配两处： str_view_all(&quot;(1,2)\\n(3,4)\\n&quot;, regex(&quot;^\\\\(.+?\\\\)$&quot;, multiline=TRUE)) str_view_all(&quot;(1,2)\\n(3,4)\\n&quot;, &quot;(?m)^\\\\(.+?\\\\)$&quot;) 36.3.15.1 逐行处理 虽然正则表达式有多行和跨行选项， 但是当源数据很长时， 匹配效率会很低。 R的readLines()函数可以把一整个文本文件读成一个字符型向量， 每个元素为一行， 元素中不包含换行符。 R的字符型函数可以对这样的字符型向量每个元素同时处理， 也就实现了逐行处理。 如果字符串x中包含了一整个文本文件内容， 其中以\\n分隔各行， 为了实现逐行处理， 可以先用str_split()函数拆分成不同行： cl &lt;- strs_plit(x, &quot;\\r?\\n&quot;)[[1]] 结果将是一个字符型向量， 每个元素是原来的一行，最后一个元素是空字符串。 如 x &lt;- c(&quot;This is first line.\\nThis is second line.\\n&quot;) cl &lt;- str_split(x, &quot;\\r?\\n&quot;)[[1]] cl ## [1] &quot;This is first line.&quot; &quot;This is second line.&quot; &quot;&quot; 36.3.16 备择模式 如果有两种模式都算正确匹配，则用|连接这两个模式表示两者都可以。 例如，某个人的名字用James和Jim都可以， 表示为James|Jim, 如 str_view(c(&quot;James, Bond&quot;, &quot;Jim boy&quot;), &quot;James|Jim&quot;) 两个字符的合法R变量名的匹配： str_view_all(c(&quot;x1&quot;, &quot;_x&quot;, &quot;.x&quot;, &quot;.1&quot;), &quot;[[:alpha:]_][[:alnum:]_.]|[.][[:alpha:]_]&quot;) 36.3.17 分组与捕获 在正则表达式中用圆括号来分出组， 作用是 确定优先规则 组成一个整体 拆分出模式中的部分内容（称为捕获） 定义一段供后续引用或者替换。 圆括号中的模式称为子模式，或者捕获。 在使用备择模式时，James|Jim是在单词James和Jim之间选择。 如果希望选择的是中间的ms和Ji怎么办？ 可以将备择模式保护起来， 如Jam(es|Ji)m， 就可以确定备择模式的作用范围。 有时一个模式中部分内容仅用于定位， 而实际有用的内容是其中的一部分， 就可以将这部分有用的内容包在圆括号中作为一个捕获。 元字符问号、加号、星号、大括号等表示重复， 前面的例子中都是重复一个字符或者字符类。 如果需要重复由多个字符组成的模式， 如x[[:digit:]]{2}怎么办？ 只要将该模式写在括号中，如： str_view_all(c(&quot;x01x02&quot;, &quot;_x11x9&quot;), &quot;(x[[:digit:]]{2})+&quot;) 上例的元数据中， 第一个元素重复了两次括号中的模式， 第二个元素仅有一次括号中的模式。 注意： 用表示重复的元字符重复某个模式时， 从第二次开始， 并不是要重复前面的子字符串， 而是重复前面的模式。 比如上例中x01x02。 如果想严格重复前面的某个子字符串怎么办？ 分组是自动编号的， 以左开括号的序号为准（除了作为选项、有名捕获等开扩号以外）。 在替换或者向后引用时， 可以用\\1，\\2等表示匹配中第一个开括号对应的分组， 第二个开扩号对应的分组，……。 在模式中可以用\\1, \\2等表示严格重复前面捕获的子字符串。 例如，([a-z]{3})\\1这样的模式可以匹配如abcabc, uxzuxz这样的三字母重复： str_view_all(c(&quot;abcabc&quot;, &quot;aabbcc&quot;), &quot;([a-z]{3})\\\\1&quot;) 又例如，下面的程序找出了年（后两位）、月、日数字相同的日期： str_view_all(c(&quot;2008-08-08&quot;, &quot;2017-01-18&quot;), &quot;\\\\d\\\\d(\\\\d\\\\d)-\\\\1-\\\\1&quot;) stringr的函数str_replace_all(string, pattern, replacement)可以指定一个查找模式pattern, 替换模式replacement， 对字符型向量string中的每个元素进行替换。 replacement中的元字符没有特殊解释， 但是\\1, \\2等代表匹配的子模式（捕获）。 例：希望把带有前导零的数字的前导零删除，可以用如 x &lt;- c(&quot;1204&quot;, &quot;01204&quot;, &quot;001204B&quot;) pat &lt;- &quot;\\\\b0+([1-9][0-9]*)\\\\b&quot; repl &lt;- &quot;\\\\1&quot; str_view_all(x, pat) str_replace_all(x, pat, repl) ## [1] &quot;1204&quot; &quot;1204&quot; &quot;001204B&quot; 上例的模式中的\\b表示单词边界， 所以中间的0不会被当作前导零， 不是整个数字的也不会被修改。 上例中的str_view_all()仅用于调试目的， 在进行替换时不时必要步骤。 例：为了交换横纵坐标，可以用如下替换 x &lt;- &quot;1st: (5,3.6), 2nd: (2.5, 1.1)&quot; pat &lt;- paste0( &quot;[(]([[:digit:].]+),&quot;, &quot;[[:space:]]*([[:digit:].]+)[)]&quot;, sep=&quot;&quot;) repl &lt;- &quot;(\\\\2, \\\\1)&quot; str_view_all(x, pat) str_replace_all(x, pat, repl) ## [1] &quot;1st: (3.6, 5), 2nd: (1.1, 2.5)&quot; 例: 要匹配yyyy-mm-dd这样的日期， 并将其改写为mm/dd/yyyy， 就可以用这样的替换模式： x &lt;- c(&quot;1998-05-31&quot;, &quot;2017-01-14&quot;) pat &lt;- &quot;([0-9]{4})-([0-9]{1,2})-([0-9]{1,2})&quot; repl &lt;- &quot;\\\\2/\\\\3/\\\\1&quot; str_view_all(x, pat) str_replace_all(x, pat, repl) ## [1] &quot;05/31/1998&quot; &quot;01/14/2017&quot; 如果某个分组仅想起到分组作用但是不会提取具体的匹配内容也不会用该组内容做替换， 可以将该组变成“非捕获分组”， 办法是把表示分组开始左圆括号变成(?:三个字符。 这在用分组表示优先级时比较有用， 如\"Jam(es|Ji)m\"可以写成\"Jam(?:es|Ji)m\"。 非捕获分组在向后引用和替换时不计入\\1、\\2这样的排列中。 比如，把1921-2020之间的世纪号删去，可以用 x &lt;- c(&quot;1978&quot;, &quot;2017&quot;, &quot;2035&quot;) pat &lt;- &quot;\\\\A(?:19|20)([0-9]{2})\\\\Z&quot; repl &lt;- &quot;\\\\1&quot; str_view_all(x, pat) str_replace_all(x, pat, repl) ## [1] &quot;78&quot; &quot;17&quot; &quot;35&quot; 其中用了非捕获分组使得备择模式19|20优先匹配。 注意模式并没有能保证日期在1921-2020之间。更周密的程序可以写成： x &lt;- c(&quot;1978&quot;, &quot;2017&quot;, &quot;2035&quot;) pat1 &lt;- &quot;\\\\A19(2[1-9]|[3-9][0-9])\\\\Z&quot; pat2 &lt;- &quot;\\\\A20([01][0-9]|20)\\\\Z&quot; repl &lt;- &quot;\\\\1&quot; str_view_all(x, pat1) str_view_all(x, pat2) x %&gt;% str_replace_all(pat1, repl) %&gt;% str_replace_all(pat2, repl) ## [1] &quot;78&quot; &quot;17&quot; &quot;2035&quot; 这里用了stringr包重新定义的管道运算， 与magrittr包定义的管道运算作用相同， 可以将函数的第一个自变量自动输入给管道的下一个处理层级。 36.4 stringr包的正则表达式函数 36.4.1 str_view()函数 str_view(string, pattern)在RStudio中打开Viewer窗格， 显示pattern给出的正则表达式模式在string中的首个匹配。 string是输入的字符型向量。 用str_view_all()显示所有匹配。 如果要匹配的是固定字符串， 写成str_view(string, fixed(pattern))。 如果要匹配的是单词等的边界， 模式用boundary()函数表示，如 str_view(\"a brown fox\", boundary(\"word\"))将匹配首个单词。 36.4.2 regex()函数 stringr包用到正则表达式模式的地方， 实际上应该写成regex(pattern)， 只写模式本身是一种简写。 regex()函数可以指定ignore_case=TRUE要求不区分大小写， 指定multi_line=TRUE使得^和$匹配用换行符分开的每行的开头和结尾， dotall=TRUE使得.能够匹配换行符。 comment=TRUE使得模式可以写成多行， 行尾的井号后面表示注释， 这时空格不再原样匹配， 为了匹配空格需要写在方括号内或者用反斜杠开头。 与regex()类似的表示模式的函数有fixed()， boundary()，coll()。 36.4.3 检查那些元素能够匹配 str_detect(string, pattern)返回字符型向量string的每个元素是否匹配pattern中的模式的逻辑型结果。 与基本R的grepl()作用类似。 如 x &lt;- c(&quot;New theme&quot;, &quot;Old times&quot;, &quot;In the present theme&quot;) str_view(x, &quot;the&quot;) str_detect(x, &quot;the&quot;) ## [1] TRUE FALSE TRUE 上例中的str_view()仅用作调试目的。 str_which(string, pattern)返回字符型向量string的元素当中能匹配pattern中的模式的元素序号。 与基本R的grep()作用类似。 如 x &lt;- c(&quot;New theme&quot;, &quot;Old times&quot;, &quot;In the present theme&quot;) str_which(x, &quot;the&quot;) ## [1] 1 3 str_count()则返回模式在每个元素中匹配的次数。 如 str_count(c(&quot;123,456&quot;, &quot;011&quot;), &quot;[[:digit:]]&quot;) ## [1] 6 3 36.4.4 替换 stringr包的str_replace_all(string, pattern, replacement)在字符型向量string的每个元素中查找模式pattern， 并将所有匹配按照replacement进行替换。 在replacement可以用\\1, \\2中表示模式中的捕获， 除此之外元字符没有特殊作用。 基本R中gsub()有类似功能。 如： str_replace_all(c(&quot;123,456&quot;, &quot;011&quot;), &quot;,&quot;, &quot;&quot;) ## [1] &quot;123456&quot; &quot;011&quot; 又如： str_replace_all(c(&quot;123,456&quot;, &quot;011&quot;), &quot;([[:digit:]]+),([[:digit:]]+)&quot;, &quot;\\\\2,\\\\1&quot;) ## [1] &quot;456,123&quot; &quot;011&quot; 注意源数据中第二个元素因为不能匹配所以就原样返回了， 没有进行替换。 str_replace()则仅对输入字符型向量的每个元素中模式的第一次出现进行替换， 不如str_replace_all()常用。 36.4.5 返回匹配的元素 str_subset(string, pattern)返回字符型向量中能匹配pattern的那些元素组成的子集， 与基本R函数grep(pattern, string, value=TRUE)效果相同。 注意，返回的是整个元素而不是匹配的子串。 比如，查找人名中间有空格的： str_view_all(c(&quot;[马思聪]&quot;, &quot;[李 明]&quot;), &quot;[[:alpha:]]+[[:space:]]+[[:alpha:]]+&quot;) str_subset(c(&quot;[马思聪]&quot;, &quot;[李 明]&quot;), &quot;[[:alpha:]]+[[:space:]]+[[:alpha:]]+&quot;) ## [1] &quot;[李 明]&quot; 注意上例中仅返回了有匹配的元素， 而且是匹配元素的整个字符串而不是匹配的部分。 当要查找的内容是tibble的一列时， 用filter()与str_detct()配合， 可以进行行子集选择。 比如，在数据框的人名中查找中间有空格的名字： tibble(name=c(&quot;马思聪&quot;, &quot;李 明&quot;)) %&gt;% filter(str_detect(name, &quot;[[:alpha:]]+[[:space:]]+[[:alpha:]]+&quot;)) ## # A tibble: 1 x 1 ## name ## &lt;chr&gt; ## 1 李 明 36.4.6 提取匹配内容 str_subset()返回的是有匹配的源字符串， 而不是匹配的部分子字符串。 用str_extract(string, pattern)从源字符串中取出首次匹配的子串。 如 str_view_all(&quot;A falling ball&quot;, &quot;all&quot;) str_extract(&quot;A falling ball&quot;, &quot;all&quot;) ## [1] &quot;all&quot; str_extract_all(string, pattern)取出所有匹配子串， 结果是一个列表， 列表的每个元素对应于字符型向量string的每个元素， 结果列表的每个元素是一个字符型数组， 存放所有匹配的子字符串。 如： x &lt;- c(&quot;A falling ball&quot;, &quot;Phone call.&quot;) str_view_all(x, &quot;all&quot;) str_extract_all(x, &quot;all&quot;) ## [[1]] ## [1] &quot;all&quot; &quot;all&quot; ## ## [[2]] ## [1] &quot;all&quot; str_extract_all()可以加选项simplyfy=TRUE， 使得返回结果变成一个字符型矩阵， 每行是原来一个元素中取出的各个子串， 列数等于最大匹配次数， 没有那么多匹配次数的填以空字符串。 如果正常匹配结果不会出现空字符就可以用这种方法简化结果的保存和访问。 如 x &lt;- c(&quot;A falling ball&quot;, &quot;Phone call.&quot;) str_view_all(x, &quot;all&quot;) str_extract_all(x, &quot;all&quot;, simplify=TRUE) ## [,1] [,2] ## [1,] &quot;all&quot; &quot;all&quot; ## [2,] &quot;all&quot; &quot;&quot; 36.4.7 提取分组捕获内容 str_subset()提取的是能匹配模式的元素子集， 而不是匹配的模式或者捕获； str_extract()和str_extract_all()提取的是每个元素的首次或者所有匹配的子字符串， 而不是其中的捕获。 str_match(string, pattern)提取每个元素的首次匹配内容以及其中各个捕获分组内容， 结果是一个矩阵， 每行对应于字符型向量string中的一个元素， 结果矩阵的每行的第一个元素是匹配内容，其它元素是各个捕获， 没有则为字符型缺失值（不是空字符串）。 比如，希望匹配中间有空格的人名并捕获空格前后部分： str_match(c(&quot;马思聪&quot;, &quot;李 明&quot;), &quot;([[:alpha:]]+)[[:space:]]+([[:alpha:]]+)&quot;) ## [,1] [,2] [,3] ## [1,] NA NA NA ## [2,] &quot;李 明&quot; &quot;李&quot; &quot;明&quot; 上例中源数据第一个元素没有匹配， 所以结果都是缺失值NA， 第二个元素的结果在第二行， 首先是整个匹配的子字符串， 然后是捕获的两个部分。 stringr::str_match_all(string, pattern)匹配每个字符串中所有出现位置， 结果是一个列表， 每个列表元素对应于输入的字符型向量string的每个元素， 结果中每个列表元素是一个字符型矩阵， 用来保存所有各个匹配以及匹配中的捕获， 每行是一个匹配的结果，首先是匹配结果，其次是各个捕获。 结果列表中每个作为列表元素的矩阵大小不一定相同。 当某个元素完全没有匹配时， 结果列表中对应元素是行数为0的矩阵。 比如，模式为19xx或者20xx的年份， 并将其分为前两位和后两位： x &lt;- c(&quot;1978-2000&quot;, &quot;2011-2020-2099&quot;, &quot;2100-2199&quot;) pat &lt;- &quot;\\\\b(19|20)([0-9]{2})\\\\b&quot; str_view_all(x, pat) mlist &lt;- str_match_all(x, pat); mlist ## [[1]] ## [,1] [,2] [,3] ## [1,] &quot;1978&quot; &quot;19&quot; &quot;78&quot; ## [2,] &quot;2000&quot; &quot;20&quot; &quot;00&quot; ## ## [[2]] ## [,1] [,2] [,3] ## [1,] &quot;2011&quot; &quot;20&quot; &quot;11&quot; ## [2,] &quot;2020&quot; &quot;20&quot; &quot;20&quot; ## [3,] &quot;2099&quot; &quot;20&quot; &quot;99&quot; ## ## [[3]] ## [,1] [,2] [,3] 下面的程序合并上面提取的年份后两位为一个字符型向量： ml &lt;- Filter(function(m) nrow(m)&gt;0, mlist) ml &lt;- Map(function(m) m[,3], ml) ml &lt;- Reduce(c, ml); ml ## [1] &quot;78&quot; &quot;00&quot; &quot;11&quot; &quot;20&quot; &quot;99&quot; 36.4.8 定位匹配位置 str_locate(string, pattern)对输入字符型向量string的每个元素返回首次匹配pattern的开始和结束位置。 输出结果是一个两列的矩阵，每行对应于输入的一个元素， 每行的两个元素分别是首次匹配的开始和结束字符序号（按字符计算）。如 x &lt;- c(&quot;A falling ball&quot;, &quot;Phone call.&quot;) str_view_all(x, &quot;all&quot;) str_locate(x, &quot;all&quot;) ## start end ## [1,] 4 6 ## [2,] 8 10 str_locate_all(string, pattern)则可以返回每个元素中所有匹配的开始和结束位置， 结果是一个列表， 每个列表元素对应于输入字符型向量的每个元素， 结果中每个列表元素是一个两列的数值型矩阵， 每行为一个匹配的开始和结束字符序号。如 x &lt;- c(&quot;A falling ball&quot;, &quot;Phone call.&quot;) str_view_all(x, &quot;all&quot;) str_locate_all(x, &quot;all&quot;) ## [[1]] ## start end ## [1,] 4 6 ## [2,] 12 14 ## ## [[2]] ## start end ## [1,] 8 10 注意如果需要取出匹配的元素可以用str_subset()， 要取出匹配的子串可以用str_extract()和str_extract_all()， 取出匹配的子串以及分组捕获可以用str_match()和str_match_all()。 36.5 利用基本R函数进行正则表达式处理 基本R函数grep, sub, gsub, regexpr, gregexpr, regexec中的 pattern参数可以是正则表达式， 这时应设参数 fixed=FALSE。 strsplit函数中的参数split也可以是正则表达式。 regmatches函数从regexpr, gregexpr, regexec的结果中提取匹配的字符串。 以原样匹配为例。 x &lt;- c(&quot;New theme&quot;, &quot;Old times&quot;, &quot;In the present theme&quot;) regexpr(&quot;the&quot;, x, perl=TRUE) ## [1] 5 -1 4 ## attr(,&quot;match.length&quot;) ## [1] 3 -1 3 ## attr(,&quot;index.type&quot;) ## [1] &quot;chars&quot; ## attr(,&quot;useBytes&quot;) ## [1] TRUE 这里使用了regexpr函数。 regexpr函数的一般用法为： x &lt;- c(&quot;New theme&quot;, &quot;Old times&quot;, &quot;In the present theme&quot;) regexpr(pattern, text, ignore.case = FALSE, perl = FALSE, fixed = FALSE, useBytes = FALSE) 自变量为： pattern 是一个正则表达式，如果用了fixed=TRUE选项，则当作普通原样文本来匹配； text 是源字符串向量，要从其每个元素中查找pattern模式出现的位置； ignore.case：是否要忽略大小写匹配； perl 选择是否采用perl格式，如果不把pattern当作普通原样文本，应该选perl=TRUE，perl语言的正则表达式是事实上的标准，所以这样兼容性更好； fixed 当fixed=TRUE时pattern作为普通原样文本解释； useBytes 为TRUE时逐字节进行匹配，否则逐字符进行匹配。之所以有这样的区别，是因为有些编码中一个字符由多个字节构成，BGK编码的汉字由两个字节组成，UTF-8编码的汉字也是由两个字节构成。 regexpr()函数返回一个整数值的向量， 长度与text向量长度相同， 结果的每个元素是在text的对应元素中pattern的首次匹配位置； 没有匹配时结果元素取-1。 结果会有一个match.length属性，表示每个匹配的长度， 无匹配时取-1。 如果仅关心源字符串向量text中哪些元素能匹配pattern， 可以用grep函数，如 x &lt;- c(&quot;New theme&quot;, &quot;Old times&quot;, &quot;In the present theme&quot;) grep(&quot;the&quot;, x, perl=TRUE) ## [1] 1 3 结果说明源字符串向量的三个元素中仅有第1、第3号元素能匹配。 如果都不匹配，返回integer(0)。 grep可以使用与regexpr相同的自变量， 另外还可以加选项invert=TRUE，这时返回的是不匹配的元素的下标。 grep()如果添加选项value=TRUE， 则结果不是返回有匹配的元素的下标而是返回有匹配的元素本身（不是匹配的子串）， 如 x &lt;- c(&quot;New theme&quot;, &quot;Old times&quot;, &quot;In the present theme&quot;) grep(&quot;the&quot;, x, perl=TRUE, value=TRUE) ## [1] &quot;New theme&quot; &quot;In the present theme&quot; grepl的作用与grep类似， 但是其返回值是一个长度与源字符串向量text等长的逻辑型向量， 每个元素的真假对应于源字符串向量中对应元素的匹配与否。如 x &lt;- c(&quot;New theme&quot;, &quot;Old times&quot;, &quot;In the present theme&quot;) grepl(&quot;the&quot;, x, perl=TRUE) ## [1] TRUE FALSE TRUE 就像grep()与grepl()本质上给出相同的结果，只是结果的表示方式不同， regexec()与regexpr()也给出仅在表示方式上有区别的结果。 regexpr()主要的结果是每个元素的匹配位置， 用一个统一的属性返回各个匹配长度； regexec()则返回一个与源字符串向量等长的列表， 列表的每个元素为匹配的位置，并且列表的每个元素有匹配长度作为属性。 所以，这两个函数只需要用其中一个就可以，下面仅使用regexpr()。 regexec()的使用效果如 x &lt;- c(&quot;New theme&quot;, &quot;Old times&quot;, &quot;In the present theme&quot;) regexec(&quot;the&quot;, x, perl=TRUE) ## [[1]] ## [1] 5 ## attr(,&quot;match.length&quot;) ## [1] 3 ## attr(,&quot;useBytes&quot;) ## [1] TRUE ## ## [[2]] ## [1] -1 ## attr(,&quot;match.length&quot;) ## [1] -1 ## attr(,&quot;useBytes&quot;) ## [1] TRUE ## ## [[3]] ## [1] 4 ## attr(,&quot;match.length&quot;) ## [1] 3 ## attr(,&quot;useBytes&quot;) ## [1] TRUE grep(), grepl(), regexpr(), regexec()都只能找到源字符串向量的每个元素中模式的首次匹配， 不能找到所有匹配。 gregexpr()函数可以找到所有匹配。 如 x &lt;- c(&quot;New theme&quot;, &quot;Old times&quot;, &quot;In the present theme&quot;) gregexpr(&quot;the&quot;, x, perl=TRUE) ## [[1]] ## [1] 5 ## attr(,&quot;match.length&quot;) ## [1] 3 ## attr(,&quot;index.type&quot;) ## [1] &quot;chars&quot; ## attr(,&quot;useBytes&quot;) ## [1] TRUE ## ## [[2]] ## [1] -1 ## attr(,&quot;match.length&quot;) ## [1] -1 ## attr(,&quot;index.type&quot;) ## [1] &quot;chars&quot; ## attr(,&quot;useBytes&quot;) ## [1] TRUE ## ## [[3]] ## [1] 4 16 ## attr(,&quot;match.length&quot;) ## [1] 3 3 ## attr(,&quot;index.type&quot;) ## [1] &quot;chars&quot; ## attr(,&quot;useBytes&quot;) ## [1] TRUE 其结果是一个与源字符串向量等长的列表， 格式与regexec()的结果格式类似， 列表的每个元素对应于源字符串向量的相应元素， 列表元素值为匹配的位置， 并有属性match.length保存了匹配长度。 匹配位置和匹配长度包含了所有的匹配， 见上面例子中第三个元素的匹配结果。 函数grep, grepl结果仅给出每个元素能否匹配。 regexpr(), regexec(), gregexpr()则包含了匹配位置与匹配长度， 这时，可以用regmatches()函数取出具体的匹配字符串。 regmatches()一般格式为 regmatches(x, m, invert = FALSE) 其中x是源字符串向量， m是regexpr()、regexec()或gregexpr()的匹配结果。 如 x &lt;- c(&quot;New theme&quot;, &quot;Old times&quot;, &quot;In the present theme&quot;) m &lt;- regexpr(&quot;the&quot;, x, perl=TRUE) regmatches(x, m) ## [1] &quot;the&quot; &quot;the&quot; 可以看出，regmatches()仅取出有匹配时的匹配内容， 无匹配的内容被忽略。 取出多处匹配的例子如： x &lt;- c(&quot;New theme&quot;, &quot;Old times&quot;, &quot;In the present theme&quot;) m &lt;- gregexpr(&quot;the&quot;, x, perl=TRUE) regmatches(x, m) ## [[1]] ## [1] &quot;the&quot; ## ## [[2]] ## character(0) ## ## [[3]] ## [1] &quot;the&quot; &quot;the&quot; 当regmatches()第二个自变量是gregexpr()的结果时， 其输出结果变成一个列表， 并且不再忽略无匹配的元素， 无匹配元素对应的列表元素为character(0)， 即长度为零的字符型向量。 对有匹配的元素， 对应的列表元素为所有的匹配字符串组成的字符型向量。 实际上， 如果pattern中没有正则表达式， grep(), grepl(), regexpr(), gregexpr() 中都可以用fixed=TRUE参数取代perl=TRUE参数， 这时匹配总是解释为原样匹配， 即使pattern中包含特殊字符也是进行原样匹配。 36.5.1 不区分大小写匹配 在基本R中， 为了不区分大小写匹配， 可以在grep等函数调用时加选项ignore.case=TRUE； 如 grep(&quot;Dr&quot;, c(&quot;Dr. Wang&quot;, &quot;DR. WANG&quot;, &quot;dR. W.R.&quot;)) ## [1] 1 grep(&quot;dr&quot;, c(&quot;Dr. Wang&quot;, &quot;DR. WANG&quot;, &quot;dR. W.R.&quot;), ignore.case=TRUE) ## [1] 1 2 3 grep(&quot;(?i)dr&quot;, c(&quot;Dr. Wang&quot;, &quot;DR. WANG&quot;, &quot;dR. W.R.&quot;)) ## [1] 1 2 3 36.5.2 匹配单个字符 在模式中用“.”匹配任意一个字符（除了换行符\"\\n\"，能否匹配此字符与选项有关）。如 s &lt;- c(&quot;abc&quot;, &quot;cabs&quot;, &quot;lab&quot;) mres &lt;- regexpr(&quot;ab.&quot;, s, perl=TRUE); mres ## [1] 1 2 -1 ## attr(,&quot;match.length&quot;) ## [1] 3 3 -1 ## attr(,&quot;index.type&quot;) ## [1] &quot;chars&quot; ## attr(,&quot;useBytes&quot;) ## [1] TRUE regexpr仅给出每个元素中模式的首次匹配位置而不是给出匹配的内容。 regmatches函数以原始字符型向量和匹配结果为输入， 结果返回每个元素中匹配的各个子字符串(不是整个元素)，如: regmatches(s, mres) ## [1] &quot;abc&quot; &quot;abs&quot; 注意返回结果和输入字符型向量元素不是一一对应的，仅返回有匹配的结果。 像句点这样的字符称为元字符（meta characters）， 在正则表达式中有特殊函数。 如果需要匹配句点本身，用“[.]”或者“\\.”表示。 比如，要匹配a.txt这个文件名，如下做法有错误： grep(&quot;a.txt&quot;, c(&quot;a.txt&quot;, &quot;a0txt&quot;), perl=TRUE) ## [1] 1 2 结果连a0txt也匹配了。用“[.]”表示句点则将句点不做特殊解释： grep(&quot;a[.]txt&quot;, c(&quot;a.txt&quot;, &quot;a0txt&quot;), perl=TRUE) ## [1] 1 grep(&quot;a\\\\.txt&quot;, c(&quot;a.txt&quot;, &quot;a0txt&quot;), perl=TRUE) ## [1] 1 注意在R语言字符型常量中一个\\需要写成两个。 如果仅需按照原样进行查找， 也可以在grep(), grepl()，regexpr()，gregexpr()等函数中加选项fixed=TRUE， 这时不要再用perl=TRUE选项。 如 grep(&quot;a.txt&quot;, c(&quot;a.txt&quot;, &quot;a0txt&quot;), fixed=TRUE) ## [1] 1 36.5.3 匹配一组字符中的某一个 模式“[ns]a.[.]xls” 表示匹配的第一个字符是n或s， 第二个字符是a，第三个字符任意，第四个字符是句点， 然后是xls。 例： regexpr(&quot;[ns]a.[.]xls&quot;, c(&quot;sa1.xls&quot;, &quot;dna2.xlss&quot;, &quot;na3.xls&quot;), perl=T) ## [1] 1 2 1 ## attr(,&quot;match.length&quot;) ## [1] 7 7 7 ## attr(,&quot;index.type&quot;) ## [1] &quot;chars&quot; ## attr(,&quot;useBytes&quot;) ## [1] TRUE 36.5.4 原样匹配元字符 例： grep(&quot;int x\\\\[5\\\\]&quot;, c(&quot;int x;&quot;, &quot;int x[5]&quot;), perl=TRUE) ## [1] 2 也可以用“[[]”表示“[”， 用“[]]”表示“]”，如 grep(&quot;int x[[]5[]]&quot;, c(&quot;int x;&quot;, &quot;int x[5]&quot;), perl=TRUE) ## [1] 2 36.5.5 匹配数字 例： grep(&quot;n\\\\d[.]xls&quot;, c(&quot;n1.xls&quot;, &quot;na.xls&quot;), perl=TRUE) ## [1] 1 36.5.6 匹配开头和末尾 例: grep(&quot;^n\\\\d[.]xls$&quot;, c(&quot;n1.xls&quot;, &quot;na.xls&quot;, &quot;cn1.xls&quot;, &quot;n1.xlsx&quot;), perl=TRUE) ## [1] 1 grep(&quot;\\\\An\\\\d[.]xls\\\\Z&quot;, c(&quot;n1.xls&quot;, &quot;na.xls&quot;, &quot;cn1.xls&quot;, &quot;n1.xlsx&quot;), perl=TRUE) ## [1] 1 只匹配了第一个输入字符串。 36.5.7 匹配字母、数字、下划线 例： m &lt;- regexpr(&quot;s\\\\w[.]&quot;, c(&quot;file-s1.xls&quot;, &quot;s#.xls&quot;), perl=TRUE) regmatches(c(&quot;file-s1.xls&quot;, &quot;s#.xls&quot;), m) ## [1] &quot;s1.&quot; 可以看出，模式匹配了s1.而没有匹配s#.。 36.5.8 十六进制和八进制数 例如 gregexpr(&quot;\\\\x0A&quot;, &quot;abc\\nefg\\n&quot;)[[1]] ## [1] 4 8 ## attr(,&quot;match.length&quot;) ## [1] 1 1 ## attr(,&quot;index.type&quot;) ## [1] &quot;chars&quot; ## attr(,&quot;useBytes&quot;) ## [1] TRUE 匹配了两个换行符。 36.5.9 POSIX字符类 例如： grep(&quot;[[:alpha:]_.][[:alnum:]_.]&quot;, c(&quot;x1&quot;, &quot;_x&quot;, &quot;.x&quot;, &quot;.1&quot;)) ## [1] 1 2 3 4 36.5.10 加号重复匹配 例 s &lt;- c(&quot;sa1&quot;, &quot;dsa123&quot;) mres &lt;- regexpr(&quot;sa[[:digit:]]+&quot;, s, perl=TRUE) regmatches(s, mres) ## [1] &quot;sa1&quot; &quot;sa123&quot; 例如： p &lt;- &quot;^[[:alnum:]_]+@[[:alnum:]_]+[.][[:alnum:]_]+$&quot; x &lt;- &quot;abc123@efg.com&quot; m &lt;- regexpr(p, x, perl=TRUE) regmatches(x, m) ## [1] &quot;abc123@efg.com&quot; 匹配的电子邮件地址在@前面可以使用任意多个字母、数字、下划线， 在@后面由小数点分成两段， 每段可以使用任意多个字母、数字、下划线。 这里用了^和$表示全字符串匹配。 36.5.11 星号和问号重复匹配 ^https?://[[:alnum:]./]+$可以匹配http或https开始的网址。 如 s &lt;- c(&quot;http://www.163.net&quot;, &quot;https://123.456.&quot;) grep(&quot;^https?://[[:alnum:]_./]+$&quot;, s, perl=TRUE) ## [1] 1 2 (注意第二个字符串不是合法网址但是按这个正则表达式也能匹配) 36.5.12 计数重复 例： grep(&quot;[[:digit:]]{3}&quot;, c(&quot;1&quot;, &quot;12&quot;, &quot;123&quot;, &quot;1234&quot;)) ## [1] 3 4 模式匹配的是三位的数字。 日期匹配例： pat &lt;- paste( c(&quot;[[:digit:]]{1,2}[-/]&quot;, &quot;[[:digit:]]{1,2}[-/]&quot;, &quot;[[:digit:]]{2,4}&quot;), collapse=&quot;&quot;) grep(pat, c(&quot;2/4/1998&quot;, &quot;13/15/198&quot;)) ## [1] 1 2 36.5.13 贪婪匹配和懒惰匹配 例如： s &lt;- &quot;&lt;B&gt;1st&lt;/B&gt; other &lt;B&gt;2nd&lt;/B&gt;&quot; p1 &lt;- &quot;&lt;[Bb]&gt;.*&lt;/[Bb]&gt;&quot; m1 &lt;- regexpr(p1, s, perl=TRUE) regmatches(s, m1)[[1]] ## [1] &quot;&lt;B&gt;1st&lt;/B&gt; other &lt;B&gt;2nd&lt;/B&gt;&quot; 我们本来期望的是提取第一个“&lt;B&gt;……&lt;/B&gt;”组合， 不料提取了两个“&lt;B&gt;……&lt;/B&gt;”组合以及中间的部分。 比如，上例中模式修改后得到了期望的结果： s &lt;- &quot;&lt;B&gt;1st&lt;/B&gt; other &lt;B&gt;2nd&lt;/B&gt;&quot; p2 &lt;- &quot;&lt;[Bb]&gt;.*?&lt;/[Bb]&gt;&quot; m2 &lt;- regexpr(p2, s, perl=TRUE) regmatches(s, m2)[[1]] ## [1] &quot;&lt;B&gt;1st&lt;/B&gt;&quot; 36.5.14 单词边界 例： grep(&quot;\\\\bcat\\\\b&quot;, c(&quot;a cat meaos&quot;, &quot;the category&quot;)) ## [1] 1 36.5.15 句点全匹配与多行模式 句点通配符一般不能匹配换行，如 s &lt;- &quot;&lt;B&gt;1st\\n&lt;/B&gt;\\n&quot; grep(&quot;&lt;[Bb]&gt;.*?&lt;/[Bb]&gt;&quot;, s, perl=TRUE) ## integer(0) 跨行匹配失败。而在HTML的规范中换行是正常的。 一种办法是预先用gsub把所有换行符替换为空格。 但是这只能解决部分问题。 另一方法是在Perl正则表达式开头添加(?s)选项， 这个选项使得句点通配符可以匹配换行符。 如 s &lt;- &quot;&lt;B&gt;1st\\n&lt;/B&gt;\\n&quot; mres &lt;- regexpr(&quot;(?s)&lt;[Bb]&gt;.*?&lt;/[Bb]&gt;&quot;, s, perl=TRUE) regmatches(s, mres) ## [1] &quot;&lt;B&gt;1st\\n&lt;/B&gt;&quot; 多行模式例： s &lt;- &quot;&lt;B&gt;1st\\n&lt;/B&gt;\\n&quot; mres1 &lt;- gregexpr(&quot;^&lt;.+?&gt;&quot;, s, perl=TRUE) mres2 &lt;- gregexpr(&quot;(?m)^&lt;.+?&gt;&quot;, s, perl=TRUE) regmatches(s, mres1)[[1]] ## [1] &quot;&lt;B&gt;&quot; regmatches(s, mres2)[[1]] ## [1] &quot;&lt;B&gt;&quot; &quot;&lt;/B&gt;&quot; 字符串s包含两行内容，中间用\\n分隔。 mres1的匹配模式没有打开多行选项， 所以模式中的^只能匹配s中整个字符串开头。 mres2的匹配模式打开了多行选项， 所以模式中的^可以匹配s中每行的开头。 36.5.16 备择模式 例如，某个人的名字用James和Jim都可以， 表示为James|Jim, 如 s &lt;- c(&quot;James, Bond&quot;, &quot;Jim boy&quot;) pat &lt;- &quot;James|Jim&quot; mres &lt;- gregexpr(pat, s, perl=TRUE) regmatches(s, mres) ## [[1]] ## [1] &quot;James&quot; ## ## [[2]] ## [1] &quot;Jim&quot; 36.5.17 分组与捕获 例： 希望把“&lt;B&gt;……&lt;/B”两边的“&lt;B&gt;”和“&lt;/B&gt;”删除， 可以用如下的替换方法： x &lt;- &quot;&lt;B&gt;1st&lt;/B&gt; other &lt;B&gt;2nd&lt;/B&gt;&quot; pat &lt;- &quot;(?s)&lt;[Bb]&gt;(.+?)&lt;/[Bb]&gt;&quot; repl &lt;- &quot;\\\\1&quot; gsub(pat, repl, x, perl=TRUE) ## [1] &quot;1st other 2nd&quot; 替换模式中的\\1(写成R字符型常量时\\要写成\\\\)表示第一个圆括号匹配的内容， 但是表示选项的圆括号（(?s)）不算在内。 例：希望把带有前导零的数字的前导零删除，可以用如 x &lt;- c(&quot;123&quot;, &quot;0123&quot;, &quot;00123&quot;) pat &lt;- &quot;\\\\b0+([1-9][0-9]*)\\\\b&quot; repl &lt;- &quot;\\\\1&quot; gsub(pat, repl, x, perl=TRUE) ## [1] &quot;123&quot; &quot;123&quot; &quot;123&quot; 其中的\\b模式表示单词边界， 这可以排除在一个没有用空格或标点分隔的字符串内部拆分出数字的情况。 例：为了交换横纵坐标，可以用如下替换 s &lt;- &quot;1st: (5,3.6), 2nd: (2.5, 1.1)&quot; pat &lt;- paste0( &quot;[(]([[:digit:].]+),&quot;, &quot;[[:space:]]*([[:digit:].]+)[)]&quot;) repl &lt;- &quot;(\\\\2, \\\\1)&quot; gsub(pat, repl, s, perl=TRUE) ## [1] &quot;1st: (3.6, 5), 2nd: (1.1, 2.5)&quot; 例如，要匹配yyyy-mm-dd这样的日期， 并将其改写为mm/dd/yyyy， 就可以用这样的替换模式： pat &lt;- &quot;([0-9]{4})-([0-9]{1,2})-([0-9]{1,2})&quot; repl &lt;- &quot;\\\\2/\\\\3/\\\\1&quot; gsub(pat, repl, c(&quot;1998-05-31&quot;, &quot;2017-01-14&quot;)) ## [1] &quot;05/31/1998&quot; &quot;01/14/2017&quot; 分组除了可以做替换外， 还可以用来表示模式中的重复出现内容。 例如，([a-z]{3})\\1这样的模式可以匹配如abcabc, uxzuxz这样的三字母重复。如 grep(&quot;([a-z]{3})\\\\1&quot;, c(&quot;abcabc&quot;, &quot;aabbcc&quot;)) ## [1] 1 又例如，下面的程序找出了年（后两位）、月、日数字相同的日期： x &lt;- c(&quot;2008-08-08&quot;, &quot;2017-01-18&quot;) m &lt;- regexpr(&quot;\\\\d\\\\d(\\\\d\\\\d)-\\\\1-\\\\1&quot;, x) regmatches(x, m) ## [1] &quot;2008-08-08&quot; 下面是一个非捕获分组示例。 设需要把1921-2020之间的世纪号删去，可以用 pat &lt;- &quot;\\\\A(?:19|20)([0-9]{2})\\\\Z&quot; repl &lt;- &quot;\\\\1&quot; x &lt;- c(&quot;1978&quot;, &quot;2017&quot;, &quot;2035&quot;) gsub(pat, repl, x, perl=TRUE) ## [1] &quot;78&quot; &quot;17&quot; &quot;35&quot; 其中用了非捕获分组使得备择模式19|20优先匹配。 注意模式并没有能保证日期在1921-2020之间。更周密的程序可以写成： x &lt;- c(&quot;1978&quot;, &quot;2017&quot;, &quot;2035&quot;) p1 &lt;- &quot;\\\\A19(2[1-9]|[3-9][0-9])\\\\Z&quot; r1 &lt;- &quot;\\\\1&quot; p2 &lt;- &quot;\\\\A20([01][0-9]|20)\\\\Z&quot; x &lt;- gsub(p1, r1, x, perl=TRUE) x &lt;- gsub(p2, r1, x, perl=TRUE) x ## [1] &quot;78&quot; &quot;17&quot; &quot;2035&quot; 36.6 正则表达式应用例子 36.6.1 数据预处理 在原始数据中， 经常需要审核数据是否合法， 已经把一些常见错误输入自动更正。 这都可以用正则表达式实现。 36.6.1.1 除去字符串开头和结尾的空格 函数stringr::str_trim()和trimws()可以除去字符串开头与结尾的空格， 也可以仅除去开头或仅除去结尾的空格。 这个任务如果用正则表达式字符串替换函数来编写，可以写成： ### 把字符串向量x的元素去除首尾的空白。 strip &lt;- function(x){ x &lt;- str_replace_all(x, &quot;^[[:space:]]+&quot;, &quot;&quot;) x &lt;- str_replace_all(x, &quot;[[:space:]]+$&quot;, &quot;&quot;) x } 或者 ### 把字符串向量x的元素去除首尾的空白。 strip &lt;- function(x){ x &lt;- gsub(&quot;^[[:space:]]+&quot;, &quot;&quot;, x, perl=TRUE) x &lt;- gsub(&quot;[[:space:]]+$&quot;, &quot;&quot;, x, perl=TRUE) x } 这个版本可以除去包括空格在内的所有首尾空白字符。 36.6.1.2 除去字符串向量每个元素中所有空格 compress &lt;- function(x){ str_replace_all(x, &quot; &quot;, &quot;&quot;) } 或者 compress &lt;- function(x){ gsub(&quot; &quot;, &quot;&quot;, x, fixed=TRUE) } 这可以解决\"李明\"与\"李 明\"不相等这样的问题。 类似的程序也可以用来把中文的标点替换成英文的标点。 36.6.1.3 判断日期是否合法 设日期必须为yyyy-mm-dd格式， 年的数字可以是两位、三位、四位， 程序为: is_yyyymmdd &lt;- function(x){ pyear &lt;- &quot;([0-9]{2}|[1-9][0-9]{2}|[1-2][0-9]{3})&quot; pmon &lt;- &quot;([1-9]|0[1-9]|1[0-2])&quot; pday &lt;- &quot;([1-9]|0[1-9]|1[0-9]|2[0-9]|3[01])&quot; pat &lt;- paste(&quot;\\\\A&quot;, pyear, &quot;-&quot;, pmon, &quot;-&quot;, pday, &quot;\\\\Z&quot;, sep=&quot;&quot;) str_detect(x, pat) } 或 is.yyyymmdd &lt;- function(x){ pyear &lt;- &quot;([0-9]{2}|[1-9][0-9]{2}|[1-2][0-9]{3})&quot; pmon &lt;- &quot;([1-9]|0[1-9]|1[0-2])&quot; pday &lt;- &quot;([1-9]|0[1-9]|1[0-9]|2[0-9]|3[01])&quot; pat &lt;- paste(&quot;\\\\A&quot;, pyear, &quot;-&quot;, pmon, &quot;-&quot;, pday, &quot;\\\\Z&quot;, sep=&quot;&quot;) grepl(pat, x, perl=TRUE) } 这样的规则还没有排除诸如9月31号、2月30号这样的错误。 例: x &lt;- c(&quot;49-10-1&quot;, &quot;1949-10-01&quot;, &quot;532-3-15&quot;, &quot;2015-6-1&quot;, &quot;2017-02-30&quot;, &quot;2017-13-11&quot;, &quot;2017-1-32&quot;) is_yyyymmdd(x) ## [1] TRUE TRUE TRUE TRUE TRUE FALSE FALSE 注意错误的2月30号没有识别出来。 36.6.1.4 把字符型日期变成yyyy-mm-dd格式。 make_date &lt;- function(x){ x %&gt;% str_trim() %&gt;% str_replace_all(&quot;[[:space:]]+&quot;, &quot;-&quot;) %&gt;% str_replace_all(&quot;/&quot;, &quot;-&quot;) %&gt;% str_replace_all(&quot;[.]&quot;, &quot;-&quot;) %&gt;% str_replace_all(&quot;^([0-9]{2})(-[0-9]{1,2}-[0-9]{1,2})$&quot;, &quot;20\\\\1\\\\2&quot;) %&gt;% str_replace_all(&quot;^([0-9]{4})-([0-9])-([0-9]{1,2})$&quot;, &quot;\\\\1-0\\\\2-\\\\3&quot;) %&gt;% str_replace_all(&quot;^([0-9]{4}-[0-9]{2})-([0-9])$&quot;, &quot;\\\\1-0\\\\2&quot;) } 或者 make.date &lt;- function(x){ x &lt;- trimws(x) x &lt;- gsub(&quot;[[:space:]]+&quot;, &quot;-&quot;, x) x &lt;- gsub(&quot;/&quot;, &quot;-&quot;, x) x &lt;- gsub(&quot;[.]&quot;, &quot;-&quot;, x) x &lt;- gsub(&quot;^([0-9]{2})(-[0-9]{1,2}-[0-9]{1,2})$&quot;, &quot;20\\\\1\\\\2&quot;, x) x &lt;- gsub(&quot;^([0-9]{4})-([0-9])-([0-9]{1,2})$&quot;, &quot;\\\\1-0\\\\2-\\\\3&quot;, x) x &lt;- gsub(&quot;^([0-9]{4}-[0-9]{2})-([0-9])$&quot;, &quot;\\\\1-0\\\\2&quot;, x) x } 另一办法是用strsplit()拆分出三个部分， 转换为整数， 再转换回字符型。 测试: x &lt;- c(&quot;49/10/1&quot;, &quot;1949.10.01&quot;, &quot;532 3 15&quot;, &quot;2015/6.1&quot;, &quot;20170230&quot;, &quot;2017.13/11&quot;, &quot;2017 1 32&quot;) make_date(x) ## [1] &quot;2049-10-01&quot; &quot;1949-10-01&quot; &quot;532-3-15&quot; &quot;2015-06-01&quot; &quot;20170230&quot; ## [6] &quot;2017-13-11&quot; &quot;2017-01-32&quot; 目前的函数还不能处理没有分隔符的情况， 也不能验证日期的合法性。 36.6.1.5 合并段落为一行 在某些纯文本格式中， 各段之间用空行分隔， 没有用空行分隔的各行看成同一段。 如下的函数把其中的不表示分段的换行删去从而合并这些段落。 函数以一个文件名作为输入， 合并段落后存回原文件。 注意， 这样修改文件的函数在调试时， 应该注意先备份文件， 等程序没有任何错误以后才可以忽略备份。 combine_paragraph &lt;- function(fname){ lines &lt;- readLines(fname) s &lt;- str_flattern(lines) s &lt;- s %&gt;% str_replace_all(&quot;^[[:space:]]+\\n&quot;, &quot;\\n&quot;) %&gt;% str_replace_all(&quot;([^\\n]+)\\n&quot;, &quot;\\\\1 &quot;) %&gt;% str_replace_all(&quot;([^\\n]+)\\n&quot;, &quot;\\\\1\\n\\n&quot;) writeLines(str_split(s, &quot;\\n&quot;)[[1]], con=fname) } 函数首先把仅有空格的行中的空格删除， 将有内容的行的行尾换行符替换成一个空格， 再把剩余的有内容的行的行尾换行符多加一个换行符。 上面的程序中特意用了基本R的readLines()函数而不是readr包的read_lines()函数, 因为readLines()使用操作系统的默认中文编码， 而read_lines()默认使用UTF-8编码， 需要用选项locale=locale(encoding=\"GB18030\")才能在中文MS Windows中正确读取中文文件。 下面的版本不使用stringr： combine.paragraph &lt;- function(fname){ lines &lt;- readLines(fname) s &lt;- paste(lines, collapse=&quot;\\n&quot;) s &lt;- gsub(&quot;^[[:space:]]+\\n&quot;, &quot;\\n&quot;, s, perl=TRUE) s &lt;- gsub(&quot;([^\\n]+)\\n&quot;, &quot;\\\\1 &quot;, s, perl=TRUE) s &lt;- gsub(&quot;([^\\n]+)\\n&quot;, &quot;\\\\1\\n\\n&quot;, s, perl=TRUE) writeLines(strsplit(s, &quot;\\n&quot;, fixed=TRUE)[[1]], con=fname) } 36.6.2 不规则Excel文件处理 作为字符型数据处理示例， 考察如下的一个Excel表格数据。 假设一个中学把所有课外小组的信息汇总到了Excel表的一个工作簿中。 每个课外小组占一块区域，各小组上下排列， 但不能作为一个数据框读取。 下图为这样的文件的一个简化样例： 不规则Excel文件样例图形 实际数据可能有很多个小组， 而且数据是随时更新的， 所以复制粘贴另存的方法不太可行， 需要用一个通用的程序处理。 Excel文件(.xls后缀或.xlsx后缀)不是文本型数据。 在Excel中，用“另存为”把文件保存为CSV格式， 内容如下： XXX中学兴趣组情况总表,,, ,,, 组名：,物理,指导教师：,刘一心 姓名,性别,班级, 伊家宝,男,初二(3), 闻月,女,初二(5), 刘阳,男,初三(1), 宋佰霖,男,初三(2), 洪晓梅,女,初三(1), ,,, 组名：,生物,指导教师：,赵晓辉 姓名,性别,班级, 刘佳琦,女,初二(1), 李雨婷,女,初二(5), 张宠,男,初三(4), 生成测试用的数据文件： demo.multitab.data &lt;- function(){ s &lt;- &quot; XXX中学兴趣组情况总表,,, ,,, 组名：,物理,指导教师：,刘一心 姓名,性别,班级, 伊家宝,男,初二(3), 闻月,女,初二(5), 刘阳,男,初三(1), 宋佰霖,男,初三(2), 洪晓梅,女,初三(1), ,,, 组名：,生物,指导教师：,赵晓辉 姓名,性别,班级, 刘佳琦,女,初二(1), 李雨婷,女,初二(5), 张宠,男,初三(4), &quot; writeLines(s, &quot;multitab.csv&quot;) } demo.multitab.data() 读入测试用的数据，转换为一整个数据框: demo_multitab &lt;- function(){ ## 读入所有行 lines &lt;- readLines(&quot;multitab.csv&quot;) ## 去掉首尾空格 lines &lt;- str_trim(lines) ## 删去所有空行和只有逗号的行 empty &lt;- str_detect(lines, &quot;^[[:space:],]*$&quot;) if(length(empty)&gt;0){ lines &lt;- lines[!empty] } ## 找到所有包含 “组名：”的行对应的行号 heads &lt;- str_which(lines, &quot;组名：&quot;) ## 定位每个表的开始行和结束行(不包括组名和表头所在的行) start &lt;- heads + 2 end &lt;- c(heads[-1]-1, length(lines)) ngroups &lt;- length(heads) ## 先把数据读入一个列表。 for(ii in seq(ngroups)){ ## 组名和指导教师所在行： line &lt;- lines[heads[ii]] v &lt;- str_split(line, &quot;,&quot;)[[1]] ## 组名：v[2] 指导教师: v[4] ## 将表格内容各行合并成一个用换行符分隔的长字符串， ## 然后变成可读取的文件 s &lt;- str_flatten(lines[start[ii]:end[ii]], collapse=&quot;\\n&quot;) con &lt;- textConnection(s, &quot;rt&quot;) da1 &lt;- read.csv( con, header=FALSE, colClasses=c(&quot;character&quot;, &quot;character&quot;, &quot;character&quot;, &quot;NULL&quot;)) close(con) names(da1) &lt;- c(&quot;姓名&quot;, &quot;性别&quot;, &quot;班级&quot;) da1 &lt;- cbind(&quot;组名&quot;=v[2], &quot;指导教师&quot;=v[4], da1) if(ii==1) { da &lt;- da1 } else { da &lt;- rbind(da, da1) } } da } da &lt;- demo_multitab() knitr::kable(da) 组名 指导教师 姓名 性别 班级 物理 刘一心 伊家宝 男 初二(3) 物理 刘一心 闻月 女 初二(5) 物理 刘一心 刘阳 男 初三(1) 物理 刘一心 宋佰霖 男 初三(2) 物理 刘一心 洪晓梅 女 初三(1) 生物 赵晓辉 刘佳琦 女 初二(1) 生物 赵晓辉 李雨婷 女 初二(5) 生物 赵晓辉 张宠 男 初三(4) 不使用stringr的版本： demo.multitab &lt;- function(){ ## 读入所有行 lines &lt;- readLines(&quot;multitab.csv&quot;) ## 去掉首尾空格 lines &lt;- trimws(lines) ## 删去所有空行和只有逗号的行 ## (1) 不用正则表达式做法 #empty &lt;- which(lines == &quot;&quot; | substring(lines, 1, 3)==&quot;,,,&quot;) ## (2) 用正则表达式做法： empty &lt;- grep(&quot;^[[:space:],]*$&quot;, lines) if(length(empty)&gt;0){ lines &lt;- lines[-empty] } ## 找到所有包含 “组名：”的行对应的行号 heads &lt;- grep(&quot;组名：&quot;, lines, fixed=TRUE) ## 定位每个表的开始行和结束行(不包括组名和表头所在的行) start &lt;- heads + 2 end &lt;- c(heads[-1]-1, length(lines)) ngroups &lt;- length(heads) ## 先把数据读入一个列表。 for(ii in seq(ngroups)){ ## 组名和指导教师所在行： line &lt;- lines[heads[ii]] v &lt;- strsplit(line, &quot;,&quot;)[[1]] ## 组名：v[2] 指导教师: v[4] ## 将表格内容各行合并成一个用换行符分隔的长字符串， ## 然后变成可读取的文件 s &lt;- paste(lines[start[ii]:end[ii]], collapse=&quot;\\n&quot;) con &lt;- textConnection(s, &quot;rt&quot;) da1 &lt;- read.csv( con, header=FALSE, colClasses=c(&quot;character&quot;, &quot;character&quot;, &quot;character&quot;, &quot;NULL&quot;)) close(con) names(da1) &lt;- c(&quot;姓名&quot;, &quot;性别&quot;, &quot;班级&quot;) da1 &lt;- cbind(&quot;组名&quot;=v[2], &quot;指导教师&quot;=v[4], da1) if(ii==1) { da &lt;- da1 } else { da &lt;- rbind(da, da1) } } da } da &lt;- demo.multitab() da 在程序中， 用readLines函数读取文本文件各行到一个字符型向量。 用grep可以找到每个小组开头的行（有“组名：”的行）。 然后可以找出每个小组学生名单的开始行号和结束行号。 各小组循环处理，读入后每个小组并入结果数据框中。 用strsplit函数拆分用逗号分开的数据项。 用textConnection函数可以把一个字符串当作文件读取， 这样read.csv函数可以从一个字符串读入数据。 36.6.3 字频统计 正则表达式中的字符类[:alpha:]指的是当前系统中的字母， 所以在中文环境中的中文字也是字母， 但中文标点不算。 下面是《红楼梦》中“秋窗风雨夕”的文本： 秋花惨淡秋草黄，耿耿秋灯秋夜长。 已觉秋窗秋不尽，那堪风雨助凄凉！ 助秋风雨来何速！惊破秋窗秋梦绿。 抱得秋情不忍眠，自向秋屏移泪烛。 泪烛摇摇爇短檠，牵愁照恨动离情。 谁家秋院无风入？何处秋窗无雨声？ 罗衾不奈秋风力，残漏声催秋雨急。 连宵脉脉复飕飕，灯前似伴离人泣。 寒烟小院转萧条，疏竹虚窗时滴沥。 不知风雨几时休，已教泪洒窗纱湿。 希望统计每个字的出现次数， 并显示频数前十的字。 设变量poem_autumnwindow中包含了上述诗词的文本。 首先用str_extract_all()提取每个中文字，组成一个字符型向量： words_vec &lt;- str_extract_all(poem_autumnwindow, &quot;[[:alpha:]]&quot;)[[1]] head(words_vec) ## [1] &quot;秋&quot; &quot;花&quot; &quot;惨&quot; &quot;淡&quot; &quot;秋&quot; &quot;草&quot; 用table()函数计算频数，并按频数排序，输出前10结果： words_freq &lt;- sort(table(words_vec), decreasing=TRUE) knitr::kable(head(words_freq, 10)) words_vec Freq 秋 15 窗 5 风 5 雨 5 不 4 泪 3 灯 2 耿 2 何 2 离 2 36.6.4 数字验证 36.6.4.1 整数 字符串完全为十进制正整数的模式，写成R字符型常量： &quot;\\\\A[0-9]+\\\\Z&quot; 这个模式也允许正整数以0开始，如果不允许以零开始，可以写成 &quot;\\\\A[1-9][0-9]*\\\\Z&quot; 对于一般的整数，字符串完全为十进制整数，但是允许前后有空格， 正负号与数字之间允许有空格，模式可以写成： &quot;\\\\A[ ]*[+-]?[ ]*[1-9][0-9]*\\\\Z&quot; 36.6.4.2 十六进制数字 字符串仅有十六进制数字，模式写成R字符型常量为 &quot;\\\\A[0-9A-Fa-f]+\\\\Z&quot; 在文中匹配带有0x前缀的十六进制数字，模式为 &quot;\\\\b0x[0-9A-Fa-f]+\\\\b&quot; 36.6.4.3 二进制数字 为了在文中匹配一个以B或b结尾的二进制非负整数，可以用 &quot;\\\\b[01]+[Bb]\\\\b&quot; 36.6.4.4 有范围的整数 1-12: &quot;\\\\b1[012]|[1-9]\\\\b&quot; 1-24: &quot;\\\\b2[0-4]|1[0-9]|[1-9]\\\\b&quot; 1-31: &quot;\\\\b3[01]|[12][0-9]|[1-9]\\\\b&quot; 1900-2099: &quot;\\\\b(?:19|20)[0-9]{2}\\\\b&quot; 这里的分组仅用于在19和20之间选择， 不需要捕获，所以用了(?:的非捕获分组格式。 36.6.4.5 判断字符型向量每个元素是否数值 如下的R函数用了多种数字的正则表达式来判断字符型向量每个元素是否合法数值。 all_numbers &lt;- function(x){ x &lt;- x %&gt;% str_replace_all(&quot;\\\\A[ ]+&quot;, &quot;&quot;) %&gt;% str_replace_all(&quot;[ ]+\\\\Z&quot;, &quot;&quot;) pint &lt;- &quot;\\\\A[+-]?[0-9]+\\\\Z&quot; # 整数, 允许有前导零 ## 浮点数1, 整数部分必须，小数部分可选，指数部分可选 pf1 &lt;- &quot;\\\\A[+-]?[0-9]+([.][0-9]*)?([Ee][+-]?[0-9]+)?\\\\Z&quot; ## 浮点数2, 整数部分省略，小数部分必须，指数部分可选 pf2 &lt;- &quot;\\\\A[+-]?[.][0-9]+([Ee][+-]?[0-9]+)?\\\\Z&quot; pat &lt;- str_c(pint, pf1, pf2, sep=&quot;|&quot;) str_detect(x, pat) } 不使用stringr的版本： all.numbers &lt;- function(x){ x &lt;- gsub(&quot;\\\\A[ ]+&quot;, &quot;&quot;, x, perl=TRUE) x &lt;- gsub(&quot;[ ]+\\\\Z&quot;, &quot;&quot;, x, perl=TRUE) pint &lt;- &quot;\\\\A[+-]?[0-9]+\\\\Z&quot; # 整数, 允许有前导零 ## 浮点数1, 整数部分必须，小数部分可选，指数部分可选 pf1 &lt;- &quot;\\\\A[+-]?[0-9]+([.][0-9]*)?([Ee][+-]?[0-9]+)?\\\\Z&quot; ## 浮点数2, 整数部分省略，小数部分必须，指数部分可选 pf2 &lt;- &quot;\\\\A[+-]?[.][0-9]+([Ee][+-]?[0-9]+)?\\\\Z&quot; pat &lt;- paste(pint, pf1, pf2, sep=&quot;|&quot;) grepl(pat, x, perl=TRUE) } 测试： all_numbers(c(&quot;1&quot;, &quot;12&quot;, &quot;-12&quot;, &quot;12.&quot;, &quot;-12.&quot;, &quot;123.45&quot;, &quot;-123.45&quot;, &quot;.45&quot;, &quot;-.45&quot;, &quot;1E3&quot;, &quot;-12E-10&quot;, &quot;1.1E3&quot;, &quot;-1.1E-3&quot;, &quot;1.0.0&quot;, &quot;1.0-0.5&quot;)) ## [1] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE ## [13] TRUE FALSE FALSE 36.6.5 文件名中的数字提取 设有如下的一些文件名： s &lt;- c(&quot;10-0.16-1700.0-42.csv&quot;, &quot;12-0.22-1799.1.csv&quot;) 希望提取出每个文件名中用减号分隔开的数字， 如第一个文件名中的10, 0.16, 1700.0, 42, 第二个文件名中的12, 0.22, 1799.1， 数字的个数不需要相同。 先定义数字的模式， 注意长备择模式中长的模式要写在前面， 否则会被短的模式优先匹配： pat &lt;- &quot;[0-9]+[.][0-9]+|[0-9]+&quot; 用stringr::str_match_all()提取其中的匹配数字： s1 &lt;- str_match_all(s, pat); s1 ## [[1]] ## [,1] ## [1,] &quot;10&quot; ## [2,] &quot;0.16&quot; ## [3,] &quot;1700.0&quot; ## [4,] &quot;42&quot; ## ## [[2]] ## [,1] ## [1,] &quot;12&quot; ## [2,] &quot;0.22&quot; ## [3,] &quot;1799.1&quot; 每个列表元素是一个矩阵， 其中第一列的各行是对模式的多次匹配， 取出这些匹配为一个字符型向量： s2 &lt;- Map(function(x) x[,1], s1); s2 ## [[1]] ## [1] &quot;10&quot; &quot;0.16&quot; &quot;1700.0&quot; &quot;42&quot; ## ## [[2]] ## [1] &quot;12&quot; &quot;0.22&quot; &quot;1799.1&quot; 如果需要，也可以将拆分出的字符型的数字结果转换成数值型： s3 &lt;- Map(as.numeric, s2); s3 ## [[1]] ## [1] 10.00 0.16 1700.00 42.00 ## ## [[2]] ## [1] 12.00 0.22 1799.10 这个问题也可以用strsplit()或者stringr::str_split()解决。如： s &lt;- c(&quot;10-0.16-1700.0-42.csv&quot;, &quot;12-0.22-1799.1.csv&quot;) s1 &lt;- substring(s, 1, nchar(s)-4) # 去掉&quot;.csv&quot; print(s1) ## [1] &quot;10-0.16-1700.0-42&quot; &quot;12-0.22-1799.1&quot; s2 &lt;- strsplit(s1, &quot;[-]&quot;) # 按减号分成几个部分，结果为列表 print(s2) ## [[1]] ## [1] &quot;10&quot; &quot;0.16&quot; &quot;1700.0&quot; &quot;42&quot; ## ## [[2]] ## [1] &quot;12&quot; &quot;0.22&quot; &quot;1799.1&quot; s3 &lt;- Map(as.numeric, s2) # 转换为数值型 print(s3) ## [[1]] ## [1] 10.00 0.16 1700.00 42.00 ## ## [[2]] ## [1] 12.00 0.22 1799.10 36.7 网站数据获取 很多网站定期频繁发布数据， 所以传统的手工复制粘贴整理是不现实的。 有些网站提供了下载功能， 有些则仅能显示。 这些数据网页往往有固定模式， 如果网页不是依赖JavaScript来展示的话， 可以读取网页然后通过字符型数据处理方法获得数据。 R扩展包rvest可以对网页按照其中的网页构成节点路径(xpath)提取数据， 转换为R数据框。 以上海证券交易所的上证综指成份股列表为例。 使用Google Chrome浏览器打开如下的页面： http://www.sse.com.cn/market/sseindex/indexlist/s/i000001/const_list.shtml 将显示上证综指成份股的名称与编码的列表页面。 利用Chrome浏览器的功能先获取表格所在页面部分的xpath， 办法是鼠标右键单击表格开头部分， 选择“检查”（inspect）， 这时会在浏览器右边打开一个html源代码窗口， 当前加亮显示部分是表格开头内容的源代码， 将鼠标单击到上层的&lt;table class=\"tablestyle\"&gt;处， 右键单击选择“Copy-Copy XPath”， 得到如下的xpath地址：'//*[@id=\"content_ab\"]/div[1]/table'。 然后， 用rvest的html_nodes()函数提取页面中用xpath指定的成分， 用html_table()函数将HTML表格转换为数据框， 结果是一个数据框列表， 因为仅有一个， 所以取列表第一项即可。 程序如下： library(rvest) ## 网页地址 urlb &lt;- &quot;http://www.sse.com.cn/market/sseindex/indexlist/s/i000001/const_list.shtml&quot; ## 网页中数据表的xpath xpath &lt;- &#39;//*[@id=&quot;content_ab&quot;]/div[1]/table&#39; ## 读入网页并提取其中的表格节点 nodes &lt;- html_nodes( read_html(urlb), xpath=xpath) ## 从表格节点转换为表格列表 tables &lt;- html_table(nodes) restab &lt;- tables[[1]] head(restab) ## X1 X2 ## 1 浦发银行\\r\\n (600000) 白云机场\\r\\n (600004) ## 2 中国国贸\\r\\n (600007) 首创股份\\r\\n (600008) ## X3 ## 1 东风汽车\\r\\n (600006) ## 2 上海机场\\r\\n (600009) 可见每一行有三个股票， 我们将数据中的\\r\\n和空格去掉， 然后转换成名称与代码分开的格式： library(tidyverse) pat1 &lt;- &quot;^(.*?)\\\\((.*?)\\\\)&quot; tab1 &lt;- restab %&gt;% ## 将三列合并为一列，结果为字符型向量 reduce(c) %&gt;% ## 去掉空格和换行符，结果为字符型向量 stringr::str_replace_all(&quot;[[:space:]]&quot;, &quot;&quot;) %&gt;% ## 提取公司简称和代码到一个矩阵行，结果为字符型矩阵 stringr::str_match(pat1) tab &lt;- tibble( name = tab1[,2], code = tab1[,3]) head(tab) ## # A tibble: 6 x 2 ## name code ## &lt;chr&gt; &lt;chr&gt; ## 1 浦发银行 600000 ## 2 中国国贸 600007 ## 3 包钢股份 600010 ## 4 华夏银行 600015 ## 5 上港集团 600018 ## 6 上海电力 600021 str(tab) ## Classes ‘tbl_df’, ‘tbl’ and &#39;data.frame&#39;: 1551 obs. of 2 variables: ## $ name: chr &quot;浦发银行&quot; &quot;中国国贸&quot; &quot;包钢股份&quot; &quot;华夏银行&quot; ... ## $ code: chr &quot;600000&quot; &quot;600007&quot; &quot;600010&quot; &quot;600015&quot; ... 对于不符合规则的网页， 可以用download.file()下载网页文件， 用str_replace_all()或者gsub()去掉不需要的成分。 用str_which()或者grep查找关键行。 有些网页是依靠JavaScript来显示数据的， 比如新浪财经的环球股指汇总网页： http://finance.sina.com.cn/money/globalindex/ 这样的网页很难用程序提取数据。 36.8 中文分词与词频 为了对中文文章进行分析， 需要将文章内容拆分为一个个单词。 R扩展包jiebaR可以进行中文分词。 用w &lt;- worker()创建一个分词器， 用segment(txt, w)对字符串txt中的中文内容进行分词， 得到字符型向量，每个元素是一个词。 也可以调用segment(fname, w)， 其中fname是输入文本文件名， 可以自动侦测其中的中文编码， 分词结果会自动保存为文件开头和文件扩展名与fname相同的一个文件， 词之间以空格分隔。 分词后， R可以很容易地进行词频统计， 如table()函数。 例如， 对金庸的《侠客行》分词： library(jiebaR) ## 载入需要的程辑包：jiebaRD wk &lt;- worker() txt &lt;- readr::read_file(&quot;xkx.txt&quot;, locale=locale(encoding=&quot;GB18030&quot;)) words &lt;- segment(txt, wk) tab &lt;- table(words) tab &lt;- sort(tab, decreasing = TRUE) ## 去掉单个字的词语 tab2 &lt;- tab[stringr::str_length(names(tab)) &gt; 1] knitr::kable(as.data.frame(head(tab2, 20))) words Freq 石破天 1800 什么 697 说道 602 自己 570 雪山 451 白万剑 443 丁当 443 一个 421 帮主 387 武功 381 石清 372 丁不四 345 谢烟客 340 一声 321 不是 319 二人 319 不知 308 咱们 304 史婆婆 291 夫妇 284 词频可以用“词云”数据可视化方式表现。 在词云图形中， 词频大的词显示为较大的字体。 R扩展包wordcloud2可以输入词频统计表， 输出图形格式的词云显示， 以HTML5格式显示。 函数wordcloud2()可以输入table()的结果， 或者有词和词频构成的两列的数据框。 library(wordcloud2) wordcloud2(data = head(tab2, 20)) 注意，这个库支持图形在HTML结果中显示， 且具有一定交互性， 但不直接支持LaTeX转换的PDF输出， 所以需要进行设置。 可以在Rmd源文件开头运行命令： is_html &lt;- knitr::opts_knit$get(&quot;rmarkdown.pandoc.to&quot;) == &quot;html&quot; 这可以定义一个变量is_html， 仅在输出格式为HTML时才为TRUE， 然后在包含特殊HTML显示的代码段选项中， 加选项eval = is_html。 "],["rcpp.html", "37 Rcpp介绍 37.1 Rcpp的用途 37.2 Rcpp入门样例", " 37 Rcpp介绍 为了提高R程序的运行效率， 可以尽量使用向量化编程， 减少循环， 尽量使用内建函数。 对于效率的瓶颈， 尤其是设计迭代算法时， 可以采用编译代码， 而Rcpp扩展包可以很容易地将C++代码连接到R程序中， 并且支持在C++中使用类似于R的数据类型。 没有学过C++语言的读者， 如果需要编写比较独立的不太依赖于R的已有功能的算法， 可以考虑学习使用Julia语言编写。 Julia语言是最近几年才发明的一种比R更现代、理念更先进的程序语言， 其运行效率一般比R高得多， 经常接近编译代码的效率。 Rcpp可以很容易地把C++代码与R程序连接在一起， 可以从R中直接调用C++代码而不需要用户关心那些繁琐的编译、链接、接口问题。 可以在R数据类型和C++数据类型之间容易地转换。 因为涉及到编译， 所以Rcpp比一般的扩展包有更多的安装要求： 除了要安装Rcpp包之外， MS Windows用户还需要安装RTools包， 这是用于C, C++, Fortran程序编译链接的开发工具包， 是自由软件。 用户的应用程序路径(PATH)中必须有RTools包可执行程序的路径 (安装RTools可以自动设置)。 如果Rcpp不能找到编译器， 可以把编译器安装到Rcpp默认的位置。 Mac系统的用户可以从应用商店安装Xcode软件， Linux操作系统可以在操作系统命令行用如下命令安装编译软件： sudo apt-get install r-base-dev 在MS Windows系统中， 从CRAN网站下载RTools工具包， 并将其安装到默认位置C:\\RTools中， 否则RStudio中使用Rcpp可能会出错。 注意， RStudio自己的自动安装RTools的功能可能有问题， 安装后不能正常编译含有Rcpp的Rmd文件。 按照RTools 4.0的要求， 还要在自己的“我的文档”文件夹中生成名为.Renviron的如下文本文件： PATH=&quot;${RTOOLS40_HOME}\\usr\\bin;${PATH}&quot; Rcpp支持把C++代码写在R源程序文件内， 执行时自动编译连接调用； 也支持把C++代码保存在单独的源文件中， 执行R程序时自动编译连接调用； 对较复杂的问题， 应制作R扩展包， 利用构建R扩展包的方法实现C++代码的编译连接， 这时接口部分也可以借助Rcpp属性功能或模块功能完成。 37.1 Rcpp的用途 把已经用R代码完成的程序中运行速度瓶颈部分改写成C++代码， 提高运行效率。 对于C++或C程序源代码或二进制代码提供的函数库， 可以用Rcpp编写C++界面程序进行R与C++程序的输入、输出的传送， 并在C++界面程序中调用外来的函数库。 注意，用Rcpp编写C++程序， 不利于把程序脱离R运行或被其他的C++程序调用。 当然，可以只把Rcpp作为界面， 主要的算法引擎完全不用Rpp的数据类型。 RInside扩展包支持把R嵌入到C++主程序中。 37.2 Rcpp入门样例 37.2.1 用cppFunction()转换简单的C++函数—Fibnacci例子 考虑用C++程序计算Fibonacci数的问题。 Fibonacci数满足\\(f_0=0, f_1=1, f_t=f_{t-1}+ f_{t-2}\\)。 可以使用如下R代码，其中有一部分C++代码， 用cppFunction转换成了R可以调用的同名R函数。 library(Rcpp) cppFunction(code=&#39; int fibonacci(const int x){ if(x &lt; 2) return x; if(x &gt; 40) return -1; // 太大的x值会占用过多计算资源 return ( fibonacci(x-1) + fibonacci(x-2) ); } &#39;) print(fibonacci(5)) ## [1] 5 编译、链接、导入是在后台由Rcpp控制自动进行的， 不需要用户去设置编译环境， 也不需要用户执行编译、链接、导入R的工作。 在没有修改C++程序时, 同一R会话期间重新运行不必重新编译。 上面的Fibonacci函数仅接受标量数值作为输入， 不允许向量输入。 这个例子也说明RCpp变异的C++函数允许输入标量(int, double, bool)， 输出标量(int, double, bool)。 从算法角度评价， 这个计算Fibonacci序列的算法是极其低效的， 其算法规模是\\(O(2^n)\\)， \\(n\\)是自变量值。 37.2.2 用sourceCpp()转换C++程序—正负交替迭代例子 设\\(x_t, t=1,2,\\dots,n\\)保存在R向量x中， 令 \\[\\begin{aligned} y_1 =&amp; x_1 \\\\ y_t =&amp; (-1)^t y_{t-1} + x_t, \\ t=2,\\dots,n \\end{aligned}\\] 希望用C++函数对输入序列x计算输出y，并用R调用这样的函数。 下面的程序用R函数sourceCpp() 把保存在R字符串中的C++代码编译并转换为同名的R函数。 sourceCpp(code=&#39; #include &lt;Rcpp.h&gt; using namespace Rcpp; //[[Rcpp::export]] NumericVector iters(NumericVector x){ int n = x.size(); NumericVector y(n); y[0] = x[0]; double sign=-1; for(int t=1; t&lt;n; t++){ sign *= -1; y[t] = sign*y[t-1] + x[t]; } return y; } &#39;) print(iters(1:5)) ## [1] 1 3 0 4 1 这个例子说明C++程序可以直接写在R程序文件内 (保存为R多行字符串)， 用sourceCpp()函数编译。 Rcpp包为C++提供了一个NumericVector数据类型， 用来存储数值型向量。 用成员函数size()访问其大小， 用方括号下标访问其元素。 C程序中定义的函数可以返回NumericVector数据类型， 将自动转换为R的数值型向量。 特殊的注释//[[Rcpp::export]] 用来指定哪些C++函数是要转换为R函数的。 这叫做Rcpp属性（attributes）功能。 37.2.3 用sourceCpp()转换C++源文件中的程序—正负交替迭代例子 直接把C++代码写在R源程序内部的好处是不用管理多个源文件， 缺点是当C++代码较长时， 不能利用专用C++编辑环境和调试环境, 出错时显示的错误行号不好定位， 而且把代码保存在R字符串内， C++代码中用到字符时需要特殊语法。 所以，稍复杂的C++代码应该放在单独的C++源文件内。 假设上面的iters函数的C++代码单独存入了一个iters.cpp源文件中，内容如下： #include &lt;Rcpp.h&gt; using namespace Rcpp; //[[Rcpp::export]] NumericVector iters(NumericVector x){ int n = x.size(); NumericVector y(n); y[0] = x[0]; double sign=-1; for(int t=1; t&lt;n; t++){ sign *= -1; y[t] = sign*y[t-1] + x[t]; } return y; } 用如下的sourceCpp()函数把C++源文件中代码编译并转换为R可访问的同名函数， 测试调用: sourceCpp(file=&#39;iters.cpp&#39;) print(iters(1:5)) ## [1] 1 3 0 4 1 37.2.4 用sourceCpp()转换C++源程序文件—卷积例子 考虑向量\\(\\boldsymbol x=(x_0, x_1, \\dots, x_{n-1})\\), \\(\\boldsymbol y=(y_0, y_1, \\dots, y_{m-1})\\), 定义\\(\\boldsymbol x\\)与\\(\\boldsymbol y\\) 的离散卷积\\(\\boldsymbol z=(z_0, z_1, \\dots, z_{n+m-2})\\)为 \\[\\begin{aligned} z_k = \\sum_{(i,j):\\, i+j=k} x_i y_j = \\sum_{i=\\max(0, k-m+1)}^{\\min(k,n)} x_i y_{k-i}. \\end{aligned}\\] 假设如下的C++程序保存到了源文件conv.cpp中。 #include &lt;Rcpp.h&gt; using namespace Rcpp; //[[Rcpp::export]] NumericVector convolveCpp( NumericVector a, NumericVector b){ int na = a.size(), nb = b.size(); int nab = na + nb - 1; NumericVector xab(nab); for(int i=0; i &lt; na; i++) for(int j=0; j &lt; nb; j++) xab[i+j] += a[i] * b[j]; return xab; } 如下的代码用sourceCpp()函数把上面的C++源文件conv.cpp 自动编译并转换为同名的R函数， 进行测试: sourceCpp(file=&#39;conv.cpp&#39;) print(convolveCpp(1:5, 1:3)) ## [1] 1 4 10 16 22 22 15 37.2.5 在Rmd文件中使用C++源程序文件 在Rmd文件中， 可以使用特殊的Rcpp代码块， 其中包含C++源代码， 可以直接起到对其调用sourceCpp()的作用。 但是，目前在MS Windows系统下仍有错误， 需要将RTools安装在默认路径， 即C:\\RTools\\bin与C:\\RTools\\mingw_64\\bin中， 并可能需要将这两个路径人为地添加到系统的PATH变量中， 办法是“Windows程序–Windows系统–控制面板–系统和安全–系统–高级系统设置–高级–环境变量–系统变量”， 其中的PATH变量是用分号分开的可执行程序搜索路径， 将其中添加RTools包的C:\\RTools\\bin与C:\\RTools\\mingw_64\\bin。 设置好以后， 在Rmd文件中输入如下的代码块： ```{Rcpp} #include &lt;Rcpp.h&gt; using namespace Rcpp; //[[Rcpp::export]] NumericVector convolveCpp( NumericVector a, NumericVector b){ int na = a.size(), nb = b.size(); int nab = na + nb - 1; NumericVector xab(nab); for(int i=0; i &lt; na; i++) for(int j=0; j &lt; nb; j++) xab[i+j] += a[i] * b[j]; return xab; } ``` 可以使得C++函数convolveCpp()被编译并转换成R可以调用的同名函数， 调用如： convolveCpp(1:5, 1:3) ## [1] 1 4 10 16 22 22 15 Rcpp代码块也可以加cache=TRUE选项， 使得C++程序在没有修改时不必每次重新编译。 "],["rcpp-typeconv.html", "38 R与C++的类型转换 38.1 用wrap()把C++变量返回到R中 38.2 用as()函数把R变量转换为C++类型 38.3 as()和wrap()的隐含调用", " 38 R与C++的类型转换 R程序与由Rcpp支持的C++程序之间需要传递数据， 就需要将R的数据类型经过转换后传递给C++函数， 将C++函数的结果经过转换后传递给R。 38.1 用wrap()把C++变量返回到R中 在R API中用.Call()函数调用C程序库函数时， R对象的数据类型一般是SEXP。 Rcpp提供了模板化的wrap() 函数把C++的函数返回值转换成R的SEXP数据类型。 此函数的声明为 template &lt;typename T&gt; SEXP wrap(const T&amp; object); wrap()能转换的类型包括： 把int, double, bool等基本类型转换为R的原子向量类型 （所有元素数据类型相同的向量）; 把std::string转换为R的字符型向量; 把STL容器如std::vector&lt;T&gt;或std::map&lt;T&gt; 转换成基本类型为T的向量，条件是T能够转换； 把STL的映射std::map&lt;std::string, T&gt; 转换为基本类型为T的有名向量，条件是T能够转换； 可以转换定义了operator SEXP()的C++类的对象； 可以转换专门化过wrap模板的C++对象。 是否可用wrap()转换是在编译时确定的。 38.2 用as()函数把R变量转换为C++类型 Rcpp提供了模板化的as()用来把SEXP类型转换成适当的C++类型。 as()函数的声明为: template &lt;typename T&gt; T as(SEXP x); as()可以把R对象转换为基础的类型如 int, double, bool, std::string等， 可以转换到元素为基础类型的STL向量如std::vector等。 如果C++类定义了以SEXP为输入的构造函数也可以利用as()来转换。 as()可以针对用户自定义类作专门化。 38.3 as()和wrap()的隐含调用 当C++中赋值运算的右侧表达式是一个R对象或R对象的部分内容时， 可以隐含地调用as()将其转换成左侧的C++类型。 当C++中赋值运算的左侧表达式是一个R对象或其部分内容时， 可以隐含地调用wrap()将右侧的C++类型转换成R类型。 在用Rcpp属性(Rcpp属性见下一节)声明的C++函数中， 可以直接以IntegerVector, NumericVector, CharacterVector, Function 等作为自变量类型或返回值， 可以与R中相应的类型直接对应。 能自动转换到R中的缺省值类型还包括： 用双撇号界定的字符串常量； 十进数值如10, 4.5; 预定义的常数如true, false, R_NilValue, NA_STRING, NA_INTEGER, NA_REAL, NA_LOGICAL； "],["rcpp-attr.html", "39 Rcpp 属性 39.1 Rcpp属性介绍 39.2 在C++源程序中指定要导出的C++函数 39.3 在R中编译链接C++代码 39.4 Rcpp属性的其它功能", " 39 Rcpp 属性 39.1 Rcpp属性介绍 Rcpp属性(attributes)用来简化把C++函数变成R函数的过程。 做法是在C++源程序中加入一些特殊注释， 利用其指示自动生成C++与R的接口程序。 属性是C++11标准的内容， 现在的编译器支持还不多， 所以在Rcpp支持的C++程序中写成了特殊格式的注释。 Rcpp属性有如下优点： 降低了同时使用R与C++的学习难度； 取消了很多繁复的接口代码； 可以在R会话中很简单地调用C++代码， 不需要用户自己考虑编译、连接、接口问题； 可以先交互地调用C++， 成熟后改编为R扩展包而不需要修改界面代码。 Rcpp属性的主要组成部分如下： 在C++中，提供Rcpp::export标注要输出到R中的C++函数。 在R中，提供sourceCpp()， 用来自动编译连接保存在文件或R字符串中的C++代码， 并自动生成界面程序把C++函数转换为R函数。 在R中，提供cppFunction()函数， 用来把保存在R字符串中的C++函数自动编译连接并转换成R函数。 提供evalCpp()函数， 用来把保存在R字符串中的C++代码片段自动编译连接并执行。 在C++中，提供Rcpp::depends标注， 说明编译连接时需要的外部头文件和库的位置。 在构建R扩展包时，提供compileAttributes() R函数， 自动给C++函数生成相应的 extern C声明和.Call接口代码。 39.2 在C++源程序中指定要导出的C++函数 用特殊注释//[[Rcpp::export]] 说明某C++函数需要在编译成动态链接库时， 把这个函数导出到链接库的对外可见部分。 例如 //[[Rcpp::export]] NumericVector convolveCpp( NumericVector a, NumericVector b){ ...... } 具体程序参见前面“用sourceCpp()转换C++源程序文件—卷积例子”。 假设此C++源程序保存到了当前工作目录的conv.cpp源文件中， 为了在R中调用此C++程序，只要用如： sourceCpp(file=&#39;conv.cpp&#39;) convolveCpp(1:3, 1:5) 注意sourceCpp() 把C++源程序自动进行了编译链接并转换成了同名的R函数。 在同一R会话内， 如果源程序和其依赖资源没有变化（根据文件更新时间判断）， 就不重新编译C++源代码。 在用特殊注释说明要导出的C++函数时， 可以用特殊的name=参数指定函数导出到R中的R函数名。 如果不指定，R函数名和C++函数名是相同的。 例如 //[[Rcpp::export(name=&quot;conv&quot;)]] NumericVector convolveCpp( NumericVector a, NumericVector b){ ...... } 则C++函数convolveCpp导入到R中后， 改名为“conv”。 对于要导出的C++函数， 必须在全局名字空间中定义， 而不能在某个C++名字空间声明内定义。 自变量必须能够用Rcpp::as转换成C++类型， 返回值必须是空值或者能够用Rcpp::wrap转换成R类型。 在自变量和返回值类型说明中， 必须使用完整的类型， 比如std::string不能简写成string。 Rcpp提供的类型如NumericVector可以不必用Rcpp::修饰。 39.3 在R中编译链接C++代码 sourceCpp()函数可以用code=指定一个R字符串， 字符串的内容是C++源程序， 其中还是用特殊注释//[[Rcpp::export]]标识要导出的C++函数。 如 sourceCpp(code=&#39; #include &lt;Rcpp.h&gt; using namespace Rcpp; //[[Rcpp::export]] NumericVector convolveCpp( NumericVector a, NumericVector b){ ......... } &#39;) convolveCpp(1:3, 1:5) 对于比较简单的单个C++函数， 可以用cppFunction()函数的code=指定一个R字符串， 字符串的内容是一个C++函数定义， 转换为一个R函数。 例如 cppFunction(code=&#39; int fibonacci(const int x){ if(x &lt; 2) return x; else return ( fibonacci(x-1) + fibonacci(x-2) ); } &#39;) print(fibonacci(5)) 为了在R中计算一个简单的C++表达式， 可以用evalCpp(’C++表达式内容’)，如 evalCpp(&#39;std::numeric_limits&lt;double&gt;::max()&#39;) 函数将返回该C++表达式的值。 在cppFunction()和evalCpp()中， 可以用depends=参数指定要链接的其它库，如 sourceCpp(depends=&#39;RcppArmadillo&#39;, code=&#39;......&#39;) 在编译代码时与RcppArmadillo的动态连接库连接。 也可以把这样的链接依赖关系写在特殊的C++注释中，如 //[[Rcpp::depends(RcppArmadillo)]] 这样的注释仅对sourceCpp()和cppFunction()有效， 在编译R扩展包时， 仍需要把依赖的包列在DESCRIPTION文件的Imports中， 把要链接的包列在LinkingTo中。 39.4 Rcpp属性的其它功能 39.4.1 自变量有缺省值的函数 借助于Rcpp, 自变量有缺省值的C++函数可以自动转换成自变量有缺省值的R函数。 定义时要符合C++语法， 比如带缺省值的自变量都要在不带缺省值的自变量的后面， 缺省值不能有变量。 例如 DataFrame readData( CharacterVector file, CharacterVector colNames = CharacterVector::create(), std::string comment = &quot;#&quot;, bool header = true){ ... } 转换到R中，相当于 function(file, colNames=character(), comment=&quot;#&quot;, header=TRUE) 39.4.2 允许用户中断 在C++代码中进行长时间的计算时， 应该允许用户可以中断计算。 Rcpp的办法是在C++计算过程中每隔若干步循环就插入一个 Rcpp::checkUserInterrupt();语句。 39.4.3 把R代码写在C++源文件中 正常情况下，应该把R代码和C++代码写在分别的源程序中， 当C++代码比较短时， 也可以把C++代码写在R源程序中作为一个字符串。 Rcpp允许把C++代码和R代码都写在一个C++源文件中， R代码作为特殊的注释，以/*** R行开头，以正常的*/结束。 在R中用sourceCpp()调用这个C++源文件， 就可以编译C++后执行其中特殊注释内的R代码。 这样的特殊注释可以有多个。 例如，下述内容保存在文件fibo.cpp中: //[[Rcpp::export]] int fibonacci(const int x){ if(x &lt; 2) return x; else return ( fibonacci(x-1) + fibonacci(x-2) ); } /*** R # 调用C++中的fibonacci()函数 print(fibonacci(10)) */ 只要在R中运行 sourceCpp(file=&#39;fibo.cpp&#39;) 就可以编译连接此C++文件， 把其中用//[[Rcpp::export]]标识的函数转换为R函数， 并在R中执行源文件内特殊注释中的R代码。 39.4.4 在C++中调用R的随机数发生器 在C或C++中调用R的随机数发生器， 需要能够同步地更新随机数发生器状态。 如果利用Rcpp属性编译C++源程序， 则Rcpp属性会自动添加一个RNGScope实例进行随机数发生器状态的同步。 "],["rcpp-vectype.html", "40 Rcpp提供的C++数据类型 40.1 RObject类 40.2 IntegerVector类 40.3 NumericVector类 40.4 NumericMatrix类 40.5 Rcpp的其它向量类 40.6 Rcpp提供的其它数据类型", " 40 Rcpp提供的C++数据类型 40.1 RObject类 Rcpp包为C++定义了NumericVector, IntegerVector, CharacterVector, Matrix等新数据类型， 可以直接与R的numeric, charactor, matrix对应。 Rcpp最基础的R数据类型是RObject, 这是NumericVector, IntegerVector等的基类, 通常不直接使用。 RObject包裹了原来R的C API的SEXP数据结构， 并且提供了自动的内存管理， 不再需要用户自己处理建立内存和消除内存的工作。 RObject存储数据完全利用R C API的SEXP数据结构， 不进行额外的复制。 因为RObject类是基类， 所以其成员函数也适用于NumericVector等类。 isNULL, isObject, isS4可以查询是否NULL, 是否对象， 是否S4对象。 inherits可以查询是否继承自某个特定类。 用attributeNames, hasAttribute, attr可以访问对象的属性。 用hasSlot, slot可以访问S4对象的插口（slot）。 RObject有如下导出类: IntegerVector: 整数向量； NumercicVector: 数值向量； LogicalVector: 逻辑向量； CharacterVector: 字符型向量； GenericVector: 列表； ExpressionVector: 表达式向量； RawVector: 元素为raw类型的向量。 IntergerMatrix, NumericMatrix: 整数值或数值矩阵。 在R向量中，如果其元素都是同一类型（如整数、双精度数、 逻辑、字符型），则称为原子向量。 Rcpp提供了IntegerVector, NumericVector, LogicalVector, CharacterVector等数据类型与R的原子向量类型对应。 在C++中可以用[]运算符存取向量元素， 也可以用STL的迭代器。用.begin(), .end()等界定范围， 用循环或或者accumulate等STL算法处理整个向量。 40.2 IntegerVector类 在R中通常不严格区分整数与浮点实数， 但是在与C++交互时，C++对整数与实数严格区分， 所以RCpp中整数向量与数值向量是区分的。 在R中，如果定义了一个仅有整数的向量， 其类型是整数(integer)的，否则是数值型(numeric)的，如： x &lt;- 1:5 class(x) ## [1] &quot;integer&quot; y &lt;- c(0, 0.5, 1) class(y) ## [1] &quot;numeric&quot; 用as.integer()和as.numeric() 函数可以显式地确保其自变量转为需要的整数型或数值型。 RCpp可以把R的整数向量传递到C++的IntegerVector中， 也可以把C++的IntegerVector函数结果传递回R中变成一个整数向量。 也可以在C++中生成IntegerVector向量，填入整数值。 40.2.1 IntegerVector示例1：返回完全数 如果一个正整数等于它所有的除本身以外的因子的和， 称这个数为完全数。如 \\[\\begin{aligned} 6 =&amp; 1 + 2 + 3 \\\\ 28 =&amp; 1 + 2 + 4 + 7 + 14 \\\\ \\end{aligned}\\] 是完全数。 任务：用C++程序输入前4个完全数偶数，返回到R中。 这4个数为6, 28, 496, 8182。 程序： library(Rcpp) sourceCpp(code=&#39; #include &lt;Rcpp.h&gt; using namespace Rcpp; //[[Rcpp::export]] IntegerVector wholeNumberA(){ IntegerVector epn(4); epn[0] = 6; epn[1] = 28; epn[2] = 496; epn[3] = 8182; return epn; } &#39;) print(wholeNumberA()) ## [1] 6 28 496 8182 对IntegerVector类型的x， 访问单个下标i格式为x[i]， 下标从0开始计算， 与R向量下标从1开始的规则不同。 从例子看出，可以在C++中建立一个IntegerVector, 需指定大小。 可以逐个填入数值。 直接返回IntegerVector到R即可， 不需用wrap()显式地转换， 函数返回值的声明可以用IntegerVector声明。 40.2.2 IntegerVector示例2：输入整数向量 任务：用C++编写函数，从R中输入整数向量， 计算其元素乘积（与R的prod()函数功能类似）。 程序如下： library(Rcpp) sourceCpp(code=&#39; #include &lt;Rcpp.h&gt; using namespace Rcpp; //[[Rcpp::export]] IntegerVector prod1(IntegerVector x){ int prod = 1; for(int i=0; i &lt; x.size(); i++){ prod *= x[i]; } return wrap(prod); } &#39;) print(prod1(1:5)) 为了获得向量的元素个数， 用x.size()这种方法。 从程序看出， 用IntegerVector从R中接受一个整数值向量时， 不需要显式地转换。 把一个C++整数值返回给R时， 可以用IntegerVector返回， 因为返回值原来是一个C++的int类型， 所以需要用Rcpp::wrap()转换一下。 在sourceCpp中可以省略Rcpp::部分。 也可以返回int, 返回值类型用int声明： library(Rcpp) sourceCpp(code=&#39; #include &lt;Rcpp.h&gt; using namespace Rcpp; //[[Rcpp::export]] int prod2(IntegerVector x){ int prod = 1; for(int i=0; i &lt; x.size(); i++){ prod *= x[i]; } return prod; } &#39;) print(prod2(1:5)) 还可以用C++ STL的算法库进行这样的累计乘积计算， std::accumlate()可以对指定范围进行遍历累计运算。 前两个参数是一个范围，用迭代器(iterators)表示开始和结束， 第三个参数是初值，第四个参数是对每个元素累计的计算。 程序如下： require(Rcpp) sourceCpp(code=&#39; #include &lt;Rcpp.h&gt; using namespace Rcpp; //[[Rcpp::export]] int prod3(IntegerVector x){ int prod = std::accumulate( x.begin(), x.end(), 1, std::multiplies&lt;int&gt;()); return prod; } &#39;) print(prod3(1:5)) 在以上的输入IntegerVector的C++程序中， 如果从R中输入了实数型的向量， 则元素被转换成整数型。比如 prod2(seq(1,1.9,by=0.1)) 结果将等于1。 如果输入了无法转换为整数型向量的内容， 比如prod2(c(’a’, ’b’, ’c’)), 程序会报错。 40.3 NumericVector类 NumericVector类在C++中保存双精度型一维数组， 可以与R的实数型向量(class为numeric)相互转换。 这是自己用C++程序与R交互时最常用到的数据类型。 x.size()返回元素个数。 40.3.1 示例1：计算元素\\(p\\)次方的和 sourceCpp(code=&#39; #include &lt;Rcpp.h&gt; using namespace Rcpp; //[[Rcpp::export]] double ssp( NumericVector vec, double p){ double sum = 0.0; for(int i=0; i &lt; vec.size(); i++){ sum += pow(vec[i], p); } return sum; } &#39;) ssp(1:4, 2) ## [1] 30 ssp((1:4)/10, 2.2) ## [1] 0.2392496 sum( ((1:4)/10)^2.2 ) ## [1] 0.2392496 从程序看出，用Rcpp属性编译时， C++函数的输入与返回值类型转换有如下规则： R中数值型向量在C++中可以用NumericVector接收； R中单个的实数在C++中可以用double来接收； 为了返回单个的实数， 可以直接返回double， 也可以返回NumericVector类型, 或者从一个double型用wrap()转换。 C++中如果返回NumericVector, 在R中转换为数值型向量。 40.3.2 示例2：clone函数 在自定义R函数时， 输入的自变量的值不会被改变， 相当于自变量都是局部变量。 如果在自定义函数中修改了自变量的值， 实际上只能修改自变量的一个副本的值。如 x &lt;- 100 f &lt;- function(x){ print(x); x &lt;- 99; print(x) } c(f(x), x) ## [1] 100 ## [1] 99 ## [1] 99 100 但是，在用Rcpp编写R函数时， 因为RObject传递的是指针， 并不自动复制自变量值， 所以修改自变量值会真的修改原始的自变量变量值。 如： sourceCpp(code=&#39; #include &lt;Rcpp.h&gt; using namespace Rcpp; //[[Rcpp::export]] NumericVector f2(NumericVector x){ x[0] = 99.0; return(x); } &#39;) x &lt;- 100 c(f2(x), x) [1] 99 99 可见自变量的值被修改了。 当然，对这个问题而言， 因为输入的是一个标量， 只要函数自变量不是NumericVector类型而是用double类型， 则自变量值会被复制，达到值传递的效果， 自变量值也就不会被真的修改。 如 sourceCpp(code=&#39; #include &lt;Rcpp.h&gt; using namespace Rcpp; //[[Rcpp::export]] NumericVector f3(double x){ x = 99.0; return(wrap(x)); } &#39;) x &lt;- 100 c(f3(x), x) ## [1] 99 100 下面的程序把输入向量每个元素平方后返回， 为了不修改输入自变量的值而是返回一个修改后的副本， 使用了Rcpp的clone函数： sourceCpp(code=&#39; #include &lt;Rcpp.h&gt; using namespace Rcpp; //[[Rcpp::export]] NumericVector square(NumericVector x){ NumericVector y = clone(x); for(int i=0; i &lt; x.size(); i++){ y[i] = x[i]*x[i]; } return(y); } &#39;) x &lt;- c(2, 7) cbind(square(x), x) ## x ## [1,] 4 2 ## [2,] 49 7 x.sort()会对x从小到大排序， 同时返回排序结果， x被修改了。如： sourceCpp(code=&#39; #include &lt;Rcpp.h&gt; using namespace Rcpp; //[[Rcpp::export]] NumericVector test_sort(NumericVector x){ return x.sort(); } &#39;) x &lt;- c(3, 5, 1) test_sort(x) ## [1] 1 3 5 x ## [1] 1 3 5 用clone制作副本，避免修改x: sourceCpp(code=&#39; #include &lt;Rcpp.h&gt; using namespace Rcpp; //[[Rcpp::export]] NumericVector test_sort(NumericVector x){ NumericVector y = clone(x); return y.sort(); } &#39;) x &lt;- c(3, 5, 1) test_sort(x) ## [1] 1 3 5 x ## [1] 3 5 1 40.3.3 示例3：向量子集 C++中Rcpp支持的向量和列表， 仍可以用正整数向量作为下标。 例如， 下面的C++函数求指定的元素子集的和： sourceCpp(code=&#39; #include &lt;Rcpp.h&gt; using namespace Rcpp; //[[Rcpp::export]] double sumsub( NumericVector x, IntegerVector i){ NumericVector y = x[i-1]; double s = 0.0; int n = y.size(); for(int j=0; j&lt;n; j++) s += y[j]; return s; } &#39;) x &lt;- 1:10 sumsub(x, c(1, 3, 5)) ## [1] 9 注意在程序中将输入的下标向量减了1， 以适应从R规则到C++规则的变化。 Rcpp在输入和输出时会自动在整型和双精度型之间转换， 比如上面例子中输入的x是整型的， 要求输入NumericVector是双精度型的， Rcpp会自动转换。 Rcpp也支持逻辑下标， 比如，下面在C++定义的函数可以取出向量的正值的子集： sourceCpp(code=&#39; #include &lt;Rcpp.h&gt; using namespace Rcpp; //[[Rcpp::export]] NumericVector get_positive(NumericVector x){ NumericVector y = x[x &gt; 0]; return y; } &#39;) x &lt;- c(1, -1, 2, -2) get_positive(x) ## [1] 1 2 Rcpp也支持按元素名访问向量元素或向量子集。 40.4 NumericMatrix类 NumericMatrix x(n,m)产生一个未初始化的\\(n\\times m\\)矩阵， 元素为double类型。 x.nrow()返回行数， x.ncol()返回列数， x.size()返回元素个数。 下标从0开始计算。 为了访问\\(x_{ij}\\)， 用x(i,j)的格式： 注意，不是x[i,j]也不是x[i][j]。 为了访问x的第i行，用x.row(i)或x(i,_)； 为了访问x的第j列，用x.column(j)或x(_,j)。 transpose(x)返回x的转置。 NumericMatrix::zeros(n)返回n阶元素为0的方阵。 NumericMatrix::eye(n)返回n阶单位阵。 40.4.1 示例1：计算矩阵各列模的最大值 输入一个矩阵，计算各列的向量模，并返回模的最大值。 library(Rcpp) sourceCpp(code=&#39; #include &lt;Rcpp.h&gt; using namespace Rcpp; //[[Rcpp::export]] double testfun(NumericMatrix x){ int nr = x.nrow(); int nc = x.ncol(); double y, y1; y = 0.0; for(int j=0; j&lt;nc; j++){ y1 = 0.0; for(int i=0; i&lt;nr; i++){ y1 += pow(x(i,j), 2); } if(y1 &gt; y) y = y1; } y = sqrt(y); return y; } &#39;) x &lt;- matrix(c(1, 2, 4, 9), 2, 2) print(x) print(testfun(x)) ## [,1] [,2] ## [1,] 1 4 ## [2,] 2 9 ## [1] 9.848858 其中对每列计算模的部分，也可以改写成： y = 0.0; NumericVector ycol(nr); for(int j=0; j&lt;nc; j++){ ycol = x.column(j); y1 = sum(ycol * ycol); if(y1 &gt; y) y = y1; } y = sqrt(y); 这里用了x.column(j)函数提取矩阵的一列， 用了ycol * ycol作向量元素之间的四则运算， 用了R的sum函数求和。 40.4.2 示例2：把输入矩阵制作副本计算元素平方根 下面的例子输入一个R矩阵， 输出其元素的平方根， 用了clone函数来避免对输入的直接修改。 没有按行列循环而是将矩阵看作一个按列拉直的向量进行遍历， 矩阵实际上也是按向量存储的。 sourceCpp(code=&#39; #include &lt;Rcpp.h&gt; using namespace Rcpp; //[[Rcpp::export]] NumericMatrix matSqrt(NumericMatrix x){ NumericMatrix y = clone(x); std::transform(y.begin(), y.end(), y.begin(), ::sqrt); return(y); } &#39;) x &lt;- rbind(c(1,2), c(3,4)) cbind(matSqrt(x), x) ## [,1] [,2] [,3] [,4] ## [1,] 1.000000 1.414214 1 2 ## [2,] 1.732051 2.000000 3 4 在上面的C++程序中， NumericMatrix看成了一维数组， 用STL的iterater遍历， 用STL的transform对每个元素计算变换。 40.4.3 示例3：访问列子集 可以用x(_,j)这样的格式将矩阵x的第j列取出为普通向量， 并可以赋值修改。 也可以用x.column(j)， 用法相同。 x(i,_)取出第i行为一个普通向量。 比如， 下面的C++函数将输入的矩阵的每一行计算累加和： library(Rcpp) sourceCpp(code=&#39; #include &lt;Rcpp.h&gt; using namespace Rcpp; //[[Rcpp::export]] NumericMatrix testfun(NumericMatrix x){ NumericMatrix y = clone(x); for(int j=1; j&lt;x.ncol(); j++){ y(_,j) = y(_,j-1) + x(_,j); } return y; } &#39;) x &lt;- matrix(c(1, 2, 4, 9), 2, 2) print(x) ## [,1] [,2] ## [1,] 1 4 ## [2,] 2 9 print(testfun(x)) ## [,1] [,2] ## [1,] 1 5 ## [2,] 2 11 40.5 Rcpp的其它向量类 40.5.1 Rcpp的LogicalVector类 LogicalVector类可以存储C++值true, false, 还可以保存缺失值NA_REAL, R_NaN, R_PosInf, 但是这些不同的缺失值转换到R中都变成NA。 如: sourceCpp(code=&#39; #include &lt;Rcpp.h&gt; using namespace Rcpp; //[[Rcpp::export]] LogicalVector f4(){ LogicalVector x(5); x[0] = false; x[1] = true; x[2] = NA_REAL; x[3] = R_NaN; x[4] = R_PosInf; return(x); } &#39;) f() ## [1] FALSE TRUE NA NA NA identical(f(), c(FALSE, TRUE, rep(NA,3))) ## [1] TRUE 40.5.2 Rcpp的CharacterVector类型 CharacterVector类型可以与R的字符型向量相互交换信息， 在C++中其元素为字符串。 字符型缺失值在C++中为R_NAString。 R的字符型向量也可以转换为std::vector。 如： sourceCpp(code=&#39; #include &lt;Rcpp.h&gt; using namespace Rcpp; //[[Rcpp::export]] CharacterVector f5(){ CharacterVector x(3); x[0] = &quot;This is a string&quot;; x[1] = &quot;Test&quot;; x[2] = R_NaString; return(x); } &#39;) f5() ## [1] &quot;This is a string&quot; &quot;Test&quot; NA 40.6 Rcpp提供的其它数据类型 40.6.1 Named类型 R中的向量、矩阵、数据框可以有元素名、列名、行名。 这些名字可以借助Named类添加。 例如： sourceCpp(code=&#39; #include &lt;Rcpp.h&gt; using namespace Rcpp; //[[Rcpp::export]] NumericVector f6(){ NumericVector x = NumericVector::create( Named(&quot;math&quot;) = 82, Named(&quot;chinese&quot;) = 95, Named(&quot;English&quot;) = 60); return(x); } &#39;) f6() ## math chinese English ## 82 95 60 “Named(元素名)”可以简写成“_元素名”。 如： sourceCpp(code=&#39; #include &lt;Rcpp.h&gt; using namespace Rcpp; //[[Rcpp::export]] NumericVector f6b(){ NumericVector x = NumericVector::create( _[&quot;math&quot;] = 82, _[&quot;chinese&quot;] = 95, _[&quot;English&quot;] = 60); return(x); } &#39;) 40.6.2 List类型 Rcpp提供的List类型对应于R的list(列表)类型， 在C++中也可以写成GenericVector类型。 其元素可以不是同一类型， 在C++中可以用方括号和字符串下标的格式访问其元素。 例如，下面的函数输入一个列表， 列表元素vec是数值型向量， 列表元素multiplier是数值型标量， 返回一个列表， 列表元素sum为vec元素和， 列表元素dsum为vec元素和乘以multiplier的结果： sourceCpp(code=&#39; #include &lt;Rcpp.h&gt; using namespace Rcpp; //[[Rcpp::export]] List f7(List x){ NumericVector vec = as&lt;NumericVector&gt;(x[&quot;vec&quot;]); double multiplier = as&lt;double&gt;(x[&quot;multiplier&quot;]); double y = 0.0, y2; for(int i=0; i&lt;vec.length(); i++){ y += vec[i]; } y2 = y*multiplier; return(List::create(Named(&quot;sum&quot;)=y, Named(&quot;dsum&quot;)=y2)); } &#39;) f7(list(vec=1:5, multiplier=10)) ## $sum ## [1] 15 ## ## $dsum ## [1] 150 上面的程序用了Rcpp::List::create()当场生成List类型， 因为用Rcpp属性功能编译所以可以略写Rcpp::。 也可以在程序中预先生成指定大小的列表， 然后再给每个元素赋值， 元素值可以是任意能够转化为SEXP的类型， 如： ......... List gv(2); gv[0] = &quot;abc&quot;; gv[1] = 123; 可以用List的reserve函数为列表指定元素个数。 40.6.3 Rcpp的DataFrame类 Rcpp的DataFrame类用来与R的data.frame交换信息。 示例如： sourceCpp(code=&#39; #include &lt;Rcpp.h&gt; using namespace Rcpp; //[[Rcpp::export]] DataFrame f8(){ IntegerVector vec = IntegerVector::create(7,8,9); std::vector&lt;std::string&gt; s(3); s[0] = &quot;abc&quot;; s[1] = &quot;ABC&quot;; s[2] = &quot;123&quot;; return(DataFrame::create( Named(&quot;x&quot;) = vec, Named(&quot;s&quot;) = s)); } &#39;) f8() ## x s ## 1 7 abc ## 2 8 ABC ## 3 9 123 40.6.4 Rcpp的Function类 Rcpp的Function类用来接收一个R函数， 并且可以在C++中调用这样的函数。 示例如: sourceCpp(code=&#39; #include &lt;Rcpp.h&gt; using namespace Rcpp; //[[Rcpp::export]] SEXP dsort(Function sortFun, SEXP x){ return sortFun(x, Named(&quot;decreasing&quot;, true)); } &#39;) dsort(sort, c(&#39;bb&#39;, &#39;ab&#39;, &#39;ca&#39;)) ## [1] &quot;ca&quot; &quot;bb&quot; &quot;ab&quot; ## dsort(sort, c(2,1,3)) ## [1] 3 2 1 程序用Function对象sortFun接收从R中传递过来的排序函数， 实际调用时传递过来的是R的sort函数。 在C++中调用R函数时， 有名的自变量用“Named(自变量字符串, 自变量值)”的格式给出。 程序中的待排序的向量与排序后的向量都用了SEXP来说明， 即直接传送原始R API指针， 这样可以不管原来类型是什么， 在C++中完全不进行类型转换或复制。 从运行例子看出数值和字符串都正确地按照降序排序后输出了。 R函数可以不作为C++的函数自变量传递进来， 而是直接调用R的函数。 R的许多函数都已经在Rcpp名字空间中输出了， 所以可以直接调用R的各个向量化的函数， 包括随机数函数。 例如， 下面的C++函数返回一个各列为随机数的数值型矩阵： sourceCpp(code=&#39; #include &lt;Rcpp.h&gt; using namespace Rcpp; // [[Rcpp::export]] NumericMatrix rngCpp(const int N) { NumericMatrix X(N, 4); X(_, 0) = runif(N); X(_, 1) = rnorm(N); X(_, 2) = rt(N, 5); X(_, 3) = rbeta(N, 1, 1); return X; }&#39;) 使用了Rcpp属性时， 生成的界面程序会自动生成一个RNGScope的实例， 用来保存当前的随机数发生器状态， 在解构时将自动更新随机数发生器状态。 这是R调用编译代码时对编译代码的要求， 如果不使用Rcpp和属性， 就需要用户自己添加命令来维护随机数种子。 测试上面的随机数调用： set.seed(101) xm &lt;- rngCpp(3) xm ## [,1] [,2] [,3] [,4] ## [1,] 0.37219838 0.4061679 0.107946 0.78664800 ## [2,] 0.04382482 -0.5242428 1.539425 0.07668112 ## [3,] 0.70968402 -0.4303593 -2.259442 0.92878745 set.seed(101) xm2 &lt;- cbind( runif(3), rnorm(3), rt(3, 5), rbeta(3,1,1) ) all.equal(xm, xm2) ## [1] TRUE 还可以使用名字空间R中的标量随机数发生器，如： sourceCpp(code=&#39; #include &lt;Rcpp.h&gt; using namespace Rcpp; // [[Rcpp::export]] NumericVector rngCppScalar() { NumericVector x(4); x[0] = R::runif(0,1); x[1] = R::rnorm(0,1); x[2] = R::rt(5); x[3] = R::rbeta(1,1); return(x); }&#39;) 40.6.5 Rcpp的Environment类 R的环境是分层的，可以逐层查找变量名对应的内容。 Rcpp的Environment类用来与R环境对应。 可以利用Environment来定位R的扩展包中的函数或数据， 例如下面的程序片段在C++中定位了stats扩展包中的 rnorm函数并进行了调用: Environment stats(&quot;package:stats&quot;); Function rnorm = stats[&quot;rnorm&quot;]; return rnorm(3, Named(&quot;sd&quot;, 100.0)); 当然，也可以用Function对象直接从各环境中搜索rnorm函数名， 但是这样指定环境更可靠。 下面的例子访问了R全局环境， 取出了全局变量x的值存入C++的双精度型STL向量中， 并把一个C++的STL map型数据转换成有名字符型向量存到了全局变量y中。 sourceCpp(code=&#39; #include &lt;Rcpp.h&gt; using namespace Rcpp; //[[Rcpp::export]] void f9(){ Environment global = Environment::global_env(); std::vector&lt;double&gt; vx = global[&quot;x&quot;]; std::map&lt;std::string, std::string&gt; ma; ma[&quot;foo&quot;] = &quot;abc&quot;; ma[&quot;bar&quot;] = &quot;123&quot;; global[&quot;y&quot;] = ma; return; } &#39;) x &lt;- c(1,5) f9() y ## bar foo ## &quot;123&quot; &quot;abc&quot; "],["rcpp-sugar.html", "41 Rcpp糖 41.1 简单示例 41.2 向量化的运算符 41.3 用Rcpp访问数学函数 41.4 返回单一逻辑值的函数 41.5 返回糖表达式的函数 41.6 R与Rcpp不同语法示例", " 41 Rcpp糖 在C++中，向量和矩阵的运算通常需要逐个元素进行， 或者调用相应的函数。 Rcpp通过C++的表达式模板(expression template)功能， 可以在C++中写出像R中对向量和矩阵运算那样的表达式。 这称为Rcpp糖(sugar)。 R中的很多函数如sin等是向量化的， Rcpp糖也提供了这样的功能。 Rcpp糖提供了一些向量化的函数如ifelse, sapply等。 比如，两个向量相加可以直接写成x + y 而不是用循环或迭代器(iterator)逐元素计算; 若x是一个NumericVector, 用sin(x)可以返回由x每个元素的正弦值组成的NumericVector。 Rcpp糖不仅简化了程序， 还提高了运行效率。 41.1 简单示例 比如，函数 \\[\\begin{aligned} f(x,y) = \\begin{cases} x^2 &amp; x &lt; y, \\\\ -y^2 &amp; x \\geq y \\end{cases} \\end{aligned}\\] 如下的程序可以在C++中定义一个向量化的版本： sourceCpp(code=&#39; #include &lt;Rcpp.h&gt; using namespace Rcpp; //[[Rcpp::export]] NumericVector f11(NumericVector x, NumericVector y){ return ifelse(x &lt; y, x*x, -(y*y)); } &#39;) f11(c(1, 3), c(4,2)) ## [1] 1 -4 上面简单例子中，x &lt; y是向量化的， x * x, y * y, -(y * y)都是向量化的。 ifelse也是向量化的。 41.2 向量化的运算符 41.2.1 向量化的四则运算 Rcpp糖向量化了+, -, *, /。 设x, y都是NumericVector, 则 x + y, x - y, x * y, x * y 将返回对应元素进行四则运算后的NumericVector变量。 向量与标量运算， 如 x + 2.0, 2.0 - x, x * 2.0, 2.0 / x 将返回标量与向量每个元素进行四则运算后的NumericVector变量。 还可以进行混合四则运算，如： NumericVector res = x * y + y / 2.0; NumericVector res = x * (y - 2.0); NumericVector res = x / (y * y); 参加四则运算的或者都是同基本类型的向量而且长度相等， 或者一边是向量，一边是同类型的标量。 注意：对向量整体赋一个相同的值， 不能简单地写成如x=0;这样的赋值， 需要用循环或STL的fill算法， 如std::fill(x.begin(), x.end(), 0);。 41.2.2 向量化的二元逻辑运算 Rcpp糖扩展了两个元素的比较到两个等长向量的比较， 以及一个向量与一个同类型标量的比较， 结果是一个同长度的LogicalVector。 比较运算符包括&lt;, &gt;, &lt;=, &gt;=, ==, !=。 也可以使用嵌套的表达式， 比如，设x, y是两个NumericVector，可以写: LogicalVector res = (x + y) &lt; (x * x); 41.2.3 向量化的一元运算符 对数值型向量或返回数值型向量的表达式前面加负号， 可以返回每个元素取相反数的结果。 比如，设x是NumericVector, 可以写: NumericVector res = -x; NumericVector res = -x * (x + 2.0); 对逻辑型向量或返回逻辑型向量的表达式前面加叹号， 可以返回每个元素取反的结果，如： NumericVector y, z; NumericVector res = ! ( y &lt; z ); 41.3 用Rcpp访问数学函数 在C和C++代码中可以调用R中的函数， 但是格式比较复杂， 而且原来不支持向量化。 Rcpp糖则使得从C++中调用R函数变得和在R调用函数格式类似。 R源程序中提供了许多数学和统计相关的函数， 这些函数可以编译成一个独立的函数库， 供其它程序链接使用，函数内容在R的Rmath.h头文件中有详细列表。 Rcpp糖把R中的数学函数在C++中向量化了， 输入一个向量， 结果是对应元素为函数值的向量。 自变量类型可以是数值型或整数型。 这些数学函数包括abs, exp, floor, ceil, pow等。 在Rcpp中支持的C++源程序中调用这些函数, 最简单的一种方法是直接在Rcpp 名字空间中使用和R中相同的函数名和调用方法， 类似sqrt这样的函数允许输入一个向量， 对向量的每个元素计算。 比如，下面的程序输入一个向量，计算相应的标准正态分布函数值： sourceCpp(code=&#39; #include &lt;Rcpp.h&gt; using namespace Rcpp; //[[Rcpp::export]] NumericVector f10(NumericVector x){ NumericVector y(x.size()); y = pnorm(x); return y; } &#39;) f10(c(0, 1.96, 2.58)) ## [1] 0.5000000 0.9750021 0.9950600 如果需要对单个的数值计算， 可以使用Rmath.h中定义的带有Rf_的版本， 如: y = ::Rf_pnorm5(x, 0.0, 1.0, 1, 0); 这里用::使用了缺省的名字空间。 注意所有自变量都不能省略。 Rcpp还提供了一个R名字空间， 可以用不带Rf_前缀的函数， 但是自变量也不能省略。如 y = R::pnorm(x, 0.0, 1.0, 1, 0); 在Rcpp的R名字空间中有许多的数学和统计相关的函数， 各函数的自变量参见Rcpp的Rmath.h文件。 R中提供了许多分布的分布密度（或概率质量函数）、分布函数、分位数函数， 分布密度函数和概率质量函数命名类似dxxxx, 分布函数命名类似pxxxx, 分位数函数命名类似qxxxx。 在Rcpp糖支持下， 这些函数可以直接用类似R中的格式调用。 如 sourceCpp(code=&#39; #include &lt;Rcpp.h&gt; using namespace Rcpp; //[[Rcpp::export]] List f14(){ NumericVector x = NumericVector::create(0, 1.96, 2.58); NumericVector p = NumericVector::create(0.95, 0.975, 0.995); NumericVector y1 = dnorm(x, 0.0, 1.0); NumericVector y2 = pnorm(x, 0.0, 1.0); NumericVector y3 = qnorm(p, 0.0, 1.0); return List::create(Named(&quot;y1&quot;)=y1, Named(&quot;y2&quot;)=y2, Named(&quot;y3&quot;)=y3); } &#39;) f14() ## $y1 ## [1] 0.39894228 0.05844094 0.01430511 ## ## $y2 ## [1] 0.5000000 0.9750021 0.9950600 ## ## $y3 ## [1] 1.644854 1.959964 2.575829 ## R中的rxxxx类的函数可以产生各种分布的随机数向量， 随机数向量与当前种子有关。 Rcpp属性会自动地维护随机数发生器的状态使其与R同步。 如 sourceCpp(code=&#39; #include &lt;Rcpp.h&gt; using namespace Rcpp; //[[Rcpp::export]] NumericVector f15(){ NumericVector x = rnorm(10, 0.0, 1.0); return x; } &#39;) round(f15(), 2) ## [1] 0.62 -0.06 -0.16 -1.47 -0.48 ## [6] 0.42 1.36 -0.10 0.39 -0.05 41.4 返回单一逻辑值的函数 在R中， any()和all()对一个逻辑向量分别判断是否有任何真值， 以及所有元素为真值。 Rcpp糖在C++中也提供了这样的any()和all()函数。 如 sourceCpp(code=&#39; #include &lt;Rcpp.h&gt; using namespace Rcpp; //[[Rcpp::export]] List f12(){ IntegerVector x = seq_len(1000); LogicalVector res1 = any( x*x &lt; 3 ); LogicalVector res2 = all( x*x &lt; 3 ); return List::create(Named(&quot;any&quot;)=res1, Named(&quot;all&quot;)=res2); } &#39;) f12() ## $any ## [1] TRUE ## ## $all ## [1] FALSE any()和all()不是直接返回逻辑值， 而是返回一个类对象， 该类定义了is_true, is_false, is_na方法与向SEXP转换的运算符。 此种结果可以保存到LogicalVector中， 但不能赋值到bool类型， 因为可能有缺失值。 逻辑型糖表达式结果可以用 is_true, is_false, is_na来判断结果。 如 bool res1 = is_true( any( x &lt; y ) ); bool res2 = is_na( all( x &lt; y ) ); 在求any()结果时，一旦遇到一个真值结果就为真值， 即使后面有缺失值也没有关系。 在求all()结果时，一旦遇到一个假值结果就为假值， 即使后面有缺失值也没有关系。 41.5 返回糖表达式的函数 is_na以任何糖表达式为输入， 输出一个逻辑类型的元素个数相同的糖表达式。 结果每个元素当输入中对应元素缺失时为TRUE, 否则为FALSE。 如 IntegerVector x = IntegerVector::create(0, 1, NA_INTEGER, 3); LogicalVector res1 is_na(x); LogicalVector res2 = all( is_na(x) ); if( is_true( any( ! is_na(x) ) ) ) ... seq_along输入一个向量， 输出一个元素为该向量的各个下标值的糖表达式。 如 IntegerVector x = IntegerVector::create(0, 1, NA_INTEGER, 3); seq_along(x); seq_along(x*x*x*x*x); 注意上述程序不会计算x*x*x*x*x的值而只利用其结果的元素个数。 所以两次调用的计算量是一样的。 seq_len自变量为个数， 返回一个元素值为正数的元素个数等于自变量值的糖表达式， 第\\(i\\)个元素等于\\(i\\)。 常可与sapply, lapply配合使用。 如 sourceCpp(code=&#39; #include &lt;Rcpp.h&gt; using namespace Rcpp; //[[Rcpp::export]] List f13(){ IntegerVector x =seq_len(3); List y = lapply( seq_len(3), seq_len); return List::create(Named(&quot;x&quot;)=x, Named(&quot;y&quot;)=y); } &#39;) f13() ## $x ## [1] 1 2 3 ## ## $y ## $y[[1]] ## [1] 1 ## ## $y[[2]] ## [1] 1 2 ## ## $y[[3]] ## [1] 1 2 3 ## pmin和pmax 自变量为两个等长的向量或糖表达式， 返回长度相同的结果，结果元素只等于对应元素的最小值或最大值。 自变量也可以取一个向量一个标量， 向量的每个元素与标量比较得到最小值或最大值。 如 IntegerVector x =seq_len(10); pmin(x, x*x); pmin(x*x, 2); ifelse函数有三个自变量， 第一自变量是一个逻辑型向量值的糖表达式， 第二和第三自变量或者是两个同类型并与第一自变量等长的糖表达式， 或者其中一个是同类型标量， 结果仍为向量型糖表达式， 第\\(i\\)元素当第一自变量第\\(i\\)元素为真时取第一自变量的第\\(i\\)元素， 当第一自变量第\\(i\\)元素为假时取第二自变量的第\\(i\\)元素， 当第一自变量第\\(i\\)元素为缺失值时取缺失值。 如 IntegerVector x, y; IntegerVector res1 = ifelse( x &lt; y, x, (x+y)*y ); IntegerVector res2 = ifelse( x &gt; y, x, 2 ); sapply函数第一自变量是一个向量或列表， 第二自变量是一个函数。 返回值类型在编译时从函数的结果类型导出。 第二自变量可以是任意的C++函数， 比如， 可以是如下的重载的模板化函数： template &lt;typename T&gt; T square( const T&amp; x ){ return x * x; } sapply( seq_len(4), square&lt;int&gt; ); 下面的例子中sapply第二自变量使用了functor， 这是一种能够产生函数的函数： template &lt;typename T&gt; struct square : std::unaray_function&lt;T,T&gt; { T operator() (const T&amp; x) { return x * x; } } sapply( seq_len(4), square&lt;int&gt;() ); lapply函数与sapply函数基本相同， 只不过lapply函数总是返回列表, 列表在Rcpp中为List或GenericVector, 在R API中类型为VECSXP。 sign函数输入一个数值型或整型表达式， 返回各元素值在\\(\\{1, 0, -1, \\text{NA} \\}\\)中取值的糖表达式， 可以保存到IntegerVector中。 结果各元素的取值表示输入中对应元素为正、零、负和缺失。 如 IntegerVector x; IntegerVector res1 = sign( x ); IntegerVector res2 = sign( x*x ); diff函数自变量为数值型或整数型向量或有这样结果的糖表达式， 输出后一元素减去前一元素的结果， 结果长度比输入长度少一。 如 IntegerVector res = diff( seq_len(5) ); 41.6 R与Rcpp不同语法示例 RCpp糖通过一些现代的C++技术， 支持部分的向量化运算， 比如，NumericVector与标量相加， 两个等长NumericVector相加， 对NumericVector计算如绝对值这样的数学函数值等。 但是，C++毕竟和R有很大差别， 要区分Rcpp能做的和不能做的。 例如，NumericVector为了把向量所有元素都改成同一值， 不能直接用等于赋值。 可以用std::fill(y.begin(), y.end(), 99.99)这样的做法。 "],["rcpp-package.html", "42 用Rcpp帮助制作R扩展包 42.1 不用扩展包共享C++代码的方法 42.2 生成扩展包 42.3 重新编译 42.4 建立C++用的接口界面", " 42 用Rcpp帮助制作R扩展包 R扩展包是把解决某种问题的可复用代码、文档整合在一起的最好的方法。 写成R扩展包后，可以自己用，也可以利用CRAN分发。 扩展包用户一般不用自己编译。 使用扩展包来组织程序， 多个源程序、头文件之间的依赖关系可以自动得到处理。 扩展包提供了测试、文档和一致性检查的统一框架。 扩展包中代码可以仅有R程序，也可以包括C程序、C++程序、Fortran程序。 如果仅有R代码，就不需要借助于Rcpp，可以使用 package.skeleton()函数生成一个扩展包框架。 如果有C++代码，就可以用Rcpp作为接口， 并用Rcpp提供的Rcpp.package.skeleton()函数制作扩展包框架。 Rcpp属性的Exports注释仍可在制作扩展包时指定如何输出 C++中定义的函数使其在R中可调用。 42.1 不用扩展包共享C++代码的方法 Rcpp属性的sourceCpp()通常只适用于写在R程序内部的简短C++代码， 或者写在一个单独C++文件中，不依赖于其它C++程序的单独代码。 如果有多个C++源程序、头文件，彼此有依赖关系， 最好使用扩展包。 在多个单独的C++文件共享某些简单的代码， 彼此不互相依赖时，可以用C++的预处理include命令共享这些代码。 比如，有多个C++源程序都用到如下的代码： #ifndef __UTILITIES__ #define __UTILITIES__ inline double timesTwo(double x) { return x * 2; } #endif // __UTILITIES__ 假设这段代码保存到当前子目录的“utilities.hpp”文件中。 则在每个需要用到这段代码的C++源程序中，插入如: #include &quot;utilities.hpp&quot; //[[Rcpp::export]] double transformValue(double x){ return timesTwo(x) * 10; } 42.2 生成扩展包 42.2.1 利用已有基于Rcpp属性的源程序制作扩展包 假设在当前目录中有了若干个C++文件， 其中需要转换到R中的C++函数已经用Rcpp::export声明过。 其中一个是conv1.cpp。 从当前目录启动R，运行 Rcpp.package.skeleton(&quot;testpack&quot;, example_code=FALSE, attributes=TRUE, cpp_files=c(&quot;conv1.cpp&quot;)) 运行显示： Creating directories ... Creating DESCRIPTION ... Creating NAMESPACE ... Creating Read-and-delete-me ... Saving functions and data ... Making help files ... Done. Further steps are described in &#39;./testpack/Read-and-delete-me&#39;. Adding Rcpp settings &gt;&gt; added Imports: Rcpp &gt;&gt; added LinkingTo: Rcpp &gt;&gt; added useDynLib directive to NAMESPACE &gt;&gt; added importFrom(Rcpp, evalCpp) directive to NAMESPACE &gt;&gt; copied conv1.cpp to src directory 运行完后，在当前目录生成了一个testpack子目录， 这是要制作的扩展包的名字。 在testpack子目录中，有文件DESCRIPTION, NAMESPACE, Read-and-delete-me, 有子目录src, R, man。 子目录src中为C++和C源程序、头文件。 子目录R中为Rcpp从C++程序转换过来的R接口程序， 用户自己的R程序也可以放在这里。 子目录man是特殊格式的文档， 其格式类似LaTeX。 42.2.2 DESCRIPTION文件 在DESCRIPTION文件中， 有扩展包名称、版本、日期、作者姓名、维护者姓名和联系方式、 简单描述、授权， 还有Imports和LinkingTo两项。 除此之外，还有许多可选的域，如Depends。 Imports给出本软件包要调用的其它扩展包, 但是这些扩展包并不随本扩展包一起调入， 仅是会调入其名字空间。这里的值为 Imports: Rcpp (&gt;= 0.12.3) LinkingTo指定在编译本软件包的C、C++、Fortran等源程序时， 会用到哪些其它扩展包的头文件。这里的值为 LinkingTo: Rcpp 指定的这些扩展包一般是编译时才有用的， 所以一般不会出现在Depends和Imports域中。 LinkingTo只解决了头文件的问题， 要链接除了Rcpp之外的二进制库文件， 还需要手工编辑src/Makevars和src/Makevars.win文件。 和Imports有些相像的的DESCRIPTION域是Depends， 指定调入本扩展包时必须预先调入的软件包。 这里“调入”是指用libraray()或require()调入扩展包。 多个扩展包名用逗号分开，可以在扩展包名字后面加圆括号， 在圆括号内写上\\(&gt;=\\)某个版本号, 如“MASS(&gt;=3.1-20)”。 Depends也可以指定依赖于某个R版本之后，如“R(&gt;=2.14.0)”。 DESCRIPTION文件中的Suggests与和Depends域类似， 但不是本扩展包必须的， 比如仅用在某个例子中或测试中、仅用来编译vignettes。 42.2.3 NAMESPACE文件 示例NAMESPACE文件如下： useDynLib(testpack) exportPattern(&quot;^[[:alpha:]]+&quot;) importFrom(Rcpp, evalCpp) 其中第一行指定调用本软件包时， 需要调入的本扩展包的动态链接库。 第二行指定扩展包需要对外部可见的R函数是所有函数名字以字母开头的R函数。 用户可以自己指定其它的模式或者指定固定的若干个函数。 第三行说明了需要从Rcpp包导入evalCpp函数。 42.3 重新编译 修改了扩展包中的C++源程序后， 需要重新编译。 只要在R中把工作目录设为软件包的子目录内， 运行 compileAttributes() 这会自动生成两个文件，一个是src/RcppExports.cpp， 是C++程序的接口函数。 另一个是R/RcpExports.R， 用.Call来调用C++接口函数，转换成R函数。 这两个文件不要自己修改。 42.4 建立C++用的接口界面 利用了Rcpp属性可以指定要输出到R中的函数。 在C++源程序中加入特殊注释 //[[Rcpp::interfaces(r, cpp)]] 则软件包在编译时也会生成该源程序文件中函数的外部可访问的接口， 这些接口的界面会在安装后的包的include子目录中出现， 在开发时出现在inst/include子目录中。 设要生成的扩展包名为testpack, 则界面文件包括include子目录中的 testpack_RcppExports.h文件和testpack.h文件， testpack.h文件仅用来包含入testpack_RcppExports.h文件。 如果需要添加自己的一些界面程序， 可以修改testpack.h文件， 这时需要去掉文件开始的自动生成标记， 并且保留对testpack_RcppExports.h文件的包含。 导出的C++界面都在与制作的扩展包同名的名字空间中， 比如，如果制作的软件包名为testpack, 其中导出的一个C++函数为convolveCpp, 则在别的包的C++源程序中调用时， 应该包含testpack.h文件， 并用testpack::convolveCpp()格式调用。 如果自己本扩展包需要在编译时包含这些头文件， 需要自己编辑src子目录中的Makevars文件和Makevars.win文件， 添加行: PKG_CPPFLAGS += -I../inst/include/ "],["examples.html", "43 R编程例子 43.1 R语言 43.2 概率 43.3 科学计算 43.4 统计计算 43.5 数据处理 43.6 文本处理", " 43 R编程例子 因为这些例子要用作学生习题， 所以这里只有问题， 没有实际内容。 43.1 R语言 43.1.1 用向量作逆变换 设向量x长度为n, 其中保存了1到n的正整数的一个排列。 把x看成是在集合\\(\\{1,2,\\dots,n \\}\\)上的一个一一变换， 求向量y使得y能够表示上述变换的逆变换。 即任给长度为\\(n\\)的向量z, z[x]表示按照x的次序重新排列z的元素， 而z[x][y]则应该恢复为z。 43.1.2 斐波那契数列计算 设数列\\(x_0=0, x_1=1\\)， 后续值按如下公式递推计算： \\[ x_n = x_{n-2} + x_{n-1}, \\ n=2,3,\\dots \\] 这样的数列叫做斐波那契数列。 希望编写R函数， 输入\\(n\\)，返回计算的\\(x_n\\)的值。 43.1.3 穷举所有排列 设向量x的各个元素为某个集合的元素。 想要列出x的元素的所有不同排列。 比如，如果x = 1:3, 所有排列为 1 2 3 1 3 2 2 1 3 2 3 1 3 1 2 3 2 1 共\\(3!=6\\)种不同的排列。 43.1.4 可重复分组方式穷举 设有\\(n\\)个编号卡片， 分别有号码\\(1, 2, \\dots, n\\)。 从中有放回地抽取\\(m\\)个并记录每次的号码， 穷举\\(m\\)个号码中多少个1，多少个2，\\(\\dots\\), 多少个\\(n\\)这样的结果。 例如，有3个编号卡片， 随机有放回第抽取2次。 用\\((x_1, x_2, x_3)\\)表示每一种个数组合， \\(x_1\\)表示2次抽取中号码1的个数， \\(x_2\\)表示2次抽取中号码2的个数， \\(x_3\\)表示2次抽取中号码3的个数。 问题就是列出\\((x_1, x_2, x_3)\\)的所有不同值。 43.1.5 升降连计数 考虑如下的数据： set.seed(101) n &lt;- 20 x &lt;- sample(n); x ## [1] 9 14 17 3 16 18 20 15 13 2 4 5 12 1 6 10 7 19 8 11 x的序列中连续上升的一段(至少两个)称为一个升连， 对升连的个数计数： 9 14 17 (1) 3 16 18 20 (2) 2 4 5 12 (3) 1 6 10 (4) 7 19 (5) 8 11 (6) 共6段。 这可以用绘图更形象地表现： plot(x, type=&quot;b&quot;, lwd=1) segs &lt;- matrix(c( 1,3, 4,7, 10,13, 14,16, 17,18, 19,20), ncol=2, byrow=TRUE) for(i in seq(nrow(segs))) { lines(seq(segs[i,1], segs[i,2]), x[seq(segs[i,1], segs[i,2])], col=&quot;red&quot;, lwd=2) } 如何用编程方式找到段数？ 最后的程序需要能解决如下问题： n &lt;- 10000 set.seed(102) x &lt;- sample(n) 升连个数=？ 43.2 概率 43.2.1 智者千虑必有一失 成语说：“智者千虑，必有一失；愚者千虑，必有一得”。 设智者作判断的准确率为\\(p_1 = 0.99\\), 愚者作判断的准确率为\\(p_2=0.01\\)， 计算智者做1000次独立的判断至少犯一次错误的概率， 与愚者做1000次独立判断至少对一次的概率。 43.2.2 圆桌夫妇座位问题 在一张圆桌上用餐时， \\(n\\)对夫妇随机入座。 计算没有任何一位妻子和她的丈夫相邻的概率。 通过推导可得此概率为 \\[ p_n = 1 + \\sum_{k=1}^{n} (-1)^k C_{n}^k \\frac{(2n-k-1)! 2^k}{(2n-1)!}. \\qquad(1) \\] 例如\\(p_2 = 1/3\\), \\(p_3 = 4/15 = 0.2667\\), \\(p_4 = 0.2952\\), \\(p_5 = 0.3101\\)。 分别用上面的理论公式以及直接穷举验证的方法， 对\\(n=2, 3, 4, 5\\)的情形进行验证。 43.3 科学计算 43.3.1 城市间最短路径 假设有\\(n\\)个城市，编号为\\(1,2,\\dots,n\\)。 已知其中的部分城市之间有高速公路连通， 每对连通城市记为\\((F_i, T_i)\\), 其中\\(F_i, T_i \\in \\{1,2,\\dots,n \\}\\)且\\(F_i &lt; T_i\\), \\(i=1,2,\\dots,m\\)。 除了这些直接连通的城市以外， 其它的任意两个城市只能途经别的城市连通， 或者根本不能靠高速公路连通。 用一个\\(m\\times 2\\)的R矩阵\\(M\\)可以输入这些连通情况， 矩阵的每行是一对\\((F_i, T_i)\\)值。 要求编写一个R函数， 输入直接连通情况\\(M\\)后， 输出一个\\(n \\times n\\)矩阵\\(R\\), R[i,i]=0, R[i,j]=1表示直接相连， R[i,j]=\\(k\\) (\\(k \\geq 2\\))表示城市i与城市j至少需要经过\\(k\\)段高速公路连通， R[i,j]=Inf表示城市i与城市j不能靠高速公路连通。 \\(R\\)的元素值仅考虑途经的高速公路段数而不考虑具体里程。 如果从一个城市通过高速公路移动到直接相连城市叫做移动一步， \\(R\\)的\\((i,j)\\)元素是从第\\(i\\)城市通过高速公路到第\\(j\\)城市需要移动的步数。 这个问题也可以作为“相识”问题的模型。 设\\(n\\)个人中有些人是直接相识的， 如果两个不相识的人想认识， 假设必须经过相识的人引荐， 问最少需要多少个引荐人。 本问题必须使用循环， 很难向量化，属于R比较不擅长的问题。 可以考虑使用Rcpp把程序用C++语言实现， 可以大大加速。 当然， 如果这个程序仅需要执行不多的次数， 用R就足够了。 43.3.2 Daubechies小波函数计算 这个例子主要展示了不用每次计算函数值而是尽可能从已经计算并储存的函数值中查找的技巧。 程序中用了比较多的循环， 如果有需要， 可考虑用Rcpp转换成C++代码以提高效率。 小波是重要数学工具, 在图像处理、信号处理等方面有广泛应用。 小波中一个重要的函数叫做尺度函数(scale function), 它满足所谓双尺度方程： \\[ \\phi (x) = \\sqrt{2} \\sum_k {h_k \\phi (2x - k)} \\] 一种特殊的尺度函数是只在有限区间上非零的, 叫做紧支集的。 紧支集尺度函数可以在给定\\(\\{h_k\\}\\)后用以下迭代公式生成： \\[ \\begin{aligned} \\eta _0 (x) =&amp; I_{[ - 0.5,0.5]} (x) \\\\ \\eta _{n + 1} (x) =&amp; \\sqrt 2 \\sum\\limits_{k = 0}^{2N - 1} {h_k \\eta _n (2x - k)} \\end{aligned} \\] 其中\\(N\\)是正整数, \\(N\\)=2时\\(h_0\\)=0.482962913145, \\(h_1\\)=0.836516303738, \\(h_2\\)=0.224143868042, \\(h_3=-0.129409522551\\)。 已知\\(\\phi(x)\\)的支集(不为零的区间)为\\([0,2N-1]\\), \\(\\eta_n(x)\\)的支集包含于\\([-0.5, 2N-1]\\)中。 任务： 编写计算\\(\\phi(x)\\)的R程序， 通过20次迭代计算， 输出\\(\\phi(x)\\)在\\([0,2N-1]\\)区间的256个等间隔点上的函数值并作图。 在迭代过程中， 应不重新结算函数格子点的值，仅计算新加入的格子点的值。 不要利用递归函数， 递归函数需要每次重新计算已经计算过的函数值。 43.3.3 房间加热温度变化 某个房屋带有天花板，天花板与屋顶之间有一定的空间。 用壁炉保持房间温度。 为了研究房间内与天花板上方的温度变化， 建立了如下的微分方程组： \\[ \\begin{aligned} \\frac{d x_1}{dt} =&amp; 0.35 \\left( -9.7 \\sin \\frac{(t+3)\\pi}{12} + 8.3 - x_1(t) \\right) + 0.46( x_2(t) - x_1(t) ) + 11.1 \\\\ \\frac{d x_2}{dt} =&amp; 0.28 \\left( -9.7 \\sin \\frac{(t+3)\\pi}{12} + 8.3 - x_2(t) \\right) + 0.46( x_1(t) - x_2(t) ) \\end{aligned} \\] 其中\\(x_1(t)\\)是房间在\\(t\\)时刻的温度（单位：摄氏度）， \\(x_2(t)\\)是天花板上方在\\(t\\)时刻的温度， \\(t\\)是单位为小时的时间。 设\\(t=0\\)时\\(x_1(t)=x_2(t)=4\\)， 用每一秒钟重新计算的方法计算24小时内的房间温度与天花板上温度， 绘图。 计算7天的温度， 查看周期性。 当温度循环变化差距小于0.05度时认为开始周期变化了。 43.4 统计计算 43.4.1 核回归与核密度估计 考虑核回归问题。核回归是非参数回归的一种, 假设变量\\(Y\\)与变量\\(X\\)之间的关系为： \\[ Y = f(X) + \\varepsilon \\] 其中函数\\(f\\)未知。 观测到X和Y的一组样本\\(X_i, Y_i\\), \\(i\\)=1,…,\\(n\\)后, 对\\(f\\)的一种估计为： \\[ \\hat f(x) = \\frac{\\sum\\limits_{i = 1}^n {K\\left( {\\frac{{x - X_i }}{h}} \\right)Y_i } } {\\sum\\limits_{i = 1}^n {K\\left( {\\frac{{x - X_i }}{h}} \\right)} } \\] 其中\\(h&gt;0\\)称为窗宽， 窗宽越大， 得到的密度估计越平滑。 \\(K\\)叫做核函数, 一般是一个非负的偶函数, 原点处的函数值最大, 在两侧迅速趋于零。 例如正态密度函数, 或所谓双三次函数核： \\[ K(x) = \\left\\{ {\\begin{array}{*{20}c} {\\left( {1 - \\left| x \\right|^3 } \\right)^3 } &amp; {\\left| x \\right| \\leq 1} \\\\ 0 &amp; \\mbox{其它} \\\\ \\end{array}} \\right. \\] 与核回归类似，可以用核平滑方法估计总体分布密度。 设样本为\\(Y_1, Y_2, \\dots, Y_n\\), 密度估计公式为 \\[ \\hat f(x) = \\frac{1}{n} \\sum\\limits_{i = 1}^n \\frac{1}{h} {K\\left( {\\frac{{x - Y_i }}{h}} \\right) } \\] 其中\\(K(x)\\)满足\\(\\int_{-\\infty}^\\infty K(x) \\,dx = 1\\)。 \\(h\\)是窗宽，窗宽越大， 估计的曲线越光滑。 \\(h\\)的一种建议公式为\\(h = 1.06 S n^{-1/5}\\), \\(S\\)为样本标准差。 对以上两个问题进行编程，其中窗宽\\(h\\)由用户输入。 43.4.2 二维随机模拟积分 设二元函数\\(f(x,y)\\)定义如下 \\[ \\begin{aligned} &amp; f(x,y) \\\\ =&amp; \\exp\\left\\{ -45(x + 0.4)^2 - 60(y-0.5)^2 \\right\\} \\\\ &amp; + 0.5 \\exp\\left\\{ -90(x-0.5)^2 - 45(y+0.1)^4 \\right\\} \\end{aligned} \\] (注意其中有一个4次方。) 求如下二重定积分 \\[ I = \\int_{-1}^1 \\int_{-1}^1 f(x,y) \\,dx\\,dy \\] \\(f(x,y)\\)有两个分别以\\((-0.4, 0.5)\\)和\\((0.5, -0.1)\\)为中心的峰， 对积分有贡献的区域主要集中在\\((-0.4,0.5)\\)和\\((0.5, -0.1)\\)附近， 在其他地方函数值很小，对积分贡献很小。 可以用随机模拟方法估计\\(I\\)的值。 第一种估计方法是平均值法。 设\\(X_i, i=1,2,\\dots, N\\)是均匀分布\\(U(-1,1)\\)的随机数， \\(Y_i, i=1,2,\\dots, N\\)也是均匀分布\\(U(-1,1)\\)的随机数， 两者独立，可估计\\(I\\)为 \\[ \\hat I_1 = \\frac{4}{N} \\sum_{i=1}^N f(X_i, Y_i). \\] 第二种估计方法是重要抽样法。 设正态分布\\(\\text{N}(\\mu, \\sigma^2)\\)的密度记为\\(p(x; \\mu, \\sigma^2)\\)， 令 \\[ \\begin{aligned} &amp; g(x,y) \\\\ =&amp; 0.5358984 p(x;-0.4,90^{-1}) p(y;0.5,120^{-1}) \\\\ &amp; + 0.4641016 p(x;0.5,180^{-1}) p(y;-0.1,20^{-1}), \\\\ &amp; -\\infty &lt; x &lt; \\infty, -\\infty &lt; y &lt; \\infty, \\end{aligned} \\] 这是一个二元随机向量的密度， 是两个二元正态密度的混合分布。 设\\(K_i, i=1,2,\\dots,N\\)是取值于\\(\\{1,2\\}\\)的随机数， \\(P(K_i = 1) = 0.5358984\\), \\(P(K_i = 2) = 1 - P(K_i = 1)\\)。 当\\(K_i=1\\)时，取\\(X_i\\)为N(\\(-0.4,90^{-1}\\))随机数， \\(Y_i\\)为N(\\(0.5,120^{-1}\\))随机数； 当\\(K_i=2\\)时，取\\(X_i\\)为N(\\(0.5,180^{-1}\\))随机数， \\(Y_i\\)为N(\\(-0.1,20^{-1}\\))随机数， 这样得到的\\((X_i, Y_i), i=1,2,\\dots,N\\)是\\(g(x,y)\\)的随机数。 令 \\[ \\hat I_2 = \\frac{1}{N} \\sum_{i=1}^n \\frac{f(X_i, Y_i)}{g(X_i, Y_i)}, \\] 称为\\(I\\)的重要抽样法估计。 43.4.2.1 编程任务 编写R函数估计计算\\(\\hat I_1\\)。 重复模拟\\(B=100\\)次， 得到\\(\\hat I_1\\)的\\(B\\)个值， 计算这些值的平均值和标准差。 编写R函数估计计算\\(\\hat I_2\\)。 重复模拟\\(B=100\\)次， 得到\\(\\hat I_2\\)的\\(B\\)个值， 计算这些值的平均值和标准差。 比较模拟得到的平均值和标准差， 验证两者是否基本一致， 通过标准差大小比较两种方法的精度。 注意尽量用向量化编程。 43.4.3 潜周期估计 设时间序列\\(\\{ y_t \\}\\)有如下模型: \\[ y_t = \\sum_{k=1}^m A_k \\cos(\\lambda_k t + \\phi_k) + x_t, \\ t=1,2,\\dots \\] 其中\\(x_t\\)为线性平稳时间序列， \\(\\lambda_k \\in (0,\\pi)\\), \\(k=1,2,\\dots,m\\)。 这样的模型称为潜周期模型。 如果有\\(\\{ y_t \\}\\)的一组样本\\(y_1, y_2, \\dots, y_n\\), 可以定义周期图函数 \\[ P(\\omega) = \\frac{1}{2\\pi n} \\left| \\sum_{t=1}^n y_t e^{-it\\omega} \\right|^2, \\ \\omega \\in [0, \\pi]. \\] 这里\\(\\omega\\)是角频率。 对于潜周期数据， 在\\(\\lambda_j\\)的对应位置\\(P(\\omega)\\)会有尖峰， 而且当\\(n\\to\\infty\\)时尖峰高度趋于无穷。 下面是一个样例图形。 如下算法可以在\\(n\\)较大时估计\\(m\\)和\\(\\{\\lambda_k \\}\\)： 首先，对\\(\\omega_j=\\pi j / n\\), \\(j=1,2,\\dots,n\\)计算\\(h_j = P(\\omega_j)\\)， 求\\(\\{ h_j, j=1,2,\\dots, n \\}\\)的3/4分位数记为\\(q\\)。 令\\(C = q n^{0.25}\\)，以\\(C\\)作为分界线， 设\\(\\{ h_j \\}\\)中大于\\(C\\)的下标\\(j\\)的集合为\\(J\\), 当\\(J\\)非空时，把\\(J\\)中相邻点分入一组， 但是当两个下标的差大于等于\\(n^{0.6}\\)时就把后一个点归入新的一组。 在每组中，以该组的\\(h_j\\)的最大值点对应的角频率\\(j \\pi / n\\)作为潜频率\\(\\{ \\lambda_k \\}\\)中的一个的估计。 用如下R程序可以模拟生成一组\\(\\{ y_t \\}\\)的观测数据: 编写R程序: 编写计算\\(P(\\omega)\\)的函数， 输入\\(\\boldsymbol y = (y_1, y_2, \\dots, y_n)^T\\) 和\\(\\boldsymbol\\omega = (\\omega_1, \\omega_2, \\dots, \\omega_s)^T\\), 输出\\((P(\\omega_1), P(\\omega_2), \\dots, P(\\omega_s))\\)。 对输入的时间序列样本\\(y_1, y_2, \\dots, y_n\\)， 编写函数用以上描述的算法估计\\(m\\)和\\(\\{ \\lambda_j, j=1,2,\\dots,m \\}\\)。 用上述模拟数据测试编写的算法程序。 进一步地，用R函数fft()计算\\(h_j=P(\\pi j / n), j=1,2,\\dots,n\\)。 把整个算法用Rcpp和C++程序实现。 43.4.4 ARMA(1,1)模型估计 考虑如下的零均值高斯ARMA(1,1)模型： \\[ X_t = a X_{t-1} + e_t + b e_{t-1}, t=1,2,\\dots,T \\] 其中\\(0 &lt; |a| &lt; 1\\), \\(0 &lt; |b| &lt; 1\\)， \\(-a \\neq b\\), \\(\\{ e_t \\}\\)独立同N(\\(0, \\sigma_e^2\\))分布。 给定观测\\(x_1, x_2, \\dots, x_T\\)， 写出在\\(x_0=0\\)且\\(e_0 = 0\\)条件下的条件对数似然函数。 编写R程序， 用条件最大似然估计方法估计参数\\(a, b, \\sigma_e^2\\)。 可使用数值优化程序如nlm()或optim()。 对\\(a=0.5\\), \\(b=0.7\\), \\(\\sigma_e=1\\)， \\(T=100\\), 模拟生成\\(x_t\\)的样本并重复模拟\\(B=1000\\)次， 据此评估\\(\\hat a, \\hat b, \\hat\\sigma_e\\)的估计精度。 模拟可使用R的arima.sim()函数。 若\\(x_0, e_0\\)已知，从\\(x_1, \\dots, x_T\\)可递推地计算 \\[ e_t = x_t - a x_{t-1} - b e_{t-1}, \\ t=1,2,\\dots, T \\] 记\\(\\boldsymbol{\\theta} = (a, b, \\sigma_e, x_0, e_0)^T\\)， 有\\(X_t | x_{t-1}, \\dots, x_1, \\boldsymbol{\\theta}\\)服从 N(\\(a x_{t-1} + b e_{t-1}, \\sigma_e^2\\))条件分布。 于是用联合密度的乘积公式可得 \\[\\begin{aligned} f(x_1, \\dots, x_T | \\boldsymbol{\\theta}) =&amp; f(x_1 | \\boldsymbol{\\theta}) f(x_2 | x_1, \\boldsymbol{\\theta}) \\dots f(x_T | X_{T-1}, \\dots, x_1, \\boldsymbol{\\theta}) \\\\ =&amp; \\prod_{t=1}^T \\text{dnorm}(x_t, a x_{t-1} + b e_{t-1}, \\sigma_e) \\\\ =&amp; \\prod_{t=1}^T (2\\pi)^{-1/2} \\sigma_e^{-1} \\exp\\left\\{ -\\frac12 \\frac{1}{\\sigma_e^2} (x_t - a x_{t-1} - b e_{t-1})^2 \\right\\} \\\\ =&amp; (2\\pi)^{-T/2} \\sigma_e^{-T} \\exp\\left\\{ -\\frac12 \\frac{1}{\\sigma_e^2} \\sum_{t=1}^T e_t^2 \\right\\} \\end{aligned}\\] 其中\\(\\text{dnorm}(x, \\mu, \\sigma)\\)表示N(\\(\\mu, \\sigma^2\\))的分布密度。 取\\(x_0=0, e_0=0\\)，给定\\(a, b\\)后递推计算\\(\\{ e_t \\}\\)序列， 对数似然函数为 \\[ l(a, b, \\sigma_e) = -T \\ln\\sigma_e - \\frac12 \\frac{1}{\\sigma_e^2} \\sum_{t=1}^T e_t^2 \\] 注意其中的\\(\\{e_t \\}\\)也与待估参数\\(a, b\\)有关。 可以用数值优化算法估计求如上的问题的最大值点。 显然\\(a, b\\)的最大值点不依赖于\\(\\sigma_e\\)的取值， 所以可以先求\\(\\sum_{t=1}^T e_t^2\\)的最小值点。 这基本是一个最小二乘估计问题， 但是\\(e_{t-1}\\)也依赖于\\(a, b\\)的值所以不能直接用线性最小二乘求解。 43.4.5 VAR模型平稳性 称\\(k\\)元时间序列\\(\\boldsymbol r_t\\)服从一个VAR(\\(p\\))模型， 如果 \\[\\begin{align} \\boldsymbol r_t = \\boldsymbol\\phi_0 + \\boldsymbol\\Phi_1 \\boldsymbol r_{t-1} + \\dots + \\boldsymbol\\Phi_p \\boldsymbol r_{t-p} + \\boldsymbol a_t \\tag{43.1} \\end{align}\\] 其中\\(\\boldsymbol\\phi_0\\)和\\(\\{ \\boldsymbol a_t \\}\\)同VAR(1)的规定， \\(\\boldsymbol\\Phi_j\\)是\\(k\\)阶方阵（\\(k=1,2,\\dots,p\\)）。 利用向后推移算子（滞后算子）\\(B\\)可以将模型写成 \\[\\begin{aligned} (\\boldsymbol I - \\boldsymbol\\Phi_1 B - \\dots - \\boldsymbol\\Phi_p B^p) \\boldsymbol r_t = \\boldsymbol\\phi_0 + \\boldsymbol a_t \\end{aligned}\\] 记 \\[\\begin{align} P(z) = \\boldsymbol I - \\boldsymbol\\Phi_1 z - \\dots - \\boldsymbol\\Phi_p z^p \\tag{43.2} \\end{align}\\] 这是一个从复数\\(z\\)到\\(k\\)阶方阵\\(P(z)\\)的变换， \\(P(z)\\)的每个元素是关于\\(z\\)的阶数不超过\\(p\\)的多项式。 称一元多项式函数\\(\\text{det}(P(z))\\)（或记为\\(|P(z)|\\)）为模型的（逆序）特征多项式。 如果\\(|P(z)| \\neq 0\\), \\(\\forall |z| &lt; 1\\)（\\(z\\)为复数）， 则模型(43.1)是平稳的。 编写R函数， 输入三维（三个下标）的系数矩阵数组arrcoef, 返回特征多项式的所有复根。 arrcoef[,,1]保存\\(\\boldsymbol\\Phi_1\\), arrcoef[,,2]保存\\(\\boldsymbol\\Phi_2\\), 等等。 作为例子， 考虑如下的三个模型，对每个计算特征多项式的复根并判断是否平稳： \\[\\begin{aligned} \\left(\\begin{array}{c} r_{1t} \\\\ r_{2t} \\end{array}\\right) =&amp; \\left(\\begin{array}{cc} 0.2 &amp; 0.3 \\\\ -0.6 &amp; 1.1 \\end{array}\\right) \\left(\\begin{array}{c} r_{1,t-1} \\\\ r_{2,t-1} \\end{array}\\right) + \\left(\\begin{array}{c} a_{1t} \\\\ a_{2t} \\end{array}\\right) \\end{aligned}\\] \\[\\begin{aligned} \\left(\\begin{array}{c} x_{1t} \\\\ x_{2t} \\end{array}\\right) = \\left(\\begin{array}{cc} 0.5 &amp; -1.0 \\\\ -0.25 &amp; 0.5 \\end{array}\\right) \\left(\\begin{array}{c} x_{1,t-1} \\\\ x_{2,t-1} \\end{array}\\right) + \\left(\\begin{array}{c} a_{1t} \\\\ a_{2t} \\end{array}\\right) \\end{aligned}\\] \\[\\begin{aligned} \\boldsymbol r_t =&amp; \\left(\\begin{array}{rrr} 0.39 &amp; 0.10 &amp; 0.05 \\\\ 0.35 &amp; 0.34 &amp; 0.47 \\\\ 0.49 &amp; 0.24 &amp; 0.24 \\end{array}\\right) \\boldsymbol r_{t-1} + \\left(\\begin{array}{rrr} 0.06 &amp; 0.11 &amp; 0.02 \\\\ -0.19 &amp; -0.18 &amp; -0.01 \\\\ -0.31 &amp; -0.13 &amp; 0.09 \\end{array}\\right) \\boldsymbol r_{t-2} + \\boldsymbol a_t \\end{aligned}\\] 43.4.6 贮存可靠性评估 设某种设备的贮存寿命为随机变量\\(X\\), 服从指数分布Exp(\\(\\theta\\)), \\(E X = \\theta &gt; 0\\)。 假设有\\(n\\)台此种设备分别在时间\\(t_1, t_2, \\dots, t_n\\)进行了试验， 第\\(i\\)台试验成功用\\(\\delta_i=1\\)表示， 试验失效用\\(\\delta_i=0\\)表示。把\\(n\\)次试验的结果写成 \\[ Z_n = \\left(\\begin{array}{cc} t_1 &amp; \\delta_1 \\\\ t_2 &amp; \\delta_2 \\\\ \\vdots &amp; \\vdots \\\\ t_n &amp; \\delta_n \\end{array}\\right) \\tag{1} \\] 这里\\(\\delta_1, \\delta_2, \\dots, \\delta_n\\)认为是随机变量， \\(t_1, t_2, \\dots, t_n\\)是固定的时间。 \\(\\delta_i\\)服从两点分布\\(\\text{B}(1, \\exp(-t_i / \\theta))\\)。 \\(Z_n\\)取某个特定组合的概率为 \\[ P(Z_n) = \\prod_{i=1}^n \\left\\{ \\left[ \\exp(-t_i / \\theta) \\right]^{\\delta_i} \\left[ 1 - \\exp(-t_i / \\theta) \\right]^{1 - \\delta_i} \\right\\}. \\tag{2} \\] 要利用观测数据\\(Z_n\\)估计\\(\\theta\\)的置信度为\\(1-\\alpha\\)的置信下限， 可以用陈家鼎《生存分析与可靠性》中的样本空间排序法。 注意到\\(Z_n\\)中每个\\(\\delta_i\\)可以取1或0， 所以\\(Z_n\\)的所有不同取值共有\\(2^n\\)个， 记这些所有不同取值为\\(\\mathcal D\\)， 在\\(\\mathcal D\\)中定义如下的序： 设\\(Z_n&#39;\\)与\\(Z_n\\)都是\\(\\mathcal D\\)中的试验结果， 称\\(Z_n&#39;\\)不次于\\(Z_n\\), 并记作\\(Z_n&#39; \\gtrsim Z_n\\)， 如果如下两个条件之一成立： \\(\\sum_{i=1}^n \\delta_i&#39; &gt; \\sum_{i=1}^n \\delta_i\\); \\(\\sum_{i=1}^n \\delta_i&#39; = \\sum_{i=1}^n \\delta_i\\), 但\\(\\sum_{i=1}^n \\delta_i&#39; t_i \\geq \\sum_{i=1}^n \\delta_i t_i\\). 记 \\[ G(\\theta) = \\sum_{Z_n&#39; \\gtrsim Z_n} P_\\theta(Z_n&#39;) = \\sum_{Z_n&#39; \\gtrsim Z_n} \\prod_{i=1}^n \\left\\{ \\left[ \\exp(-t_i / \\theta) \\right]^{\\delta_i&#39;} \\left[ 1 - \\exp(-t_i / \\theta) \\right]^{1 - \\delta_i&#39;} \\right\\}. \\tag{3} \\] 这是\\(\\theta\\)的严格单调增函数， 求解如下的方程 \\[ G(\\theta) - \\alpha = 0 \\tag{4} \\] 得到解\\(\\underline{\\theta}\\)是\\(\\theta\\) 的置信度为\\(1-\\alpha\\)的置信下限。 当所有\\(n\\)次试验都失效时， 恒有\\(G(\\theta)=1\\), 方程(4)无解， 取\\(\\underline{\\theta}=0\\)。 当\\(n\\)次试验都没有失效， 即失效数\\(n - \\sum_{i=1}^n \\delta_i = 0\\)时, 方程为 \\[ \\exp \\left( -\\frac{1}{\\theta} \\sum_{i=1}^n t_i \\right) - \\alpha = 0, \\] 解得 \\[ \\underline{\\theta} = \\frac{\\sum_{i=1}^n t_i}{\\ln \\frac{1}{\\alpha}} . \\] 当失效数为1时，最多仅有\\(n\\)个结果不次于\\(Z_n\\)， 很容易可以计算\\(G(\\theta)\\)的值。 在\\(n\\)较大而且\\(Z_n\\)中失效数较多时， \\(G(\\theta)\\)的求和(3)中项数很多，计算量很大。 当\\(n=10\\)时，\\(\\mathcal D\\)约有一千项， 当\\(n=20\\)时，\\(\\mathcal D\\)约有一百万项， 还在可以穷举计算的范围内。 但是，当\\(n \\geq 30\\)时， \\(\\mathcal D\\)就有10亿项， 每计算一次\\(G(\\theta)\\)都需要很长时间。 针对\\(n\\)不太大的情形， 可以用精确的公式(3)计算\\(G(\\theta)\\) 并用(4)求解\\(\\underline{\\theta}\\)， 编写这个问题的纯R程序版本， 输入一组\\(Z_n\\)值后（包括试验时间和试验结果）， 输出用(3)和(4)求解\\(\\underline{\\theta}\\)得到的置信下限\\(\\underline{\\theta}\\)的值。 在文件store-reliab-data.csv中已经生成了10组模拟数据， 对这10组模拟数据计算相应的\\(\\underline{\\theta}\\)的值。 在此数据文件中，testid相同的行属于同一次试验的不同设备的时间和结果。 这个程序中用到比较多的循环， 考虑把主要计算部分用Rcpp包和C++代码实现， 看能够提高效率多少倍。 另一种计算\\(G(\\theta)\\)的方法是用随机模拟方法估计 \\(G(\\theta)\\)的值然后求解(4)。 随机模拟方法计算简单而且不受失效个数多少的影响， 但是有随机误差，在求解(4)要考虑到随机误差的影响。 随机模拟方法如下。 取模拟次数\\(N\\), 对给定\\(\\theta\\)， 为了计算\\(G(\\theta)\\)， 模拟生成\\(N\\)组独立的寿命 \\((X_1^{(i)}, X_2^{(i)}, \\dots, X_n^{(i)})\\), \\(i=1,2,\\dots,N\\)， 其中每个\\(X_j^{(i)}\\)服从Exp(\\(\\theta\\))分布， 各分量相互独立。 计算\\(\\delta_j^{(i)} = I_{\\{ X_j^{(i)} &gt; t_j \\}}\\), 记 \\[ Z_n^{(i)} = \\left(\\begin{array}{cc} t_1 &amp; \\delta_1^{(i)} \\\\ t_2 &amp; \\delta_2^{(i)} \\\\ \\vdots &amp; \\vdots \\\\ t_n &amp; \\delta_n^{(i)} \\end{array}\\right) \\] 用 \\[ \\frac{1}{N} \\sum_{i=1}^N I_{\\{ Z_n^{(i)} \\gtrsim Z_n \\}} \\] 来估计\\(G(\\theta)\\)。 43.5 数据处理 43.5.1 小题分题型分数汇总 考虑中学某科的一次考试， 考卷各小题小题情况汇总在如下的用逗号符分隔的文本文件subscore-subtype.csv中: 序号,题型 1,选择题 2,选择题 3,选择题 4,选择题 5,选择题 6,选择题 7,选择题 8,选择题 9,选择题 10,选择题 11,简答题 12,简答题 13,填空题 14,简答题 15,简答题 16,简答题 17,简答题 18,写作 读入此数据为R数据框，只要用如下程序: dm &lt;- read.csv(&#39;subscore-subtype.csv&#39;, header=TRUE, stringsAsFactors=FALSE) 结果显示如下: knitr::kable(dm) 序号 题型 1 选择题 2 选择题 3 选择题 4 选择题 5 选择题 6 选择题 7 选择题 8 选择题 9 选择题 10 选择题 11 简答题 12 简答题 13 填空题 14 简答题 15 简答题 16 简答题 17 简答题 18 写作 设部分学生的小题分录入到如下的用逗号分隔的文本文件 subscore-subscore.csv中: 学号,Y1,Y2,Y3,Y4,Y5,Y6,Y7,Y8,Y9,Y10,Y11,Y12,Y13,Y14,Y15,Y16,Y17,Y18 1138010104,3,3,3,3,0,3,7.5,2.5,3.5,6,5,4,2.5,5.5,0,4,2,45.5 1138010108,3,0,3,0,3,0,6,3,4,4,2,5,2,5,6,4,2,48.5 1138010114,3,3,3,3,0,3,5.5,3.5,4,6,2,5,2,5.5,6,1,2,44.5 1138010128,3,3,3,0,0,0,8.5,3.5,2.5,4,5,5,0,4.5,6,4,2,45 1138010126,3,3,3,3,3,3,7,0,4,6,5,5,2.5,4.5,6,4.5,2,44 用如下R程序读入小题分数据为R数据框: ds &lt;- read.csv(&#39;subscore-subscore.csv&#39;, header=TRUE, stringsAsFactors=FALSE) 结果显示如下: knitr::kable(ds) 学号 Y1 Y2 Y3 Y4 Y5 Y6 Y7 Y8 Y9 Y10 Y11 Y12 Y13 Y14 Y15 Y16 Y17 Y18 1138010104 3 3 3 3 0 3 7.5 2.5 3.5 6 5 4 2.5 5.5 0 4.0 2 45.5 1138010108 3 0 3 0 3 0 6.0 3.0 4.0 4 2 5 2.0 5.0 6 4.0 2 48.5 1138010114 3 3 3 3 0 3 5.5 3.5 4.0 6 2 5 2.0 5.5 6 1.0 2 44.5 1138010128 3 3 3 0 0 0 8.5 3.5 2.5 4 5 5 0.0 4.5 6 4.0 2 45.0 1138010126 3 3 3 3 3 3 7.0 0.0 4.0 6 5 5 2.5 4.5 6 4.5 2 44.0 在数据框dm中有每个小题的题型信息， 在数据框ds中有每个学生的每个小题的分数。 从这两个数据框， 汇总计算每个学生的题型分， 即每个学生选择题共考多少分，简答题共考多少分， 等等。 要注意的是， 最终的程序应该写成一个函数， 其中的计算不依赖于具体的题型名称、小题个数、小题与题型如何对应， 只要输入dm和ds两个数据框就可以进行统计。 如果没有这样的通用性要求， 这个问题就可以这样简单解决： resm &lt;- data.frame( &#39;学号&#39;=ds[,&#39;学号&#39;], &#39;选择题&#39;= rowSums(ds[, paste(&#39;Y&#39;, 1:10, sep=&#39;&#39;)]), &#39;简答题&#39;=rowSums(ds[,paste(&#39;Y&#39;, c(11,12,14:17), sep=&#39;&#39; )]), &#39;填空题&#39;=ds[,&#39;Y13&#39;], &#39;作文&#39;=ds[,&#39;Y18&#39;] ) knitr::kable(resm[order(resm[,&#39;学号&#39;]),], row.names=FALSE) 学号 选择题 简答题 填空题 作文 1138010104 34.5 20.5 2.5 45.5 1138010108 26.0 24.0 2.0 48.5 1138010114 34.0 21.5 2.0 44.5 1138010126 35.0 27.0 2.5 44.0 1138010128 27.5 26.5 0.0 45.0 但是， 我们要求最后的函数在允许修改小题类型、试卷中小题个数、各小题的类型、学生分数数据的条件下也能正常工作。 43.5.2 类别编号重排 设聚类分析对若干个样本点聚成了3类， 结果如下： dc0 &lt;- tibble::tibble( obs = 1:10, g = c(3, 1, 3, 1, 2, 2, 1, 3, 3, 1) ) knitr::kable(dc0) obs g 1 3 2 1 3 3 4 1 5 2 6 2 7 1 8 3 9 3 10 1 这些类别的次序并没有意义， 重新聚类可能会将类别标签打乱重排但类别组成不变。 所以， 需要人为地指定合适的类别标签。 设对每个类进行概括统计得到了有代表性的统计量，结果如下： dcstat &lt;- tibble::tibble( g = 1:3, stat=c(2.3, 1.1, 3.0) ) knitr::kable(dcstat) g stat 1 2.3 2 1.1 3 3.0 按照统计量从大到小的次序重排3个组， 得到新的分组： g stat ng 3 3.0 1 1 2.3 2 2 1.1 3 将原始观测添加新的分组标签ng， 并按ng排列， 结果为： obs g ng 1 3 1 3 3 1 8 3 1 9 3 1 2 1 2 4 1 2 7 1 2 10 1 2 5 2 3 6 2 3 输入dc0和dcstat数据框， 如何用程序解决上述问题？ 43.6 文本处理 43.6.1 用R语言下载处理《红楼梦》htm文件 网上许多资源是html格式的文本文件。 比如， 《红楼梦》在许多网站可以浏览， 是在浏览器中按章节浏览。 我们希望将其下载到本地， 并转换为txt格式， 在手机或者电纸书阅读器中阅读。 这个任务涉及到R的文件访问， 字符型连接， 正则表达式， 中文编码问题。 设下载网站主页是 http://www.xiexingcun.net/hongloumeng/index.html， 各个章节的文件名是01.htm到99.htm， 100.htm到120.htm。 已下载的文件在如下链接中：hongloumeng.zip 将这些文件转换成txt格式， 然后合并成一个txt文件。 要求： 每一段仅用一行，中间不换行； 不同段落之间用换行分开； 每一回目开始有回目标题， 标题前后空行，标题格式为“第xxX回 标题内容”。 "],["references.html", "References", " References "]]
